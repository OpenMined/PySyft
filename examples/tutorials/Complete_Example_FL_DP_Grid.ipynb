{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVyabxJLuQ79"
   },
   "source": [
    "# Train an Image-Classifier using Federated Learning with Differential Privacy\n",
    "## A complete End-to-End Real World Example - PySyft, PyGrid\n",
    "* This tutorial aims at demonstrating a high level of privacy using **Secured Federated Learning** and **Differential Privacy based on the Laplace-Mechanism** as part of the **PATE framework**. To tackle a problem similair to a real-world-problem, yet still using a well explored example (the privacy tools are of main interest in this tutorial) it was chosen to train an Image-Classifier on the **[Cifar-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)**. In the [original paper on the PATE framework](https://arxiv.org/pdf/1610.05755.pdf), simpler problems such as training a classifier on MNIST and SVHN were tackled.\n",
    "* Containing 60000 32x32 pixels coloured images of 10 different classes (airplanes, birds, etc.) this should showcase a reasonably similair task to another real-world example such as the training of a classifier for skin-cancer-classification, which heavily relies on sensitive private data. See [Stanford's Skin Cancer Classification with Deep Learning](https://cs.stanford.edu/people/esteva/nature/) for more information on this specific example.\n",
    "* To be able to give a complete end-to-end example the goal is to also use PyGrid to build a peer-to-peer network which should be used as basis for a coordination of the workers. \n",
    "* Besides a tutorial this should also serve as good testing ground for the *\"production-readyness\"* of PySyft and PyGrid. (Speed, Accuracy, etc.)\n",
    "\n",
    "### Specific Situation - Real-World-Scenario: \n",
    "To make the example as close to a real world production use-case and to best give a quick overview over the PATE framework for DP along with FL, we define a simple usecase along three different parties taking part in this setup. <br>\n",
    "**We will assume the role of the model provider who also coordinates the procedure given the following parties.** One can imagine that requests from both model providers and data providers can lead to the initiation of the proecss given a neutral party which coordinates the procedure in the future (See *Shortcomings* Section)\n",
    "  1. **Data Provider:** Owns personal sensitive data. **E.g.:** in this case some photographers who all made pictures of some objects in real life and sorted them (into the ten classes for this examle). His/her goal is to either *create/train a classifier* which automates the sorting of the images for him/her or to *participate in creating a general image classifier which can recognize objects on images in general*. Possibly he/she also wants somebody to *host the classifier to speed up inference time*. \n",
    "  2. **Model Provider:** Creates the model, in this case the classifier-model. His/her goal is to use his model-architecture and train it on the photographers (Data Provider) personal data and to then make this trained model available to a broad range of user. \n",
    "  3. **Hosting Provider:** Provides computing ressources along possible hosting capabilities. His/her goal is to provide the Data and Model Provider with the neccessary computing power for training and hosting capabilities for deployment. \n",
    "  * **How is this example representative for the need/usage of privacy preserving ML?**\n",
    "    This example portrays some of the key characteristics of privacy-preserving ML. \n",
    "      * **Combining Knowledge:** A single photographer wouldn't provide enough data to train a good image classifier and wouldn't have the knowledge to build a classifier. Together with different other (possibly even competing photographers) and a model provider he can train a good model together with the other parties. \n",
    "      * **Federated Learning:** He doesn't want his sorted photographs to be accessable by either the other competing photographers or the model creator. (He wants to sell his photographs)\n",
    "      * **Differential Privacy:** Classifiers as ML-Models in general can memorize specific parts of the training data, making it possible to retrieve information about the training data (or even parts of some datapoints). In this case the photographer doesn't want users of the classifier (e.g.: the competing photographers) to be able to retrieve information about his unique way of photograhping (e.g.: key motives, etc.)  \n",
    "      * *All the above points are also exactly the critical points when trainng a classifier e.g. on a skin-cancer dataset.*\n",
    "\n",
    "### The PP-techniques that will be used here:\n",
    "* **FL** - Federated Learning: We will be using **SMPC-Encrypted Federated Learning** *(For a quick overview see below)*\n",
    "* **DP** - Differential Privacy: We will be using the **Laplace-Mechanism** as part of the \"noisy voting\" in the PATE procedure *(More information below)*\n",
    "\n",
    "\n",
    "### The PP-tools that will be used here: TO BE UPDATE \n",
    "* **PySyft**\n",
    "  * Plans (NOT YET: Currently can't be usefully applied with this setting, see *Shortcomings*)\n",
    "  * Protocols (NOT YET: Currently can't be usefully applied with this setting, see *Shortcomings*)\n",
    "  * VirtualWorkers\n",
    "* **PyGrid** \n",
    "  * Gateway (To come)\n",
    "  * GridNode (To come)\n",
    "  \n",
    "**TODO: CHECK SPECIFIC TYPES AND IN WHICH LIBRARIES THEY ARE! (Apparently currently changing)**\n",
    "\n",
    "Author:\n",
    "- Nicolas Remerscheid - GitHub: [@NiWaRe](https://github.com/NiWaRe)\n",
    "\n",
    "References: \n",
    "*This example/usecase partly uses code from previous tutorials on PySyft and PyGrid and the Udacity Tutorial on Cifar10-Image-Classification (Part of the Deep Learning Nanodegree):* \n",
    "- Andrew Trask: DP and PATE Explanation part of [the Udacity Private AI Course](https://www.udacity.com/course/secure-and-private-ai--ud185) \n",
    "- Théo Ryffel: The general PySyft Tutorial Series, notably [Part 12 - Encrypted MNIST](https://github.com/OpenMined/PySyft/blob/master/examples/tutorials/Part%2012%20bis%20-%20Encrypted%20Training%20on%20MNIST.ipynb)\n",
    "- [Udacity's Cifar 10 Notebook](https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks/cifar-cnn/cifar10_cnn_solution.ipynb)\n",
    "\n",
    " \n",
    "***TODO: LINK SPECIFIC LEARNING MATERIALS AS PREREQUESITS.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dnwbloHjuQ7-"
   },
   "source": [
    "# The PATE Framework\n",
    "## The assumptions \n",
    "Introduced in [this paper](https://arxiv.org/pdf/1610.05755.pdf) the *Private Aggregation of Teacher\n",
    "Ensembles* (PATE) framework consists of the following basic setup. <br>\n",
    "**Before:** It is important to note that the PATE framework assumes a certain situation: \n",
    "* **Discrete Model Output:** The PATE framework (acoording to the original paper) assumes that a model should be trained that has a discrete output i.e. it categorizes or classifies some input into categories. In this case this is an image-classifier. \n",
    "* **Data structure:** The PATE framework assumes that the following data exists and is stored in the following way:\n",
    "  * **Private Data:** The private data is stored on multiple workers (photographers here) The private data is *labeled* and each worker has *different datapoints* (different photographs). Furthermore the private data isn't sufficient to train a good classifier alone.  \n",
    "  * **Public Data:** In addition to the private data PATE assumes that there exists a second larger dataset of *unlabeled, public and unsensitive* images. In this case for example this could be very large database of pictures from various newspapers. They aren't labeled and everybody can access them since the newspapers decided to share them (e.g.: they don't sell them directly)\n",
    "* **Semi-Supervised Learning:** Given the particular datasets that are given PATE assumes that we want to leverage smaller labeled datasets (normally used for supervised learning) together with an unlabeled dataset (normally used for unsupervised learning) to train a final model, meaning we want to train it using semi-supervised learning. \n",
    "\n",
    "\n",
    "## The procedure\n",
    "(For more info see in the learning material section above, notably Andrew Trask's tutorial) <br>\n",
    "This image shows an overview over the procedure: (from the [the original paper](https://arxiv.org/pdf/1610.05755.pdf))\n",
    "<img src=\"./material/PATE_framework_overview_from_paper.png\" width=\"600\">\n",
    "\n",
    "1. STEP: **Multiple Teacher-Models are trained on each of the private datasets**\n",
    "  * This is also where we want to use **Federated Learning** to not *directly* access the data at all. To make sure that the photographers don't see the model of the model provider (he/she sells that) we'll be encrypting both the model and the data via Additive Secret Sharing using Secure Multi-Party Computing (SMPC). \n",
    "2. STEP: **For each unlabeled datapoint in the public dataset teacher-models jointly predict a label**\n",
    "  * This is where noise is added for **Differential Privacy**. \n",
    "3. STEP: **One Student-Model is trained on the newly labeled public dataset**\n",
    "  * This is where **the final model** is created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STxuhaHOuQ7_"
   },
   "source": [
    "#  Setting Up (No Grid yet)  !CHECK NEEDED!\n",
    "## Motivation/Explanation of the approach for the PATE Setup \n",
    "Ideally we would like to initiate a PATE procedure which is coordinated completely automatically given some existing workers (which could be searched for with the grid infrastructure) To achieve that we would need to assume the role of a neutral party which can remotely coordinate the process. <br> \n",
    "To date certain features don't exist to fully coordinate everything coordinately:  (more in *Shortcomings*) \n",
    "* ReLUs, Maxpool, etc. which are one of the most used functions in DNNs can only be computed encrypted on **2 workers** (based on the current implementation of the crypto-protocls [secureNN](https://www.microsoft.com/en-us/research/publication/securenn-efficient-and-private-neural-network-training/) and the SPDZ protocol for adding, mm)\n",
    "* There is no possibility to `remote_share()` remotely encrypted a tensor which is stored on another machine. <br>(***TODO: Check if solvable***)\n",
    "For setting up the PATE-Scenario as described above we assume that the data from the data providers and the model from the model provider are distributed for encryption (SMPC) <br>\n",
    "Despite the given constraints the goal is to make the PATE procedure as realistic as possible: \n",
    "* For SMPC **\"Hosting Groups\"** consisting of 2 workers are created, one for each teacher. The idea is that only one hosting_group consisting of 2 workers is not powerful enough to host the potentially parallel (goal for the future) training of all the different teacher-models. To guarantee that the two workers don't work together for decryption of either the model or some dataset all the groups consist of a teacher (with his dataset) and the student. <br> In the future the goal is to dynamically host additional neutral workers from a third-party provider to support the computation if necessary. \n",
    "* *For now* the training of the student-models and the labeling of the student dataset through the noisy voting process happen both in **sequential order** \n",
    "* *For now* **no plans or protocols** were implemented for further automation of the procedure, because no alternative for a remote encryption (remote-share) was found. This would be needed e.g. to move the public dataset from hosting group to hosting group automatically to gather the teacher predictions (remote_share() from model provider, after first prediction remote_get() and again remote_share to next hosting group)\n",
    "    * Nevertheless **the future goal** is to be able to create a completely automated PATE-protocol which only needs to be provided with the participating parties. (teachers, students + *dynamic task-based number of external hosting-workers* )\n",
    "* *For now* **usage of the grid** (actual workers with a Public or Private Grid) as an added first step for finding of the correct workers to initiate a PATE-procedure. Whith the search functionality data-tags can be searched for and the corresponding workers (potential teachers) can be found (location attribute) The remaining procedure stays the same as with VirtualWorkers and without gateway.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "jMik5JqKuTLW",
    "outputId": "cf7c22cc-ba1c-4a60-f432-40b5815af671"
   },
   "outputs": [],
   "source": [
    "!pip install syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_P9Po8IquQ8A"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import syft as sy \n",
    "from copy import deepcopy\n",
    "\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DjFvC12IuQ8D"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding (Copied from @laRiffle Part 12)\n",
    "def one_hot_of(index_tensor):\n",
    "        \"\"\"\n",
    "        Transform to one hot tensor\n",
    "        \n",
    "        Example:\n",
    "            [0, 3, 9]\n",
    "            =>\n",
    "            [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "             [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]\n",
    "            \n",
    "        \"\"\"\n",
    "        onehot_tensor = torch.zeros(*index_tensor.shape, 10) # 10 classes for Cifar10\n",
    "        onehot_tensor = onehot_tensor.scatter(1, index_tensor.view(-1, 1), 1)\n",
    "        return onehot_tensor\n",
    "    \n",
    "# TODO: If we want to automated protocoll, we need to assume the role of a neutral instance which means we need \n",
    "#       a way to remotely share data \n",
    "def remote_share():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-JbPNLkuQ8H"
   },
   "outputs": [],
   "source": [
    "## SIMPLE VERSION ##\n",
    " \n",
    "# TODO: Change explanation: Everything could be executed by neutral player except model distribution \n",
    "#       and encryption and training (remote training job and remote_share haven't been implemented for now)\n",
    "#       For the other tasks the usage of plans doesn't make sense (as seen in notes on iPAD!)\n",
    "\n",
    "###################\n",
    "# WORKER CREATION #\n",
    "###################\n",
    "\n",
    "# TODO: Extend to be a central worker creation function (introduce variable grid=False)\n",
    "#       to choose between creating actual grid workers or VirtualWorkers. \n",
    "def CREATE_V_WORKERS(w_number, w_name):\n",
    "    \"\"\"\n",
    "        Create multiple, named virtual workers\n",
    "        \n",
    "        Args:\n",
    "            w_number - number of workers to be created \n",
    "            w_name - name of worker group \n",
    "            \n",
    "        Return:\n",
    "            array of the workers \n",
    "    \"\"\"\n",
    "    worker = []\n",
    "    for i in range(w_number):\n",
    "        worker.append(sy.VirtualWorker(hook, id=w_name+str(i)))\n",
    "    if len(worker) == 1: \n",
    "        worker = worker[0]\n",
    "    return worker\n",
    "\n",
    "# NOT USED YET \n",
    "# TODO: Find heuristic to estimate training effort. (Potentially also take in other arguments)\n",
    "# TODO: Potentially also consider prediction of public dataset (if public dataset is large)\n",
    "#       Normally the forward pass for the student dataset labeling is comparable small to training n-teacher-models\n",
    "def ASSESS_COMP_EFFORD(size_model, size_teacher_ds, size_student_ds):\n",
    "    \"\"\"\n",
    "        This function takes in the number of params of the model to be trained, the average size of the teacher\n",
    "        datasets and the size of the student dataset. It then estimates the total amount of work necessary for \n",
    "        the PATE process using some metric. ...\n",
    "    \"\"\"\n",
    "    comp_effort = 0 \n",
    "    return comp_effort\n",
    "\n",
    "\n",
    "# TODO: Potentially only take in teachers and students (from which the model and the dataset can be taken)\n",
    "def CREATE_HOSTING_GROUPS(teachers, student, model=None, datatest=None, configs=None): \n",
    "    \"\"\"\n",
    "        This function creates and returns worker hosting groups for hosting the models and the data in a \n",
    "        SMPC-Encrypted way to then later use those for PATE process. If needed it dynamically adds hosts based \n",
    "        on the computational ressources of the workers and the assessed computational effort. \n",
    "        \n",
    "        Args: \n",
    "            teachers - Array of the teacher workers\n",
    "            student - Single worker \n",
    "            model - The model to be used for student and teachers \n",
    "            dataset - The data used\n",
    "            configs - Dict with user specified configs (speed of procedure, etc.) for determining extra hosting\n",
    "        \n",
    "        Return: \n",
    "            Array of different hosting groups (also arrays)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create Groups based on two criteria: \n",
    "    # 1. Partners shouldn't be likely to collaborate for security reasons => Model-Owner and Data-Owner\n",
    "    # 2. Enough computational ressources, otherwise additional hosting workers are created. \n",
    "    \n",
    "    # TODO: Get comp. ressources of teachers and workers (For now: just set to 100)\n",
    "    comp_res = {teacher.id:100 for teacher in teachers}\n",
    "    comp_res[student.id] = 100\n",
    "    \n",
    "    # TODO: Get comp ressources from host from config file\n",
    "    host_comp_res = 20\n",
    "    \n",
    "    # TODO: Get model and the datasets from the students and the teachers and calc numb_params and size of datasets\n",
    "    # Get computational effort for task \n",
    "    comp_eff = ASSESS_COMP_EFFORD(0, 0, 0)\n",
    "    \n",
    "    # Create hosting groups (teacher always first, student always second)\n",
    "    # TODO: Maybe use dicts instead of ordering \n",
    "    hosting_groups = []\n",
    "    for teacher in teachers: \n",
    "        comp_diff = comp_res[teacher.id] + comp_res[student.id] - comp_eff\n",
    "        if comp_diff >= 0: \n",
    "            hosting_groups.append([teacher, student])\n",
    "        else: \n",
    "            # TODO: Dynamic adding of extra hosting providers only possible if secureNN with more than 2\n",
    "            #       participants is possible\n",
    "            required_extra = np.ceil(comp_diff / host_comp_res)\n",
    "            extra_hosts = CREATE_V_WORKERS(required_extra, \"hosting_providers\")\n",
    "            hosting_groups.append([teacher, student] + extra_hosts)\n",
    "            \n",
    "    return hosting_groups\n",
    "    \n",
    "    \n",
    "##################### \n",
    "# Data Distribution #\n",
    "#####################\n",
    " \n",
    "# This could be done client-side from the data-providers in a real scenario \n",
    "# (Or could be initiated automatically by some protocol)\n",
    "\n",
    "# TODO: Think about doing batching on device, having only one pointer to dataloader \n",
    "#       Could decrease communication complexity (Check how FederatedDataset Tut did that)\n",
    "def SIMPLE_PATE_SETUP(hosting_groups, dataset, batch_size, crypto_provider, ratio=0.4, extra_public_ds=False):\n",
    "    \"\"\"\n",
    "        Given the current implementation of secureNN Model-Encryption via SMPC only two hosts are possible.\n",
    "        This function securely (SMPC) distributes a single dataset equally across different given \n",
    "        hosting groups. \n",
    "        \n",
    "        The function takes an array of hosting groups (a hosting group is an array in the following order: \n",
    "        [teacher, student, possibly extra hosting workers]), a dataset, a batch_size, a crypto_provider and a ratio \n",
    "        which determines how much of the provided data should be regarded as private teacher data and how much \n",
    "        as public student data.\n",
    "        \n",
    "        If wanted the user can decide to pass in only the private dataset (setting extra_public_ds=True) \n",
    "        and send the public dataset himself to the student. (If for example the user wishes to take data \n",
    "        from another distribution for the public dataset)\n",
    "        \n",
    "        Args: \n",
    "            hosting_groups - Array of different worker groups (also array)\n",
    "            dataset - Dataset to be used by torch.utils.data.DataLoader\n",
    "            batch_size, crypto_provider - Self Explanatory \n",
    "            ratio - e.g.: 0.4 -> 40% of the total data wil be stored on teachers as sensitive data \n",
    "                    the rest on the student \n",
    "            extra_public_ds - If True the user can create a public dataset for the student from another dataset \n",
    "                              If e.g. tests want to be made where public data is of different distribution \n",
    "            \n",
    "        Return: \n",
    "            dist_dataset_teachers - Dict, keys are the teacher.id, values are (inp, target) batches stored as arrays\n",
    "            dist_dataset_student - Array of (inp) batches \n",
    "    \"\"\"\n",
    "    # No differentiation between training and testing is made, \n",
    "    # because in reality the data providers won't have the data seperated for ML \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    numb_teachers = len(hosting_groups)\n",
    "    # increment = len(dataset) / numb_teachers\n",
    "    # Student is stored in any group, second place \n",
    "    student = hosting_groups[0][1]\n",
    "\n",
    "    # Directly store (input, target) pairs as an array to enumerate over them -> use as dataLoader over PTRs\n",
    "    # Create dict of teacher pointer arrays, helpful for training afterwards \n",
    "    dist_dataset_teachers = {}\n",
    "    # Instantiate to be able to use .append() in main loop afterwards \n",
    "    for hosting in hosting_groups: \n",
    "        # The teacher is always stored first in hosting group\n",
    "        current_teacher = hosting[0]\n",
    "        dist_dataset_teachers[current_teacher.id] = []\n",
    "    dist_dataset_student = []\n",
    "    \n",
    "    for i, (data, target) in enumerate(dataloader):\n",
    "        # Teachers: The first 40% (normally less than on public) of the data\n",
    "        current_group = hosting_groups[i%numb_teachers]\n",
    "        current_teacher = current_group[0]\n",
    "        # TODO: Make faster and using index arrays directly split data and share only once \n",
    "        if i < int(ratio * (len(dataset)/batch_size)):\n",
    "            ### PySyft ###\n",
    "            # TODO: Add descritpion when using PyGrid.\n",
    "            data = data.tag(\"cifar\", \"input\").fix_precision().share(*current_group, crypto_provider=crypto_provider, \n",
    "                                                                    requires_grad=True)\n",
    "            # As nn.CrossEntropyLoss can't be used we have to one-hot encode the targets\n",
    "            target = one_hot_of(target).tag(\"cifar\", \"input\").fix_precision().share(*current_group, \n",
    "                                                                        crypto_provider=crypto_provider, \n",
    "                                                                        requires_grad=True)\n",
    "            # Store the pointers to the send data.\n",
    "            dist_dataset_teachers[current_teacher.id].append((data, target))\n",
    "        # Student: The larger part is unlabeled \n",
    "        else: \n",
    "            if not extra_public_ds:    \n",
    "                # Directly send to student (should be public dataset) \n",
    "                ### PySyft ###\n",
    "                # FOR NOW: We assume the role of the model owner, for neutral instance we need a remote_share()\n",
    "                # data = data.tag(\"cifar\", \"input\").send(student, requires_grad=True)\n",
    "                # Store the pointers to the send data.\n",
    "                dist_dataset_student.append(data)\n",
    "        \n",
    "    return dist_dataset_teachers, dist_dataset_student "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "referenced_widgets": [
      "97a06761c16a422bad8fcf1352550064",
      "8d63b715b45a46c7ad8edbdc24471260",
      "bc92e82516dc4ad28a668bffb17f1efc",
      "4b53b397d479414c93c27f5d641d587e",
      "65a169eb06ec4bc5a1679e0a2e923778",
      "b137011132224017852a1f3301739595",
      "e057d7850d48478eb6dcbd64c5d897a5",
      "0e8eeb282352437097c6955a2cad3b95"
     ]
    },
    "colab_type": "code",
    "id": "-ygpTnBmuQ8K",
    "outputId": "3783e602-de66-4f11-def6-3872afe2ac17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[[<VirtualWorker id:photographer0 #objects:0>, <VirtualWorker id:model_provider0 #objects:0>], [<VirtualWorker id:photographer1 #objects:0>, <VirtualWorker id:model_provider0 #objects:0>], [<VirtualWorker id:photographer2 #objects:0>, <VirtualWorker id:model_provider0 #objects:0>]]\n"
     ]
    }
   ],
   "source": [
    "## SIMPLE VERSION ##\n",
    "\n",
    "# Create Argument class (as @LaRiflle in Part 12)\n",
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.numb_teachers = 3\n",
    "        self.numb_classes = 10\n",
    "        # Epsilon we will use for noisy voting\n",
    "        self.epsilon = 0.1\n",
    "        # Delta we want for the total privacy leakage analysis AFTER training\n",
    "        self.delta = 1e-5\n",
    "        # TODO: Increase before complete test-run (only to have quick forward, backward for testing)\n",
    "        self.batch_size = 20\n",
    "        self.test_batch_size = 64\n",
    "        # TODO: Increase if more time (training faster)\n",
    "        self.epochs = 2\n",
    "        self.lr = 0.02\n",
    "        self.seed = 1\n",
    "        self.patience = 3\n",
    "        self.val_size = 0.2\n",
    "        # self.ratio = 0.4\n",
    "        # self.log_interval = 1 # Log info at each batch\n",
    "        # self.precision_fractional = 3\n",
    "    \n",
    "args = Arguments()\n",
    "\n",
    "# TODO: WHY DOESN?T THIS WORK?????????????????????????????????\n",
    "_ = torch.manual_seed(args.seed)\n",
    "\n",
    "# Normalize data and convert to torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "# Get Cifar10 Dataset from torchvision.datasets\n",
    "cifar10_train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "\n",
    "# We distribute testing data also on workers, as in a real scenario. \n",
    "cifar10_test_data = datasets.CIFAR10('data', train=False,\n",
    "                              download=True, transform=transform)\n",
    "\n",
    "# For Testing\n",
    "sample_input = torch.randn((args.batch_size, 3, 32, 32))*255\n",
    "\n",
    "# Model Provider (+ Public Data Provider)\n",
    "student = CREATE_V_WORKERS(1, \"model_provider\")\n",
    "\n",
    "# We assume the role of the model provider (initiator of PATE procedure)\n",
    "# IMPORTANT: Local worker should not be a client worker\n",
    "#hook.local_worker.is_client_worker = False\n",
    "#student = hook.local_worker\n",
    "\n",
    "# Private Data Provider\n",
    "teachers = CREATE_V_WORKERS(args.numb_teachers, \"photographer\")\n",
    "\n",
    "# Crypto Provider \n",
    "crypto_provider = CREATE_V_WORKERS(1, \"crypto_provider\")\n",
    "\n",
    "# Create Hosting Groups for SMPC-Encryption \n",
    "hosting_groups = CREATE_HOSTING_GROUPS(teachers, student)\n",
    "print(hosting_groups)\n",
    "\n",
    "# Distribute Data \n",
    "PTR_dtrain_teachers, dtrain_student = SIMPLE_PATE_SETUP(hosting_groups, cifar10_train_data, \n",
    "                                                            args.batch_size, crypto_provider)\n",
    "\n",
    "# We assume that the we got a pointer to the total dataset on the worker and then parted the pointers into \n",
    "# the training and testing dicts \n",
    "# Note: There are now labeled test samples on the student as well for evaluation purposes only\n",
    "PTR_dtest_teachers, dtest_student = SIMPLE_PATE_SETUP(hosting_groups, cifar10_test_data,\n",
    "                                                        args.batch_size, crypto_provider)\n",
    "\n",
    "# CHANGE: This is just for sim purposes: This test-data wouldn't exist normally but is still created for \n",
    "# performance evalulation purposes of the final model. (compare it to normal training)\n",
    "# TODO: Possibly better for evaluation to use complete test data for testing (only store it on teachers)\n",
    "# Merge part of the test data that was distributed on student together with rest, because \n",
    "# unlabeled datapoints can't be used for testing \n",
    "#PTR_dtrain_student += temp1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "3xMtCgCjuQ8O",
    "outputId": "9dafa679-38c6-41d8-af10-6ba0d196b875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Providers: \n",
      "(Wrapper)>AutogradTensor>FixedPrecisionTensor>[AdditiveSharingTensor]\n",
      "\t-> [PointerTensor | me:70559082793 -> photographer0:99088322026]\n",
      "\t-> [PointerTensor | me:2845580457 -> model_provider0:3833413114]\n",
      "\t*crypto provider: crypto_provider0*\n",
      "Total batches on student: 1500  +  300\n",
      "Total batches on teachers: training:  [334, 333, 333]  + testing:  [67, 67, 66]\n",
      "Distributed:  60000  /60.000 datapoints\n"
     ]
    }
   ],
   "source": [
    "## SIMPLE VERSION ##\n",
    "# TODO: Mini-Test: Make dynamic based on actual args.batch_size and consider non-complete batches \n",
    "\n",
    "# As an example: Get the target of the first example in the first batch -> Note: Not one-hot-encoded\n",
    "print(\"Data Providers: \")\n",
    "example_worker = teachers[0].id\n",
    "print(PTR_dtrain_teachers[example_worker][0][0])\n",
    "# For Encryption: no single location obviously \n",
    "##print(PTR_dtrain_teachers[\"target\"][1][0].location)\n",
    "##print(PTR_dtrain_teachers[\"target\"][2][0].location)\n",
    "#print(\"Pointer on first batch on student: \", dtrain_student[0])\n",
    "\n",
    "numb_student_batches = len(dtrain_student) + len(dtest_student)\n",
    "print(\"Total batches on student:\",  len(dtrain_student), \" + \", len(dtest_student))\n",
    "\n",
    "# TODO: Important that they have equal number of datapoints (each from other distribution)\n",
    "#       Introduce weighting at averaging afterwards?\n",
    "numb_teacher_train_batches = [len(PTR_dtrain_teachers[worker.id]) for worker in teachers]\n",
    "numb_teacher_test_batches = [len(PTR_dtest_teachers[worker.id]) for worker in teachers]\n",
    "print(\"Total batches on teachers: training: \", numb_teacher_train_batches, \" + testing: \", numb_teacher_test_batches)\n",
    "\n",
    "# Total 60.000 datapoints = 1800 * 20 + 1200 * 20 = 60.000 (batch_size = 20)\n",
    "total_distributed_batches = numb_student_batches + sum(numb_teacher_train_batches+numb_teacher_test_batches)\n",
    "print(\"Distributed: \", total_distributed_batches*args.batch_size, \" /60.000 datapoints\")\n",
    "\n",
    "# Quick check if data is rightfully stored on workers\n",
    "#print(teachers[0]._objects)\n",
    "#print(student._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "G8LOdSEsuQ8S",
    "outputId": "f421dede-e970-4f72-8941-d37f3c17b3be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "268\n",
      "66\n",
      "267\n",
      "66\n",
      "267\n"
     ]
    }
   ],
   "source": [
    "## Validation Set Creation ##\n",
    "\n",
    "# image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# TODO: Possibly make function because we need to split twice \n",
    "def split_train_val(val_size): \n",
    "    pass\n",
    "\n",
    "PTR_dvalid_teachers = {}\n",
    "# Shuffle + Train/Val Split\n",
    "for teacher in teachers:\n",
    "    # Current batch \n",
    "    batches = PTR_dtrain_teachers[teacher.id]\n",
    "    \n",
    "    # Randomize Batches (Don't learn a pattern the photograher might have used for sorting)\n",
    "    np.random.shuffle(batches)\n",
    "\n",
    "    # Split Val and Train Data \n",
    "    numb_batches = len(batches)\n",
    "    split = int(args.val_size * numb_batches)\n",
    "    PTR_dvalid_teachers[teacher.id] = batches[:split] \n",
    "    PTR_dtrain_teachers[teacher.id] = batches[split:]\n",
    "\n",
    "    # Test\n",
    "    print(len(PTR_dvalid_teachers[teacher.id]))\n",
    "    print(len(PTR_dtrain_teachers[teacher.id]))\n",
    "\n",
    "# Student - Splitting: Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtukZcNDuQ8W"
   },
   "source": [
    "## Setup Done. Actual Start.\n",
    "Now we have all the workers the way we described in the setup above. (Everything in batches, for datapoints \" \\* self.batch_size\") *Little Recap:* \n",
    "* `PTR_dtrain_teachers` 802 *labeled* batches are distributed across *3 teacher workers* (= **40% of 2500** batches (60.000 datapoints) in total = *1000* and again **80%** left for training and 20% for validation)\n",
    "* `PTR_dtest_teachers` 200 *labeled* examples are also distributed across *3 teacher workers*\n",
    "* `PTR_dvalid_teachers` 198 *labeled* examples for validation during trainig (66 + 66 + 66)\n",
    "* `PTR_dtrain_student` 1500 (from test distribution) *unlabeled* examples are stored on *1 student worker*\n",
    "* `PTR_dtest_student` 300 *labeled* examples are also distributed across *1 student* (only for testing)\n",
    "\n",
    "* `PTR_dvalid_student` array (LATER)\n",
    "\n",
    "<br> <br>\n",
    "* We have the different pointers without access to the actual data/model. (*Assumption, Passiv Sec.:* We can't call `.get()` ?)\n",
    "**IMPORTANT: This is where we would start normally, if real workers existed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeoSqfcauQ8W"
   },
   "source": [
    "### Model Creation \n",
    "The goal was to **ResNet18** to allow for fast training but to showcase SMPC-encryption with state-of-the-art models (using residual connections, batchnorm, relu, etc.) <br>\n",
    "*Unfortunately for now this isn't possible, see Shortcomings* <br>\n",
    "For that reason I used the same model as was used in Udacity's Notebook (for performance comparison afterwards) and a very small one for testing purposes. (both work, the second just takes considerably longer with SMPC)\n",
    "<br>\n",
    "<br>\n",
    "***TODO: MAKE A SECTION: SECURITY ASSUMPTIONS***\n",
    "* **IMPORTANT TO NOTE:** We could call `.get()` on the pointers to retrieve all the data, but in a real scenario with a gateway this wouldn't be possible. The important part is that we only see pointers and never the actual model or the data.\n",
    "* The hosting parties could communicate with each other and make it possible to decrypt a tensor which was safed via SMPC on the hosting providers. (given they can identify which of the parts belong to each other, e.g. by recording the time when they were received along with some network model, knowledge)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "C1-9R99HuQ8X",
    "outputId": "df7f5891-20be-44bd-e066-b1c9a8f2e4c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'photographer0': Small_Model(\n",
      "  (fc1): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "), 'photographer1': Small_Model(\n",
      "  (fc1): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      "), 'photographer2': Small_Model(\n",
      "  (fc1): Linear(in_features=3072, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################# \n",
    "# Model Creation & Distribution #\n",
    "#################################\n",
    "\n",
    "# (Public dataset is already on student (local_worker) #\n",
    "# Normally the model would also be send to the local_worker and then form there to the \n",
    "# different hosting_groups, but there isn't anything like .remote_share() for now\n",
    "# (If there would be, we could assume a neutral role and coordinate the complete process, which then could also be\n",
    "#  done completely automatically)\n",
    "\n",
    "class Small_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Small_Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 * 32 * 32, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 3 Channels, 32x32 images\n",
    "        x = x.view(-1, 3 * 32 * 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Copied and changed from Udacity's Notebook \n",
    "# define the CNN architecture\n",
    "class Cifar10Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cifar10Model, self).__init__()\n",
    "        # convolutional layer (sees 32x32x3 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 8x8x32 tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        \n",
    "        # max pooling layer \n",
    "        # PR: !!! RuntimeError: \"max_pool2d_with_indices_cpu\" not implemented for 'Long'\n",
    "        # Should work as part of secureNN protocol\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Conv with 1x1 kernel is the same as average pool -> good alternative \n",
    "        # TODO: Check number of params this alternative approach changes \n",
    "        self.pool1 = nn.Conv2d(16, 16, kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.Conv2d(32, 32, kernel_size=2, stride=2)\n",
    "        self.pool3 = nn.Conv2d(64, 64, kernel_size=2, stride=2)\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 2nd hidden layer, with relu activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cifar10_model = Small_Model()\n",
    "#print(cifar10_model)\n",
    "\n",
    "# Copy and distribute to all hosting_groups\n",
    "PTR_models = {}\n",
    "for i, hosting_group in enumerate(hosting_groups): \n",
    "    # TODO: Could also use model as a plan (any advantages in this scenario?)\n",
    "    # Create new model instance \n",
    "    cifar10_model_copy = type(cifar10_model)() \n",
    "    # Load actual params \n",
    "    cifar10_model_copy.load_state_dict(cifar10_model.state_dict()) \n",
    "    # Index models also with the teachers.id (the same for as for the data!)\n",
    "    current_teacher = hosting_group[0]\n",
    "    PTR_models[current_teacher.id] = cifar10_model_copy.fix_precision().share(*hosting_group, \n",
    "                                                      crypto_provider=crypto_provider, requires_grad=True)\n",
    "    \n",
    "print(PTR_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG9DcDQBuQ8a"
   },
   "outputs": [],
   "source": [
    "## Nr.2 - DO NOT EXECUTE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EBiHhyV6uQ8d"
   },
   "outputs": [],
   "source": [
    "## Nr.3 - TESTING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRAelFfmuQ8f"
   },
   "outputs": [],
   "source": [
    "## Nr.4 - TESTING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHGRJ1mQuQ8j"
   },
   "outputs": [],
   "source": [
    "## Nr.5 - TESTING ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYOyoNHOuQ8m"
   },
   "outputs": [],
   "source": [
    "## Nr.6 - DO NOT EXECUTE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JfWVK1IuQ8p"
   },
   "source": [
    "## PATE Step 1: Traning Teacher Models \n",
    "***TODO: Possibly add more explanation.***\n",
    "Here FL learning will be done. <br>\n",
    "* **First** the **Sequential approach:** \n",
    "    * train one student model and produce labels for student dataset and store them on teacher\n",
    "    * do this for all students one after the other\n",
    "    * then to create the final labeling, cound the number a class was predicted by the teachers. Then add laplacian noise to every label count to then take the majority label (the label that was predicted the most among the teachers) | *the whole = laplace mechanism*\n",
    "    * finally train the model on the newly labeled public dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bceJTuG_uQ8p"
   },
   "outputs": [],
   "source": [
    "# First start with a sequential approach: Parallel exection for protocols isn't possible for now \n",
    "# + I first have to checkout in more detail the serde aproach for serilization (remote training plans)\n",
    "# Also deepcopy of the model and afterwards automatic encryption isn't possible because remote_share() doesn't exist\n",
    "\n",
    "def criterion(pred, target):\n",
    "            # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "            batch_size = pred.shape[0]\n",
    "            loss = ((pred - target)**2).sum().refresh()/batch_size\n",
    "            return loss\n",
    "\n",
    "### Sequential approach ###\n",
    "def run_epoch(model, dataloader, train, optimizer=None, criterion=None):\n",
    "    for i, (inp, target) in enumerate(dataloader):\n",
    "\n",
    "        # Reset Optimizer \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        out = model(inp)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(out, target)\n",
    "        \n",
    "        # Only train if function is used for training \n",
    "        if train: \n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "            # Optimizer Step \n",
    "            optimizer.step()\n",
    "        \n",
    "        # Stats\n",
    "        true_classes = torch.argmax(target, dim=0).get().float_precision()\n",
    "        pred_classes = torch.argmax(out, dim=0).get().float_precision()\n",
    "        \n",
    "        numb_correct = sum(torch.eq(true_classes, pred_classes)).item()\n",
    "        batch_size = inp.shape[0]\n",
    "        epoch_acc = numb_correct/batch_size\n",
    "        \n",
    "        # get and convert tensor into normal variable\n",
    "        epoch_loss = loss.get().item()\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# TODO: Do test as well \n",
    "def test(): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "X1RFBR0SuQ8r",
    "outputId": "ffc0ded1-e04a-49a6-e792-d152d2db549b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Start training of teacher-model Nr.  0  ####\n",
      "Epoch   1/2, train loss: 7.90e+02, accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "## Train the teacher models ##\n",
    "for i in range(args.numb_teachers):\n",
    "    print(\"#### Start training of teacher-model Nr. \", i, \" ####\")\n",
    "    # Choose the model \n",
    "    model = PTR_models[teachers[i].id]\n",
    "    \n",
    "    # Create an optimizer for each model\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "    # Optimizer has to also have int values (see Part 12 Tutorial)\n",
    "    optimizer = optimizer.fix_precision() \n",
    "    \n",
    "    # Choose the dataset of the corresponding teacher \n",
    "    train_loader = PTR_dtrain_teachers[teachers[i].id]\n",
    "    valid_loader = PTR_dvalid_teachers[teachers[i].id]\n",
    "    \n",
    "    # patience for early stoppping \n",
    "    current_patience = 0\n",
    "    best_acc = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        # Training\n",
    "        train = True\n",
    "        model.train()\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, train, optimizer, criterion)\n",
    "        print(f\"Epoch {epoch + 1: >3}/{args.epochs}, train loss: {train_loss:.2e}, accuracy: {train_acc * 100:.2f}%\")\n",
    "        \n",
    "        current_patience += 1\n",
    "        \n",
    "        # Evaluation after each epoch for stats and for hyperparam tuning (epochs through early stopping for now)\n",
    "        train = False\n",
    "        model.eval()\n",
    "        val_loss, val_acc = run_epoch(model, valid_loader, train, optimizer, criterion)\n",
    "        print(f\"Epoch {epoch + 1: >3}/{args.epochs}, val loss: {val_loss:.2e}, accuracy: {val_acc * 100:.2f}%\")\n",
    "        \n",
    "        # Early stopping \n",
    "        #if val_acc > best_acc: \n",
    "            # reset timer\n",
    "        #    current_patience = 0\n",
    "        #    best_acc = val_acc\n",
    "            \n",
    "            # TODO: Neither of the both approaches work (Think about how it should work in theory with pointers)\n",
    "            # Copy current best model, simple assignment won't work because it \n",
    "            # only copies a pointer on model which is still trained\n",
    "            # normal copy.copy() isn't enough because dict has nested structure -> copy.deepcopy()\n",
    "            #best_model = deepcopy(model.state_dict())\n",
    "            \n",
    "            # Create new model instance \n",
    "            #best_model = type(model)() \n",
    "            # Load actual params \n",
    "            #best_model.load_state_dict(model.state_dict()) \n",
    "        \n",
    "        #if current_patience > args.patience: \n",
    "        #    break\n",
    "        \n",
    "    # Load final best model (Scope in Python egal!!)\n",
    "    #model.load_state_dict(best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z554Jl8yuQ8u"
   },
   "source": [
    "## PATE Step 2: Label Public Dataset with aggregated teacher-predictions\n",
    "* *Quick recap:*\n",
    "    * For each teacher a model was trained and is stored on the corresponding hosting group\n",
    "    * A public dataset still resides unencrypted on model owner device (in this case a simple variable locally)\n",
    "* **Adding DP, Noise:**\n",
    "    * *1. Approach:* Adding noise to labels on respective hosting_groups, that way no raw label is ever stored on this device. (Given the model owner or possibly a neutral instance doesn't call .get())\n",
    "    * *2. Approach:* First storing all raw labels from all different teachers and then add noise after the max-function. This would probably require less noise to be added for an equal privacy leakage (see Andrew Trasks tutorial series on that or PATE paper) but possibly respresent a greater security risk as the raw labels are stored unencrypted on a device other than the teacher's device. \n",
    "    * **CHOICE:** In this example we go for the first approach which should give us better performance at a lower privacy leakage. <br> ***TODO: THINK ABOUT HOW TO AGGREGATE WITHOUT TRUSTED CURATOR, EXAMPLE WITH ACTIVE SEC.***\n",
    "   \n",
    "*This could be executed in parallel while other teacher models are still being trained. (That's why has been put in an extra cell)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "9H02WUEnuQ8u",
    "outputId": "7a6f2036-c02d-4f92-af80-98c2e62d7d7f"
   },
   "outputs": [],
   "source": [
    "## SIMPLE VERSION (Sequ.) ##\n",
    "\n",
    "# TODO: Possibly put the for loop to get the PTR_preds in this function in more general utility function \n",
    "#       Also in general: try to create more general purpose functions out of the capital functions \n",
    "def PATE_GET_LABELS(): \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "def DP_NOISY_VOTING(teacher_preds, num_classes, epsilon): \n",
    "    \"\"\"\n",
    "        Does \"noisy voting\" (ref. PATE paper above) given the label predictions of all participating teachers. \n",
    "        Implements Laplace Mechanism: Query on teacher_preds sample (extract majority label) and add laplace noise.\n",
    "        \n",
    "        Args: \n",
    "            teacher_preds - Matrix: num_teachers x num_samples\n",
    "            num_classes - Int indicating how many classes exist\n",
    "            epsilon - Int indicating the desired privacy budget (epsilon, delta)\n",
    "        \n",
    "        Returns: \n",
    "            Array of final noisy aggregated labels \n",
    "    \"\"\"\n",
    "    \n",
    "    # Adding noise through laplace mechanism (based on tutorial from Andrew Trask) \n",
    "    new_labels = list()\n",
    "    # Iterate through all samples (columns)\n",
    "    for i in range(teacher_preds.shape[1]):\n",
    "        # All different teacher predictions for a sample\n",
    "        # TODO: Change to do everything in tensors (find alternative for np.bincount())\n",
    "        # FloatTensor -> Numpy \n",
    "        preds = teacher_preds[:, i].numpy().astype(int)\n",
    "      \n",
    "        # Gives back array with counts of all values that exist in preds \n",
    "        # (array should be min of length num_classes so that all classes, even with 0 occurences, are present)\n",
    "        label_counts = np.bincount(preds, minlength=num_classes)\n",
    "\n",
    "        # laplace distr. param (delta = 0 for laplacian noise)\n",
    "        beta = 1 / epsilon\n",
    "\n",
    "        # label_counts should never have more than num_classes: Otherwise something wrong with preds \n",
    "        for i in range(num_classes):\n",
    "            # loc = 0, scale = beta, output_dim = scalar\n",
    "            label_counts[i] += np.random.laplace(0, beta, 1)\n",
    "\n",
    "        new_label = np.argmax(label_counts)\n",
    "\n",
    "        new_labels.append(new_label)\n",
    "    return new_labels \n",
    "\n",
    "# Store pointers to predicted labels\n",
    "teacher_preds = {}\n",
    "\n",
    "for i in range(args.numb_teachers):\n",
    "    # Select current variables\n",
    "    teacher = teachers[i].id\n",
    "    print(\"#### Starting Prediction Teacher: \", teacher, \" ####\")\n",
    "    \n",
    "    model = PTR_models[teacher]\n",
    "    hosting_group = hosting_groups[i]\n",
    "    \n",
    "    # Move public dataset to correct hosting group: share (also encrypts public data in case it is sensitive)\n",
    "    # TODO: Possibly also consider letting the test set also be labeled by the teachers\n",
    "    PTR_dtrain_student = []\n",
    "    for i, data in enumerate(dtrain_student):\n",
    "        PTR_dtrain_student.append(data.fix_precision().share(*hosting_group, crypto_provider=crypto_provider))\n",
    "    \n",
    "    # Make predictions\n",
    "    teacher_preds[teacher] = []\n",
    "    for i, data in enumerate(PTR_dtrain_student):\n",
    "        #print(\"Predicting Batch Nr.\", i)\n",
    "        # Run Forward Pass\n",
    "        batch_out = model(data)\n",
    "        \n",
    "        # Get batch predictions\n",
    "        batch_pred = torch.argmax(batch_out, dim=0)\n",
    "        \n",
    "        # (Append would create array of arrays, we want one array)\n",
    "        teacher_preds[teacher] += batch_pred.get().float_precision()\n",
    "    \n",
    "    # Get student datasets back for next round\n",
    "    dtrain_student = []\n",
    "    for i, data in enumerate(PTR_dtrain_student):\n",
    "        dtrain_student.append(data.get().float_precision())\n",
    "    \n",
    "    # TODO: Better than trusted curator: Running average + add noise ? (But first on still unprotected)\n",
    "\n",
    "# Noisy aggregation of labels will be saved in array\n",
    "# TODO: Think of better way to get all labels before aggregation \n",
    "#       (Secure Aggregator would require remote_share given current setup)\n",
    "    \n",
    "# Create prediction matrix: teachers x predictions\n",
    "tuple_of_preds = [teacher_preds[teacher] for teacher in teacher_preds.keys()]\n",
    "teacher_preds = np.stack(tuple_of_preds, axis=0)\n",
    "\n",
    "# Do the actual noisy labeling\n",
    "noisy_labels = torch.Tensor(DP_NOISY_VOTING(teacher_preds, args.numb_classes, args.epsilon))\n",
    "\n",
    "# Merge labels into unlabeled student dataset \n",
    "temp = []\n",
    "for i, data in enumerate(dtrain_student):\n",
    "    corresp_targets = noisy_labels[i:i+args.batch_size]\n",
    "    temp.append((data, corresp_targets))\n",
    "    \n",
    "dtrain_student = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_MeZ4HFLFtS"
   },
   "outputs": [],
   "source": [
    "### TEMPORARY ###\n",
    "\n",
    "print(len(dtrain_student[-1]))\n",
    "print(len(dtrain_student[-1]))\n",
    "print(len(dtrain_student)*args.batch_size)\n",
    "print(len(PTR_dtrain_teachers) * args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PX-018EYw2Ba"
   },
   "outputs": [],
   "source": [
    "### TEMPORARY ###\n",
    "\n",
    "# Create prediction matrix: teachers x predictions\n",
    "test = (np.random.rand(len(dtrain_student)*args.batch_size, len(teachers)) * 10).astype(int)\n",
    "print(test.shape)\n",
    "#tuple_of_preds = [teacher_preds[teacher] for teacher in teacher_preds.keys()]\n",
    "#teacher_preds = np.stack(tuple_of_preds, axis=1)\n",
    "\n",
    "# TODO: Convert to Tensor earlier \n",
    "# Do the actual noisy labeling\n",
    "noisy_labels = torch.LongTensor(DP_NOISY_VOTING(test, args.numb_classes, args.epsilon))\n",
    "print(len(noisy_labels))\n",
    "# Merge labels into unlabeled student dataset \n",
    "temp = []\n",
    "for i, data in enumerate(dtrain_student):\n",
    "    inc = i+args.batch_size\n",
    "    # If not enough elements for whole batch, cut off (otherwise [] is returned and the target batch is larger than the data batch)\n",
    "    if inc > len(noisy_labels):\n",
    "        inc = len(noisy_labels) + 1\n",
    "    corresp_targets = noisy_labels[i:inc]\n",
    "    temp.append((data, one_hot_of(corresp_targets)))\n",
    "    print(\"Data\", data.shape)\n",
    "    print(\"Target\", corresp_targets.shape)\n",
    "    \n",
    "dtrain_student = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VuiimOc0uQ8x"
   },
   "source": [
    "## PATE Step 3: Train Student Model\n",
    "Here Student Model will be trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7b5BUYxouQ8x"
   },
   "outputs": [],
   "source": [
    "# As for training the student models: split training into train and valid\n",
    "dvalid_student = []\n",
    "batches = dtrain_student\n",
    "    \n",
    "# Randomize Batches\n",
    "np.random.shuffle(batches)\n",
    "\n",
    "# Split Val and Train Data \n",
    "numb_batches = len(batches)\n",
    "split = int(args.val_size * numb_batches)\n",
    "dvalid_student = batches[:split] \n",
    "dtrain_student = batches[split:]\n",
    "\n",
    "# Test\n",
    "print(len(dvalid_student))\n",
    "print(len(dtrain_student))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUxC6J5_Cdo4"
   },
   "outputs": [],
   "source": [
    "# First start with a sequential approach: Parallel exection for protocols isn't possible for now \n",
    "# + I first have to checkout in more detail the serde aproach for serilization (remote training plans)\n",
    "# Also deepcopy of the model and afterwards automatic encryption isn't possible because remote_share() doesn't exist\n",
    "\n",
    "def criterion_stud(pred, target):\n",
    "            # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "            batch_size = pred.shape[0]\n",
    "            loss = ((pred - target)**2).sum()/batch_size\n",
    "            return loss\n",
    "\n",
    "### Sequential approach ###\n",
    "def run_epoch_stud(model, dataloader, train, optimizer=None, criterion=None):\n",
    "    for i, (inp, target) in enumerate(dataloader):\n",
    "\n",
    "        # Reset Optimizer \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        out = model(inp)\n",
    "\n",
    "       # print(\"Inp\", inp.shape)\n",
    "       # print(\"Target\", target.shape)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion_stud(out, target)\n",
    "        \n",
    "        # Only train if function is used for training \n",
    "        if train: \n",
    "            # Backward Pass\n",
    "            loss.backward()\n",
    "            # Optimizer Step \n",
    "            optimizer.step()\n",
    "        \n",
    "        # Stats\n",
    "        true_classes = torch.argmax(target, dim=0)\n",
    "        pred_classes = torch.argmax(out, dim=0)\n",
    "\n",
    "        numb_correct = sum(torch.eq(true_classes, pred_classes)).item()\n",
    "        batch_size = inp.shape[0]\n",
    "        epoch_acc = numb_correct/batch_size\n",
    "        \n",
    "        # get and convert tensor into normal variable\n",
    "        epoch_loss = loss.item()\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# TODO: Do test as well \n",
    "def test(): \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKtvedD7uQ81"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement training of student model (Potentially other train configs could be used, change ARG-Class)\n",
    "\n",
    "# Same as for student training but now training can happen on device.\n",
    "# Choose the model \n",
    "#student_model = Cifar10Model()\n",
    "student_model = Small_Model() \n",
    "    \n",
    "# Create an optimizer for each model\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=args.lr)\n",
    "    \n",
    "for epoch in range(args.epochs):\n",
    "    print(\"#### Start training of student model ####\")\n",
    "    # Training\n",
    "    train = True\n",
    "    student_model.train()\n",
    "    train_loss, train_acc = run_epoch_stud(student_model, dtrain_student, train, optimizer, criterion_stud)\n",
    "    print(f\"Epoch {epoch + 1: >3}/{args.epochs}, train loss: {train_loss:.2e}, accuracy: {train_acc * 100:.2f}%\")\n",
    "        \n",
    "    #current_patience += 1\n",
    "    \n",
    "    # Evaluation after each epoch for stats and for hyperparam tuning (epochs through early stopping for now)\n",
    "    train = False\n",
    "    student_model.eval()\n",
    "    val_loss, val_acc = run_epoch_stud(student_model, dvalid_student, train, optimizer, criterion_stud)\n",
    "    print(f\"Epoch {epoch + 1: >3}/{args.epochs}, val loss: {val_loss:.2e}, accuracy: {val_acc * 100:.2f}%\")\n",
    "        \n",
    "    # Early stopping \n",
    "    #if val_acc > best_acc: \n",
    "        # reset timer\n",
    "     #   current_patience = 0\n",
    "     #   best_acc = val_acc\n",
    "        # Copy current best model, simple assignment won't work because it \n",
    "        # only copies a pointer on model which is still trained\n",
    "     #   best_model = deepcopy(model.state_dict())\n",
    "        \n",
    "    #if current_patience > args.patience: \n",
    "    #    break\n",
    "        \n",
    "# Load final best model: \n",
    "#student_model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6A1guFdhuQ83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OA91FDyGuQ85"
   },
   "source": [
    "## Testing of PATE Procedure \n",
    "* **Evaluation:**\n",
    "    * *Privacy Leakage:* PATE Analysis from syft library\n",
    "    * *Model Performance Evaluation:* Test student model (and compare to alternative -> Udacity Notebook)\n",
    "    * *Speed Evaluation:* How much more time did this take? \n",
    "* **OLD:**\n",
    "    * Here using the testing infrastructure the PATE procedure will be tested. <br>\n",
    "    * The goal is to implement the PATE procedure as a `PySyft.protocoll` using `PySyft.plans` which also should be tested as a general automated procedure before deploying everything on actual workers and a grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1u2RtibuQ86"
   },
   "outputs": [],
   "source": [
    "# This calculates the privacy leakage using the PATE approach above: \n",
    "# From the pate.py file\n",
    "# preds: a torch tensor of dim (num_teachers x num_examples). Each value corresponds to the\n",
    "#        index of the label which a teacher gave for a specific example\n",
    "# indices: a torch tensor of dim (num_examples) of aggregated examples which were aggregated using\n",
    "#          the noisy max mechanism.\n",
    "# noise_eps: the epsilon level USED to create the indices\n",
    "# delta: the DESIRED level of delta\n",
    "from syft.frameworks.torch.dp import pate\n",
    "\n",
    "# No Float inputs\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=teacher_preds.type(torch.LongTensor),\n",
    "                                                   indices=noisy_labels.type(torch.LongTensor), \n",
    "                                                   noise_eps=args.epsilon, delta=args.delta)\n",
    "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMSlp6E2uQ88"
   },
   "outputs": [],
   "source": [
    "# Model Performance Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gipKD3SauQ8_"
   },
   "outputs": [],
   "source": [
    "# Speed Evaluation (gathered data from training and testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4tl2HwWuQ9C"
   },
   "source": [
    "# Performance Evaluation (Combine with above)\n",
    "* **Performance Evaluation:** *Depending on time can be extended or not*\n",
    "  Analyse Performance of Decentralized Training with normal Training, Possible metrics: \n",
    "    * Training Time: Convergence Speed, Compuation Time (incl. communication, etc.)\n",
    "    * Model-Performance: Relevant Metrics (Accuracy, etc.)\n",
    "    * Privacy-Leakage-Anlysis in different security situations (active and passive security)\n",
    "    * Model-Robustness: Impact of decentralized \n",
    "    * Model-Fairness: Impact of decentralized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4KQJadFuQ9D"
   },
   "outputs": [],
   "source": [
    "# Possibly just use the Udacity Notebook as comparision for performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHmq0GR0uQ9F"
   },
   "source": [
    "# The final project on the grid (INCORPORATE NEW STRATEGY IN NOTES)\n",
    "Here the final real end-to-end example of photographers training a image-classfier together with a model provider should be showcased using an actual grid, whith a gateway and workers which could actually run on remote machines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEQbNS38uQ9F"
   },
   "outputs": [],
   "source": [
    "# TODO: Setting up a grid with workers + documentation + further links to grid tutorials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ul5y5bJBuQ9I"
   },
   "outputs": [],
   "source": [
    "# The main difference: we have a gateway and can automate the matching process + add an initiation/request func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVrZ3flMuQ9L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzW6lLgvuQ9P"
   },
   "source": [
    "# Shortcomings \n",
    "## What can't be done\n",
    "Why for now the PATE framework was implemented using **two host-providers** (and not as originally thought using all participating parties and only dynamically add hosts if needed for computation) and **sequentially** (the training of the teachers and the prediction on the public set could happen in parallel and would greatly speed overall execution time of the PATE procedure)\n",
    "* **ReLU** can't yet be applied if more than two different workers are used for encryption \n",
    "* For automatic execution or creation of a completely automated protocol: \n",
    "    * No way of remotely encrypting data (no remote_share() for example). *Relevance:* Even if one assumes that every worker encrypts his data on his own at the beginning, for executing PATE in a parallel manner one would need to copy (after calling remote_get() to unencrypt the model) and re-encrypt (here remote_share() would be good) the model to then be able to train different teacher models in parallel. An alternative to a remote_share() function could be to alter the current `Plan` to support more than just tensor arguments. (Workers for example)\n",
    "    * No stable way of creating a training plan. (Some experimental, limited work) <br> ***TODO: NEED TO FURTHER CHECK OUT THE WORK***\n",
    "* ResNet can't be used because relu() with inplace param is not supported \n",
    "* MaxPooling isn't supported either (problem with secureNN implementation?)\n",
    "* CUDA isn't possible with SMPC-encrypted model and data? \n",
    "    * In Google Colab it was tested to add data and model directly to cuda device -> produced error. (Float, Long Problem, ***TODO: DIG DEEPER***)\n",
    "* CrossEntropyLoss can't be used! **NO:** F.nll_loss(output, target)\n",
    "* Deepcopy or .load_state_dict() both fail for early stopping -> ***TODO: Better understand how it should work in theory with pointers***\n",
    "* Training of Students uses VERY MUCH RAM. (Google Colab Session stopped after first epoch of second student because apparently RAM of 12.21 GB wasn't sufficient)\n",
    "* Pate-Analysis also takes very much time on big datasets (timing data coming, for now 30 min still running)\n",
    "\n",
    "## What wasn't done (yet)\n",
    "* Parallelization: ***LINK TO EXPERIMENTAL NOTEBOOK IMPLEMENTING PARALLEL WORKERS***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2hyVKRquQ9P"
   },
   "source": [
    "# OLD CODE \n",
    "## Possibly interesting parts to reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmiNtsTVuQ9P"
   },
   "outputs": [],
   "source": [
    "## Nr.1 - DO NOT EXECUTE ##\n",
    "# Note: \n",
    "# - Federated Dataset could be used \n",
    "# - data attribute with VirtualWorkes can't be used to not use efficient data loading of DataLoader\n",
    "#   everything would be stored in one place....think further about that (relook at forum)\n",
    "# - Implement GPU Usage \n",
    "# - DOC. better\n",
    "\n",
    "# TODO: Potentially extend the function to support creation of actual workers with additional argument \n",
    "#       Possibly create a worker-class with different worker options with and without grid-usage \n",
    "def CREATE_V_WORKERS(w_number, w_name):\n",
    "    \"\"\"\n",
    "        Create multiple, named virtual workers\n",
    "    \"\"\"\n",
    "    worker = []\n",
    "    for i in range(w_number):\n",
    "        worker.append(sy.VirtualWorker(hook, id=w_name+str(i)))\n",
    "    if len(worker) == 1: \n",
    "        worker = worker[0]\n",
    "    return worker\n",
    "\n",
    "# TODO: ENCRYPTED=False (case in reality) NOT POSSIBLE, because neither with the PyGrid nor with PySyft a \n",
    "#       remote-share() has been developed beyond prototyping. For now: \n",
    "#       Train-Config torchscript-based jit-serialization or serde-based FL-Plans have been prototyped so far \n",
    "#       -> Look into that. (+ supported hosting if necessary)\n",
    "# TODO: Think about a better way to pass in all the particpating parties (incl. crypto_Provider)\n",
    "def PATE_DATA_SETUP(teachers, student, model_owner, dataset, batch_size, crypto_provider,\n",
    "                    ratio=0.4, encrypted=True, hosting=False):\n",
    "    \"\"\"\n",
    "        MAINLY FOR TESTING PURPOSES (having a centrally stored dataset)\n",
    "        Takes in teachers and a student as workers, a dataset, a batch_size and a ratio\n",
    "        The ratio specifies the percentage of the total data that gets stored on the teachers \n",
    "        Returns a a student and a teacher dataset consisting of pointers on the either already encrypted data \n",
    "        or the equally split data between the teachers. Encryption is done using all participating parties. \n",
    "        In a further step (if encrypted=False) a grid could remotely encrypt and/or support the teachers/students\n",
    "        with hosting nodes to enhance computational power. \n",
    "    \"\"\"\n",
    "    # No differentiation between training and testing is made, \n",
    "    # because in reality the data providers won't have the data seperated for ML \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    numb_workers = len(teachers)+1\n",
    "    increment = len(dataset) / numb_workers\n",
    "\n",
    "    # Directly store (input, target) pairs as an array to enumerate over them -> use as dataLoader over PTRs\n",
    "    # Create dict of teacher pointer arrays, helpful for training afterwards \n",
    "    dist_dataset_teachers = {}\n",
    "    # Initiate to be able to use .append() in main loop afterwards \n",
    "    for worker in teachers: \n",
    "        dist_dataset_teachers[worker.id] = []\n",
    "    dist_dataset_student = []\n",
    "    \n",
    "    # TODO: Dynamic Hosting Provider: Create only if needed (Think of return!)\n",
    "    hosting_provider = {}\n",
    "    if hosting: \n",
    "        pass\n",
    "        #hosting_provider[\"hosting\"] = CREATE_V_WORKERS().....\n",
    "    else: \n",
    "        pass\n",
    "        #hosting_provider[\"hosting\"]  = dataproviders.....\n",
    "      \n",
    "    # Create array of all participating workers, [] because all elements need to lists to concatenate \n",
    "    workers = teachers + [student] + [model_owner]\n",
    "    # Neutral party should provide necessary numbs for encryption\n",
    "    crypto_provider = CREATE_V_WORKERS(1, \"crypto_provider\")\n",
    "    \n",
    "    for i, (data, target) in enumerate(dataloader):\n",
    "        # Teachers: The first 40% (normally less than on public) of the data\n",
    "        # TODO: Iterate through teachers to distribute data equally (Possibly more efficient way?)\n",
    "        current_worker = teachers[i%len(teachers)]\n",
    "        if i < int(ratio * (len(dataset)/batch_size)):\n",
    "            if encrypted: \n",
    "                ### PySyft ###\n",
    "                # TODO: Add descritpion when using PyGrid.\n",
    "                data = data.tag(\"cifar\", \"input\").fix_precision().share(*workers, crypto_provider=crypto_provider)\n",
    "                target = target.tag(\"cifar\", \"input\").fix_precision().share(*workers, crypto_provider=crypto_provider)\n",
    "            else: \n",
    "                ### PySyft ###\n",
    "                data = data.tag(\"cifar\", \"input\").send(current_worker)\n",
    "                target = target.tag(\"cifar\", \"target\").send(current_worker)\n",
    "            # Store the pointers to the send data.\n",
    "            dist_dataset_teachers[current_worker.id].append((data, target))\n",
    "        # Student: The larger part is unlabeled \n",
    "        else:    \n",
    "            # Doesn't need to be encrypted \n",
    "            ### PySyft ###\n",
    "            data = data.tag(\"cifar\", \"input\").send(student)\n",
    "            # Store the pointers to the send data.\n",
    "            dist_dataset_student.append(data)\n",
    "        \n",
    "    return dist_dataset_teachers, dist_dataset_student \n",
    "\n",
    "# Normalize data and convert to torch.FloatTensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "# Get Cifar10 Dataset from torchvision.datasets\n",
    "cifar10_train_data = datasets.CIFAR10('data', train=True,\n",
    "                              download=True, transform=transform)\n",
    "\n",
    "# We distribute testing data also on workers, as in a real scenario. \n",
    "cifar10_test_data = datasets.CIFAR10('data', train=False,\n",
    "                              download=True, transform=transform)\n",
    "\n",
    "# Args\n",
    "batch_size = 20 \n",
    "ratio = 0.4\n",
    "sample_input = torch.randn((batch_size, 3, 32, 32))*255\n",
    "\n",
    "# Model Provider\n",
    "model_provider = CREATE_V_WORKERS(1, \"model_provider\")\n",
    "\n",
    "# Private Data Provider\n",
    "teachers = CREATE_V_WORKERS(3, \"photographer\")\n",
    "\n",
    "# Public Data Provider\n",
    "student = CREATE_V_WORKERS(1, \"public_cloud\")\n",
    "\n",
    "# Crypto Provider \n",
    "crypto_provider = CREATE_V_WORKERS(1, \"crypto_provider\")\n",
    "\n",
    "# All workers\n",
    "all_workers = [model_provider] + teachers + [student]\n",
    "\n",
    "# Distribute Data \n",
    "PTR_dtrain_teachers, PTR_dtrain_student = PATE_DATA_SETUP(teachers, student, model_provider, \n",
    "                                                          cifar10_train_data, batch_size, crypto_provider)\n",
    "\n",
    "# We assume that the we got a pointer to the total dataset on the worker and then parted the pointers into \n",
    "# the training and testing dicts \n",
    "# Note: There are now labeled test samples on the \n",
    "PTR_dtest_teachers, PTR_dtest_student = PATE_DATA_SETUP(teachers, student, model_provider, \n",
    "                                                        cifar10_test_data, batch_size, crypto_provider)\n",
    "\n",
    "# CHANGE: This is just for sim purposes: This test-data wouldn't exist normally but is still created for \n",
    "# performance evalulation purposes of the final model. (compare it to normal training)\n",
    "# TODO: Possibly better for evaluation to use complete test data for testing (only store it on teachers)\n",
    "# Merge part of the test data that was distributed on student together with rest, because \n",
    "# unlabeled datapoints can't be used for testing \n",
    "#PTR_dtrain_student += temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPd9QZSQuQ9S",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Nr.2 - DO NOT EXECUTE ##\n",
    "\n",
    "### AGAIN: NOT POSSIBLE to start like that because no remote encrypting is possible\n",
    "class Cifar10_model(sy.Plan): \n",
    "    def __init__(self):\n",
    "        super(Cifar10_model , self).__init__()\n",
    "        # ONLY WORKS WITH TWO PARTIES: FILE PR!!!!!\n",
    "        # syft/frameworks/torch/mpc/securenn.py in relu_deriv(a_sh), line 386 \"too many values to unpack (expected 2)\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        # Change network classifier to have 10 output classes (standard has 1000)\n",
    "        # See Transfer Learning Example from PyTorch \n",
    "        resnet.fc = nn.Linear(512, 10)\n",
    "        self.resnet = resnet\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.resnet(x)\n",
    "\n",
    "# Model Provider\n",
    "model_provider = CREATE_V_WORKERS(1, \"model_provider\")\n",
    "# Create model as plan\n",
    "cifar10_model = Cifar10_model()\n",
    "# Build plan with arbitrary input: (batch_size, channels, img_w, img_h) * intensitie value (not necessary)\n",
    "cifar10_model.build(sample_input)\n",
    "# Check if successful\n",
    "print(\"Build successful: \", cifar10_model.is_built)\n",
    "# Send model to model provider\n",
    "PTR_model = cifar10_model.tag(\"model\", \"cifar10\").send(model_provider)\n",
    "# Check if successful (ptr on model plan stored on worker)\n",
    "print(PTR_model)\n",
    "\n",
    "\n",
    "# TODO: CHECK if always true: Models aren't directly tagable or sendable -> First convert to plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vg4yqJBvuQ9V"
   },
   "outputs": [],
   "source": [
    "### TESTING ###\n",
    "\n",
    "# Test Forward Pass: Input of first batch of first teacher (batch are stored as (inp, target) tupels)\n",
    "sample_input_2 = PTR_dtrain_teachers[teachers[0].id][0][0]\n",
    "sample_target_2 = PTR_dtrain_teachers[teachers[0].id][0][1]\n",
    "sample_model = Cifar10Model()\n",
    "sample_model = sample_model.fix_precision().share(*hosting_groups[0], crypto_provider=crypto_provider, \n",
    "                                                  requires_grad=True)\n",
    "# WHY CAN'T I ACCESS THE MODEL POINTER?\n",
    "# Check if on same hosting_group\n",
    "#assert(sample_input.child.child.child.keys() == sample_model.child.child.child.keys())\n",
    "print(sample_input_2.shape)\n",
    "PTR_out = sample_model(sample_input_2)\n",
    "print(\"Forward Pass: \", PTR_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6D76wAEuQ9X"
   },
   "outputs": [],
   "source": [
    "### TESTING ###\n",
    "\n",
    "#Sample Forward Pass works - Now test criterion, optmizer and Backward Pass\n",
    "\n",
    "def criterion(pred, target):\n",
    "    # loss = F.nll_loss(output, target)  <-- not possible here\n",
    "    batch_size = pred.shape[0]\n",
    "    loss = ((pred - target)**2).sum().refresh()/batch_size\n",
    "    return loss\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(sample_model.parameters(), lr=0.01)\n",
    "optimizer = optimizer.fix_precision() \n",
    "\n",
    "loss = criterion(PTR_out, sample_target_2)\n",
    "# Backward Pass\n",
    "loss.backward()\n",
    "# Optimization Step\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yrUEM0NuQ9a"
   },
   "outputs": [],
   "source": [
    "### TESTING ###\n",
    "\n",
    "# Stats \n",
    "#loss = loss.get().float_precision()\n",
    "# Get predicted class per sample in batch \n",
    "print(sample_target_2.shape)\n",
    "PTR_target_class = torch.argmax(sample_target_2, dim=1).get().float_precision()\n",
    "PTR_pred_class = torch.argmax(PTR_out, dim=1).get().float_precision()\n",
    "# DOCH: SONST GEHT AUTOGRAD DINGS AUCH NICHT WEG!!!!!\n",
    "# Giant numbers because still fixed_precision numbers (could call float_precision but doesn't matter for comparison)\n",
    "print(PTR_pred_class)\n",
    "print(PTR_target_class)\n",
    "# Check how much are correct \n",
    "print(PTR_out.shape)\n",
    "print(sample_target_2.shape)\n",
    "temp2 = torch.eq(PTR_target_class, PTR_pred_class)\n",
    "#temp2 = temp2.get()\n",
    "print(temp2)\n",
    "# Get the \n",
    "numb_correct = sum(temp2).item()\n",
    "batch_size = PTR_out.shape[0]\n",
    "print(batch_size)\n",
    "bach_acc = numb_correct/batch_size\n",
    "\n",
    "print(\"Loss: \", loss.get().item())\n",
    "print(\"Batch_Accuracy: \", bach_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87wv5VnfuQ9d"
   },
   "outputs": [],
   "source": [
    "## DO NOT EXECUTE ##\n",
    "\n",
    "### OLD ###\n",
    "\n",
    "# DOING FL WITHOUT BEING A PARTICIPANT AND WITHOUT HELP OF PYGRID VERY COMPLICATED BECAUSE REMOTE ENCRYPTION\n",
    "# DOESN'T WORK (.share()) PLANS ONLY WORK WITH TENSORS...\n",
    "# DOING .SHARE MANUALLY WOULD REQUIRE KNOWING WHAT WORKERS EXIST, etc. -> THAT'S THE MAIN FUNCT. OF PYGRID!\n",
    "\n",
    "### Create DataLoaders consisting of pointers to encrypted data and model on hosting providers ###\n",
    "# TODO: Create a scenario where data and model are SMPC encrypted without hosting provider and \n",
    "#       hosting provider are only used if necessary for computation (Also Read SDPZ-Protocol) \n",
    "#       Also possibly use FederatedTrainingLoader from PySyft\n",
    "\n",
    "# SMPC-encrypt datasets and model using the hosting provider workers \n",
    "\n",
    "# TODO: Specifiy precision of converted tensor in args \n",
    "# This plan should make it possible to remotely encrypt data via SMPC-enryption (Additive Secret Sharing)\n",
    "\n",
    "@sy.func2plan()\n",
    "def remote_share(data, hosting_provider1, hosting_provider2, crypto_provider):\n",
    "    \"\"\"\n",
    "        Create plan which enables to remotely execute the share() method. \n",
    "        Is needed here to be able to remotely encrypt data via SMPC\n",
    "    \"\"\"\n",
    "    if data.type() == 'torch.FloatTensor': \n",
    "        data = data.fix_precision()\n",
    "    ptr = data.share(hosting_provider1, hosting_provider2, crypto_provider=crypto_provider)\n",
    "    return ptr\n",
    "\n",
    "# TODO: IS REMOTE SHARE POSSIBLE? DO we have to have a specific plan for every worker? \n",
    "# -> Think about defining overloading some of the functions or moving around? \n",
    "def send_to_all(data, workers):\n",
    "    \"\"\"\n",
    "        Send copys of some data to multiple workers \n",
    "    \"\"\"\n",
    "    ptrs = {}\n",
    "    for worker in workers: \n",
    "        # Use deepcopy because we want the plan on each worker and is data is nested we want to copy everything \n",
    "        # deepcopy also copies nested arrays e.g. (important for model sending for example)\n",
    "        ptrs[worker.id] = deepcopy(data).send(worker)\n",
    "    return ptrs\n",
    "\n",
    "hosting_provider = {}\n",
    "\n",
    "extra_hosting = True\n",
    "if extra_hosting: \n",
    "    hosting_provider[\"hosting\"] = CreateVWorker().....\n",
    "else: \n",
    "    hosting_provider[\"hosting\"]  = dataproviders.....\n",
    "\n",
    "# TODO: quick explanation of crypto_provider\n",
    "# Build plan\n",
    "remote_share.build(sample_input, hosting_provider[\"hosting\"][0],\n",
    "                   hosting_provider[\"hosting\"][1], hosting_provider[\"crypto\"])\n",
    "# Send to data_providers\n",
    "PTRS_remote_share = send_to_all(remote_share)\n",
    "PTRS_remote_share[0]\n",
    "\n",
    "#remote_share(sample_input, hosting_provider[\"hosting\"], hosting_provider[\"crypto\"])\n",
    "#ptr = sample_input.fix_precision().share(*hosting_provider[\"hosting\"], crypto_provider=hosting_provider[\"crypto\"], \n",
    "#                                        requires_grad=False)\n",
    "#remote_share.build(sample_input, hosting_provider[\"hosting\"], hosting_provider[\"crypto\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WluyJ_5KuQ9f"
   },
   "outputs": [],
   "source": [
    "### ADITIONAL TESTS ####\n",
    "\n",
    "# Test: compute with tensor which are saved on different devices -> Not possible \n",
    "# Logically: Additive Secret Sharing Concept: Computation can only be made in an encrypted, decentralized manner\n",
    "# if input tensors to calculation exist on all parties that are participating in calculation. \n",
    "# (A share of all participating variables has to be on all participating workers)\n",
    "worker1 = sy.VirtualWorker(hook, id=\"worker1\")\n",
    "worker2 = sy.VirtualWorker(hook, id=\"worker2\")\n",
    "worker3 = sy.VirtualWorker(hook, id=\"worker3\")\n",
    "crypto_provider = sy.VirtualWorker(hook, id=\"c_provider\")\n",
    "test = torch.tensor([1., 2.])\n",
    "model = nn.Sequential(nn.Linear(2, 1), nn.ReLU())\n",
    "model(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STSrW1x5uQ9i"
   },
   "outputs": [],
   "source": [
    "w_group = [worker1, worker2]\n",
    "w_group2 = [worker2, worker3]\n",
    "w_group3 = [worker1, worker3]\n",
    "PTR_test = test.fix_precision().tag(\"test1\").share(*w_group, crypto_provider=crypto_provider)\n",
    "print(PTR_test)\n",
    "\n",
    "test2 = torch.tensor([2., 4.])\n",
    "PTR_test2 = test2.fix_precision().share(*w_group2, crypto_provider=crypto_provider)\n",
    "print(PTR_test2)\n",
    "\n",
    "PTR_model = model.fix_precision().share(*w_group, crypto_provider=crypto_provider)\n",
    "print(PTR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfFyBvzkuQ9k"
   },
   "outputs": [],
   "source": [
    "PTR_test.child.child.child.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZwny1QMuQ9m"
   },
   "outputs": [],
   "source": [
    "# Two questions: \n",
    "# 1. Why can I only use tagging if I specifiy data through creation a worker (data argument)\n",
    "# 2. Why can't I only pass in one variable to VirtualWorker at beginning? \n",
    "\n",
    "x11 = torch.tensor([-1, 2.]).tag('input_data')\n",
    "x12 = torch.tensor([1, -2.]).tag('input_data2')\n",
    "x13 = torch.tensor([1, -2.]).tag('input_data3')\n",
    "\n",
    "device_1 = sy.VirtualWorker(hook, id=\"device_1\", data=(x11, x12)) \n",
    "(x11, x12).send(device_1)\n",
    "\n",
    "print(device_1.search(\"input_data3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qAIPkuXruQ9p",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ISSUE!!!!!!\n",
    "out1 = PTR_model(PTR_test)\n",
    "out2 = PTR_model(PTR_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3SSMmQiuQ9s"
   },
   "outputs": [],
   "source": [
    "# QUESTIONS: \n",
    "# Why does the data also need \"requires_grad=True\" also autograd_tensor?\n",
    "# Fundamentally: How is it restricted who can call .get() on the pointers? (Passive -> Active Security)\n",
    "# Why does DP-Def. (constraint) only describe an upper bound? If Pr[M(x) e S] + Pr[M(y) e S] = 1? (Prob. not)\n",
    "# Cuda doesn't with secureNN: Float can't be converted to Long .... Check in more detail (tested in Google Colab)\n",
    "# max pooling layer \n",
    "        # PR: !!! RuntimeError: \"max_pool2d_with_indices_cpu\" not implemented for 'Long'\n",
    "        # Should work as part of secureNN protocol\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "# get_all() would be a cool functionality as often pointer array on pointer data (issue/PR?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9WlUOxFuQ9v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6M14bGH-uQ9x"
   },
   "outputs": [],
   "source": [
    "workers = hosting_groups[0]\n",
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAeTfHvAuQ9z"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net , self).__init__()\n",
    "        # ONLY WORKS WITH TWO PARTIES: FILE PR!!!!!\n",
    "        # syft/frameworks/torch/mpc/securenn.py in relu_deriv(a_sh), line 386 \"too many values to unpack (expected 2)\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        # Change network classifier to have 10 output classes (standard has 1000)\n",
    "        # See Transfer Learning Example from PyTorch \n",
    "        resnet.fc = nn.Linear(512, 10)\n",
    "        self.resnet = resnet\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.resnet(x)\n",
    "\n",
    "sample_input = torch.randn((20, 3, 32, 32))*255\n",
    "sample_model = Net()\n",
    "print(sample_input.shape)\n",
    "print(sample_model(sample_input).shape)\n",
    "ptr_si = sample_input.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "ptr_sm = sample_model.fix_precision().share(*workers, crypto_provider=crypto_provider, requires_grad=True)\n",
    "print(ptr_si)\n",
    "print(ptr_sm)\n",
    "print(ptr_sm(ptr_si))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "OpenMined_Complete_Example_FL_DP_Grid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('py-grid': conda)",
   "language": "python",
   "name": "python38264bitpygridcondaf38530e3ed324efaac7c8fb1b149269d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e8eeb282352437097c6955a2cad3b95": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b53b397d479414c93c27f5d641d587e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e8eeb282352437097c6955a2cad3b95",
      "placeholder": "​",
      "style": "IPY_MODEL_e057d7850d48478eb6dcbd64c5d897a5",
      "value": " 170500096/? [00:20&lt;00:00, 83243541.81it/s]"
     }
    },
    "65a169eb06ec4bc5a1679e0a2e923778": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8d63b715b45a46c7ad8edbdc24471260": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97a06761c16a422bad8fcf1352550064": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc92e82516dc4ad28a668bffb17f1efc",
       "IPY_MODEL_4b53b397d479414c93c27f5d641d587e"
      ],
      "layout": "IPY_MODEL_8d63b715b45a46c7ad8edbdc24471260"
     }
    },
    "b137011132224017852a1f3301739595": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc92e82516dc4ad28a668bffb17f1efc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b137011132224017852a1f3301739595",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65a169eb06ec4bc5a1679e0a2e923778",
      "value": 1
     }
    },
    "e057d7850d48478eb6dcbd64c5d897a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
