{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Asynchronous federated learning on MNIST\n",
    "\n",
    "This notebook will go through the steps to run a federated learning via websocket workers in an asynchronous way. We will use federated averaging to join the remotely trained models. \n",
    "\n",
    "Authors:\n",
    "- Silvia - GitHub [@midokura-silvia](https://github.com/midokura-silvia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning setup\n",
    "\n",
    "For a Federated Learning we need different participants:\n",
    "\n",
    "* _Workers_ that own datasets.\n",
    "\n",
    "* An entity that knows the workers and the dataset name that lives in each worker. We'll call this a _scheduler_.\n",
    "\n",
    "Each worker is represented by two parts, a proxy local to the scheduler (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation: Start the websocket workers\n",
    "So first, we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_servers.py\n",
    "```\n",
    "\n",
    "#### What's going on?\n",
    "\n",
    "The script will instantiate three workers, Alice, Bob and Charlie and prepare their local data. \n",
    "Each worker is set up to have a subset of the MNIST training dataset. \n",
    "Alice holds all images corresponding to the digits 0-3, \n",
    "Bob holds all images corresponding to the digits 4-6 and \n",
    "Charlie holds all images corresponding to the digits 7-9.\n",
    "\n",
    "| Worker      | Digits in local dataset | Number of samples |\n",
    "| ----------- | ----------------------- | ----------------- |\n",
    "| Alice       | 0-3                     | 24754             |\n",
    "| Bob         | 4-6                     | 17181             |\n",
    "| Charlie     | 7-9                     | 18065             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following to see the code of the function that starts a worker\n",
    "# import run_websocket_server\n",
    "\n",
    "# print(inspect.getsource(run_websocket_server.start_websocket_server_worker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "import syft as sy\n",
    "from syft.workers import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syft.frameworks.torch.federated import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_websocket_client as rwc\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, cuda=False, federate_after_n_batches=10, lr=0.1, save_model=False, seed=1, test_batch_size=128, training_rounds=100, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "args = rwc.define_and_get_arguments(args=[])\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local proxies to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WebsocketClientWorker id:alice #objects local:0 #objects remote: 350>, <WebsocketClientWorker id:bob #objects local:0 #objects remote: 346>, <WebsocketClientWorker id:charlie #objects local:0 #objects remote: 349>]\n"
     ]
    }
   ],
   "source": [
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "worker_instances = [alice, bob, charlie]\n",
    "print(worker_instances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a scheduler\n",
    "\n",
    "We'll use this notebook as a scheduler, for this we'll need to:\n",
    "\n",
    "* Have a model\n",
    "* Have a loss function\n",
    "* Define an optimizer\n",
    "* Define hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "Let's instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Net(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(Net, self).__init__()\n",
      "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
      "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
      "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
      "        self.fc2 = nn.Linear(500, 10)\n",
      "\n",
      "    def forward(self, x):\n",
      "        x = F.relu(self.conv1(x))\n",
      "        x = F.max_pool2d(x, 2, 2)\n",
      "        x = F.relu(self.conv2(x))\n",
      "        x = F.max_pool2d(x, 2, 2)\n",
      "        x = x.view(-1, 4 * 4 * 50)\n",
      "        x = F.relu(self.fc1(x))\n",
      "        x = self.fc2(x)\n",
      "        return F.log_softmax(x, dim=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(rwc.Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the training, let's load the MNIST test data and configure the logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"../data\",\n",
    "            train=False,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "(data, target) = test_loader.__iter__().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the logging of the training process.\n",
    "import logging\n",
    "logger = logging.getLogger(\"run_websocket_client\")\n",
    "if not len(logger.handlers):\n",
    "    FORMAT = \"%(asctime)s - %(message)s\"\n",
    "    DATE_FMT = \"%H:%M:%S\"\n",
    "    formatter = logging.Formatter(FORMAT, DATE_FMT)\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.propagate = False\n",
    "LOG_LEVEL = logging.DEBUG\n",
    "logger.setLevel(LOG_LEVEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training\n",
    "\n",
    "Now we are ready to start the federated training. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model.\n",
    "\n",
    "Every 10th training round we will evaluate the performance of the models returned by the workers and of the model obtained by federated averaging. \n",
    "\n",
    "The performance will be given both as the accuracy (ratio of correct predictions) and as the histograms of predicted digits. This is of interest, as each worker only owns a subset of the digits. Therefore, in the beginning each worker will only predict 'his' numbers and only know about the other numbers via the federated averaging process.\n",
    "\n",
    "The training is done in an asynchronous manner. This means that the scheduler just tell the workers to train and does not block to wait for the result of the training before talking to the next worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the training are given in the arguments. \n",
    "Each worker will train on a given number of batches, given by the value of federate_after_n_batches.\n",
    "The training batch size and learning rate are also configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federate_after_n_batches: 10\n",
      "Batch size: 32\n",
      "Initial learning rate: 0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Federate_after_n_batches: \" + str(args.federate_after_n_batches))\n",
    "print(\"Batch size: \" + str(args.batch_size))\n",
    "print(\"Initial learning rate: \" + str(args.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:42:48 - Starting training round 1/100\n",
      "09:42:48 - Training round 1, calling fit on worker: charlie, lr = 0.100\n",
      "09:42:48 - Training round 1, calling fit on worker: alice, lr = 0.100\n",
      "09:42:49 - Training round 1, calling fit on worker: bob, lr = 0.100\n",
      "09:42:51 - Training round: 1, worker: bob, avg_loss: tensor(2.7445, grad_fn=<MeanBackward1>)\n",
      "09:42:52 - Training round: 1, worker: charlie, avg_loss: tensor(1.5985, grad_fn=<MeanBackward1>)\n",
      "09:42:54 - Training round: 1, worker: alice, avg_loss: tensor(1.1139, grad_fn=<MeanBackward1>)\n",
      "09:42:58 - Prediction hist: [ 8327  1331  240  102  0  0  0  0  0  0]\n",
      "09:42:58 - alice: Test set: Average loss: 0.0269, Accuracy: 2192/10000 (22)\n",
      "09:43:00 - Prediction hist: [ 0  0  0  0  5097  0  4903  0  0  0]\n",
      "09:43:00 - bob: Test set: Average loss: 0.0182, Accuracy: 1779/10000 (18)\n",
      "09:43:02 - Prediction hist: [ 0  0  0  0  0  0  0  0  0  10000]\n",
      "09:43:02 - charlie: Test set: Average loss: 0.0200, Accuracy: 1009/10000 (10)\n",
      "09:43:05 - Prediction hist: [ 4556  0  0  0  0  0  54  1352  4022  16]\n",
      "09:43:05 - Federated model: Test set: Average loss: 0.0179, Accuracy: 2130/10000 (21)\n",
      "09:43:05 - Starting training round 2/100\n",
      "09:43:05 - Training round 2, calling fit on worker: bob, lr = 0.098\n",
      "09:43:05 - Training round 2, calling fit on worker: alice, lr = 0.098\n",
      "09:43:05 - Training round 2, calling fit on worker: charlie, lr = 0.098\n",
      "09:43:08 - Training round: 2, worker: bob, avg_loss: tensor(1.0034, grad_fn=<MeanBackward1>)\n",
      "09:43:10 - Training round: 2, worker: alice, avg_loss: tensor(1.2521, grad_fn=<MeanBackward1>)\n",
      "09:43:11 - Training round: 2, worker: charlie, avg_loss: tensor(1.1845, grad_fn=<MeanBackward1>)\n",
      "09:43:12 - Starting training round 3/100\n",
      "09:43:12 - Training round 3, calling fit on worker: alice, lr = 0.096\n",
      "09:43:12 - Training round 3, calling fit on worker: bob, lr = 0.096\n",
      "09:43:12 - Training round 3, calling fit on worker: charlie, lr = 0.096\n",
      "09:43:13 - Training round: 3, worker: bob, avg_loss: tensor(0.9281, grad_fn=<MeanBackward1>)\n",
      "09:43:15 - Training round: 3, worker: charlie, avg_loss: tensor(0.6142, grad_fn=<MeanBackward1>)\n",
      "09:43:16 - Training round: 3, worker: alice, avg_loss: tensor(0.4381, grad_fn=<MeanBackward1>)\n",
      "09:43:17 - Starting training round 4/100\n",
      "09:43:17 - Training round 4, calling fit on worker: alice, lr = 0.094\n",
      "09:43:18 - Training round 4, calling fit on worker: charlie, lr = 0.094\n",
      "09:43:18 - Training round 4, calling fit on worker: bob, lr = 0.094\n",
      "09:43:19 - Training round: 4, worker: alice, avg_loss: tensor(0.7261, grad_fn=<MeanBackward1>)\n",
      "09:43:21 - Training round: 4, worker: charlie, avg_loss: tensor(0.3941, grad_fn=<MeanBackward1>)\n",
      "09:43:22 - Training round: 4, worker: bob, avg_loss: tensor(0.2606, grad_fn=<MeanBackward1>)\n",
      "09:43:23 - Starting training round 5/100\n",
      "09:43:23 - Training round 5, calling fit on worker: charlie, lr = 0.092\n",
      "09:43:23 - Training round 5, calling fit on worker: alice, lr = 0.092\n",
      "09:43:23 - Training round 5, calling fit on worker: bob, lr = 0.092\n",
      "09:43:25 - Training round: 5, worker: charlie, avg_loss: tensor(1.9466, grad_fn=<MeanBackward1>)\n",
      "09:43:26 - Training round: 5, worker: alice, avg_loss: tensor(0.0968, grad_fn=<MeanBackward1>)\n",
      "09:43:27 - Training round: 5, worker: bob, avg_loss: tensor(0.1922, grad_fn=<MeanBackward1>)\n",
      "09:43:28 - Starting training round 6/100\n",
      "09:43:28 - Training round 6, calling fit on worker: charlie, lr = 0.090\n",
      "09:43:28 - Training round 6, calling fit on worker: bob, lr = 0.090\n",
      "09:43:29 - Training round 6, calling fit on worker: alice, lr = 0.090\n",
      "09:43:30 - Training round: 6, worker: alice, avg_loss: tensor(0.5653, grad_fn=<MeanBackward1>)\n",
      "09:43:31 - Training round: 6, worker: bob, avg_loss: tensor(0.0294, grad_fn=<MeanBackward1>)\n",
      "09:43:32 - Training round: 6, worker: charlie, avg_loss: tensor(0.2061, grad_fn=<MeanBackward1>)\n",
      "09:43:33 - Starting training round 7/100\n",
      "09:43:33 - Training round 7, calling fit on worker: alice, lr = 0.089\n",
      "09:43:33 - Training round 7, calling fit on worker: charlie, lr = 0.089\n",
      "09:43:33 - Training round 7, calling fit on worker: bob, lr = 0.089\n",
      "09:43:35 - Training round: 7, worker: alice, avg_loss: tensor(0.1133, grad_fn=<MeanBackward1>)\n",
      "09:43:36 - Training round: 7, worker: bob, avg_loss: tensor(0.0446, grad_fn=<MeanBackward1>)\n",
      "09:43:37 - Training round: 7, worker: charlie, avg_loss: tensor(0.1715, grad_fn=<MeanBackward1>)\n",
      "09:43:38 - Starting training round 8/100\n",
      "09:43:38 - Training round 8, calling fit on worker: charlie, lr = 0.087\n",
      "09:43:38 - Training round 8, calling fit on worker: alice, lr = 0.087\n",
      "09:43:38 - Training round 8, calling fit on worker: bob, lr = 0.087\n",
      "09:43:40 - Training round: 8, worker: charlie, avg_loss: tensor(0.4156, grad_fn=<MeanBackward1>)\n",
      "09:43:41 - Training round: 8, worker: alice, avg_loss: tensor(0.3371, grad_fn=<MeanBackward1>)\n",
      "09:43:42 - Training round: 8, worker: bob, avg_loss: tensor(0.0491, grad_fn=<MeanBackward1>)\n",
      "09:43:43 - Starting training round 9/100\n",
      "09:43:43 - Training round 9, calling fit on worker: alice, lr = 0.085\n",
      "09:43:43 - Training round 9, calling fit on worker: bob, lr = 0.085\n",
      "09:43:43 - Training round 9, calling fit on worker: charlie, lr = 0.085\n",
      "09:43:45 - Training round: 9, worker: charlie, avg_loss: tensor(0.0625, grad_fn=<MeanBackward1>)\n",
      "09:43:46 - Training round: 9, worker: alice, avg_loss: tensor(0.0840, grad_fn=<MeanBackward1>)\n",
      "09:43:47 - Training round: 9, worker: bob, avg_loss: tensor(0.0314, grad_fn=<MeanBackward1>)\n",
      "09:43:48 - Starting training round 10/100\n",
      "09:43:48 - Training round 10, calling fit on worker: alice, lr = 0.083\n",
      "09:43:48 - Training round 10, calling fit on worker: bob, lr = 0.083\n",
      "09:43:48 - Training round 10, calling fit on worker: charlie, lr = 0.083\n",
      "09:43:50 - Training round: 10, worker: alice, avg_loss: tensor(0.1781, grad_fn=<MeanBackward1>)\n",
      "09:43:51 - Training round: 10, worker: charlie, avg_loss: tensor(0.1119, grad_fn=<MeanBackward1>)\n",
      "09:43:52 - Training round: 10, worker: bob, avg_loss: tensor(0.1251, grad_fn=<MeanBackward1>)\n",
      "09:43:53 - Starting training round 11/100\n",
      "09:43:53 - Training round 11, calling fit on worker: alice, lr = 0.082\n",
      "09:43:53 - Training round 11, calling fit on worker: charlie, lr = 0.082\n",
      "09:43:53 - Training round 11, calling fit on worker: bob, lr = 0.082\n",
      "09:43:55 - Training round: 11, worker: alice, avg_loss: tensor(0.3459, grad_fn=<MeanBackward1>)\n",
      "09:43:56 - Training round: 11, worker: charlie, avg_loss: tensor(0.1570, grad_fn=<MeanBackward1>)\n",
      "09:43:57 - Training round: 11, worker: bob, avg_loss: tensor(0.0900, grad_fn=<MeanBackward1>)\n",
      "09:44:01 - Prediction hist: [ 1391  1048  2228  4575  487  26  75  67  27  76]\n",
      "09:44:01 - alice: Test set: Average loss: 0.0145, Accuracy: 4718/10000 (47)\n",
      "09:44:03 - Prediction hist: [ 7  1031  412  0  2221  3214  2390  725  0  0]\n",
      "09:44:03 - bob: Test set: Average loss: 0.0168, Accuracy: 4872/10000 (49)\n",
      "09:44:05 - Prediction hist: [ 306  242  93  0  0  0  321  2307  4600  2131]\n",
      "09:44:05 - charlie: Test set: Average loss: 0.0182, Accuracy: 3794/10000 (38)\n",
      "09:44:07 - Prediction hist: [ 996  1117  1030  939  691  965  1042  1124  866  1230]\n",
      "09:44:07 - Federated model: Test set: Average loss: 0.0031, Accuracy: 8910/10000 (89)\n",
      "09:44:07 - Starting training round 12/100\n",
      "09:44:08 - Training round 12, calling fit on worker: charlie, lr = 0.080\n",
      "09:44:08 - Training round 12, calling fit on worker: alice, lr = 0.080\n",
      "09:44:08 - Training round 12, calling fit on worker: bob, lr = 0.080\n",
      "09:44:09 - Training round: 12, worker: alice, avg_loss: tensor(0.0522, grad_fn=<MeanBackward1>)\n",
      "09:44:10 - Training round: 12, worker: bob, avg_loss: tensor(0.0402, grad_fn=<MeanBackward1>)\n",
      "09:44:12 - Training round: 12, worker: charlie, avg_loss: tensor(0.3846, grad_fn=<MeanBackward1>)\n",
      "09:44:13 - Starting training round 13/100\n",
      "09:44:13 - Training round 13, calling fit on worker: charlie, lr = 0.078\n",
      "09:44:13 - Training round 13, calling fit on worker: alice, lr = 0.078\n",
      "09:44:13 - Training round 13, calling fit on worker: bob, lr = 0.078\n",
      "09:44:15 - Training round: 13, worker: bob, avg_loss: tensor(0.1641, grad_fn=<MeanBackward1>)\n",
      "09:44:16 - Training round: 13, worker: alice, avg_loss: tensor(0.0432, grad_fn=<MeanBackward1>)\n",
      "09:44:17 - Training round: 13, worker: charlie, avg_loss: tensor(0.3050, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:44:18 - Starting training round 14/100\n",
      "09:44:18 - Training round 14, calling fit on worker: alice, lr = 0.077\n",
      "09:44:18 - Training round 14, calling fit on worker: bob, lr = 0.077\n",
      "09:44:19 - Training round 14, calling fit on worker: charlie, lr = 0.077\n",
      "09:44:20 - Training round: 14, worker: charlie, avg_loss: tensor(0.1591, grad_fn=<MeanBackward1>)\n",
      "09:44:21 - Training round: 14, worker: bob, avg_loss: tensor(0.0101, grad_fn=<MeanBackward1>)\n",
      "09:44:23 - Training round: 14, worker: alice, avg_loss: tensor(0.0155, grad_fn=<MeanBackward1>)\n",
      "09:44:24 - Starting training round 15/100\n",
      "09:44:24 - Training round 15, calling fit on worker: bob, lr = 0.075\n",
      "09:44:24 - Training round 15, calling fit on worker: charlie, lr = 0.075\n",
      "09:44:24 - Training round 15, calling fit on worker: alice, lr = 0.075\n",
      "09:44:25 - Training round: 15, worker: charlie, avg_loss: tensor(0.2015, grad_fn=<MeanBackward1>)\n",
      "09:44:27 - Training round: 15, worker: alice, avg_loss: tensor(0.1064, grad_fn=<MeanBackward1>)\n",
      "09:44:28 - Training round: 15, worker: bob, avg_loss: tensor(0.0517, grad_fn=<MeanBackward1>)\n",
      "09:44:29 - Starting training round 16/100\n",
      "09:44:29 - Training round 16, calling fit on worker: charlie, lr = 0.074\n",
      "09:44:29 - Training round 16, calling fit on worker: bob, lr = 0.074\n",
      "09:44:29 - Training round 16, calling fit on worker: alice, lr = 0.074\n",
      "09:44:30 - Training round: 16, worker: charlie, avg_loss: tensor(0.0876, grad_fn=<MeanBackward1>)\n",
      "09:44:32 - Training round: 16, worker: alice, avg_loss: tensor(0.1455, grad_fn=<MeanBackward1>)\n",
      "09:44:33 - Training round: 16, worker: bob, avg_loss: tensor(0.0221, grad_fn=<MeanBackward1>)\n",
      "09:44:34 - Starting training round 17/100\n",
      "09:44:34 - Training round 17, calling fit on worker: alice, lr = 0.072\n",
      "09:44:34 - Training round 17, calling fit on worker: bob, lr = 0.072\n",
      "09:44:34 - Training round 17, calling fit on worker: charlie, lr = 0.072\n",
      "09:44:35 - Training round: 17, worker: charlie, avg_loss: tensor(0.0452, grad_fn=<MeanBackward1>)\n",
      "09:44:37 - Training round: 17, worker: bob, avg_loss: tensor(0.0149, grad_fn=<MeanBackward1>)\n",
      "09:44:38 - Training round: 17, worker: alice, avg_loss: tensor(0.2631, grad_fn=<MeanBackward1>)\n",
      "09:44:39 - Starting training round 18/100\n",
      "09:44:39 - Training round 18, calling fit on worker: alice, lr = 0.071\n",
      "09:44:39 - Training round 18, calling fit on worker: charlie, lr = 0.071\n",
      "09:44:39 - Training round 18, calling fit on worker: bob, lr = 0.071\n",
      "09:44:41 - Training round: 18, worker: charlie, avg_loss: tensor(0.0928, grad_fn=<MeanBackward1>)\n",
      "09:44:42 - Training round: 18, worker: alice, avg_loss: tensor(0.0252, grad_fn=<MeanBackward1>)\n",
      "09:44:43 - Training round: 18, worker: bob, avg_loss: tensor(0.0039, grad_fn=<MeanBackward1>)\n",
      "09:44:45 - Starting training round 19/100\n",
      "09:44:45 - Training round 19, calling fit on worker: charlie, lr = 0.070\n",
      "09:44:45 - Training round 19, calling fit on worker: alice, lr = 0.070\n",
      "09:44:45 - Training round 19, calling fit on worker: bob, lr = 0.070\n",
      "09:44:45 - Training round: 19, worker: charlie, avg_loss: tensor(0.0516, grad_fn=<MeanBackward1>)\n",
      "09:44:47 - Training round: 19, worker: bob, avg_loss: tensor(0.0067, grad_fn=<MeanBackward1>)\n",
      "09:44:48 - Training round: 19, worker: alice, avg_loss: tensor(0.0240, grad_fn=<MeanBackward1>)\n",
      "09:44:49 - Starting training round 20/100\n",
      "09:44:49 - Training round 20, calling fit on worker: charlie, lr = 0.068\n",
      "09:44:49 - Training round 20, calling fit on worker: bob, lr = 0.068\n",
      "09:44:49 - Training round 20, calling fit on worker: alice, lr = 0.068\n",
      "09:44:51 - Training round: 20, worker: bob, avg_loss: tensor(0.0047, grad_fn=<MeanBackward1>)\n",
      "09:44:52 - Training round: 20, worker: charlie, avg_loss: tensor(0.3328, grad_fn=<MeanBackward1>)\n",
      "09:44:53 - Training round: 20, worker: alice, avg_loss: tensor(0.0346, grad_fn=<MeanBackward1>)\n",
      "09:44:54 - Starting training round 21/100\n",
      "09:44:54 - Training round 21, calling fit on worker: alice, lr = 0.067\n",
      "09:44:54 - Training round 21, calling fit on worker: charlie, lr = 0.067\n",
      "09:44:54 - Training round 21, calling fit on worker: bob, lr = 0.067\n",
      "09:44:55 - Training round: 21, worker: alice, avg_loss: tensor(0.3417, grad_fn=<MeanBackward1>)\n",
      "09:44:57 - Training round: 21, worker: bob, avg_loss: tensor(0.0132, grad_fn=<MeanBackward1>)\n",
      "09:44:58 - Training round: 21, worker: charlie, avg_loss: tensor(0.0811, grad_fn=<MeanBackward1>)\n",
      "09:45:01 - Prediction hist: [ 1193  1406  1541  1874  982  468  709  547  561  719]\n",
      "09:45:01 - alice: Test set: Average loss: 0.0048, Accuracy: 7906/10000 (79)\n",
      "09:45:03 - Prediction hist: [ 14  1041  857  261  2006  2860  1958  940  63  0]\n",
      "09:45:03 - bob: Test set: Average loss: 0.0129, Accuracy: 5878/10000 (59)\n",
      "09:45:06 - Prediction hist: [ 332  482  455  397  0  87  389  1347  4233  2278]\n",
      "09:45:06 - charlie: Test set: Average loss: 0.0125, Accuracy: 5055/10000 (51)\n",
      "09:45:08 - Prediction hist: [ 915  1138  1037  983  1044  985  1022  1015  937  924]\n",
      "09:45:08 - Federated model: Test set: Average loss: 0.0018, Accuracy: 9372/10000 (94)\n",
      "09:45:08 - Starting training round 22/100\n",
      "09:45:08 - Training round 22, calling fit on worker: bob, lr = 0.065\n",
      "09:45:08 - Training round 22, calling fit on worker: alice, lr = 0.065\n",
      "09:45:08 - Training round 22, calling fit on worker: charlie, lr = 0.065\n",
      "09:45:09 - Training round: 22, worker: alice, avg_loss: tensor(0.1547, grad_fn=<MeanBackward1>)\n",
      "09:45:10 - Training round: 22, worker: charlie, avg_loss: tensor(0.0236, grad_fn=<MeanBackward1>)\n",
      "09:45:12 - Training round: 22, worker: bob, avg_loss: tensor(0.0031, grad_fn=<MeanBackward1>)\n",
      "09:45:13 - Starting training round 23/100\n",
      "09:45:13 - Training round 23, calling fit on worker: bob, lr = 0.064\n",
      "09:45:13 - Training round 23, calling fit on worker: charlie, lr = 0.064\n",
      "09:45:13 - Training round 23, calling fit on worker: alice, lr = 0.064\n",
      "09:45:14 - Training round: 23, worker: bob, avg_loss: tensor(0.0027, grad_fn=<MeanBackward1>)\n",
      "09:45:16 - Training round: 23, worker: alice, avg_loss: tensor(0.0095, grad_fn=<MeanBackward1>)\n",
      "09:45:17 - Training round: 23, worker: charlie, avg_loss: tensor(0.1091, grad_fn=<MeanBackward1>)\n",
      "09:45:18 - Starting training round 24/100\n",
      "09:45:18 - Training round 24, calling fit on worker: charlie, lr = 0.063\n",
      "09:45:18 - Training round 24, calling fit on worker: bob, lr = 0.063\n",
      "09:45:18 - Training round 24, calling fit on worker: alice, lr = 0.063\n",
      "09:45:20 - Training round: 24, worker: charlie, avg_loss: tensor(0.0596, grad_fn=<MeanBackward1>)\n",
      "09:45:21 - Training round: 24, worker: alice, avg_loss: tensor(0.0108, grad_fn=<MeanBackward1>)\n",
      "09:45:22 - Training round: 24, worker: bob, avg_loss: tensor(0.0164, grad_fn=<MeanBackward1>)\n",
      "09:45:23 - Starting training round 25/100\n",
      "09:45:23 - Training round 25, calling fit on worker: alice, lr = 0.062\n",
      "09:45:23 - Training round 25, calling fit on worker: bob, lr = 0.062\n",
      "09:45:23 - Training round 25, calling fit on worker: charlie, lr = 0.062\n",
      "09:45:24 - Training round: 25, worker: bob, avg_loss: tensor(0.0011, grad_fn=<MeanBackward1>)\n",
      "09:45:26 - Training round: 25, worker: charlie, avg_loss: tensor(0.3236, grad_fn=<MeanBackward1>)\n",
      "09:45:27 - Training round: 25, worker: alice, avg_loss: tensor(0.1287, grad_fn=<MeanBackward1>)\n",
      "09:45:28 - Starting training round 26/100\n",
      "09:45:28 - Training round 26, calling fit on worker: charlie, lr = 0.060\n",
      "09:45:28 - Training round 26, calling fit on worker: bob, lr = 0.060\n",
      "09:45:28 - Training round 26, calling fit on worker: alice, lr = 0.060\n",
      "09:45:30 - Training round: 26, worker: alice, avg_loss: tensor(0.0709, grad_fn=<MeanBackward1>)\n",
      "09:45:31 - Training round: 26, worker: charlie, avg_loss: tensor(0.1776, grad_fn=<MeanBackward1>)\n",
      "09:45:32 - Training round: 26, worker: bob, avg_loss: tensor(0.0338, grad_fn=<MeanBackward1>)\n",
      "09:45:33 - Starting training round 27/100\n",
      "09:45:33 - Training round 27, calling fit on worker: charlie, lr = 0.059\n",
      "09:45:33 - Training round 27, calling fit on worker: alice, lr = 0.059\n",
      "09:45:33 - Training round 27, calling fit on worker: bob, lr = 0.059\n",
      "09:45:35 - Training round: 27, worker: alice, avg_loss: tensor(0.0749, grad_fn=<MeanBackward1>)\n",
      "09:45:36 - Training round: 27, worker: charlie, avg_loss: tensor(0.1101, grad_fn=<MeanBackward1>)\n",
      "09:45:37 - Training round: 27, worker: bob, avg_loss: tensor(0.0071, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:45:38 - Starting training round 28/100\n",
      "09:45:38 - Training round 28, calling fit on worker: alice, lr = 0.058\n",
      "09:45:38 - Training round 28, calling fit on worker: bob, lr = 0.058\n",
      "09:45:38 - Training round 28, calling fit on worker: charlie, lr = 0.058\n",
      "09:45:40 - Training round: 28, worker: bob, avg_loss: tensor(0.0012, grad_fn=<MeanBackward1>)\n",
      "09:45:41 - Training round: 28, worker: alice, avg_loss: tensor(0.1312, grad_fn=<MeanBackward1>)\n",
      "09:45:42 - Training round: 28, worker: charlie, avg_loss: tensor(0.0675, grad_fn=<MeanBackward1>)\n",
      "09:45:43 - Starting training round 29/100\n",
      "09:45:43 - Training round 29, calling fit on worker: charlie, lr = 0.057\n",
      "09:45:44 - Training round 29, calling fit on worker: bob, lr = 0.057\n",
      "09:45:44 - Training round 29, calling fit on worker: alice, lr = 0.057\n",
      "09:45:45 - Training round: 29, worker: bob, avg_loss: tensor(0.0881, grad_fn=<MeanBackward1>)\n",
      "09:45:46 - Training round: 29, worker: alice, avg_loss: tensor(0.0110, grad_fn=<MeanBackward1>)\n",
      "09:45:48 - Training round: 29, worker: charlie, avg_loss: tensor(0.1433, grad_fn=<MeanBackward1>)\n",
      "09:45:49 - Starting training round 30/100\n",
      "09:45:49 - Training round 30, calling fit on worker: charlie, lr = 0.056\n",
      "09:45:49 - Training round 30, calling fit on worker: bob, lr = 0.056\n",
      "09:45:49 - Training round 30, calling fit on worker: alice, lr = 0.056\n",
      "09:45:50 - Training round: 30, worker: charlie, avg_loss: tensor(0.0120, grad_fn=<MeanBackward1>)\n",
      "09:45:51 - Training round: 30, worker: bob, avg_loss: tensor(0.0191, grad_fn=<MeanBackward1>)\n",
      "09:45:53 - Training round: 30, worker: alice, avg_loss: tensor(0.1566, grad_fn=<MeanBackward1>)\n",
      "09:45:54 - Starting training round 31/100\n",
      "09:45:54 - Training round 31, calling fit on worker: alice, lr = 0.055\n",
      "09:45:54 - Training round 31, calling fit on worker: bob, lr = 0.055\n",
      "09:45:54 - Training round 31, calling fit on worker: charlie, lr = 0.055\n",
      "09:45:55 - Training round: 31, worker: alice, avg_loss: tensor(0.0203, grad_fn=<MeanBackward1>)\n",
      "09:45:56 - Training round: 31, worker: bob, avg_loss: tensor(0.0060, grad_fn=<MeanBackward1>)\n",
      "09:45:58 - Training round: 31, worker: charlie, avg_loss: tensor(0.0702, grad_fn=<MeanBackward1>)\n",
      "09:46:01 - Prediction hist: [ 1291  1396  1250  1941  905  277  642  812  681  805]\n",
      "09:46:01 - alice: Test set: Average loss: 0.0044, Accuracy: 8141/10000 (81)\n",
      "09:46:03 - Prediction hist: [ 440  1035  925  433  1725  2485  1652  888  338  79]\n",
      "09:46:03 - bob: Test set: Average loss: 0.0073, Accuracy: 6837/10000 (68)\n",
      "09:46:05 - Prediction hist: [ 722  1008  710  652  14  396  938  1293  1975  2292]\n",
      "09:46:05 - charlie: Test set: Average loss: 0.0062, Accuracy: 7262/10000 (73)\n",
      "09:46:08 - Prediction hist: [ 980  1139  1021  1008  954  893  1002  1016  973  1014]\n",
      "09:46:08 - Federated model: Test set: Average loss: 0.0013, Accuracy: 9549/10000 (95)\n",
      "09:46:08 - Starting training round 32/100\n",
      "09:46:08 - Training round 32, calling fit on worker: alice, lr = 0.053\n",
      "09:46:08 - Training round 32, calling fit on worker: charlie, lr = 0.053\n",
      "09:46:08 - Training round 32, calling fit on worker: bob, lr = 0.053\n",
      "09:46:09 - Training round: 32, worker: bob, avg_loss: tensor(0.0048, grad_fn=<MeanBackward1>)\n",
      "09:46:10 - Training round: 32, worker: alice, avg_loss: tensor(0.1026, grad_fn=<MeanBackward1>)\n",
      "09:46:12 - Training round: 32, worker: charlie, avg_loss: tensor(0.0651, grad_fn=<MeanBackward1>)\n",
      "09:46:13 - Starting training round 33/100\n",
      "09:46:13 - Training round 33, calling fit on worker: charlie, lr = 0.052\n",
      "09:46:13 - Training round 33, calling fit on worker: alice, lr = 0.052\n",
      "09:46:13 - Training round 33, calling fit on worker: bob, lr = 0.052\n",
      "09:46:14 - Training round: 33, worker: bob, avg_loss: tensor(0.0143, grad_fn=<MeanBackward1>)\n",
      "09:46:16 - Training round: 33, worker: charlie, avg_loss: tensor(0.1375, grad_fn=<MeanBackward1>)\n",
      "09:46:17 - Training round: 33, worker: alice, avg_loss: tensor(0.0136, grad_fn=<MeanBackward1>)\n",
      "09:46:18 - Starting training round 34/100\n",
      "09:46:18 - Training round 34, calling fit on worker: alice, lr = 0.051\n",
      "09:46:18 - Training round 34, calling fit on worker: bob, lr = 0.051\n",
      "09:46:18 - Training round 34, calling fit on worker: charlie, lr = 0.051\n",
      "09:46:19 - Training round: 34, worker: alice, avg_loss: tensor(0.0393, grad_fn=<MeanBackward1>)\n",
      "09:46:21 - Training round: 34, worker: bob, avg_loss: tensor(0.0140, grad_fn=<MeanBackward1>)\n",
      "09:46:22 - Training round: 34, worker: charlie, avg_loss: tensor(0.2481, grad_fn=<MeanBackward1>)\n",
      "09:46:23 - Starting training round 35/100\n",
      "09:46:23 - Training round 35, calling fit on worker: charlie, lr = 0.050\n",
      "09:46:23 - Training round 35, calling fit on worker: bob, lr = 0.050\n",
      "09:46:23 - Training round 35, calling fit on worker: alice, lr = 0.050\n",
      "09:46:24 - Training round: 35, worker: charlie, avg_loss: tensor(0.0273, grad_fn=<MeanBackward1>)\n",
      "09:46:26 - Training round: 35, worker: bob, avg_loss: tensor(0.0050, grad_fn=<MeanBackward1>)\n",
      "09:46:27 - Training round: 35, worker: alice, avg_loss: tensor(0.0901, grad_fn=<MeanBackward1>)\n",
      "09:46:28 - Starting training round 36/100\n",
      "09:46:28 - Training round 36, calling fit on worker: bob, lr = 0.049\n",
      "09:46:28 - Training round 36, calling fit on worker: charlie, lr = 0.049\n",
      "09:46:28 - Training round 36, calling fit on worker: alice, lr = 0.049\n",
      "09:46:29 - Training round: 36, worker: alice, avg_loss: tensor(0.0081, grad_fn=<MeanBackward1>)\n",
      "09:46:31 - Training round: 36, worker: charlie, avg_loss: tensor(0.0177, grad_fn=<MeanBackward1>)\n",
      "09:46:32 - Training round: 36, worker: bob, avg_loss: tensor(0.0029, grad_fn=<MeanBackward1>)\n",
      "09:46:33 - Starting training round 37/100\n",
      "09:46:33 - Training round 37, calling fit on worker: charlie, lr = 0.048\n",
      "09:46:33 - Training round 37, calling fit on worker: bob, lr = 0.048\n",
      "09:46:33 - Training round 37, calling fit on worker: alice, lr = 0.048\n",
      "09:46:35 - Training round: 37, worker: alice, avg_loss: tensor(0.2536, grad_fn=<MeanBackward1>)\n",
      "09:46:36 - Training round: 37, worker: bob, avg_loss: tensor(0.0432, grad_fn=<MeanBackward1>)\n",
      "09:46:37 - Training round: 37, worker: charlie, avg_loss: tensor(0.0237, grad_fn=<MeanBackward1>)\n",
      "09:46:38 - Starting training round 38/100\n",
      "09:46:39 - Training round 38, calling fit on worker: alice, lr = 0.047\n",
      "09:46:39 - Training round 38, calling fit on worker: bob, lr = 0.047\n",
      "09:46:39 - Training round 38, calling fit on worker: charlie, lr = 0.047\n",
      "09:46:40 - Training round: 38, worker: alice, avg_loss: tensor(0.0021, grad_fn=<MeanBackward1>)\n",
      "09:46:41 - Training round: 38, worker: charlie, avg_loss: tensor(0.1268, grad_fn=<MeanBackward1>)\n",
      "09:46:42 - Training round: 38, worker: bob, avg_loss: tensor(0.0050, grad_fn=<MeanBackward1>)\n",
      "09:46:43 - Starting training round 39/100\n",
      "09:46:44 - Training round 39, calling fit on worker: alice, lr = 0.046\n",
      "09:46:44 - Training round 39, calling fit on worker: charlie, lr = 0.046\n",
      "09:46:44 - Training round 39, calling fit on worker: bob, lr = 0.046\n",
      "09:46:45 - Training round: 39, worker: charlie, avg_loss: tensor(0.0121, grad_fn=<MeanBackward1>)\n",
      "09:46:46 - Training round: 39, worker: alice, avg_loss: tensor(0.0433, grad_fn=<MeanBackward1>)\n",
      "09:46:47 - Training round: 39, worker: bob, avg_loss: tensor(0.1452, grad_fn=<MeanBackward1>)\n",
      "09:46:48 - Starting training round 40/100\n",
      "09:46:49 - Training round 40, calling fit on worker: charlie, lr = 0.045\n",
      "09:46:49 - Training round 40, calling fit on worker: alice, lr = 0.045\n",
      "09:46:49 - Training round 40, calling fit on worker: bob, lr = 0.045\n",
      "09:46:50 - Training round: 40, worker: alice, avg_loss: tensor(0.2003, grad_fn=<MeanBackward1>)\n",
      "09:46:51 - Training round: 40, worker: bob, avg_loss: tensor(0.0040, grad_fn=<MeanBackward1>)\n",
      "09:46:52 - Training round: 40, worker: charlie, avg_loss: tensor(0.0623, grad_fn=<MeanBackward1>)\n",
      "09:46:53 - Starting training round 41/100\n",
      "09:46:53 - Training round 41, calling fit on worker: bob, lr = 0.045\n",
      "09:46:53 - Training round 41, calling fit on worker: alice, lr = 0.045\n",
      "09:46:53 - Training round 41, calling fit on worker: charlie, lr = 0.045\n",
      "09:46:55 - Training round: 41, worker: bob, avg_loss: tensor(0.0085, grad_fn=<MeanBackward1>)\n",
      "09:46:56 - Training round: 41, worker: charlie, avg_loss: tensor(0.0401, grad_fn=<MeanBackward1>)\n",
      "09:46:58 - Training round: 41, worker: alice, avg_loss: tensor(0.0720, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:47:01 - Prediction hist: [ 1156  1240  1041  2305  902  193  871  853  605  834]\n",
      "09:47:01 - alice: Test set: Average loss: 0.0041, Accuracy: 8259/10000 (83)\n",
      "09:47:03 - Prediction hist: [ 783  1084  1003  300  1506  2377  1114  957  567  309]\n",
      "09:47:03 - bob: Test set: Average loss: 0.0052, Accuracy: 7711/10000 (77)\n",
      "09:47:05 - Prediction hist: [ 423  859  639  585  342  164  812  1255  3183  1738]\n",
      "09:47:05 - charlie: Test set: Average loss: 0.0070, Accuracy: 6709/10000 (67)\n",
      "09:47:07 - Prediction hist: [ 978  1123  1007  1014  967  906  971  1034  1006  994]\n",
      "09:47:07 - Federated model: Test set: Average loss: 0.0010, Accuracy: 9619/10000 (96)\n",
      "09:47:07 - Starting training round 42/100\n",
      "09:47:08 - Training round 42, calling fit on worker: alice, lr = 0.044\n",
      "09:47:08 - Training round 42, calling fit on worker: bob, lr = 0.044\n",
      "09:47:08 - Training round 42, calling fit on worker: charlie, lr = 0.044\n",
      "09:47:10 - Training round: 42, worker: charlie, avg_loss: tensor(0.0219, grad_fn=<MeanBackward1>)\n",
      "09:47:11 - Training round: 42, worker: bob, avg_loss: tensor(0.0020, grad_fn=<MeanBackward1>)\n",
      "09:47:12 - Training round: 42, worker: alice, avg_loss: tensor(0.0176, grad_fn=<MeanBackward1>)\n",
      "09:47:13 - Starting training round 43/100\n",
      "09:47:13 - Training round 43, calling fit on worker: charlie, lr = 0.043\n",
      "09:47:13 - Training round 43, calling fit on worker: alice, lr = 0.043\n",
      "09:47:14 - Training round 43, calling fit on worker: bob, lr = 0.043\n",
      "09:47:15 - Training round: 43, worker: alice, avg_loss: tensor(0.0361, grad_fn=<MeanBackward1>)\n",
      "09:47:16 - Training round: 43, worker: charlie, avg_loss: tensor(0.0347, grad_fn=<MeanBackward1>)\n",
      "09:47:17 - Training round: 43, worker: bob, avg_loss: tensor(0.0333, grad_fn=<MeanBackward1>)\n",
      "09:47:18 - Starting training round 44/100\n",
      "09:47:18 - Training round 44, calling fit on worker: bob, lr = 0.042\n",
      "09:47:19 - Training round 44, calling fit on worker: alice, lr = 0.042\n",
      "09:47:19 - Training round 44, calling fit on worker: charlie, lr = 0.042\n",
      "09:47:20 - Training round: 44, worker: bob, avg_loss: tensor(0.0066, grad_fn=<MeanBackward1>)\n",
      "09:47:21 - Training round: 44, worker: charlie, avg_loss: tensor(0.0873, grad_fn=<MeanBackward1>)\n",
      "09:47:22 - Training round: 44, worker: alice, avg_loss: tensor(0.0043, grad_fn=<MeanBackward1>)\n",
      "09:47:23 - Starting training round 45/100\n",
      "09:47:24 - Training round 45, calling fit on worker: bob, lr = 0.041\n",
      "09:47:24 - Training round 45, calling fit on worker: alice, lr = 0.041\n",
      "09:47:24 - Training round 45, calling fit on worker: charlie, lr = 0.041\n",
      "09:47:25 - Training round: 45, worker: alice, avg_loss: tensor(0.0642, grad_fn=<MeanBackward1>)\n",
      "09:47:26 - Training round: 45, worker: charlie, avg_loss: tensor(0.0361, grad_fn=<MeanBackward1>)\n",
      "09:47:27 - Training round: 45, worker: bob, avg_loss: tensor(0.0062, grad_fn=<MeanBackward1>)\n",
      "09:47:28 - Starting training round 46/100\n",
      "09:47:29 - Training round 46, calling fit on worker: alice, lr = 0.040\n",
      "09:47:29 - Training round 46, calling fit on worker: bob, lr = 0.040\n",
      "09:47:29 - Training round 46, calling fit on worker: charlie, lr = 0.040\n",
      "09:47:30 - Training round: 46, worker: alice, avg_loss: tensor(0.0070, grad_fn=<MeanBackward1>)\n",
      "09:47:31 - Training round: 46, worker: bob, avg_loss: tensor(0.0117, grad_fn=<MeanBackward1>)\n",
      "09:47:33 - Training round: 46, worker: charlie, avg_loss: tensor(0.0334, grad_fn=<MeanBackward1>)\n",
      "09:47:34 - Starting training round 47/100\n",
      "09:47:34 - Training round 47, calling fit on worker: bob, lr = 0.039\n",
      "09:47:34 - Training round 47, calling fit on worker: alice, lr = 0.039\n",
      "09:47:34 - Training round 47, calling fit on worker: charlie, lr = 0.039\n",
      "09:47:36 - Training round: 47, worker: bob, avg_loss: tensor(0.0094, grad_fn=<MeanBackward1>)\n",
      "09:47:37 - Training round: 47, worker: charlie, avg_loss: tensor(0.0107, grad_fn=<MeanBackward1>)\n",
      "09:47:38 - Training round: 47, worker: alice, avg_loss: tensor(0.0381, grad_fn=<MeanBackward1>)\n",
      "09:47:39 - Starting training round 48/100\n",
      "09:47:39 - Training round 48, calling fit on worker: bob, lr = 0.039\n",
      "09:47:39 - Training round 48, calling fit on worker: charlie, lr = 0.039\n",
      "09:47:39 - Training round 48, calling fit on worker: alice, lr = 0.039\n",
      "09:47:41 - Training round: 48, worker: alice, avg_loss: tensor(0.0597, grad_fn=<MeanBackward1>)\n",
      "09:47:42 - Training round: 48, worker: bob, avg_loss: tensor(0.0038, grad_fn=<MeanBackward1>)\n",
      "09:47:43 - Training round: 48, worker: charlie, avg_loss: tensor(0.0515, grad_fn=<MeanBackward1>)\n",
      "09:47:45 - Starting training round 49/100\n",
      "09:47:45 - Training round 49, calling fit on worker: alice, lr = 0.038\n",
      "09:47:45 - Training round 49, calling fit on worker: bob, lr = 0.038\n",
      "09:47:45 - Training round 49, calling fit on worker: charlie, lr = 0.038\n",
      "09:47:46 - Training round: 49, worker: alice, avg_loss: tensor(0.0038, grad_fn=<MeanBackward1>)\n",
      "09:47:47 - Training round: 49, worker: bob, avg_loss: tensor(0.0128, grad_fn=<MeanBackward1>)\n",
      "09:47:48 - Training round: 49, worker: charlie, avg_loss: tensor(0.0302, grad_fn=<MeanBackward1>)\n",
      "09:47:50 - Starting training round 50/100\n",
      "09:47:50 - Training round 50, calling fit on worker: charlie, lr = 0.037\n",
      "09:47:50 - Training round 50, calling fit on worker: alice, lr = 0.037\n",
      "09:47:50 - Training round 50, calling fit on worker: bob, lr = 0.037\n",
      "09:47:51 - Training round: 50, worker: charlie, avg_loss: tensor(0.3227, grad_fn=<MeanBackward1>)\n",
      "09:47:52 - Training round: 50, worker: bob, avg_loss: tensor(0.0977, grad_fn=<MeanBackward1>)\n",
      "09:47:53 - Training round: 50, worker: alice, avg_loss: tensor(0.3530, grad_fn=<MeanBackward1>)\n",
      "09:47:54 - Starting training round 51/100\n",
      "09:47:54 - Training round 51, calling fit on worker: charlie, lr = 0.036\n",
      "09:47:54 - Training round 51, calling fit on worker: bob, lr = 0.036\n",
      "09:47:55 - Training round 51, calling fit on worker: alice, lr = 0.036\n",
      "09:47:56 - Training round: 51, worker: charlie, avg_loss: tensor(0.1383, grad_fn=<MeanBackward1>)\n",
      "09:47:57 - Training round: 51, worker: bob, avg_loss: tensor(0.0742, grad_fn=<MeanBackward1>)\n",
      "09:47:58 - Training round: 51, worker: alice, avg_loss: tensor(0.0303, grad_fn=<MeanBackward1>)\n",
      "09:48:02 - Prediction hist: [ 1129  1246  1242  1328  1010  772  855  819  733  866]\n",
      "09:48:02 - alice: Test set: Average loss: 0.0023, Accuracy: 9082/10000 (91)\n",
      "09:48:04 - Prediction hist: [ 562  1119  987  630  1964  1820  1147  965  734  72]\n",
      "09:48:04 - bob: Test set: Average loss: 0.0053, Accuracy: 7761/10000 (78)\n",
      "09:48:06 - Prediction hist: [ 934  951  896  769  357  440  788  1044  1696  2125]\n",
      "09:48:06 - charlie: Test set: Average loss: 0.0041, Accuracy: 8026/10000 (80)\n",
      "09:48:09 - Prediction hist: [ 986  1136  1064  990  1032  944  934  983  966  965]\n",
      "09:48:09 - Federated model: Test set: Average loss: 0.0009, Accuracy: 9632/10000 (96)\n",
      "09:48:09 - Starting training round 52/100\n",
      "09:48:09 - Training round 52, calling fit on worker: alice, lr = 0.036\n",
      "09:48:09 - Training round 52, calling fit on worker: bob, lr = 0.036\n",
      "09:48:09 - Training round 52, calling fit on worker: charlie, lr = 0.036\n",
      "09:48:10 - Training round: 52, worker: alice, avg_loss: tensor(0.0246, grad_fn=<MeanBackward1>)\n",
      "09:48:11 - Training round: 52, worker: bob, avg_loss: tensor(0.0110, grad_fn=<MeanBackward1>)\n",
      "09:48:13 - Training round: 52, worker: charlie, avg_loss: tensor(0.0416, grad_fn=<MeanBackward1>)\n",
      "09:48:14 - Starting training round 53/100\n",
      "09:48:14 - Training round 53, calling fit on worker: alice, lr = 0.035\n",
      "09:48:14 - Training round 53, calling fit on worker: bob, lr = 0.035\n",
      "09:48:14 - Training round 53, calling fit on worker: charlie, lr = 0.035\n",
      "09:48:15 - Training round: 53, worker: alice, avg_loss: tensor(0.0610, grad_fn=<MeanBackward1>)\n",
      "09:48:17 - Training round: 53, worker: charlie, avg_loss: tensor(0.2422, grad_fn=<MeanBackward1>)\n",
      "09:48:18 - Training round: 53, worker: bob, avg_loss: tensor(0.3343, grad_fn=<MeanBackward1>)\n",
      "09:48:19 - Starting training round 54/100\n",
      "09:48:19 - Training round 54, calling fit on worker: charlie, lr = 0.034\n",
      "09:48:19 - Training round 54, calling fit on worker: bob, lr = 0.034\n",
      "09:48:19 - Training round 54, calling fit on worker: alice, lr = 0.034\n",
      "09:48:21 - Training round: 54, worker: charlie, avg_loss: tensor(0.1387, grad_fn=<MeanBackward1>)\n",
      "09:48:22 - Training round: 54, worker: bob, avg_loss: tensor(0.0054, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:48:23 - Training round: 54, worker: alice, avg_loss: tensor(0.2276, grad_fn=<MeanBackward1>)\n",
      "09:48:24 - Starting training round 55/100\n",
      "09:48:24 - Training round 55, calling fit on worker: bob, lr = 0.034\n",
      "09:48:24 - Training round 55, calling fit on worker: alice, lr = 0.034\n",
      "09:48:25 - Training round 55, calling fit on worker: charlie, lr = 0.034\n",
      "09:48:26 - Training round: 55, worker: alice, avg_loss: tensor(0.0086, grad_fn=<MeanBackward1>)\n",
      "09:48:27 - Training round: 55, worker: charlie, avg_loss: tensor(0.0086, grad_fn=<MeanBackward1>)\n",
      "09:48:28 - Training round: 55, worker: bob, avg_loss: tensor(0.0099, grad_fn=<MeanBackward1>)\n",
      "09:48:29 - Starting training round 56/100\n",
      "09:48:29 - Training round 56, calling fit on worker: alice, lr = 0.033\n",
      "09:48:29 - Training round 56, calling fit on worker: bob, lr = 0.033\n",
      "09:48:29 - Training round 56, calling fit on worker: charlie, lr = 0.033\n",
      "09:48:31 - Training round: 56, worker: bob, avg_loss: tensor(0.2595, grad_fn=<MeanBackward1>)\n",
      "09:48:32 - Training round: 56, worker: alice, avg_loss: tensor(0.0135, grad_fn=<MeanBackward1>)\n",
      "09:48:33 - Training round: 56, worker: charlie, avg_loss: tensor(0.0017, grad_fn=<MeanBackward1>)\n",
      "09:48:34 - Starting training round 57/100\n",
      "09:48:34 - Training round 57, calling fit on worker: charlie, lr = 0.032\n",
      "09:48:34 - Training round 57, calling fit on worker: bob, lr = 0.032\n",
      "09:48:34 - Training round 57, calling fit on worker: alice, lr = 0.032\n",
      "09:48:35 - Training round: 57, worker: bob, avg_loss: tensor(0.1122, grad_fn=<MeanBackward1>)\n",
      "09:48:37 - Training round: 57, worker: charlie, avg_loss: tensor(0.0109, grad_fn=<MeanBackward1>)\n",
      "09:48:38 - Training round: 57, worker: alice, avg_loss: tensor(0.0104, grad_fn=<MeanBackward1>)\n",
      "09:48:39 - Starting training round 58/100\n",
      "09:48:39 - Training round 58, calling fit on worker: charlie, lr = 0.032\n",
      "09:48:39 - Training round 58, calling fit on worker: alice, lr = 0.032\n",
      "09:48:39 - Training round 58, calling fit on worker: bob, lr = 0.032\n",
      "09:48:40 - Training round: 58, worker: alice, avg_loss: tensor(0.0762, grad_fn=<MeanBackward1>)\n",
      "09:48:42 - Training round: 58, worker: charlie, avg_loss: tensor(0.0335, grad_fn=<MeanBackward1>)\n",
      "09:48:43 - Training round: 58, worker: bob, avg_loss: tensor(0.0380, grad_fn=<MeanBackward1>)\n",
      "09:48:44 - Starting training round 59/100\n",
      "09:48:44 - Training round 59, calling fit on worker: bob, lr = 0.031\n",
      "09:48:44 - Training round 59, calling fit on worker: alice, lr = 0.031\n",
      "09:48:44 - Training round 59, calling fit on worker: charlie, lr = 0.031\n",
      "09:48:46 - Training round: 59, worker: bob, avg_loss: tensor(0.0036, grad_fn=<MeanBackward1>)\n",
      "09:48:47 - Training round: 59, worker: alice, avg_loss: tensor(0.0030, grad_fn=<MeanBackward1>)\n",
      "09:48:48 - Training round: 59, worker: charlie, avg_loss: tensor(0.0401, grad_fn=<MeanBackward1>)\n",
      "09:48:49 - Starting training round 60/100\n",
      "09:48:49 - Training round 60, calling fit on worker: bob, lr = 0.030\n",
      "09:48:49 - Training round 60, calling fit on worker: alice, lr = 0.030\n",
      "09:48:49 - Training round 60, calling fit on worker: charlie, lr = 0.030\n",
      "09:48:51 - Training round: 60, worker: charlie, avg_loss: tensor(0.0839, grad_fn=<MeanBackward1>)\n",
      "09:48:52 - Training round: 60, worker: bob, avg_loss: tensor(0.0038, grad_fn=<MeanBackward1>)\n",
      "09:48:53 - Training round: 60, worker: alice, avg_loss: tensor(0.0042, grad_fn=<MeanBackward1>)\n",
      "09:48:54 - Starting training round 61/100\n",
      "09:48:54 - Training round 61, calling fit on worker: alice, lr = 0.030\n",
      "09:48:54 - Training round 61, calling fit on worker: bob, lr = 0.030\n",
      "09:48:55 - Training round 61, calling fit on worker: charlie, lr = 0.030\n",
      "09:48:56 - Training round: 61, worker: alice, avg_loss: tensor(0.0057, grad_fn=<MeanBackward1>)\n",
      "09:48:57 - Training round: 61, worker: charlie, avg_loss: tensor(0.0425, grad_fn=<MeanBackward1>)\n",
      "09:48:58 - Training round: 61, worker: bob, avg_loss: tensor(0.0560, grad_fn=<MeanBackward1>)\n",
      "09:49:02 - Prediction hist: [ 1116  1215  1172  1372  990  679  890  912  704  950]\n",
      "09:49:02 - alice: Test set: Average loss: 0.0020, Accuracy: 9155/10000 (92)\n",
      "09:49:04 - Prediction hist: [ 836  1132  1014  875  1438  1283  1193  985  766  478]\n",
      "09:49:04 - bob: Test set: Average loss: 0.0025, Accuracy: 8768/10000 (88)\n",
      "09:49:06 - Prediction hist: [ 880  946  698  711  751  374  823  1179  2384  1254]\n",
      "09:49:06 - charlie: Test set: Average loss: 0.0043, Accuracy: 8079/10000 (81)\n",
      "09:49:08 - Prediction hist: [ 999  1138  1018  1012  994  882  966  1033  986  972]\n",
      "09:49:08 - Federated model: Test set: Average loss: 0.0008, Accuracy: 9675/10000 (97)\n",
      "09:49:08 - Starting training round 62/100\n",
      "09:49:09 - Training round 62, calling fit on worker: bob, lr = 0.029\n",
      "09:49:09 - Training round 62, calling fit on worker: alice, lr = 0.029\n",
      "09:49:09 - Training round 62, calling fit on worker: charlie, lr = 0.029\n",
      "09:49:10 - Training round: 62, worker: charlie, avg_loss: tensor(0.0110, grad_fn=<MeanBackward1>)\n",
      "09:49:11 - Training round: 62, worker: alice, avg_loss: tensor(0.1472, grad_fn=<MeanBackward1>)\n",
      "09:49:12 - Training round: 62, worker: bob, avg_loss: tensor(0.0183, grad_fn=<MeanBackward1>)\n",
      "09:49:13 - Starting training round 63/100\n",
      "09:49:14 - Training round 63, calling fit on worker: charlie, lr = 0.029\n",
      "09:49:14 - Training round 63, calling fit on worker: alice, lr = 0.029\n",
      "09:49:14 - Training round 63, calling fit on worker: bob, lr = 0.029\n",
      "09:49:15 - Training round: 63, worker: charlie, avg_loss: tensor(0.0180, grad_fn=<MeanBackward1>)\n",
      "09:49:16 - Training round: 63, worker: alice, avg_loss: tensor(0.0162, grad_fn=<MeanBackward1>)\n",
      "09:49:18 - Training round: 63, worker: bob, avg_loss: tensor(0.0059, grad_fn=<MeanBackward1>)\n",
      "09:49:19 - Starting training round 64/100\n",
      "09:49:19 - Training round 64, calling fit on worker: alice, lr = 0.028\n",
      "09:49:19 - Training round 64, calling fit on worker: charlie, lr = 0.028\n",
      "09:49:19 - Training round 64, calling fit on worker: bob, lr = 0.028\n",
      "09:49:20 - Training round: 64, worker: charlie, avg_loss: tensor(0.0297, grad_fn=<MeanBackward1>)\n",
      "09:49:22 - Training round: 64, worker: bob, avg_loss: tensor(0.0720, grad_fn=<MeanBackward1>)\n",
      "09:49:23 - Training round: 64, worker: alice, avg_loss: tensor(0.0366, grad_fn=<MeanBackward1>)\n",
      "09:49:24 - Starting training round 65/100\n",
      "09:49:24 - Training round 65, calling fit on worker: charlie, lr = 0.027\n",
      "09:49:24 - Training round 65, calling fit on worker: alice, lr = 0.027\n",
      "09:49:24 - Training round 65, calling fit on worker: bob, lr = 0.027\n",
      "09:49:26 - Training round: 65, worker: alice, avg_loss: tensor(0.0300, grad_fn=<MeanBackward1>)\n",
      "09:49:27 - Training round: 65, worker: charlie, avg_loss: tensor(0.0218, grad_fn=<MeanBackward1>)\n",
      "09:49:28 - Training round: 65, worker: bob, avg_loss: tensor(0.0034, grad_fn=<MeanBackward1>)\n",
      "09:49:30 - Starting training round 66/100\n",
      "09:49:30 - Training round 66, calling fit on worker: charlie, lr = 0.027\n",
      "09:49:30 - Training round 66, calling fit on worker: bob, lr = 0.027\n",
      "09:49:30 - Training round 66, calling fit on worker: alice, lr = 0.027\n",
      "09:49:31 - Training round: 66, worker: bob, avg_loss: tensor(0.0644, grad_fn=<MeanBackward1>)\n",
      "09:49:32 - Training round: 66, worker: alice, avg_loss: tensor(0.0168, grad_fn=<MeanBackward1>)\n",
      "09:49:33 - Training round: 66, worker: charlie, avg_loss: tensor(0.0167, grad_fn=<MeanBackward1>)\n",
      "09:49:35 - Starting training round 67/100\n",
      "09:49:35 - Training round 67, calling fit on worker: charlie, lr = 0.026\n",
      "09:49:35 - Training round 67, calling fit on worker: alice, lr = 0.026\n",
      "09:49:35 - Training round 67, calling fit on worker: bob, lr = 0.026\n",
      "09:49:36 - Training round: 67, worker: alice, avg_loss: tensor(0.0128, grad_fn=<MeanBackward1>)\n",
      "09:49:37 - Training round: 67, worker: charlie, avg_loss: tensor(0.0502, grad_fn=<MeanBackward1>)\n",
      "09:49:39 - Training round: 67, worker: bob, avg_loss: tensor(0.1876, grad_fn=<MeanBackward1>)\n",
      "09:49:40 - Starting training round 68/100\n",
      "09:49:40 - Training round 68, calling fit on worker: bob, lr = 0.026\n",
      "09:49:40 - Training round 68, calling fit on worker: charlie, lr = 0.026\n",
      "09:49:40 - Training round 68, calling fit on worker: alice, lr = 0.026\n",
      "09:49:41 - Training round: 68, worker: bob, avg_loss: tensor(0.0849, grad_fn=<MeanBackward1>)\n",
      "09:49:43 - Training round: 68, worker: alice, avg_loss: tensor(0.0264, grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:49:44 - Training round: 68, worker: charlie, avg_loss: tensor(0.0440, grad_fn=<MeanBackward1>)\n",
      "09:49:45 - Starting training round 69/100\n",
      "09:49:45 - Training round 69, calling fit on worker: alice, lr = 0.025\n",
      "09:49:45 - Training round 69, calling fit on worker: charlie, lr = 0.025\n",
      "09:49:45 - Training round 69, calling fit on worker: bob, lr = 0.025\n",
      "09:49:47 - Training round: 69, worker: charlie, avg_loss: tensor(0.1417, grad_fn=<MeanBackward1>)\n",
      "09:49:48 - Training round: 69, worker: bob, avg_loss: tensor(0.0074, grad_fn=<MeanBackward1>)\n",
      "09:49:49 - Training round: 69, worker: alice, avg_loss: tensor(0.1743, grad_fn=<MeanBackward1>)\n",
      "09:49:50 - Starting training round 70/100\n",
      "09:49:50 - Training round 70, calling fit on worker: charlie, lr = 0.025\n",
      "09:49:50 - Training round 70, calling fit on worker: alice, lr = 0.025\n",
      "09:49:50 - Training round 70, calling fit on worker: bob, lr = 0.025\n",
      "09:49:52 - Training round: 70, worker: bob, avg_loss: tensor(0.0284, grad_fn=<MeanBackward1>)\n",
      "09:49:53 - Training round: 70, worker: charlie, avg_loss: tensor(0.0146, grad_fn=<MeanBackward1>)\n",
      "09:49:54 - Training round: 70, worker: alice, avg_loss: tensor(0.0370, grad_fn=<MeanBackward1>)\n",
      "09:49:56 - Starting training round 71/100\n",
      "09:49:56 - Training round 71, calling fit on worker: alice, lr = 0.024\n",
      "09:49:56 - Training round 71, calling fit on worker: charlie, lr = 0.024\n",
      "09:49:56 - Training round 71, calling fit on worker: bob, lr = 0.024\n",
      "09:49:57 - Training round: 71, worker: bob, avg_loss: tensor(0.0225, grad_fn=<MeanBackward1>)\n",
      "09:49:59 - Training round: 71, worker: alice, avg_loss: tensor(0.0820, grad_fn=<MeanBackward1>)\n",
      "09:50:00 - Training round: 71, worker: charlie, avg_loss: tensor(0.1629, grad_fn=<MeanBackward1>)\n",
      "09:50:03 - Prediction hist: [ 1108  1206  1180  1397  1046  729  903  886  730  815]\n",
      "09:50:03 - alice: Test set: Average loss: 0.0021, Accuracy: 9115/10000 (91)\n",
      "09:50:06 - Prediction hist: [ 895  1123  985  675  1359  1433  1152  1007  819  552]\n",
      "09:50:06 - bob: Test set: Average loss: 0.0026, Accuracy: 8753/10000 (88)\n",
      "09:50:08 - Prediction hist: [ 917  962  751  825  714  670  898  1136  1784  1343]\n",
      "09:50:08 - charlie: Test set: Average loss: 0.0031, Accuracy: 8654/10000 (87)\n",
      "09:50:10 - Prediction hist: [ 1005  1127  1017  991  1001  920  964  1027  995  953]\n",
      "09:50:10 - Federated model: Test set: Average loss: 0.0008, Accuracy: 9690/10000 (97)\n",
      "09:50:10 - Starting training round 72/100\n",
      "09:50:10 - Training round 72, calling fit on worker: bob, lr = 0.024\n",
      "09:50:10 - Training round 72, calling fit on worker: alice, lr = 0.024\n",
      "09:50:10 - Training round 72, calling fit on worker: charlie, lr = 0.024\n",
      "09:50:11 - Training round: 72, worker: alice, avg_loss: tensor(0.0091, grad_fn=<MeanBackward1>)\n",
      "09:50:13 - Training round: 72, worker: bob, avg_loss: tensor(0.0171, grad_fn=<MeanBackward1>)\n",
      "09:50:14 - Training round: 72, worker: charlie, avg_loss: tensor(0.0074, grad_fn=<MeanBackward1>)\n",
      "09:50:15 - Starting training round 73/100\n",
      "09:50:15 - Training round 73, calling fit on worker: alice, lr = 0.023\n",
      "09:50:15 - Training round 73, calling fit on worker: charlie, lr = 0.023\n",
      "09:50:15 - Training round 73, calling fit on worker: bob, lr = 0.023\n",
      "09:50:16 - Training round: 73, worker: bob, avg_loss: tensor(0.1364, grad_fn=<MeanBackward1>)\n",
      "09:50:18 - Training round: 73, worker: alice, avg_loss: tensor(0.0074, grad_fn=<MeanBackward1>)\n",
      "09:50:19 - Training round: 73, worker: charlie, avg_loss: tensor(0.0360, grad_fn=<MeanBackward1>)\n",
      "09:50:20 - Starting training round 74/100\n",
      "09:50:20 - Training round 74, calling fit on worker: charlie, lr = 0.023\n",
      "09:50:20 - Training round 74, calling fit on worker: bob, lr = 0.023\n",
      "09:50:20 - Training round 74, calling fit on worker: alice, lr = 0.023\n",
      "09:50:22 - Training round: 74, worker: alice, avg_loss: tensor(0.0069, grad_fn=<MeanBackward1>)\n",
      "09:50:23 - Training round: 74, worker: charlie, avg_loss: tensor(0.0832, grad_fn=<MeanBackward1>)\n",
      "09:50:24 - Training round: 74, worker: bob, avg_loss: tensor(0.0030, grad_fn=<MeanBackward1>)\n",
      "09:50:26 - Starting training round 75/100\n",
      "09:50:26 - Training round 75, calling fit on worker: alice, lr = 0.022\n",
      "09:50:26 - Training round 75, calling fit on worker: bob, lr = 0.022\n",
      "09:50:26 - Training round 75, calling fit on worker: charlie, lr = 0.022\n",
      "09:50:27 - Training round: 75, worker: alice, avg_loss: tensor(0.2674, grad_fn=<MeanBackward1>)\n",
      "09:50:29 - Training round: 75, worker: charlie, avg_loss: tensor(0.2843, grad_fn=<MeanBackward1>)\n",
      "09:50:30 - Training round: 75, worker: bob, avg_loss: tensor(0.0139, grad_fn=<MeanBackward1>)\n",
      "09:50:31 - Starting training round 76/100\n",
      "09:50:31 - Training round 76, calling fit on worker: alice, lr = 0.022\n",
      "09:50:31 - Training round 76, calling fit on worker: charlie, lr = 0.022\n",
      "09:50:31 - Training round 76, calling fit on worker: bob, lr = 0.022\n",
      "09:50:32 - Training round: 76, worker: alice, avg_loss: tensor(0.0989, grad_fn=<MeanBackward1>)\n",
      "09:50:34 - Training round: 76, worker: charlie, avg_loss: tensor(0.1242, grad_fn=<MeanBackward1>)\n",
      "09:50:35 - Training round: 76, worker: bob, avg_loss: tensor(0.0418, grad_fn=<MeanBackward1>)\n",
      "09:50:36 - Starting training round 77/100\n",
      "09:50:36 - Training round 77, calling fit on worker: alice, lr = 0.022\n",
      "09:50:36 - Training round 77, calling fit on worker: charlie, lr = 0.022\n",
      "09:50:36 - Training round 77, calling fit on worker: bob, lr = 0.022\n",
      "09:50:37 - Training round: 77, worker: alice, avg_loss: tensor(0.0237, grad_fn=<MeanBackward1>)\n",
      "09:50:38 - Training round: 77, worker: charlie, avg_loss: tensor(0.0189, grad_fn=<MeanBackward1>)\n",
      "09:50:40 - Training round: 77, worker: bob, avg_loss: tensor(0.2027, grad_fn=<MeanBackward1>)\n",
      "09:50:41 - Starting training round 78/100\n",
      "09:50:41 - Training round 78, calling fit on worker: bob, lr = 0.021\n",
      "09:50:41 - Training round 78, calling fit on worker: charlie, lr = 0.021\n",
      "09:50:41 - Training round 78, calling fit on worker: alice, lr = 0.021\n",
      "09:50:42 - Training round: 78, worker: charlie, avg_loss: tensor(0.0238, grad_fn=<MeanBackward1>)\n",
      "09:50:44 - Training round: 78, worker: alice, avg_loss: tensor(0.0078, grad_fn=<MeanBackward1>)\n",
      "09:50:45 - Training round: 78, worker: bob, avg_loss: tensor(0.0040, grad_fn=<MeanBackward1>)\n",
      "09:50:46 - Starting training round 79/100\n",
      "09:50:46 - Training round 79, calling fit on worker: alice, lr = 0.021\n",
      "09:50:46 - Training round 79, calling fit on worker: charlie, lr = 0.021\n",
      "09:50:46 - Training round 79, calling fit on worker: bob, lr = 0.021\n",
      "09:50:48 - Training round: 79, worker: bob, avg_loss: tensor(0.0074, grad_fn=<MeanBackward1>)\n",
      "09:50:49 - Training round: 79, worker: charlie, avg_loss: tensor(0.0053, grad_fn=<MeanBackward1>)\n",
      "09:50:50 - Training round: 79, worker: alice, avg_loss: tensor(0.0210, grad_fn=<MeanBackward1>)\n",
      "09:50:51 - Starting training round 80/100\n",
      "09:50:51 - Training round 80, calling fit on worker: charlie, lr = 0.020\n",
      "09:50:51 - Training round 80, calling fit on worker: bob, lr = 0.020\n",
      "09:50:51 - Training round 80, calling fit on worker: alice, lr = 0.020\n",
      "09:50:53 - Training round: 80, worker: alice, avg_loss: tensor(0.0271, grad_fn=<MeanBackward1>)\n",
      "09:50:54 - Training round: 80, worker: bob, avg_loss: tensor(0.0045, grad_fn=<MeanBackward1>)\n",
      "09:50:55 - Training round: 80, worker: charlie, avg_loss: tensor(0.0908, grad_fn=<MeanBackward1>)\n",
      "09:50:56 - Starting training round 81/100\n",
      "09:50:56 - Training round 81, calling fit on worker: charlie, lr = 0.020\n",
      "09:50:56 - Training round 81, calling fit on worker: bob, lr = 0.020\n",
      "09:50:56 - Training round 81, calling fit on worker: alice, lr = 0.020\n",
      "09:50:57 - Training round: 81, worker: bob, avg_loss: tensor(0.0151, grad_fn=<MeanBackward1>)\n",
      "09:50:59 - Training round: 81, worker: charlie, avg_loss: tensor(0.0048, grad_fn=<MeanBackward1>)\n",
      "09:51:00 - Training round: 81, worker: alice, avg_loss: tensor(0.1976, grad_fn=<MeanBackward1>)\n",
      "09:51:03 - Prediction hist: [ 1104  1177  1262  1560  973  739  849  874  534  928]\n",
      "09:51:03 - alice: Test set: Average loss: 0.0025, Accuracy: 8961/10000 (90)\n",
      "09:51:06 - Prediction hist: [ 839  1122  1019  819  1253  1292  1119  1005  841  691]\n",
      "09:51:06 - bob: Test set: Average loss: 0.0020, Accuracy: 9039/10000 (90)\n",
      "09:51:08 - Prediction hist: [ 900  1006  791  818  389  568  813  1228  1659  1828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:51:08 - charlie: Test set: Average loss: 0.0039, Accuracy: 8232/10000 (82)\n",
      "09:51:10 - Prediction hist: [ 994  1133  1046  1021  972  898  942  1028  966  1000]\n",
      "09:51:10 - Federated model: Test set: Average loss: 0.0007, Accuracy: 9723/10000 (97)\n",
      "09:51:10 - Starting training round 82/100\n",
      "09:51:10 - Training round 82, calling fit on worker: charlie, lr = 0.019\n",
      "09:51:10 - Training round 82, calling fit on worker: bob, lr = 0.019\n",
      "09:51:10 - Training round 82, calling fit on worker: alice, lr = 0.019\n",
      "09:51:12 - Training round: 82, worker: charlie, avg_loss: tensor(0.0246, grad_fn=<MeanBackward1>)\n",
      "09:51:13 - Training round: 82, worker: bob, avg_loss: tensor(0.0089, grad_fn=<MeanBackward1>)\n",
      "09:51:15 - Training round: 82, worker: alice, avg_loss: tensor(0.0548, grad_fn=<MeanBackward1>)\n",
      "09:51:16 - Starting training round 83/100\n",
      "09:51:16 - Training round 83, calling fit on worker: bob, lr = 0.019\n",
      "09:51:16 - Training round 83, calling fit on worker: alice, lr = 0.019\n",
      "09:51:16 - Training round 83, calling fit on worker: charlie, lr = 0.019\n",
      "09:51:17 - Training round: 83, worker: bob, avg_loss: tensor(0.0427, grad_fn=<MeanBackward1>)\n",
      "09:51:18 - Training round: 83, worker: charlie, avg_loss: tensor(0.1542, grad_fn=<MeanBackward1>)\n",
      "09:51:20 - Training round: 83, worker: alice, avg_loss: tensor(0.0250, grad_fn=<MeanBackward1>)\n",
      "09:51:21 - Starting training round 84/100\n",
      "09:51:21 - Training round 84, calling fit on worker: alice, lr = 0.019\n",
      "09:51:21 - Training round 84, calling fit on worker: bob, lr = 0.019\n",
      "09:51:21 - Training round 84, calling fit on worker: charlie, lr = 0.019\n",
      "09:51:22 - Training round: 84, worker: charlie, avg_loss: tensor(0.0053, grad_fn=<MeanBackward1>)\n",
      "09:51:23 - Training round: 84, worker: alice, avg_loss: tensor(0.0642, grad_fn=<MeanBackward1>)\n",
      "09:51:25 - Training round: 84, worker: bob, avg_loss: tensor(0.0015, grad_fn=<MeanBackward1>)\n",
      "09:51:26 - Starting training round 85/100\n",
      "09:51:26 - Training round 85, calling fit on worker: charlie, lr = 0.018\n",
      "09:51:26 - Training round 85, calling fit on worker: bob, lr = 0.018\n",
      "09:51:26 - Training round 85, calling fit on worker: alice, lr = 0.018\n",
      "09:51:28 - Training round: 85, worker: charlie, avg_loss: tensor(0.0159, grad_fn=<MeanBackward1>)\n",
      "09:51:29 - Training round: 85, worker: alice, avg_loss: tensor(0.0108, grad_fn=<MeanBackward1>)\n",
      "09:51:30 - Training round: 85, worker: bob, avg_loss: tensor(0.0025, grad_fn=<MeanBackward1>)\n",
      "09:51:31 - Starting training round 86/100\n",
      "09:51:31 - Training round 86, calling fit on worker: charlie, lr = 0.018\n",
      "09:51:31 - Training round 86, calling fit on worker: alice, lr = 0.018\n",
      "09:51:31 - Training round 86, calling fit on worker: bob, lr = 0.018\n",
      "09:51:33 - Training round: 86, worker: bob, avg_loss: tensor(0.0093, grad_fn=<MeanBackward1>)\n",
      "09:51:34 - Training round: 86, worker: charlie, avg_loss: tensor(0.0340, grad_fn=<MeanBackward1>)\n",
      "09:51:35 - Training round: 86, worker: alice, avg_loss: tensor(0.0759, grad_fn=<MeanBackward1>)\n",
      "09:51:37 - Starting training round 87/100\n",
      "09:51:37 - Training round 87, calling fit on worker: alice, lr = 0.018\n",
      "09:51:37 - Training round 87, calling fit on worker: charlie, lr = 0.018\n",
      "09:51:37 - Training round 87, calling fit on worker: bob, lr = 0.018\n",
      "09:51:38 - Training round: 87, worker: charlie, avg_loss: tensor(0.0566, grad_fn=<MeanBackward1>)\n",
      "09:51:39 - Training round: 87, worker: bob, avg_loss: tensor(0.0068, grad_fn=<MeanBackward1>)\n",
      "09:51:40 - Training round: 87, worker: alice, avg_loss: tensor(0.0339, grad_fn=<MeanBackward1>)\n",
      "09:51:41 - Starting training round 88/100\n",
      "09:51:41 - Training round 88, calling fit on worker: alice, lr = 0.017\n",
      "09:51:42 - Training round 88, calling fit on worker: charlie, lr = 0.017\n",
      "09:51:42 - Training round 88, calling fit on worker: bob, lr = 0.017\n",
      "09:51:43 - Training round: 88, worker: charlie, avg_loss: tensor(0.0684, grad_fn=<MeanBackward1>)\n",
      "09:51:44 - Training round: 88, worker: bob, avg_loss: tensor(0.0158, grad_fn=<MeanBackward1>)\n",
      "09:51:45 - Training round: 88, worker: alice, avg_loss: tensor(0.0117, grad_fn=<MeanBackward1>)\n",
      "09:51:46 - Starting training round 89/100\n",
      "09:51:46 - Training round 89, calling fit on worker: bob, lr = 0.017\n",
      "09:51:46 - Training round 89, calling fit on worker: alice, lr = 0.017\n",
      "09:51:46 - Training round 89, calling fit on worker: charlie, lr = 0.017\n",
      "09:51:48 - Training round: 89, worker: alice, avg_loss: tensor(0.0654, grad_fn=<MeanBackward1>)\n",
      "09:51:49 - Training round: 89, worker: bob, avg_loss: tensor(0.0271, grad_fn=<MeanBackward1>)\n",
      "09:51:50 - Training round: 89, worker: charlie, avg_loss: tensor(0.0430, grad_fn=<MeanBackward1>)\n",
      "09:51:51 - Starting training round 90/100\n",
      "09:51:51 - Training round 90, calling fit on worker: charlie, lr = 0.017\n",
      "09:51:51 - Training round 90, calling fit on worker: bob, lr = 0.017\n",
      "09:51:52 - Training round 90, calling fit on worker: alice, lr = 0.017\n",
      "09:51:53 - Training round: 90, worker: charlie, avg_loss: tensor(0.0200, grad_fn=<MeanBackward1>)\n",
      "09:51:54 - Training round: 90, worker: bob, avg_loss: tensor(0.0467, grad_fn=<MeanBackward1>)\n",
      "09:51:55 - Training round: 90, worker: alice, avg_loss: tensor(0.1456, grad_fn=<MeanBackward1>)\n",
      "09:51:56 - Starting training round 91/100\n",
      "09:51:56 - Training round 91, calling fit on worker: alice, lr = 0.016\n",
      "09:51:57 - Training round 91, calling fit on worker: bob, lr = 0.016\n",
      "09:51:57 - Training round 91, calling fit on worker: charlie, lr = 0.016\n",
      "09:51:58 - Training round: 91, worker: bob, avg_loss: tensor(0.0030, grad_fn=<MeanBackward1>)\n",
      "09:51:59 - Training round: 91, worker: alice, avg_loss: tensor(0.0070, grad_fn=<MeanBackward1>)\n",
      "09:52:00 - Training round: 91, worker: charlie, avg_loss: tensor(0.0203, grad_fn=<MeanBackward1>)\n",
      "09:52:04 - Prediction hist: [ 1085  1182  1237  1388  998  771  884  922  617  916]\n",
      "09:52:04 - alice: Test set: Average loss: 0.0020, Accuracy: 9155/10000 (92)\n",
      "09:52:06 - Prediction hist: [ 901  1127  1015  855  1107  1374  1007  1018  790  806]\n",
      "09:52:06 - bob: Test set: Average loss: 0.0017, Accuracy: 9202/10000 (92)\n",
      "09:52:08 - Prediction hist: [ 937  1045  859  823  796  675  917  1110  1546  1292]\n",
      "09:52:08 - charlie: Test set: Average loss: 0.0023, Accuracy: 8961/10000 (90)\n",
      "09:52:11 - Prediction hist: [ 998  1136  1047  1014  979  915  943  1025  956  987]\n",
      "09:52:11 - Federated model: Test set: Average loss: 0.0007, Accuracy: 9727/10000 (97)\n",
      "09:52:11 - Starting training round 92/100\n",
      "09:52:11 - Training round 92, calling fit on worker: charlie, lr = 0.016\n",
      "09:52:11 - Training round 92, calling fit on worker: alice, lr = 0.016\n",
      "09:52:11 - Training round 92, calling fit on worker: bob, lr = 0.016\n",
      "09:52:12 - Training round: 92, worker: bob, avg_loss: tensor(0.0080, grad_fn=<MeanBackward1>)\n",
      "09:52:13 - Training round: 92, worker: charlie, avg_loss: tensor(0.0849, grad_fn=<MeanBackward1>)\n",
      "09:52:15 - Training round: 92, worker: alice, avg_loss: tensor(0.0034, grad_fn=<MeanBackward1>)\n",
      "09:52:16 - Starting training round 93/100\n",
      "09:52:16 - Training round 93, calling fit on worker: bob, lr = 0.016\n",
      "09:52:16 - Training round 93, calling fit on worker: charlie, lr = 0.016\n",
      "09:52:16 - Training round 93, calling fit on worker: alice, lr = 0.016\n",
      "09:52:18 - Training round: 93, worker: bob, avg_loss: tensor(0.0031, grad_fn=<MeanBackward1>)\n",
      "09:52:19 - Training round: 93, worker: charlie, avg_loss: tensor(0.1207, grad_fn=<MeanBackward1>)\n",
      "09:52:20 - Training round: 93, worker: alice, avg_loss: tensor(0.0106, grad_fn=<MeanBackward1>)\n",
      "09:52:21 - Starting training round 94/100\n",
      "09:52:22 - Training round 94, calling fit on worker: charlie, lr = 0.015\n",
      "09:52:22 - Training round 94, calling fit on worker: bob, lr = 0.015\n",
      "09:52:22 - Training round 94, calling fit on worker: alice, lr = 0.015\n",
      "09:52:23 - Training round: 94, worker: charlie, avg_loss: tensor(0.0094, grad_fn=<MeanBackward1>)\n",
      "09:52:24 - Training round: 94, worker: bob, avg_loss: tensor(0.0012, grad_fn=<MeanBackward1>)\n",
      "09:52:25 - Training round: 94, worker: alice, avg_loss: tensor(0.1548, grad_fn=<MeanBackward1>)\n",
      "09:52:27 - Starting training round 95/100\n",
      "09:52:27 - Training round 95, calling fit on worker: bob, lr = 0.015\n",
      "09:52:27 - Training round 95, calling fit on worker: charlie, lr = 0.015\n",
      "09:52:27 - Training round 95, calling fit on worker: alice, lr = 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:52:28 - Training round: 95, worker: charlie, avg_loss: tensor(0.0128, grad_fn=<MeanBackward1>)\n",
      "09:52:30 - Training round: 95, worker: bob, avg_loss: tensor(0.0417, grad_fn=<MeanBackward1>)\n",
      "09:52:31 - Training round: 95, worker: alice, avg_loss: tensor(0.0148, grad_fn=<MeanBackward1>)\n",
      "09:52:32 - Starting training round 96/100\n",
      "09:52:32 - Training round 96, calling fit on worker: bob, lr = 0.015\n",
      "09:52:32 - Training round 96, calling fit on worker: charlie, lr = 0.015\n",
      "09:52:32 - Training round 96, calling fit on worker: alice, lr = 0.015\n",
      "09:52:33 - Training round: 96, worker: charlie, avg_loss: tensor(0.0039, grad_fn=<MeanBackward1>)\n",
      "09:52:35 - Training round: 96, worker: bob, avg_loss: tensor(0.0060, grad_fn=<MeanBackward1>)\n",
      "09:52:36 - Training round: 96, worker: alice, avg_loss: tensor(0.0096, grad_fn=<MeanBackward1>)\n",
      "09:52:38 - Starting training round 97/100\n",
      "09:52:38 - Training round 97, calling fit on worker: charlie, lr = 0.014\n",
      "09:52:38 - Training round 97, calling fit on worker: bob, lr = 0.014\n",
      "09:52:38 - Training round 97, calling fit on worker: alice, lr = 0.014\n",
      "09:52:39 - Training round: 97, worker: bob, avg_loss: tensor(0.0130, grad_fn=<MeanBackward1>)\n",
      "09:52:41 - Training round: 97, worker: charlie, avg_loss: tensor(0.0221, grad_fn=<MeanBackward1>)\n",
      "09:52:42 - Training round: 97, worker: alice, avg_loss: tensor(0.0062, grad_fn=<MeanBackward1>)\n",
      "09:52:43 - Starting training round 98/100\n",
      "09:52:43 - Training round 98, calling fit on worker: alice, lr = 0.014\n",
      "09:52:43 - Training round 98, calling fit on worker: charlie, lr = 0.014\n",
      "09:52:43 - Training round 98, calling fit on worker: bob, lr = 0.014\n",
      "09:52:44 - Training round: 98, worker: charlie, avg_loss: tensor(0.0099, grad_fn=<MeanBackward1>)\n",
      "09:52:46 - Training round: 98, worker: alice, avg_loss: tensor(0.0576, grad_fn=<MeanBackward1>)\n",
      "09:52:47 - Training round: 98, worker: bob, avg_loss: tensor(0.1070, grad_fn=<MeanBackward1>)\n",
      "09:52:48 - Starting training round 99/100\n",
      "09:52:48 - Training round 99, calling fit on worker: alice, lr = 0.014\n",
      "09:52:48 - Training round 99, calling fit on worker: charlie, lr = 0.014\n",
      "09:52:49 - Training round 99, calling fit on worker: bob, lr = 0.014\n",
      "09:52:50 - Training round: 99, worker: charlie, avg_loss: tensor(0.0113, grad_fn=<MeanBackward1>)\n",
      "09:52:51 - Training round: 99, worker: alice, avg_loss: tensor(0.0107, grad_fn=<MeanBackward1>)\n",
      "09:52:53 - Training round: 99, worker: bob, avg_loss: tensor(0.0193, grad_fn=<MeanBackward1>)\n",
      "09:52:54 - Starting training round 100/100\n",
      "09:52:54 - Training round 100, calling fit on worker: alice, lr = 0.014\n",
      "09:52:54 - Training round 100, calling fit on worker: charlie, lr = 0.014\n",
      "09:52:54 - Training round 100, calling fit on worker: bob, lr = 0.014\n",
      "09:52:55 - Training round: 100, worker: charlie, avg_loss: tensor(0.1779, grad_fn=<MeanBackward1>)\n",
      "09:52:57 - Training round: 100, worker: alice, avg_loss: tensor(0.0050, grad_fn=<MeanBackward1>)\n",
      "09:52:58 - Training round: 100, worker: bob, avg_loss: tensor(0.0033, grad_fn=<MeanBackward1>)\n",
      "09:53:01 - Prediction hist: [ 1043  1165  1092  1352  989  801  920  898  796  944]\n",
      "09:53:01 - alice: Test set: Average loss: 0.0014, Accuracy: 9404/10000 (94)\n",
      "09:53:04 - Prediction hist: [ 921  1120  1009  899  1159  1130  1062  1015  863  822]\n",
      "09:53:04 - bob: Test set: Average loss: 0.0014, Accuracy: 9350/10000 (94)\n",
      "09:53:06 - Prediction hist: [ 901  1005  824  832  722  619  903  1141  1728  1325]\n",
      "09:53:06 - charlie: Test set: Average loss: 0.0028, Accuracy: 8729/10000 (87)\n",
      "09:53:08 - Prediction hist: [ 990  1127  1021  1007  975  901  955  1029  994  1001]\n",
      "09:53:08 - Federated model: Test set: Average loss: 0.0006, Accuracy: 9740/10000 (97)\n"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, data)\n",
    "learning_rate = args.lr\n",
    "for curr_round in range(1, args.training_rounds + 1):\n",
    "    logger.info(\"Starting training round %s/%s\", curr_round, args.training_rounds)\n",
    "\n",
    "    results = await asyncio.gather(\n",
    "        *[\n",
    "            rwc.fit_model_on_worker(\n",
    "                worker=worker,\n",
    "                traced_model=traced_model,                batch_size=args.batch_size,\n",
    "                curr_round=curr_round,\n",
    "                max_nr_batches=args.federate_after_n_batches,\n",
    "                lr=learning_rate,\n",
    "            )\n",
    "            for worker in worker_instances\n",
    "        ]\n",
    "    )\n",
    "    models = {}\n",
    "    loss_values = {}\n",
    "\n",
    "    test_models = curr_round % 10 == 1 or curr_round == args.training_rounds\n",
    "    if test_models:\n",
    "        rwc.evaluate_models_on_test_data(test_loader, results)\n",
    "\n",
    "    for worker_id, worker_model, worker_loss in results:\n",
    "        if worker_model is not None:\n",
    "            models[worker_id] = worker_model\n",
    "            loss_values[worker_id] = worker_loss\n",
    "\n",
    "    traced_model = utils.federated_avg(models)\n",
    "    if test_models:\n",
    "        rwc.evaluate_model(\"Federated model\", traced_model, \"cpu\", test_loader)\n",
    "\n",
    "    # decay learning rate\n",
    "    learning_rate = max(0.98 * learning_rate, args.lr * 0.01)\n",
    "\n",
    "if args.save_model:\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 rounds of training we acheive an accuracy > 95% on the entire testing dataset. \n",
    "This is impressing, given that no worker has access to more than 4 digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
