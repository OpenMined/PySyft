{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 - SplitNN for Vertically Partitioned Data\n",
    "\n",
    "<b>Recap:</b> The previous tutorial looked at building a basic SplitNN, where an NN was split into two segments on two seperate hosts. However, what if clients have multi-modal multi-institutional collaboration?\n",
    "\n",
    "<b>What is Vertically Partitioned Data? </b> Data is said to be vertically partitioned when several organizations own different attributes or modalities of information for the same set of entities.\n",
    "\n",
    "<b>Why use Partitioned Data? </b> Partition allows for orgnizations holding different modalities of data to learn distributed models without data sharing. Partitioning scheme is traditionally used to reduce the size of data by splitting and distribute to each client\n",
    "\n",
    "<b>Description: </b>This configuration allows for multiple clients holding different modalities of data to learn distributed models without data sharing. As a concrete example we walkthrough the case where radiology centers collaborate with pathology test centers and a server for disease diagnosis. Radiology centers holding imaging data modalities train a partial model upto the cut layer. In the same way the pathology test center having patient test results trains a partial model upto its own cut layer. The outputs at the cut layer from both these centers are then concatenated and sent to the disease diagnosis server that trains the rest of the model. This process is continued back and forth to complete the forward and backward propagations in order to train the distributed deep learning model without sharing each others raw data. In this tutorial, we split a single flatten image into two segments to mimic different modalities of data, you can also split it into arbitrary number.\n",
    "\n",
    "\n",
    "<img src=\"images/SplitNN_Veritically.png\" width=\"20%\">\n",
    "\n",
    "\n",
    "In this tutorial, we demonstrate the SplitNN class with a 3 segment distribution [[1](https://arxiv.org/abs/1812.00564)]. This time;\n",
    "\n",
    "- <b>$Alice_{0}$</b>\n",
    "    - Has Model Segment 1\n",
    "    - Has the handwritten images segment 1\n",
    "- <b>$Alice_{1}$</b>\n",
    "    - Has model Segment 2\n",
    "    - Has the handwritten images segment 2\n",
    "- <b>$Bob$</b> \n",
    "    - Has Model Segment 3\n",
    "    - Has the image labels\n",
    "\n",
    "Author:\n",
    "- Haofan Wang - githubï¼š[@haofanwang](https://github.com/haofanwang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitNN(torch.nn.Module):\n",
    "    def __init__(self, models, optimizers):\n",
    "        self.models = models\n",
    "        self.optimizers = optimizers\n",
    "        self.outputs = [None]*len(self.models)\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # save output of each client\n",
    "        for i in range(len(self.models)-1):\n",
    "          self.outputs[i] = self.models[i](x[i])\n",
    "        # concatenate outputs from clients\n",
    "        self.concatenated_input = torch.cat([self.outputs[i].copy().get() for i in range(len(self.outputs)-1)],dim=1)\n",
    "        self.concatenated_input = self.concatenated_input.detach().send(self.models[-1].location).requires_grad_()\n",
    "        # make a prediction on server model using recieved signal\n",
    "        self.outputs[-1] = self.models[-1](self.concatenated_input)\n",
    "        return self.outputs[-1]\n",
    "    \n",
    "    def backward(self):\n",
    "        for i in range(len(self.models)-1):\n",
    "          if i == 0:\n",
    "            grad_a = self.concatenated_input.grad[:,0:self.outputs[0].copy().get().size()[1]].copy().move(self.models[i].location)\n",
    "          else:\n",
    "            grad_a = self.concatenated_input.grad[:,self.outputs[i-1].copy().get().size()[1]:self.outputs[i-1].copy().get().size()[1]+self.outputs[i].copy().get().size()[1]].copy().move(self.models[i].location)\n",
    "          self.outputs[i].backward(grad_a)\n",
    "    \n",
    "    def zero_grads(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.step()\n",
    "    \n",
    "    def train(self):\n",
    "        for model in self.models:\n",
    "            model.train()\n",
    "    \n",
    "    def eval(self):\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            \n",
    "    @property\n",
    "    def location(self):\n",
    "        return self.models[0].location if self.models and len(self.models) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# define the input size for each client, each client may have different input size\n",
    "# you can also try arbitrary number of vertical splits, [size_1, size_2, ... size_n] where n is the total number of segments\n",
    "input_sizes = [392, 392]\n",
    "\n",
    "# define the hidden layer size, each client can have different hidden layer size, all clients share the same size for convinence\n",
    "hidden_sizes = [128, 320]\n",
    "\n",
    "# define the input size for the server\n",
    "concatenated_size = hidden_sizes[-1]*len(input_sizes)\n",
    "\n",
    "# define the output size, it should be the number of classes\n",
    "output_size = 10\n",
    "\n",
    "# define clients models, you can define any model here, but remember to make input sizes consistent with the size of splitted segments\n",
    "client_models = []\n",
    "for i in range(len(input_sizes)):\n",
    "  client_models.append(\n",
    "      nn.Sequential(\n",
    "                nn.Linear(input_sizes[i], hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "    )\n",
    "  )\n",
    "\n",
    "# define server model\n",
    "server_model = [\n",
    "    nn.Sequential(\n",
    "                nn.Linear(concatenated_size, output_size),\n",
    "                nn.LogSoftmax(dim=1),\n",
    "    )               \n",
    "]\n",
    "\n",
    "# complete model array\n",
    "models = client_models + server_model\n",
    "\n",
    "# create optimisers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(model.parameters(), lr=0.03,)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "# create client workers\n",
    "client_locations = []\n",
    "for i in range(len(input_sizes)):\n",
    "  alice = sy.VirtualWorker(hook, id=\"alice_\"+str(i))\n",
    "  client_locations.append(alice)\n",
    "\n",
    "# create server worker\n",
    "server_location = []\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "server_location.append(bob)\n",
    "\n",
    "# send model segments to starting locations\n",
    "model_locations = client_locations + server_location\n",
    "\n",
    "for model, location in zip(models, model_locations):\n",
    "    model.send(location)\n",
    "\n",
    "# instantiate a SpliNN class with our distributed segments and their respective optimizers\n",
    "splitNN =  SplitNN(models, optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def train(images, target, splitNN):\n",
    "\n",
    "      #1) zero our grads\n",
    "      splitNN.zero_grads()\n",
    "\n",
    "      #2) make a prediction\n",
    "      pred = splitNN.forward(images)\n",
    "\n",
    "      #3) calculate the loss\n",
    "      criterion = nn.NLLLoss()\n",
    "      loss = criterion(pred, labels)\n",
    "\n",
    "      #4) backprop the loss on the end layer\n",
    "      loss.backward()\n",
    "\n",
    "      #5) feed gradients backward through the nework\n",
    "      splitNN.backward()\n",
    "\n",
    "      #6) update the weights\n",
    "      splitNN.step()\n",
    "      \n",
    "      return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    splitNN.train()\n",
    "    for images, labels in trainloader:\n",
    "        # flatten data\n",
    "        images = images.view(images.shape[0],-1)\n",
    "        # splitted image segments\n",
    "        split_images = []\n",
    "        for i in range(len(input_sizes)):\n",
    "          if i == 0:\n",
    "            split_image = images[:,0:input_sizes[i]].send(model_locations[i])\n",
    "          else:\n",
    "            split_image = images[:,input_sizes[i-1]:input_sizes[i-1]+input_sizes[i]].send(model_locations[i])\n",
    "          split_image = split_image.view(images.shape[0], -1)\n",
    "          split_images.append(split_image)\n",
    "        # image labels\n",
    "        labels = labels.send(bob)\n",
    "        loss = train(split_images, labels, splitNN)\n",
    "        running_loss += loss.get()\n",
    "\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, dataset_name):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            # flatten data\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            # splitted image segments\n",
    "            split_images = []\n",
    "            for i in range(len(input_sizes)):\n",
    "              if i == 0:\n",
    "                split_image = data[:,0:input_sizes[i]].send(model_locations[i])\n",
    "              else:\n",
    "                split_image = data[:,input_sizes[i-1]:input_sizes[i-1]+input_sizes[i]].send(model_locations[i])\n",
    "              split_image = split_image.view(data.shape[0], -1)\n",
    "              split_images.append(split_image)\n",
    "\n",
    "            output = model(split_images).get()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    print(\"{}: Accuracy {}/{} ({:.0f}%)\".format(dataset_name, \n",
    "                                                correct,\n",
    "                                                len(dataloader.dataset), \n",
    "                                                100. * correct / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "test(splitNN, testloader, \"Test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}