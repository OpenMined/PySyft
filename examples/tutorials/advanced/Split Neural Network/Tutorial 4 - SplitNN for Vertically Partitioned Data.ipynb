{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 - SplitNN for Vertically Partitioned Data\n",
    "\n",
    "<b>Recap:</b> The previous tutorial looked at building a basic SplitNN, where an NN was split into two or multiple segments on two or multiple seperate hosts. However, what if clients have multi-modal multi-institutional collaboration?\n",
    "\n",
    "<b>Description: </b> This configuration allows for multiple clients holding different modalities of data to learn distributed models without data sharing. As a concrete example we walkthrough the case where two clients collaborate with a server for handwritten images recognition. The client_{0} holding imaging data modalities train a partial model upto the cut layer. In the same way the client_{1} having different data modalities trains a partial model upto its own cut layer. The outputs at the cut layer from both clients are then concatenated and sent to the server that trains the rest of the model. Here we have two clients that hold data of different modal. For simplification, we use two same images to represent the multi-modal data.\n",
    "\n",
    "\n",
    "<img src=\"images/SplitNN_Veritically.png\" width=\"20%\">\n",
    "\n",
    "\n",
    "In this tutorial, we demonstrate the SplitNN class with a 3 segment distribution [[1](https://arxiv.org/abs/1812.00564)]. This time;\n",
    "\n",
    "- <b>$Alice_{0}$</b>\n",
    "    - Has Model Segment 1\n",
    "    - Has the handwritten images\n",
    "- <b>$Alice_{1}$</b>\n",
    "    - Has model Segment 2\n",
    "    - Has the handwritten images\n",
    "- <b>$Bob$</b> \n",
    "    - Has Model Segment 3\n",
    "    - Has the image labels\n",
    "    \n",
    "We use the exact same model as we used in the previous tutorial, only this time we have two clients and one host.\n",
    "\n",
    "\n",
    "Author:\n",
    "- Haofan Wang - githubï¼š[@haofanwang](https://github.com/haofanwang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Define our model segments\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 320, 640]\n",
    "output_size = 10\n",
    "\n",
    "models = [\n",
    "    nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[2], output_size),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create optimisers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(model.parameters(), lr=0.03,)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "# create some workers\n",
    "alice_0 = sy.VirtualWorker(hook, id=\"alice_0\")\n",
    "alice_1 = sy.VirtualWorker(hook, id=\"alice_1\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "workers = alice_0, alice_1, bob\n",
    "\n",
    "# Send Model Segments to starting locations\n",
    "model_locations = [alice_0, alice_1, bob]\n",
    "\n",
    "for model, location in zip(models, model_locations):\n",
    "    model.send(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def train(images_0, images_1, target, models, optimizers):\n",
    "    # Training Logic\n",
    "\n",
    "    #1) erase previous gradients (if they exist)\n",
    "    for opt in optimizers:\n",
    "      opt.zero_grad()\n",
    "\n",
    "    #2) each client makes a prediction\n",
    "    a_0 = models[0](images_0)\n",
    "    a_1 = models[1](images_1)\n",
    "\n",
    "    #3) break the computation graph link, and send the activation signal to the next model\n",
    "    remote_a_0 = a_0.detach().move(models[2].location).requires_grad_()\n",
    "    remote_a_1 = a_1.detach().move(models[2].location).requires_grad_()\n",
    "\n",
    "    #4) the outputs from both clients are concatenated and sent to the server that trains the rest of the model\n",
    "    remote_a = torch.zeros(images.shape[0],hidden_sizes[2])\n",
    "    remote_a[:,:hidden_sizes[1]] = remote_a_0.copy().get()\n",
    "    remote_a[:,hidden_sizes[1]:] = remote_a_1.copy().get()\n",
    "    remote_a = remote_a.detach().send(models[2].location).requires_grad_()\n",
    "\n",
    "    #5) make prediction on next model using recieved signal\n",
    "    pred = models[2](remote_a)\n",
    "\n",
    "    #6) calculate how much we missed\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = criterion(pred, labels)\n",
    "\n",
    "    #7) figure out which weights caused us to miss\n",
    "    loss.backward()\n",
    "\n",
    "    #8) send gradient of the recieved activation signal to the models behind\n",
    "    grad_a_0 = remote_a.grad[:,:hidden_sizes[1]].copy().move(models[0].location)\n",
    "    grad_a_1 = remote_a.grad[:,hidden_sizes[1]:hidden_sizes[2]].copy().move(models[1].location)\n",
    "\n",
    "    #9) backpropagate on bottom models given this gradient\n",
    "    a_0.backward(grad_a_0)\n",
    "    a_1.backward(grad_a_1)\n",
    "\n",
    "    #10) change the weights\n",
    "    for opt in optimizers:\n",
    "        opt.step()\n",
    "    \n",
    "    #11) print our progress\n",
    "    return loss.detach().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images_0 = images.send(alice_0)\n",
    "        images_0 = images_0.view(images_0.shape[0], -1)\n",
    "        images_1 = images.send(alice_1)\n",
    "        images_1 = images_1.view(images_1.shape[0], -1)\n",
    "        labels = labels.send(bob)\n",
    "\n",
    "        loss = train(images_0, images_1, labels, models, optimizers)\n",
    "        running_loss += loss\n",
    "\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, dataloader, dataset_name):\n",
    "    for model in models:\n",
    "      model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, target in testloader:\n",
    "          #1) send data to clients\n",
    "          images_0 = images.send(alice_0)\n",
    "          images_0 = images_0.view(images_0.shape[0], -1)\n",
    "          images_1 = images.send(alice_1)\n",
    "          images_1 = images_1.view(images_1.shape[0], -1)\n",
    "          #2) each client makes a prediction\n",
    "          a_0 = models[0](images_0)\n",
    "          a_1 = models[1](images_1)\n",
    "          #3) break the computation graph link, and send the activation signal to the client\n",
    "          remote_a_0 = a_0.detach().move(models[2].location).requires_grad_()\n",
    "          remote_a_1 = a_1.detach().move(models[2].location).requires_grad_()\n",
    "          #4) the outputs from both clients are concatenated and sent to the server that trains the rest of the model\n",
    "          remote_a = torch.zeros(images.shape[0],hidden_sizes[2])\n",
    "          remote_a[:,:hidden_sizes[1]] = remote_a_0.copy().get()\n",
    "          remote_a[:,hidden_sizes[1]:] = remote_a_1.copy().get()\n",
    "          remote_a = remote_a.detach().send(models[2].location).requires_grad_()\n",
    "          #5) make prediction on next model using recieved signal\n",
    "          output = models[2](remote_a).get()\n",
    "          #6) calculate the the number of correct predictions\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    \n",
    "    print(\"{}: Accuracy {}/{} ({:.0f}%)\".format(dataset_name, \n",
    "                                                correct,\n",
    "                                                len(dataloader.dataset), \n",
    "                                                100. * correct / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "test(models, testloader, \"Test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
