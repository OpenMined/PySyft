{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 - SplitNN for Vertically Partitioned Data\n",
    "\n",
    "<b>Recap:</b> The previous tutorial looked at building a basic SplitNN, where an NN was split into two segments on two seperate hosts. However, what if clients have multi-modal multi-institutional collaboration?\n",
    "\n",
    "<b>Description: </b>Here we simply use two same images to represent the multi-modal data. We demonstrate the SplitNN class with a 3 segment distribution. This time,\n",
    "\n",
    "\n",
    "<img src=\"images/SplitNN_Veritically.png\" width=\"20%\">\n",
    "\n",
    "\n",
    "In this tutorial, we demonstrate the SplitNN class with a 3 segment distribution [[1](https://arxiv.org/abs/1812.00564)]. This time;\n",
    "\n",
    "- <b>$Alice_{0}$</b>\n",
    "    - Has Model Segment 1\n",
    "    - Has the handwritten images\n",
    "- <b>$Alice_{1}$</b>\n",
    "    - Has model Segment 2\n",
    "    - Has the handwritten images\n",
    "- <b>$Bob$</b> \n",
    "    - Has Model Segment 3\n",
    "    - Has the image labels\n",
    "    \n",
    "We use the exact same model as we used in the previous tutorial, only this time we have two clients and one host.\n",
    "\n",
    "\n",
    "Author:\n",
    "- Haofan Wang - githubï¼š[@haofanwang](https://github.com/haofanwang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# Define our model segments\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 320, 640]\n",
    "output_size = 10\n",
    "\n",
    "models = [\n",
    "    nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[2], output_size),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create optimisers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(model.parameters(), lr=0.03,)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "# create some workers\n",
    "alice_0 = sy.VirtualWorker(hook, id=\"alice_0\")\n",
    "alice_1 = sy.VirtualWorker(hook, id=\"alice_1\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "workers = alice_0, alice_1, bob\n",
    "\n",
    "# Send Model Segments to starting locations\n",
    "model_locations = [alice_0, alice_1, bob]\n",
    "\n",
    "for model, location in zip(models, model_locations):\n",
    "    model.send(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "def train(images_0, images_1, target, models, optimizers):\n",
    "    # Training Logic\n",
    "\n",
    "    #1) erase previous gradients (if they exist)\n",
    "    for opt in optimizers:\n",
    "      opt.zero_grad()\n",
    "\n",
    "    #2) make a prediction\n",
    "    a_0 = models[0](images_0)\n",
    "    a_1 = models[1](images_1)\n",
    "\n",
    "    #3) break the computation graph link, and send the activation signal to the next model\n",
    "    remote_a_0 = a_0.detach().move(models[2].location).requires_grad_()\n",
    "    remote_a_1 = a_1.detach().move(models[2].location).requires_grad_()\n",
    "    remote_a = torch.zeros(images.shape[0],hidden_sizes[2])\n",
    "    remote_a[:,:hidden_sizes[1]] = remote_a_0.copy().get()\n",
    "    remote_a[:,hidden_sizes[1]:] = remote_a_1.copy().get()\n",
    "    remote_a = remote_a.detach().send(models[2].location).requires_grad_()\n",
    "\n",
    "    #4) make prediction on next model using recieved signal\n",
    "    pred = models[2](remote_a)\n",
    "\n",
    "    #5) calculate how much we missed\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = criterion(pred, labels)\n",
    "\n",
    "    #6) figure out which weights caused us to miss\n",
    "    loss.backward()\n",
    "\n",
    "    #7) send gradient of the recieved activation signal to the model behind\n",
    "    grad_a_0 = remote_a.grad[:,:hidden_sizes[1]].copy().move(models[0].location)\n",
    "    grad_a_1 = remote_a.grad[:,hidden_sizes[1]:hidden_sizes[2]].copy().move(models[1].location)\n",
    "\n",
    "    #8) backpropagate on bottom model given this gradient\n",
    "    a_0.backward(grad_a_0)\n",
    "    a_1.backward(grad_a_1)\n",
    "\n",
    "    #9) change the weights\n",
    "    for opt in optimizers:\n",
    "        opt.step()\n",
    "    \n",
    "    #10) print our progress\n",
    "    return loss.detach().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images_0 = images.send(alice_0)\n",
    "        images_0 = images_0.view(images_0.shape[0], -1)\n",
    "        images_1 = images.send(alice_1)\n",
    "        images_1 = images_1.view(images_1.shape[0], -1)\n",
    "        labels = labels.send(bob)\n",
    "\n",
    "        loss = train(images_0, images_1, labels, models, optimizers)\n",
    "        running_loss += loss\n",
    "\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, running_loss/len(trainloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, dataloader, dataset_name):\n",
    "    for model in models:\n",
    "      model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, target in testloader:\n",
    "          images_0 = images.send(alice_0)\n",
    "          images_0 = images_0.view(images_0.shape[0], -1)\n",
    "          images_1 = images.send(alice_1)\n",
    "          images_1 = images_1.view(images_1.shape[0], -1)\n",
    "          a_0 = models[0](images_0)\n",
    "          a_1 = models[1](images_1)\n",
    "          remote_a_0 = a_0.detach().move(models[2].location).requires_grad_()\n",
    "          remote_a_1 = a_1.detach().move(models[2].location).requires_grad_()\n",
    "          remote_a = torch.zeros(images.shape[0],hidden_sizes[2])\n",
    "          remote_a[:,:hidden_sizes[1]] = remote_a_0.copy().get()\n",
    "          remote_a[:,hidden_sizes[1]:] = remote_a_1.copy().get()\n",
    "          remote_a = remote_a.detach().send(models[2].location).requires_grad_()\n",
    "          output = models[2](remote_a).get()\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    \n",
    "    print(\"{}: Accuracy {}/{} ({:.0f}%)\".format(dataset_name, \n",
    "                                                correct,\n",
    "                                                len(dataloader.dataset), \n",
    "                                                100. * correct / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)",
    "test(models, testloader, \"Test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
