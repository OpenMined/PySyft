{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Federated learning with websockets and federated averaging\n",
    "\n",
    "This notebook will go through the steps to run a federated learning via websocket workers. We will use federated averaging to join the remotely trained models. \n",
    "\n",
    "Authors:\n",
    "- midokura-silvia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: start the websocket server workers\n",
    "Each worker is represented by two parts, a local handle (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is calle a websocket server worker.\n",
    "\n",
    "So first, we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook) the script start_websocket_servers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the websocket client workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import syft as sy\n",
    "from syft.workers import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syft.frameworks.torch.federated import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_websocket_client as rwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, cuda=False, epochs=2, federate_after_n_batches=50, lr=0.01, save_model=False, seed=1, test_batch_size=1000, use_virtual=False, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "args = rwc.define_and_get_arguments(args=[])\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local access point to the remote workers.\n",
    "Note that this step will fail, if the websocket server workers are not running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WebsocketClientWorker id:alice #tensors:0>, <WebsocketClientWorker id:bob #tensors:0>, <WebsocketClientWorker id:charlie #tensors:0>]\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "workers = [alice, bob, charlie]\n",
    "print(workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and distribute the training data\n",
    "\n",
    "We will use the MNIST dataset and distribute the data randomly onto the workers. \n",
    "This is not realistic for a federated training setup, where the data would normally already be available at the remote workers.\n",
    "\n",
    "We instantiate two FederatedDataLoaders, one for the train and one for the test set of the MNIST dataset.\n",
    "\n",
    "If you run into BrokenPipe errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ).federate(tuple(workers)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    iter_per_worker=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)\n",
    "#forward method of the model:\n",
    "#    def forward(self, x):\n",
    "#        x = F.relu(self.conv1(x))\n",
    "#        x = F.max_pool2d(x, 2, 2)\n",
    "#        x = F.relu(self.conv2(x))\n",
    "#        x = F.max_pool2d(x, 2, 2)\n",
    "#        x = x.view(-1, 4 * 4 * 50)\n",
    "#        x = F.relu(self.fc1(x))\n",
    "#        x = self.fc2(x)\n",
    "#        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define the training loop. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, federated_train_loader, lr, federate_after_n_batches):\n",
    "    model.train()\n",
    "\n",
    "    nr_batches = federate_after_n_batches\n",
    "\n",
    "    models = {}\n",
    "    loss_values = {}\n",
    "\n",
    "    iter(federated_train_loader)  # initialize iterators\n",
    "    batches = rwc.get_next_batches(federated_train_loader, nr_batches)\n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "        print(\"Starting training round, batches [{}, {}]\".format(counter, counter + nr_batches))\n",
    "        data_for_all_workers = True\n",
    "        for worker in batches:\n",
    "            curr_batches = batches[worker]\n",
    "            if curr_batches:\n",
    "                models[worker], loss_values[worker] = rwc.train_on_batches(\n",
    "                    worker, curr_batches, model, device, lr\n",
    "                )\n",
    "            else:\n",
    "                data_for_all_workers = False\n",
    "        counter += nr_batches\n",
    "        if not data_for_all_workers:\n",
    "            logger.debug(\"At least one worker ran out of data, stopping.\")\n",
    "            break\n",
    "\n",
    "        model = utils.federated_avg(models)\n",
    "        batches = rwc.get_next_batches(federated_train_loader, nr_batches)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "FORMAT = \"%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s\"\n",
    "LOG_LEVEL = logging.DEBUG\n",
    "logging.basicConfig(format=FORMAT, level=LOG_LEVEL)\n",
    "logger = logging.getLogger(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training\n",
    "\n",
    "Now we are ready to start the federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:25:59,866 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 2.310694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [0, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:26:01,036 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 2.204401\n",
      "2019-04-02 13:26:04,014 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 2.298535\n",
      "2019-04-02 13:26:05,164 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 2.222379\n",
      "2019-04-02 13:26:08,184 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.314186\n",
      "2019-04-02 13:26:09,346 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 2.209582\n",
      "2019-04-02 13:26:21,017 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 2.073505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [50, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:26:22,160 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 1.754840\n",
      "2019-04-02 13:26:25,317 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 2.028851\n",
      "2019-04-02 13:26:26,494 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 1.828003\n",
      "2019-04-02 13:26:29,629 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.114206\n",
      "2019-04-02 13:26:30,820 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 1.715694\n",
      "2019-04-02 13:26:43,002 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 1.188415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [100, 150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:26:44,367 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.915637\n",
      "2019-04-02 13:26:47,746 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 1.236009\n",
      "2019-04-02 13:26:49,033 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.994033\n",
      "2019-04-02 13:26:52,542 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 1.239189\n",
      "2019-04-02 13:26:54,501 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.812181\n",
      "2019-04-02 13:27:06,706 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.611034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [150, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:27:08,065 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.636844\n",
      "2019-04-02 13:27:11,406 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.665273\n",
      "2019-04-02 13:27:12,602 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.513543\n",
      "2019-04-02 13:27:15,916 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.644994\n",
      "2019-04-02 13:27:17,085 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.593856\n",
      "2019-04-02 13:27:29,204 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.418159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [200, 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:27:30,578 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.521532\n",
      "2019-04-02 13:27:33,963 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.413765\n",
      "2019-04-02 13:27:35,185 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.422564\n",
      "2019-04-02 13:27:38,570 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.481335\n",
      "2019-04-02 13:27:39,781 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.268464\n",
      "2019-04-02 13:27:52,044 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.301184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [250, 300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:27:53,321 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.271859\n",
      "2019-04-02 13:27:56,802 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.295570\n",
      "2019-04-02 13:27:58,075 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.330974\n",
      "2019-04-02 13:28:01,467 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.302555\n",
      "2019-04-02 13:28:02,717 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.363734\n",
      "2019-04-02 13:28:08,105 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/13 (0%)]\tLoss: 0.312827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [300, 350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:28:10,777 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/13 (0%)]\tLoss: 0.382983\n",
      "2019-04-02 13:28:13,487 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.212429\n",
      "2019-04-02 13:28:16,078 DEBUG <ipython-input-8-997890e4f55a>(l:26) - At least one worker ran out of data, stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [350, 400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:28:17,982 INFO run_websocket_client.py(l:158) - \n",
      "\n",
      "2019-04-02 13:28:17,982 INFO run_websocket_client.py(l:162) - Test set: Average loss: 0.3572, Accuracy: 8959/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:28:27,004 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.307087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [0, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:28:28,109 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.221510\n",
      "2019-04-02 13:28:31,311 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.469802\n",
      "2019-04-02 13:28:32,359 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.318596\n",
      "2019-04-02 13:28:35,480 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.334569\n",
      "2019-04-02 13:28:36,542 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.489715\n",
      "2019-04-02 13:28:48,620 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.323010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [50, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:28:49,725 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.175121\n",
      "2019-04-02 13:28:52,975 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.478969\n",
      "2019-04-02 13:28:54,038 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.158733\n",
      "2019-04-02 13:28:57,275 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.179302\n",
      "2019-04-02 13:28:58,411 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.251905\n",
      "2019-04-02 13:29:10,734 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.667642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [100, 150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:29:11,868 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.083659\n",
      "2019-04-02 13:29:15,079 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.304384\n",
      "2019-04-02 13:29:16,111 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.226942\n",
      "2019-04-02 13:29:19,384 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.329214\n",
      "2019-04-02 13:29:20,480 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.758069\n",
      "2019-04-02 13:29:32,499 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.140696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [150, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:29:33,633 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.359507\n",
      "2019-04-02 13:29:36,912 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.220139\n",
      "2019-04-02 13:29:38,016 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.487040\n",
      "2019-04-02 13:29:41,303 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.230506\n",
      "2019-04-02 13:29:42,376 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.130359\n",
      "2019-04-02 13:29:54,624 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.224828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [200, 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:29:55,730 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.233075\n",
      "2019-04-02 13:29:59,035 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.114764\n",
      "2019-04-02 13:30:00,125 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.273777\n",
      "2019-04-02 13:30:03,486 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.222909\n",
      "2019-04-02 13:30:04,553 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.245994\n",
      "2019-04-02 13:30:16,801 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.363002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [250, 300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:30:17,914 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.283861\n",
      "2019-04-02 13:30:21,192 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.337727\n",
      "2019-04-02 13:30:22,280 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.853602\n",
      "2019-04-02 13:30:25,504 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.163174\n",
      "2019-04-02 13:30:26,581 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.240322\n",
      "2019-04-02 13:30:32,306 DEBUG run_websocket_client.py(l:77) - Train Worker alice: [0/13 (0%)]\tLoss: 0.200543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [300, 350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:30:35,006 DEBUG run_websocket_client.py(l:77) - Train Worker bob: [0/13 (0%)]\tLoss: 0.136794\n",
      "2019-04-02 13:30:37,764 DEBUG run_websocket_client.py(l:77) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.507194\n",
      "2019-04-02 13:30:40,336 DEBUG <ipython-input-8-997890e4f55a>(l:26) - At least one worker ran out of data, stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [350, 400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 13:30:42,234 INFO run_websocket_client.py(l:158) - \n",
      "\n",
      "2019-04-02 13:30:42,234 INFO run_websocket_client.py(l:162) - Test set: Average loss: 0.2389, Accuracy: 9261/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n",
    "    model = train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)\n",
    "    rwc.test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
