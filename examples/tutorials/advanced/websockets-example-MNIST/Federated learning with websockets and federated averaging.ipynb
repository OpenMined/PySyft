{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Federated learning with websockets and federated averaging with possible solutions for problem you might face\n",
    "\n",
    "This notebook will discuss detailed steps and problems you might face when going through these steps\n",
    "\n",
    "Make sure you have correct websocket-client library because if you have another websocket library installed on top of websocket-client when you run this command ``` import websocket ``` it try will access that additional websocket library first because websocket-client is also called imported into your python script by ``` import websocket ``` and when you try to create connection with this command ``` websocket.create_connection() ``` this causes websocket don't have any module named create_connection\n",
    "Solution: in terminal activate that environment where syft is installed run ```pip uninstall websocket``` to remove any additional websocket libraries then run ```pip install --upgrade websocket_client```\n",
    "\n",
    "Authors:\n",
    "- midokura-silvia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: start the websocket server workers\n",
    "\n",
    "Each worker is represented by two parts, a local handle (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker.\n",
    "\n",
    "So first, you need to ```cd``` to the folder where this notebook and other additional files for running server and client are \n",
    "\n",
    "for example\n",
    "in windows 10  \n",
    ">cd (path till projects directory) \\python_projects\\websockets-example-MNIST\n",
    "\n",
    "Note: Don't copy paste the path above because this is purely for the sake example your path may differ depending on your OS and project folder\n",
    " \n",
    "\n",
    "\n",
    "because if you don't when you try to run ```python start_websocket_servers.py``` command in terminal this script open sub processes with python which runs other scripts that starts websocket server workers and only the name of the file with its extension is mentioned because the file's path may vary.\n",
    "we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_servers.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the websocket client workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/george/.conda/envs/pysyft-contrib/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/george/.conda/envs/pysyft-contrib/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import syft as sy\n",
    "from syft.workers.websocket_client import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syft.frameworks.torch.fl import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_websocket_client as rwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, cuda=False, epochs=2, federate_after_n_batches=50, lr=0.01, save_model=False, seed=1, test_batch_size=1000, use_virtual=False, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "args = rwc.define_and_get_arguments(args=[])\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local access point to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WebsocketClientWorker id:alice #objects local:0 #objects remote: 0>, <WebsocketClientWorker id:bob #objects local:0 #objects remote: 0>, <WebsocketClientWorker id:charlie #objects local:0 #objects remote: 0>]\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "workers = [alice, bob, charlie]\n",
    "print(workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and distribute the training data\n",
    "\n",
    "We will use the MNIST dataset and distribute the data randomly onto the workers. \n",
    "This is not realistic for a federated training setup, where the data would normally already be available at the remote workers.\n",
    "\n",
    "We instantiate two FederatedDataLoaders, one for the train and one for the test set of the MNIST dataset.\n",
    "\n",
    "*If you run into BrokenPipe errors go to the parrent directory of the directory where your project is and delete data folder then restart notebook and try again if the error comes again delete that data folder again run the following command*\n",
    "\n",
    "for example directory for data \n",
    "\n",
    ">(path till projects directory) \\python_projects\\\n",
    "\n",
    "directory for project notebook and scripts\n",
    "\n",
    ">(path till projects directory) \\python_projects\\websockets-example-MNIST\n",
    "\n",
    "Note: Don't copy paste the path above because this is purely for the sake example your path may differ depending on your OS and project folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f80ea69b310>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this box only if the the next box gives pipeline error\n",
    "torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ).federate(tuple(workers)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    iter_per_worker=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training\n",
    "\n",
    "\n",
    "Now we are ready to start the federated training. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model and calculate test accuracy over that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 21:07:41,373 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [0, 50]\n",
      "2019-12-09 21:07:41,550 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 2.310694\n",
      "2019-12-09 21:07:43,630 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 2.204400\n",
      "2019-12-09 21:07:47,418 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 2.298535\n",
      "2019-12-09 21:07:49,171 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 2.222379\n",
      "2019-12-09 21:07:52,802 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.314187\n",
      "2019-12-09 21:07:54,292 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 2.209582\n",
      "2019-12-09 21:08:13,388 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [50, 100]\n",
      "2019-12-09 21:08:13,556 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 2.071486\n",
      "2019-12-09 21:08:15,052 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 1.756470\n",
      "2019-12-09 21:08:18,689 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 2.031766\n",
      "2019-12-09 21:08:20,194 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 1.829469\n",
      "2019-12-09 21:08:23,824 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.106292\n",
      "2019-12-09 21:08:25,330 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 1.713612\n",
      "2019-12-09 21:08:47,079 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [100, 150]\n",
      "2019-12-09 21:08:47,251 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 1.196825\n",
      "2019-12-09 21:08:50,516 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.914292\n",
      "2019-12-09 21:08:55,299 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 1.225523\n",
      "2019-12-09 21:08:57,426 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.988041\n",
      "2019-12-09 21:09:01,921 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 1.251325\n",
      "2019-12-09 21:09:03,436 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.804794\n",
      "2019-12-09 21:09:22,593 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [150, 200]\n",
      "2019-12-09 21:09:22,771 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.593456\n",
      "2019-12-09 21:09:24,228 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.623448\n",
      "2019-12-09 21:09:27,722 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.602651\n",
      "2019-12-09 21:09:29,133 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.504970\n",
      "2019-12-09 21:09:32,700 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.615778\n",
      "2019-12-09 21:09:34,137 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.596605\n",
      "2019-12-09 21:09:51,329 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [200, 250]\n",
      "2019-12-09 21:09:51,501 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.370626\n",
      "2019-12-09 21:09:52,917 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.519373\n",
      "2019-12-09 21:09:56,484 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.387380\n",
      "2019-12-09 21:09:57,915 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.425014\n",
      "2019-12-09 21:10:01,646 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.468316\n",
      "2019-12-09 21:10:03,109 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.269933\n",
      "2019-12-09 21:10:20,823 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [250, 300]\n",
      "2019-12-09 21:10:20,990 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.275170\n",
      "2019-12-09 21:10:22,658 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.284278\n",
      "2019-12-09 21:10:26,249 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.286956\n",
      "2019-12-09 21:10:28,027 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.333495\n",
      "2019-12-09 21:10:32,305 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.309012\n",
      "2019-12-09 21:10:33,837 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.366567\n",
      "2019-12-09 21:10:42,084 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [300, 350]\n",
      "2019-12-09 21:10:42,250 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/13 (0%)]\tLoss: 0.288976\n",
      "2019-12-09 21:10:45,047 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/13 (0%)]\tLoss: 0.315323\n",
      "2019-12-09 21:10:48,312 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.173295\n",
      "2019-12-09 21:10:51,328 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [350, 400]\n",
      "2019-12-09 21:10:51,338 DEBUG run_websocket_client.py(l:142) - At least one worker ran out of data, stopping.\n",
      "2019-12-09 21:10:53,502 DEBUG run_websocket_client.py(l:164) - \n",
      "\n",
      "2019-12-09 21:10:53,503 INFO run_websocket_client.py(l:168) - Test set: Average loss: 0.3283, Accuracy: 9021/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 21:11:13,931 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [0, 50]\n",
      "2019-12-09 21:11:14,078 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.270971\n",
      "2019-12-09 21:11:15,791 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.448859\n",
      "2019-12-09 21:11:19,723 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.380279\n",
      "2019-12-09 21:11:21,356 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.445413\n",
      "2019-12-09 21:11:25,686 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.381758\n",
      "2019-12-09 21:11:27,680 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.317653\n",
      "2019-12-09 21:11:48,052 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [50, 100]\n",
      "2019-12-09 21:11:48,234 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.275575\n",
      "2019-12-09 21:11:49,727 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.230490\n",
      "2019-12-09 21:11:53,355 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.331888\n",
      "2019-12-09 21:11:54,878 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.349561\n",
      "2019-12-09 21:11:59,956 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.204984\n",
      "2019-12-09 21:12:02,972 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.296030\n",
      "2019-12-09 21:12:23,484 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [100, 150]\n",
      "2019-12-09 21:12:23,664 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.410305\n",
      "2019-12-09 21:12:25,466 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.126691\n",
      "2019-12-09 21:12:29,390 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.191846\n",
      "2019-12-09 21:12:31,150 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.179417\n",
      "2019-12-09 21:12:35,296 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.309651\n",
      "2019-12-09 21:12:36,854 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.510307\n",
      "2019-12-09 21:13:02,592 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [150, 200]\n",
      "2019-12-09 21:13:02,929 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.121450\n",
      "2019-12-09 21:13:05,179 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.334305\n",
      "2019-12-09 21:13:09,146 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.240957\n",
      "2019-12-09 21:13:10,840 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.252314\n",
      "2019-12-09 21:13:14,599 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.243795\n",
      "2019-12-09 21:13:16,091 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.151225\n",
      "2019-12-09 21:13:44,315 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [200, 250]\n",
      "2019-12-09 21:13:44,556 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.177041\n",
      "2019-12-09 21:13:46,065 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.169899\n",
      "2019-12-09 21:13:49,780 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.294366\n",
      "2019-12-09 21:13:51,420 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.263524\n",
      "2019-12-09 21:13:55,500 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.191694\n",
      "2019-12-09 21:13:57,364 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.232365\n",
      "2019-12-09 21:14:21,936 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [250, 300]\n",
      "2019-12-09 21:14:22,150 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/50 (0%)]\tLoss: 0.224772\n",
      "2019-12-09 21:14:24,315 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [25/50 (50%)]\tLoss: 0.321485\n",
      "2019-12-09 21:14:30,373 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/50 (0%)]\tLoss: 0.207911\n",
      "2019-12-09 21:14:33,320 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [25/50 (50%)]\tLoss: 0.578944\n",
      "2019-12-09 21:14:38,600 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.093329\n",
      "2019-12-09 21:14:40,613 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.251194\n",
      "2019-12-09 21:14:48,856 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [300, 350]\n",
      "2019-12-09 21:14:49,021 DEBUG run_websocket_client.py(l:78) - Train Worker alice: [0/13 (0%)]\tLoss: 0.232479\n",
      "2019-12-09 21:14:52,118 DEBUG run_websocket_client.py(l:78) - Train Worker bob: [0/13 (0%)]\tLoss: 0.103535\n",
      "2019-12-09 21:14:55,431 DEBUG run_websocket_client.py(l:78) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.352951\n",
      "2019-12-09 21:14:58,515 DEBUG run_websocket_client.py(l:129) - Starting training round, batches [350, 400]\n",
      "2019-12-09 21:14:58,523 DEBUG run_websocket_client.py(l:142) - At least one worker ran out of data, stopping.\n",
      "2019-12-09 21:15:00,820 DEBUG run_websocket_client.py(l:164) - \n",
      "\n",
      "2019-12-09 21:15:00,821 INFO run_websocket_client.py(l:168) - Test set: Average loss: 0.2076, Accuracy: 9375/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n",
    "    model = rwc.train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)\n",
    "    rwc.test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
