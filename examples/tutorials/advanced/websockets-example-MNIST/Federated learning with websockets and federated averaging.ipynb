{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Federated learning with websockets and federated averaging with possible solutions for problem you might face\n",
    "\n",
    "This notebook will discuss detailed steps and problems you might face when going through these steps\n",
    "\n",
    "Make sure you have correct websocket-client library because if you have another websocket library installed on top of websocket-client when you run this command ``` import websocket ``` it try will access that additional websocket library first because websocket-client is also called imported into your python script by ``` import websocket ``` and when you try to create connection with this command ``` websocket.create_connection() ``` this causes websocket don't have any module named create_connection\n",
    "Solution: in terminal activate that environment where syft is installed run ```pip uninstall websocket``` to remove any additional websocket libraries then run ```pip install --upgrade websocket_client```\n",
    "\n",
    "Authors:\n",
    "- midokura-silvia\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: start the websocket server workers\n",
    "\n",
    "Each worker is represented by two parts, a local handle (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker.\n",
    "\n",
    "So first, you need to ```cd``` to the folder where this notebook and other additional files for running server and client are \n",
    "\n",
    "for example\n",
    "in windows 10  \n",
    ">cd (path till projects directory) \\python_projects\\websockets-example-MNIST\n",
    "\n",
    "Note: Don't copy paste the path above because this is purely for the sake example your path may differ depending on your OS and project folder\n",
    " \n",
    "\n",
    "\n",
    "because if you don't when you try to run ```python start_websocket_servers.py``` command in terminal this script open sub processes with python which runs other scripts that starts websocket server workers and only the name of the file with its extension is mentioned because the file's path may vary.\n",
    "we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_servers.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the websocket client workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0729 17:18:05.992472 13792 secure_random.py:22] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.14.0). Fix this by compiling custom ops.\n",
      "W0729 17:18:06.043451 13792 deprecation_wrapper.py:119] From h:\\softwares\\anaconda\\envs\\dlpytorch\\lib\\site-packages\\tf_encrypted\\session.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import syft as sy\n",
    "from syft.workers import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syft.frameworks.torch.federated import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_websocket_client as rwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, cuda=False, epochs=2, federate_after_n_batches=50, lr=0.01, save_model=False, seed=1, test_batch_size=1000, use_virtual=False, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "args = rwc.define_and_get_arguments(args=[])\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local access point to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WebsocketClientWorker id:alice #objects local:0 #objects remote: 0>, <WebsocketClientWorker id:bob #objects local:0 #objects remote: 0>, <WebsocketClientWorker id:charlie #objects local:0 #objects remote: 0>]\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "workers = [alice, bob, charlie]\n",
    "print(workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and distribute the training data\n",
    "\n",
    "We will use the MNIST dataset and distribute the data randomly onto the workers. \n",
    "This is not realistic for a federated training setup, where the data would normally already be available at the remote workers.\n",
    "\n",
    "We instantiate two FederatedDataLoaders, one for the train and one for the test set of the MNIST dataset.\n",
    "\n",
    "*If you run into BrokenPipe errors go to the parrent directory of the directory where your project is and delete data folder then restart notebook and try again if the error comes again delete that data folder again run the following command*\n",
    "\n",
    "for example directory for data \n",
    "\n",
    ">(path till projects directory) \\python_projects\\\n",
    "\n",
    "directory for project notebook and scripts\n",
    "\n",
    ">(path till projects directory) \\python_projects\\websockets-example-MNIST\n",
    "\n",
    "Note: Don't copy paste the path above because this is purely for the sake example your path may differ depending on your OS and project folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x20261c9f978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this box only if the the next box gives pipeline error\n",
    "torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ).federate(tuple(workers)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    iter_per_worker=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rwc.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training\n",
    "\n",
    "\n",
    "Now we are ready to start the federated training. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model and calculate test accuracy over that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-29 17:21:41,521 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [0, 50]\n",
      "2019-07-29 17:21:42,179 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 2.310694\n",
      "2019-07-29 17:21:45,464 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 2.204359\n",
      "2019-07-29 17:21:52,887 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 2.298535\n",
      "2019-07-29 17:21:56,445 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 2.222411\n",
      "2019-07-29 17:22:03,861 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.314186\n",
      "2019-07-29 17:22:07,290 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 2.209582\n",
      "2019-07-29 17:22:38,985 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [50, 100]\n",
      "2019-07-29 17:22:39,355 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 2.071541\n",
      "2019-07-29 17:22:42,655 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 1.756296\n",
      "2019-07-29 17:22:49,923 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 2.031839\n",
      "2019-07-29 17:22:53,262 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 1.829425\n",
      "2019-07-29 17:23:00,400 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.106277\n",
      "2019-07-29 17:23:03,748 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 1.713753\n",
      "2019-07-29 17:23:34,826 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [100, 150]\n",
      "2019-07-29 17:23:35,204 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 1.196739\n",
      "2019-07-29 17:23:38,561 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.914129\n",
      "2019-07-29 17:23:45,760 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 1.225457\n",
      "2019-07-29 17:23:49,063 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.987763\n",
      "2019-07-29 17:23:56,239 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 1.251302\n",
      "2019-07-29 17:23:59,629 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.804577\n",
      "2019-07-29 17:24:30,790 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [150, 200]\n",
      "2019-07-29 17:24:31,158 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.593472\n",
      "2019-07-29 17:24:34,505 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.623788\n",
      "2019-07-29 17:24:41,577 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.602587\n",
      "2019-07-29 17:24:44,868 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.504740\n",
      "2019-07-29 17:24:51,996 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.615880\n",
      "2019-07-29 17:24:55,412 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.596581\n",
      "2019-07-29 17:25:27,429 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [200, 250]\n",
      "2019-07-29 17:25:27,808 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.370606\n",
      "2019-07-29 17:25:31,254 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.519494\n",
      "2019-07-29 17:25:38,467 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.387370\n",
      "2019-07-29 17:25:41,834 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.424825\n",
      "2019-07-29 17:25:49,345 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.468345\n",
      "2019-07-29 17:25:52,966 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.270213\n",
      "2019-07-29 17:26:24,497 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [250, 300]\n",
      "2019-07-29 17:26:24,906 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.275150\n",
      "2019-07-29 17:26:28,621 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.284582\n",
      "2019-07-29 17:26:36,040 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.286806\n",
      "2019-07-29 17:26:39,406 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.333217\n",
      "2019-07-29 17:26:46,630 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.309225\n",
      "2019-07-29 17:26:50,181 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.366464\n",
      "2019-07-29 17:27:03,823 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [300, 350]\n",
      "2019-07-29 17:27:04,208 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/13 (0%)]\tLoss: 0.288865\n",
      "2019-07-29 17:27:09,828 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/13 (0%)]\tLoss: 0.315002\n",
      "2019-07-29 17:27:15,378 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.173256\n",
      "2019-07-29 17:27:20,828 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [350, 400]\n",
      "2019-07-29 17:27:20,849 DEBUG run_websocket_client.py(l:144) - At least one worker ran out of data, stopping.\n",
      "2019-07-29 17:27:26,161 DEBUG run_websocket_client.py(l:168) - \n",
      "\n",
      "2019-07-29 17:27:26,162 INFO run_websocket_client.py(l:172) - Test set: Average loss: 0.3281, Accuracy: 9024/10000 (90%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-29 17:27:51,358 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [0, 50]\n",
      "2019-07-29 17:27:51,661 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.270621\n",
      "2019-07-29 17:27:55,137 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.448597\n",
      "2019-07-29 17:28:02,405 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.380246\n",
      "2019-07-29 17:28:05,742 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.445294\n",
      "2019-07-29 17:28:12,956 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.381303\n",
      "2019-07-29 17:28:16,495 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.317282\n",
      "2019-07-29 17:28:48,148 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [50, 100]\n",
      "2019-07-29 17:28:48,496 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.275295\n",
      "2019-07-29 17:28:52,037 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.230472\n",
      "2019-07-29 17:28:59,531 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.331581\n",
      "2019-07-29 17:29:03,064 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.349212\n",
      "2019-07-29 17:29:10,366 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.205014\n",
      "2019-07-29 17:29:13,858 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.295628\n",
      "2019-07-29 17:29:45,990 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [100, 150]\n",
      "2019-07-29 17:29:46,367 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.410303\n",
      "2019-07-29 17:29:50,000 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.126529\n",
      "2019-07-29 17:29:57,413 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.191981\n",
      "2019-07-29 17:30:00,829 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.179206\n",
      "2019-07-29 17:30:08,112 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.309445\n",
      "2019-07-29 17:30:11,604 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.510404\n",
      "2019-07-29 17:30:43,343 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [150, 200]\n",
      "2019-07-29 17:30:43,730 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.121338\n",
      "2019-07-29 17:30:47,157 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.334477\n",
      "2019-07-29 17:30:54,657 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.240656\n",
      "2019-07-29 17:30:57,962 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.251898\n",
      "2019-07-29 17:31:05,139 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.243358\n",
      "2019-07-29 17:31:08,566 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.151492\n",
      "2019-07-29 17:31:40,577 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [200, 250]\n",
      "2019-07-29 17:31:40,938 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.176912\n",
      "2019-07-29 17:31:44,476 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.169594\n",
      "2019-07-29 17:31:51,769 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.294377\n",
      "2019-07-29 17:31:55,218 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.263648\n",
      "2019-07-29 17:32:02,762 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.191624\n",
      "2019-07-29 17:32:06,197 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.232179\n",
      "2019-07-29 17:32:38,326 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [250, 300]\n",
      "2019-07-29 17:32:38,693 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/50 (0%)]\tLoss: 0.224762\n",
      "2019-07-29 17:32:42,141 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [25/50 (50%)]\tLoss: 0.322799\n",
      "2019-07-29 17:32:49,598 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/50 (0%)]\tLoss: 0.207845\n",
      "2019-07-29 17:32:53,173 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [25/50 (50%)]\tLoss: 0.579644\n",
      "2019-07-29 17:33:00,696 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.093232\n",
      "2019-07-29 17:33:04,444 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.251291\n",
      "2019-07-29 17:33:18,053 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [300, 350]\n",
      "2019-07-29 17:33:18,407 DEBUG run_websocket_client.py(l:76) - Train Worker alice: [0/13 (0%)]\tLoss: 0.232582\n",
      "2019-07-29 17:33:24,298 DEBUG run_websocket_client.py(l:76) - Train Worker bob: [0/13 (0%)]\tLoss: 0.103469\n",
      "2019-07-29 17:33:30,363 DEBUG run_websocket_client.py(l:76) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.353351\n",
      "2019-07-29 17:33:35,902 DEBUG run_websocket_client.py(l:132) - Starting training round, batches [350, 400]\n",
      "2019-07-29 17:33:35,926 DEBUG run_websocket_client.py(l:144) - At least one worker ran out of data, stopping.\n",
      "2019-07-29 17:33:40,785 DEBUG run_websocket_client.py(l:168) - \n",
      "\n",
      "2019-07-29 17:33:40,787 INFO run_websocket_client.py(l:172) - Test set: Average loss: 0.2075, Accuracy: 9378/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n",
    "    model = rwc.train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)\n",
    "    rwc.test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
