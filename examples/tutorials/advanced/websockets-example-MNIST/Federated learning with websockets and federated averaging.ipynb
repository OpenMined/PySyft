{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Federated learning with websockets and federated averaging\n",
    "\n",
    "This notebook will go through the steps to run a federated learning via websocket workers. We will use federated averaging to join the remotely trained models. \n",
    "\n",
    "Authors:\n",
    "- midokura-silvia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: start the websocket client workers\n",
    "\n",
    "Each worker is represented by two parts, a local handle (websocket client proxy) and the remote instance that holds the data and performs the computations. The remote part is called a websocket client worker.\n",
    "\n",
    "So first, we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python start_websocket_clients.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the websocket client proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import syft as sy\n",
    "from syft.workers import WebsocketClientWorker\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from syft.frameworks.torch.federated import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_training_websockets as rtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, cuda=False, epochs=2, federate_after_n_batches=50, lr=0.01, save_model=False, seed=1, test_batch_size=1000, use_virtual=False, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "args = rtw.define_and_get_arguments(args=[])\n",
    "use_cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client proxies, our local access point to the remote workers.\n",
    "Note that **this step will fail, if the websocket client workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<WebsocketClientWorker id:alice #tensors:0>, <WebsocketClientWorker id:bob #tensors:0>, <WebsocketClientWorker id:charlie #tensors:0>]\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": args.verbose}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)\n",
    "bob = WebsocketClientWorker(id=\"bob\", port=8778, **kwargs_websocket)\n",
    "charlie = WebsocketClientWorker(id=\"charlie\", port=8779, **kwargs_websocket)\n",
    "\n",
    "workers = [alice, bob, charlie]\n",
    "print(workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and distribute the training data\n",
    "\n",
    "We will use the MNIST dataset and distribute the data randomly onto the workers. \n",
    "This is not realistic for a federated training setup, where the data would normally already be available at the remote workers.\n",
    "\n",
    "We instantiate two FederatedDataLoaders, one for the train and one for the test set of the MNIST dataset.\n",
    "\n",
    "*If you run into BrokenPipe errors try to restart the notebook or try running [run_training_websockets.py](run_training_websockets.py) (Python script that contains the same code of this notebook)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ).federate(tuple(workers)),\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=True,\n",
    "    iter_per_worker=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to instantiate the machine learning model. It is a small neural network with 2 convolutional and two fully connected layers. \n",
    "It uses ReLU activations and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = rtw.Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define the training loop. We will perform training over a given number of batches separately on each worker and then calculate the federated average of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, federated_train_loader, lr, federate_after_n_batches):\n",
    "    model.train()\n",
    "\n",
    "    nr_batches = federate_after_n_batches\n",
    "\n",
    "    models = {}\n",
    "    loss_values = {}\n",
    "\n",
    "    iter(federated_train_loader)  # initialize iterators\n",
    "    batches = rtw.get_next_batches(federated_train_loader, nr_batches)\n",
    "    counter = 0\n",
    "\n",
    "    while True:\n",
    "        print(\"Starting training round, batches [{}, {}]\".format(counter, counter + nr_batches))\n",
    "        data_for_all_workers = True\n",
    "        for worker in batches:\n",
    "            curr_batches = batches[worker]\n",
    "            if curr_batches:\n",
    "                models[worker], loss_values[worker] = rtw.train_on_batches(\n",
    "                    worker, curr_batches, model, device, lr\n",
    "                )\n",
    "            else:\n",
    "                data_for_all_workers = False\n",
    "        counter += nr_batches\n",
    "        if not data_for_all_workers:\n",
    "            logger.debug(\"At least one worker ran out of data, stopping.\")\n",
    "            break\n",
    "\n",
    "        model = utils.federated_avg(models)\n",
    "        batches = rtw.get_next_batches(federated_train_loader, nr_batches)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "FORMAT = \"%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d) - %(message)s\"\n",
    "LOG_LEVEL = logging.DEBUG\n",
    "logging.basicConfig(format=FORMAT, level=LOG_LEVEL)\n",
    "logger = logging.getLogger(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start the training\n",
    "\n",
    "Now we are ready to start the federated training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:13,773 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 2.292449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [0, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:14,346 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 2.227838\n",
      "2019-05-06 10:20:14,868 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 2.293974\n",
      "2019-05-06 10:20:15,434 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 2.215798\n",
      "2019-05-06 10:20:16,007 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.288719\n",
      "2019-05-06 10:20:16,522 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 2.208295\n",
      "2019-05-06 10:20:18,897 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 2.116791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [50, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:19,431 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 1.910448\n",
      "2019-05-06 10:20:19,955 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 2.114580\n",
      "2019-05-06 10:20:20,496 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 1.886086\n",
      "2019-05-06 10:20:21,076 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 2.119986\n",
      "2019-05-06 10:20:21,591 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 1.887199\n",
      "2019-05-06 10:20:24,052 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 1.522649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [100, 150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:24,598 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 1.055046\n",
      "2019-05-06 10:20:25,166 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 1.517945\n",
      "2019-05-06 10:20:25,690 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 1.020536\n",
      "2019-05-06 10:20:26,285 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 1.482994\n",
      "2019-05-06 10:20:26,845 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.890410\n",
      "2019-05-06 10:20:29,327 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.738316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [150, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:29,911 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.540463\n",
      "2019-05-06 10:20:30,519 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.732491\n",
      "2019-05-06 10:20:31,112 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.743134\n",
      "2019-05-06 10:20:31,715 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.562895\n",
      "2019-05-06 10:20:32,317 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.641788\n",
      "2019-05-06 10:20:34,786 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.461945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [200, 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:35,364 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.579697\n",
      "2019-05-06 10:20:35,968 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.681678\n",
      "2019-05-06 10:20:36,572 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.492056\n",
      "2019-05-06 10:20:37,107 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.685956\n",
      "2019-05-06 10:20:37,592 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.411767\n",
      "2019-05-06 10:20:40,202 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.260810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [250, 300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:40,762 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.270737\n",
      "2019-05-06 10:20:41,346 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.437046\n",
      "2019-05-06 10:20:42,015 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.380653\n",
      "2019-05-06 10:20:42,695 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.337475\n",
      "2019-05-06 10:20:43,304 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.542475\n",
      "2019-05-06 10:20:44,549 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/13 (0%)]\tLoss: 0.499773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [300, 350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:44,882 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/13 (0%)]\tLoss: 0.490549\n",
      "2019-05-06 10:20:45,225 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.492409\n",
      "2019-05-06 10:20:45,566 DEBUG <ipython-input-10-0154d686842f>(l:26) - At least one worker ran out of data, stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [350, 400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:47,675 INFO run_training_websockets.py(l:158) - \n",
      "\n",
      "2019-05-06 10:20:47,675 INFO run_training_websockets.py(l:162) - Test set: Average loss: 0.3661, Accuracy: 8942/10000 (89%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:49,628 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.154455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [0, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:50,013 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.137421\n",
      "2019-05-06 10:20:50,440 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.152596\n",
      "2019-05-06 10:20:50,865 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.380003\n",
      "2019-05-06 10:20:51,336 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.275673\n",
      "2019-05-06 10:20:51,756 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.252321\n",
      "2019-05-06 10:20:54,175 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.260835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [50, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:54,570 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.329296\n",
      "2019-05-06 10:20:54,982 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.412892\n",
      "2019-05-06 10:20:55,413 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.415060\n",
      "2019-05-06 10:20:55,902 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.241264\n",
      "2019-05-06 10:20:56,378 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.214134\n",
      "2019-05-06 10:20:58,811 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.167569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [100, 150]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:20:59,195 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.152678\n",
      "2019-05-06 10:20:59,681 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.248470\n",
      "2019-05-06 10:21:00,102 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.436833\n",
      "2019-05-06 10:21:00,550 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.374089\n",
      "2019-05-06 10:21:01,031 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.203165\n",
      "2019-05-06 10:21:03,489 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.385209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [150, 200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:21:03,881 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.206849\n",
      "2019-05-06 10:21:04,336 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.364890\n",
      "2019-05-06 10:21:04,781 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.200526\n",
      "2019-05-06 10:21:05,295 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.291709\n",
      "2019-05-06 10:21:05,825 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.335515\n",
      "2019-05-06 10:21:08,363 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.532576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [200, 250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:21:08,801 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.392866\n",
      "2019-05-06 10:21:09,283 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.243079\n",
      "2019-05-06 10:21:09,822 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.196531\n",
      "2019-05-06 10:21:10,344 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.455996\n",
      "2019-05-06 10:21:10,873 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.150996\n",
      "2019-05-06 10:21:13,434 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/50 (0%)]\tLoss: 0.272999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [250, 300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:21:13,859 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [25/50 (50%)]\tLoss: 0.111411\n",
      "2019-05-06 10:21:14,360 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/50 (0%)]\tLoss: 0.304220\n",
      "2019-05-06 10:21:14,863 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [25/50 (50%)]\tLoss: 0.211269\n",
      "2019-05-06 10:21:15,334 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/50 (0%)]\tLoss: 0.282027\n",
      "2019-05-06 10:21:15,792 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [25/50 (50%)]\tLoss: 0.538883\n",
      "2019-05-06 10:21:16,807 DEBUG run_training_websockets.py(l:77) - Train Worker alice: [0/13 (0%)]\tLoss: 0.308333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [300, 350]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:21:17,086 DEBUG run_training_websockets.py(l:77) - Train Worker bob: [0/13 (0%)]\tLoss: 0.163183\n",
      "2019-05-06 10:21:17,362 DEBUG run_training_websockets.py(l:77) - Train Worker charlie: [0/13 (0%)]\tLoss: 0.153138\n",
      "2019-05-06 10:21:17,601 DEBUG <ipython-input-10-0154d686842f>(l:26) - At least one worker ran out of data, stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training round, batches [350, 400]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-06 10:21:19,734 INFO run_training_websockets.py(l:158) - \n",
      "\n",
      "2019-05-06 10:21:19,735 INFO run_training_websockets.py(l:162) - Test set: Average loss: 0.2398, Accuracy: 9320/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(\"Starting epoch {}/{}\".format(epoch, args.epochs))\n",
    "    model = train(model, device, federated_train_loader, args.lr, args.federate_after_n_batches)\n",
    "    rtw.test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
