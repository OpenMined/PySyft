{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Build an Encrypted, Decentralized Database\n",
    "\n",
    "In the last section (Part 5), we learned about the basic tools PySyft supports for encrypted computation. In this section, we're going to give one example of how to use those tools to build an encrypted, decentralized database. \n",
    "\n",
    "# Encrypted\n",
    "\n",
    "The database will be encrypted because BOTH the values in the database will be encrypted AND all queries to the database will be encrypted.\n",
    "\n",
    "# Decentralized\n",
    "\n",
    "The database will be decentralized because, using SMPC, all values will be \"shared\" amongst a variety of owners, meaning that all owners must agree to allow a query to be performed. It has no central \"owner\".\n",
    "\n",
    "# The Schema:\n",
    "\n",
    "While we could construct a variety of database types, for this first tutorial we're going to focus on a simple key-value store, where both the keys and values are strings.\n",
    "\n",
    "\n",
    "Authors:\n",
    "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "hook = sy.TorchHook()\n",
    "\n",
    "bob = sy.VirtualWorker(id=\"bob\")\n",
    "alice = sy.VirtualWorker(id=\"alice\")\n",
    "bill = sy.VirtualWorker(id=\"bill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Constructing a Key System\n",
    "\n",
    "In this section, we're going to show how to use the equality operation to build a simple key system. The only tricky part about this is that we need to choose the datatype we want to use for keys. The most common usecase is probably strings, so that's what we're going to use here.\n",
    "\n",
    "Now, one thing you'll notice about our SMPC techniques, they all use exclusively numbers. Thus, we now have an issue. We need to decide how to encode our strings into numbers so that we can query them efficiently as \"keys\". The fastest way would be to map every possible key to a unique hash (integer) and then key based on that. Let's use that approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that sy.mpc.securenn.field is the max value that we can encode using SMPC by default\n",
    "# This is, however, somewhat configurable in the system.\n",
    "def string2key(input_str):\n",
    "    return sy.LongTensor([hash(input_str) % sy.mpc.securenn.field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 7.3583e+08\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2key(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.4739e+09\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2key(\"world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Constructing a Value Storage System\n",
    "\n",
    "Now, we are able to convert our string \"keys\" to integers which we can use for our database, but now we need to figure out how to encode the values in our database using numbers as well. For this, we're going to simply encode each string as a list of numbers like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "for i,c in enumerate(\" \"+string.ascii_letters + '0123456789'+string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2values(input_str):\n",
    "    values = list()\n",
    "    for char in input_str:\n",
    "        values.append(char2int[char])\n",
    "    return sy.LongTensor(values)\n",
    "\n",
    "def values2string(input_values):\n",
    "    s = \"\"\n",
    "    for v in input_values:\n",
    "        s += int2char[int(v)]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  8\n",
       "  5\n",
       " 12\n",
       " 12\n",
       " 15\n",
       "  0\n",
       " 23\n",
       " 15\n",
       " 18\n",
       " 12\n",
       "  4\n",
       "[syft.core.frameworks.torch.tensor.LongTensor of size 11]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs = string2values(\"hello world\")\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values2string(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Creating the Tensor Based Key-Value Store\n",
    "\n",
    "Now for our next operation, we want to write some logic which will allow us to query this database using ONLY addition, multiplication, and comparison operations. For this we will use a simple strategy. \n",
    "\n",
    "The database will be a list of integer keys and a list of integer arrays (values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list()\n",
    "values = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a value to the database, we'll just add its key and value to the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entry(string_key, string_value):\n",
    "    keys.append(string2key(string_key))\n",
    "    values.append(string2values(string_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_entry(\"Bob\",\"(123) 456-7890\")\n",
    "add_entry(\"Bill\", \"(234) 567-8901\")\n",
    "add_entry(\"Sue\",\"(345) 678-9012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  1.8915e+09\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  1.2644e+09\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  1.2281e+09\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  70\n",
       "  54\n",
       "  55\n",
       "  56\n",
       "  71\n",
       "   0\n",
       "  57\n",
       "  58\n",
       "  59\n",
       "  75\n",
       "  60\n",
       "  61\n",
       "  62\n",
       "  53\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 14], \n",
       "  70\n",
       "  55\n",
       "  56\n",
       "  57\n",
       "  71\n",
       "   0\n",
       "  58\n",
       "  59\n",
       "  60\n",
       "  75\n",
       "  61\n",
       "  62\n",
       "  53\n",
       "  54\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 14], \n",
       "  70\n",
       "  56\n",
       "  57\n",
       "  58\n",
       "  71\n",
       "   0\n",
       "  59\n",
       "  60\n",
       "  61\n",
       "  75\n",
       "  62\n",
       "  53\n",
       "  54\n",
       "  55\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 14]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Querying the Key->Value Store\n",
    "\n",
    "Our query will be in three:\n",
    "\n",
    "- 1) check for equality between the query key and every key in the database - returning a 1 or 0 for each row. We'll call each row's result it's \"key_match\" integer\n",
    "\n",
    "- 2) Multiply each row's \"key_match\" integer by all the values in its corresponding row. This will zero out all rows in the database which don't have matching keys.\n",
    "\n",
    "- 3) Sum all the masked rows in the database together. \n",
    "\n",
    "- 4) Return the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891469763"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is our query\n",
    "query = \"Bob\"\n",
    "\n",
    "# convert our query to a hash\n",
    "qhash = string2key(query)\n",
    "qhash[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  1\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  0\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1], \n",
       "  0\n",
       " [syft.core.frameworks.torch.tensor.LongTensor of size 1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if our query matches any key\n",
    "key_match = list()\n",
    "for key in keys:\n",
    "    key_match.append((key == qhash).long())\n",
    "key_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply each row's value by its corresponding keymatch\n",
    "value_match = list()\n",
    "for i,value in enumerate(values):\n",
    "    value_match.append(key_match[i].expand(value.shape) * value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the values together\n",
    "final_value = value_match[0]\n",
    "for v in value_match[1:]:\n",
    "    final_value = final_value + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-7890'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decypher final value\n",
    "values2string(final_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Putting It Together\n",
    "\n",
    "Here's what this logic looks like when put together in a simple database class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "for i,c in enumerate(\" \"+string.ascii_letters + '0123456789'+string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c\n",
    "\n",
    "def string2key(input_str):\n",
    "    return sy.LongTensor([hash(input_str) % sy.mpc.securenn.field])\n",
    "\n",
    "def string2values(input_str):\n",
    "    values = list()\n",
    "    for char in input_str:\n",
    "        values.append(char2int[char])\n",
    "    return sy.LongTensor(values)\n",
    "\n",
    "def values2string(input_values):\n",
    "    s = \"\"\n",
    "    for v in input_values:\n",
    "        s += int2char[int(v)]\n",
    "    return s\n",
    "\n",
    "class TensorDB:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.keys = list()\n",
    "        self.values = list()\n",
    "        \n",
    "    def add_entry(self, string_key, string_value):\n",
    "        self.keys.append(string2key(string_key))\n",
    "        self.values.append(string2values(string_value))\n",
    "        \n",
    "    def query(self, str_query):\n",
    "\n",
    "        # hash the query string\n",
    "        qhash = string2key(str_query)\n",
    "        \n",
    "        # see if our query matches any key\n",
    "        key_match = list()\n",
    "        for key in self.keys:\n",
    "            key_match.append((key == qhash).long())\n",
    "\n",
    "        # Multiply each row's value by its corresponding keymatch\n",
    "        value_match = list()\n",
    "        for i,value in enumerate(self.values):\n",
    "            value_match.append(key_match[i].expand(value.shape) * value)\n",
    "            \n",
    "        # sum the values together\n",
    "        final_value = value_match[0]\n",
    "        for v in value_match[1:]:\n",
    "            final_value = final_value + v\n",
    "            \n",
    "        # Decypher final value\n",
    "        return values2string(final_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = TensorDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.add_entry(\"Bob\",\"(123) 456-7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567-8901\")\n",
    "db.add_entry(\"Sue\",\"(345) 678-9012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456-7890'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(234) 567-8901'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(345) 678-9012'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Sue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Building an Encrypted, Decentralized Database\n",
    "\n",
    "Now, the interesting thing here is that we have not used a single operation other than addition, multiplication, and comparison (equality). Thus, we can trivially create an encrypted database by simply encrypting all of our keys and values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "for i,c in enumerate(\" \"+string.ascii_letters + '0123456789'+string.punctuation):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c\n",
    "\n",
    "def string2key(input_str):\n",
    "    return sy.LongTensor([(hash(input_str)+1234) % int(sy.mpc.securenn.field)])\n",
    "\n",
    "def string2values(input_str):\n",
    "    values = list()\n",
    "    for char in input_str:\n",
    "        values.append(char2int[char])\n",
    "    return sy.LongTensor(values)\n",
    "\n",
    "def values2string(input_values):\n",
    "    s = \"\"\n",
    "    for v in input_values:\n",
    "        if(int(v) in int2char):\n",
    "            s += int2char[int(v)]\n",
    "        else:\n",
    "            s += \".\"\n",
    "    return s\n",
    "\n",
    "\n",
    "class DecentraliedDB:\n",
    "    \n",
    "    def __init__(self, *owners):\n",
    "        \n",
    "        self.owners = owners\n",
    "        self.keys = list()\n",
    "        self.values = list()\n",
    "        \n",
    "    def add_entry(self, string_key, string_value):\n",
    "        \n",
    "        key = string2key(string_key).share(*self.owners)\n",
    "        value = string2values(string_value).share(*self.owners)\n",
    "        \n",
    "        self.keys.append(key)\n",
    "        self.values.append(value)\n",
    "        \n",
    "    def query(self, str_query):\n",
    "\n",
    "        # hash the query string\n",
    "        qhash = sy.LongTensor([string2key(str_query)])\n",
    "        qhash = qhash.share(*self.owners)\n",
    "        \n",
    "        # see if our query matches any key\n",
    "        key_match = list()\n",
    "        for key in self.keys:\n",
    "            key_match.append((key == qhash))\n",
    "\n",
    "        # Multiply each row's value by its corresponding keymatch\n",
    "        value_match = list()\n",
    "        for i,value in enumerate(self.values):\n",
    "            shape = list(value.get_shape())\n",
    "            km = key_match[i]\n",
    "            expanded_key = km.expand(1,shape[0])[0]\n",
    "            value_match.append(expanded_key * value)\n",
    "            \n",
    "        # sum the values together\n",
    "        final_value = value_match[0]\n",
    "        for v in value_match[1:]:\n",
    "            final_value = final_value + v\n",
    "        \n",
    "        result = values2string(final_value.get())\n",
    "        \n",
    "        # there is a certain element of randomness\n",
    "        # which can cause the database to return empty\n",
    "        # so if this happens, just try again\n",
    "        if(list(set(result))[0] == '.'):\n",
    "            return self.query(str_query)\n",
    "            \n",
    "        # Decypher final value\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DecentraliedDB(bob, alice)\n",
    "db.add_entry(\"Bob\",\"(123) 456-7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567-8901\")\n",
    "db.add_entry(\"Sam\",\"(345) 678-9012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..... ........'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(234) 567-8901'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(345) 678-9012'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Sam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Success!!!\n",
    "\n",
    "And there you have it! We now have a key-value store capable of storing arbitrary strings and values in an encrypted, decentralzied state such that even the queries are also private/encrypted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Increasing Performance\n",
    "\n",
    "\n",
    "### Strategy 1: One-hot Encoded Keys\n",
    "\n",
    "As it turns out, comparisons (like ==) can be very expensive to compute, which make the query take a long time. Thus, we also have another option. We can encode our strings using one_hot encodings. This allows us to exclusively use multiplication for our database query, like so.\n",
    "\n",
    "### Strategy 2: Fixed Length Values\n",
    "By using fixed length values, we can encode the whole database as a single tensor which lets us use the underlying hardware to work a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "char2int = {}\n",
    "int2char = {}\n",
    "for i,c in enumerate(\" \"+string.ascii_lowercase + '0123456789().'):\n",
    "    char2int[c] = i\n",
    "    int2char[i] = c\n",
    "\n",
    "def one_hot(index, length):\n",
    "    vect = sy.zeros(length).long()\n",
    "    vect[index]  = 1\n",
    "    return vect\n",
    "    \n",
    "def string2one_hot_matrix(str_input, max_len=8):\n",
    "    \n",
    "    # truncate strings longer than 16\n",
    "    str_input = str_input[:max_len].lower()\n",
    "    \n",
    "    # pad strings shorter than 16\n",
    "    if(len(str_input) < max_len):\n",
    "        str_input = str_input + \".\" * (max_len - len(str_input))\n",
    "    \n",
    "    char_vectors = list()\n",
    "    for char in str_input:\n",
    "        char_vectors.append(one_hot(char2int[char],len(int2char)).unsqueeze(0))\n",
    "    \n",
    "    return sy.cat(char_vectors,dim=0)\n",
    "\n",
    "def string2values(str_input, max_len=128):\n",
    "\n",
    "    # truncate strings longer than 16\n",
    "    str_input = str_input[:max_len].lower()\n",
    "    \n",
    "    # pad strings shorter than 16\n",
    "    if(len(str_input) < max_len):\n",
    "        str_input = str_input + \".\" * (max_len - len(str_input))\n",
    "    \n",
    "    \n",
    "    values = list()\n",
    "    for char in str_input:\n",
    "        values.append(char2int[char])\n",
    "        \n",
    "    return sy.LongTensor(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hots = string2one_hot_matrix(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentraliedDB:\n",
    "    \n",
    "    def __init__(self, *owners, max_key_len=8, max_value_len=256):\n",
    "        \n",
    "        self.max_key_len = max_key_len\n",
    "        self.max_value_len = max_value_len\n",
    "        self.owners = owners\n",
    "        self.keys = list()\n",
    "        self.values = list()\n",
    "        \n",
    "    def add_entry(self, string_key, string_value):\n",
    "        \n",
    "        key = string2one_hot_matrix(string_key, self.max_key_len).share(*self.owners)\n",
    "        value = string2values(string_value, self.max_value_len).share(*self.owners)\n",
    "        \n",
    "        self.keys.append(key)\n",
    "        self.values.append(value)\n",
    "        \n",
    "    def query(self,query_str):\n",
    "        \n",
    "        query = string2one_hot_matrix(query_str, self.max_key_len).send(bob,alice)\n",
    "        \n",
    "        # see if our query matches any key\n",
    "        key_match = list()\n",
    "        for key in self.keys:\n",
    "\n",
    "            vect = (key * query).sum(1)\n",
    "\n",
    "            x = vect[0]\n",
    "            for i in range(vect.get_shape()[0]):\n",
    "                x = x * vect[i]\n",
    "\n",
    "            key_match.append(x)\n",
    "\n",
    "        # Multiply each row's value by its corresponding keymatch\n",
    "        value_match = list()\n",
    "        for i,value in enumerate(self.values):\n",
    "            shape = list(value.get_shape())\n",
    "            km = key_match[i]\n",
    "            expanded_key = km.expand(1,shape[0])[0]\n",
    "            value_match.append(expanded_key * value)\n",
    "\n",
    "        # sum the values together\n",
    "        final_value = value_match[0]\n",
    "        for v in value_match[1:]:\n",
    "            final_value = final_value + v\n",
    "\n",
    "        result = values2string(final_value.get())\n",
    "        \n",
    "        return result.replace(\".\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "db  = DecentraliedDB(bob, alice, max_key_len=3)\n",
    "db.add_entry(\"Bob\",\"(123) 456 7890\")\n",
    "db.add_entry(\"Bill\", \"(234) 567 8901\")\n",
    "db.add_entry(\"Sam\",\"(345) 678 9012\")\n",
    "db.add_entry(\"Key\",\"really big json value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456 7890'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(234) 567 8901'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(345) 678 9012'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Sam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                '"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Not a Person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'really big json value'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!!\n",
    "\n",
    "And there we have it - a marginally more performant version. We could further add performance by running the query on all the rows in parallel, but we'll leave that for someone else to work on :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
