{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 4: Föderiertes Lernen mit Modellmittelung\n",
    "\n",
    "** Rückblick: ** In Teil 2 dieses Tutorials haben wir ein Modell mit einer sehr einfachen Version von Federated Learning trainiert. Dies erforderte, dass jeder Dateneigentümer dem Modellbesitzer vertraute, um seine Verläufe sehen zu können.\n",
    "\n",
    "** Beschreibung: ** In diesem Lernprogramm wird gezeigt, wie die erweiterten Aggregationstools aus Teil 3 verwendet werden, damit die Gewichte von einem vertrauenswürdigen \"sicheren Mitarbeiter\" aggregiert werden können, bevor das endgültige resultierende Modell an den Modellbesitzer zurückgesendet wird (uns).\n",
    "\n",
    "Auf diese Weise kann nur der sichere Arbeiter sehen, wessen Gewichte von wem stammen. Wir können möglicherweise feststellen, welche Teile des Modells sich geändert haben, aber wir wissen NICHT, welcher Mitarbeiter (Bob oder Alice) welche Änderung vorgenommen hat, wodurch eine Ebene der Privatsphäre entsteht.\n",
    "\n",
    "Autoren:\n",
    "  - Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)\n",
    "  - Jason Mancuso - Twitter: [@jvmancuso](https://twitter.com/jvmancuso)\n",
    "  \n",
    "Übersetzer:\n",
    "- Vineet Jain - Github: [@vineetjai](https://github.com/vineetjai)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import syft as sy\n",
    "import copy\n",
    "hook = sy.TorchHook(torch)\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 1: Dateneigentümer erstellen\n",
    "\n",
    "Zuerst erstellen wir zwei Dateneigentümer (Bob und Alice) mit jeweils einer kleinen Datenmenge. Wir werden auch einen sicheren Computer namens \"secure_worker\" initialisieren. In der Praxis kann dies sichere Hardware (wie Intels SGX) oder einfach ein vertrauenswürdiger Vermittler sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "\n",
    "\n",
    "# A Toy Dataset\n",
    "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
    "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to bob and alice\n",
    "bobs_data = data[0:2].send(bob)\n",
    "bobs_target = target[0:2].send(bob)\n",
    "\n",
    "alices_data = data[2:].send(alice)\n",
    "alices_target = target[2:].send(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 2: Erstellen Sie unser Modell\n",
    "\n",
    "In diesem Beispiel werden wir mit einem einfachen linearen Modell trainieren. Wir können es normal mit dem nn.Linear-Konstruktor von PyTorch initialisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 3: Senden Sie eine Kopie des Modells an Alice und Bob\n",
    "\n",
    "Als nächstes müssen wir Alice und Bob eine Kopie des aktuellen Modells senden, damit sie Lernschritte für ihre eigenen Datensätze ausführen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = model.copy().send(bob)\n",
    "alices_model = model.copy().send(alice)\n",
    "\n",
    "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 4: Trainiere Bobs und Alices Modelle (parallel)\n",
    "\n",
    "Wie bei Federated Learning über Secure Averaging üblich, trainiert jeder Dateneigentümer sein Modell zunächst lokal für mehrere Iterationen, bevor die Modelle zusammen gemittelt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(0.2026) Alice:tensor(0.1496)\n",
      "Bob:tensor(0.0725) Alice:tensor(0.0861)\n",
      "Bob:tensor(0.0391) Alice:tensor(0.0714)\n",
      "Bob:tensor(0.0282) Alice:tensor(0.0594)\n",
      "Bob:tensor(0.0228) Alice:tensor(0.0495)\n",
      "Bob:tensor(0.0192) Alice:tensor(0.0412)\n",
      "Bob:tensor(0.0163) Alice:tensor(0.0343)\n",
      "Bob:tensor(0.0139) Alice:tensor(0.0285)\n",
      "Bob:tensor(0.0119) Alice:tensor(0.0237)\n",
      "Bob:tensor(0.0101) Alice:tensor(0.0198)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(bobs_data)\n",
    "    bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(alices_data)\n",
    "    alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 5: Senden Sie beide aktualisierten Modelle an einen sicheren Mitarbeiter\n",
    "\n",
    "Jetzt, da jeder Dateneigentümer über ein teilweise geschultes Modell verfügt, ist es an der Zeit, diese auf sichere Weise zusammen zu mitteln. Dies erreichen wir, indem wir Alice und Bob anweisen, ihr Modell an den sicheren (vertrauenswürdigen) Server zu senden.\n",
    "\n",
    "Beachten Sie, dass diese Verwendung unserer API bedeutet, dass jedes Modell DIREKT an den Secure_worker gesendet wird. Wir sehen es nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alices_model.move(secure_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model.move(secure_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 6: Durchschnitt der Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich besteht der letzte Schritt für diese Trainingsepoche darin, die trainierten Modelle von Bob und Alice zusammen zu mitteln und dann die Werte für unser globales \"Modell\" festzulegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
    "    model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spülen und wiederholen\n",
    "\n",
    "Und jetzt müssen wir das nur noch mehrmals wiederholen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(0.0023) Alice:tensor(0.0103)\n",
      "Bob:tensor(0.0005) Alice:tensor(0.0047)\n",
      "Bob:tensor(8.8708e-05) Alice:tensor(0.0021)\n",
      "Bob:tensor(5.4481e-05) Alice:tensor(0.0010)\n",
      "Bob:tensor(0.0001) Alice:tensor(0.0005)\n",
      "Bob:tensor(0.0002) Alice:tensor(0.0002)\n",
      "Bob:tensor(0.0002) Alice:tensor(0.0001)\n",
      "Bob:tensor(0.0002) Alice:tensor(5.7441e-05)\n",
      "Bob:tensor(0.0002) Alice:tensor(3.0624e-05)\n",
      "Bob:tensor(0.0001) Alice:tensor(1.6988e-05)\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "worker_iters = 5\n",
    "\n",
    "for a_iter in range(iterations):\n",
    "    \n",
    "    bobs_model = model.copy().send(bob)\n",
    "    alices_model = model.copy().send(alice)\n",
    "\n",
    "    bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "    alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)\n",
    "\n",
    "    for wi in range(worker_iters):\n",
    "\n",
    "        # Train Bob's Model\n",
    "        bobs_opt.zero_grad()\n",
    "        bobs_pred = bobs_model(bobs_data)\n",
    "        bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "        bobs_loss.backward()\n",
    "\n",
    "        bobs_opt.step()\n",
    "        bobs_loss = bobs_loss.get().data\n",
    "\n",
    "        # Train Alice's Model\n",
    "        alices_opt.zero_grad()\n",
    "        alices_pred = alices_model(alices_data)\n",
    "        alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "        alices_loss.backward()\n",
    "\n",
    "        alices_opt.step()\n",
    "        alices_loss = alices_loss.get().data\n",
    "    \n",
    "    alices_model.move(secure_worker)\n",
    "    bobs_model.move(secure_worker)\n",
    "    with torch.no_grad():\n",
    "        model.weight.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
    "        model.bias.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuletzt möchten wir sicherstellen, dass unser resultierendes Modell korrekt gelernt wurde, damit wir es anhand eines Testdatensatzes bewerten können. In diesem Spielzeugproblem werden wir die Originaldaten verwenden, aber in der Praxis möchten wir neue Daten verwenden, um zu verstehen, wie gut sich das Modell auf unsichtbare Beispiele verallgemeinert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(data)\n",
    "loss = ((preds - target) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0370],\n",
      "        [0.0326],\n",
      "        [0.9583],\n",
      "        [0.9540]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.]], requires_grad=True)\n",
      "tensor(0.0063)\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(target)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Spielzeugbeispiel ist das gemittelte Modell im Vergleich zu einem lokal trainierten Klartextmodell unterpassend. Wir konnten es jedoch trainieren, ohne die Trainingsdaten der einzelnen Mitarbeiter offenzulegen. Wir konnten auch die aktualisierten Modelle von jedem Mitarbeiter auf einem vertrauenswürdigen Aggregator aggregieren, um Datenlecks an den Modellbesitzer zu verhindern.\n",
    "\n",
    "In einem zukünftigen Tutorial werden wir versuchen, unsere vertrauenswürdige Aggregation direkt mit den Verläufen durchzuführen, damit wir das Modell mit besseren Gradientenschätzungen aktualisieren und zu einem stärkeren Modell gelangen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herzliche Glückwünsche!!! - Zeit, der Community beizutreten!\n",
    "\n",
    "Herzlichen Glückwunsch zum Abschluss dieses Notebook-Tutorials! Wenn Ihnen dies gefallen hat und Sie sich der Bewegung zur Wahrung der Privatsphäre, zum dezentralen Besitz von KI und der KI-Lieferkette (Daten) anschließen möchten, können Sie dies auf folgende Weise tun!\n",
    "\n",
    "### Star PySyft auf GitHub\n",
    "\n",
    "Der einfachste Weg, unserer Community zu helfen, besteht darin, die Repos in der Hauptrolle zu spielen! Dies hilft, das Bewusstsein für die coolen Tools zu schärfen, die wir bauen.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Mach mit bei unserem Slack!\n",
    "\n",
    "Der beste Weg, um über die neuesten Entwicklungen auf dem Laufenden zu bleiben, ist, sich unserer Community anzuschließen! Sie können dies tun, indem Sie das Formular unter [http://slack.openmined.org](http://slack.openmined.org) ausfüllen.\n",
    "\n",
    "### Treten Sie einem Code-Projekt bei!\n",
    "\n",
    "Der beste Weg, um zu unserer Community beizutragen, besteht darin, Code-Mitwirkender zu werden! Sie können jederzeit zur Seite PySyft GitHub Issues gehen und nach \"Projekten\" filtern. Dies zeigt Ihnen alle Top-Level-Tickets und gibt einen Überblick darüber, an welchen Projekten Sie teilnehmen können! Wenn Sie nicht an einem Projekt teilnehmen möchten, aber ein wenig programmieren möchten, können Sie auch nach weiteren \"einmaligen\" Miniprojekten suchen, indem Sie nach GitHub-Problemen suchen, die als \"gute erste Ausgabe\" gekennzeichnet sind.\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "\n",
    "\n",
    "### Spenden\n",
    "\n",
    "Wenn Sie keine Zeit haben, zu unserer Codebasis beizutragen, aber dennoch Unterstützung leisten möchten, können Sie auch Unterstützer unseres Open Collective werden. Alle Spenden fließen in unser Webhosting und andere Community-Ausgaben wie Hackathons und Meetups!\n",
    "\n",
    "[Open Collective Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
