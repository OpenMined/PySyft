{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 6 - Föderiertes Lernen auf MNIST mit einem CNN\n",
    "\n",
    "## Upgrade auf Federated Learning in 10 Zeilen von PyTorch + PySyft\n",
    "\n",
    "\n",
    "### Kontext\n",
    "\n",
    "Federated Learning ist eine sehr aufregende und aufstrebende Technik des maschinellen Lernens, die darauf abzielt, Systeme aufzubauen, die auf dezentralen Daten lernen. Die Idee ist, dass die Daten in den Händen des Herstellers (der auch als _worker_ bezeichnet wird) verbleiben, was zur Verbesserung der Privatsphäre und des Eigentums beiträgt, und das Modell zwischen den Arbeitnehmern geteilt wird. Eine sofortige Anwendung besteht beispielsweise darin, das nächste Wort auf Ihrem Mobiltelefon vorherzusagen, wenn Sie Text schreiben: Sie möchten nicht, dass die für das Training verwendeten Daten - d. H. Ihre Textnachrichten - an einen zentralen Server gesendet werden.\n",
    "\n",
    "Der Aufstieg von Federated Learning ist daher eng mit der Verbreitung des Datenschutzbewusstseins verbunden, und die DSGVO in der EU, die den Datenschutz seit Mai 2018 durchsetzt, hat als Katalysator gewirkt. Um die Regulierung vorwegzunehmen, haben große Akteure wie Apple oder Google massiv in diese Technologie investiert, insbesondere um die Privatsphäre der mobilen Benutzer zu schützen, aber sie haben ihre Tools nicht zur Verfügung gestellt. Wir bei OpenMined sind der Meinung, dass jeder, der bereit ist, ein Projekt für maschinelles Lernen durchzuführen, in der Lage sein sollte, Tools zum Schutz der Privatsphäre mit sehr geringem Aufwand zu implementieren. Wir haben Tools zum Verschlüsseln von Daten in einer einzigen Zeile erstellt [wie in unserem Blogbeitrag erwähnt](https://blog.openmined.org/training-cnns-using-spdz/) und veröffentlichen jetzt unser Federated Learning-Framework, das das nutzt Die neue PyTorch 1.0-Version bietet eine intuitive Benutzeroberfläche zum Erstellen sicherer und skalierbarer Modelle.\n",
    "\n",
    "In diesem Tutorial verwenden wir direkt [das kanonische Beispiel für das Trainieren eines CNN auf MNIST mit PyTorch](https://github.com/pytorch/examples/blob/master/mnist/main.py) und zeigen, wie einfach es ist ist die Implementierung von Federated Learning mit unserer [PySyft-Bibliothek](https://github.com/OpenMined/PySyft/). Wir werden jeden Teil des Beispiels durchgehen und den Code unterstreichen, der geändert wird.\n",
    "\n",
    "Sie finden dieses Material auch in [unserem Blogpost](https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines).\n",
    "\n",
    "Autoren:\n",
    "- Théo Ryffel - GitHub: [@LaRiffle](https://github.com/LaRiffle)\n",
    "\n",
    "\n",
    "Übersetzer:\n",
    "- Vineet Jain - Github: [@vineetjai](https://github.com/vineetjai)\n",
    "\n",
    "** Ok, lass uns anfangen! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importe und Modellspezifikationen\n",
    "\n",
    "Zuerst machen wir die offiziellen Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und als die für PySyft spezifischen. Insbesondere definieren wir Remote Worker `Alice` und `Bob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy  # <-- NEW: import the Pysyft library\n",
    "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir definieren die Einstellung der Lernaufgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = epochs\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden und Senden von Daten an Mitarbeiter\n",
    "Wir laden zuerst die Daten und wandeln den Trainingsdatensatz mit der Methode \".federate\" in einen Verbunddatensatz um, der auf die Mitarbeiter aufgeteilt ist. Dieser Verbunddatensatz wird jetzt an einen Verbunddatenlader übergeben. Der Testdatensatz bleibt unverändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-Spezifikation\n",
    "Hier verwenden wir genau das gleiche CNN wie im offiziellen Beispiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definieren Sie die Zug- und Testfunktionen\n",
    "Für die Zugfunktion müssen Sie das Modell für jede Charge an den richtigen Ort senden, da die Datenstapel auf `Alice` und `Bob` verteilt sind. Anschließend führen Sie alle Vorgänge remote mit derselben Syntax aus wie bei lokalem PyTorch. Wenn Sie fertig sind, erhalten Sie das aktualisierte Modell zurück und den Verlust, nach Verbesserungen zu suchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, federated_train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
    "        model.send(data.location) # <-- NEW: send the model to the right location\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.get() # <-- NEW: get the model back\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Testfunktion ändert sich nicht!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starten Sie das Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.305134\n",
      "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.156802\n",
      "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.896587\n",
      "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 1.440329\n",
      "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.867023\n",
      "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.654317\n",
      "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.593099\n",
      "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.455322\n",
      "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.371323\n",
      "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.304580\n",
      "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.314122\n",
      "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.369122\n",
      "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.238122\n",
      "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.187751\n",
      "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.523146\n",
      "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.224569\n",
      "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.143539\n",
      "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.267939\n",
      "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.187936\n",
      "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.303569\n",
      "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.240382\n",
      "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.255795\n",
      "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.191860\n",
      "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.173757\n",
      "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.220809\n",
      "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.324368\n",
      "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.273730\n",
      "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.129955\n",
      "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.182368\n",
      "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.222771\n",
      "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.081074\n",
      "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.143568\n",
      "\n",
      "Test set: Average loss: 0.1574, Accuracy: 9512/10000 (95%)\n",
      "\n",
      "CPU times: user 5min 32s, sys: 4min 51s, total: 10min 23s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "    test(args, model, device, test_loader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà! Hier haben Sie ein Modell für Remote-Daten mit Federated Learning trainiert!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eine letzte Sache\n",
    "Ich weiß, es gibt eine Frage, die Sie unbedingt stellen möchten: **Wie lange dauert es, Federated Learning im Vergleich zu normalem PyTorch durchzuführen?**\n",
    "\n",
    "Die Rechenzeit ist tatsächlich **weniger als doppelt so lang** wie für die normale PyTorch-Ausführung ! Genauer gesagt dauert es 1.9-mal länger, was im Vergleich zu den Funktionen, die wir hinzufügen konnten, sehr wenig ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit\n",
    "\n",
    "Wie Sie sehen, haben wir 10 Codezeilen geändert, um das offizielle Pytorch-Beispiel auf MNIST auf eine echte Federated Learning-Einstellung zu aktualisieren!\n",
    "\n",
    "Natürlich gibt es Dutzende von Verbesserungen, die wir uns vorstellen können. Wir möchten, dass die Berechnung parallel für die Mitarbeiter ausgeführt wird und eine Verbundmittelung durchgeführt wird, um das zentrale Modell nur alle n Stapel zu aktualisieren, um die Anzahl der Nachrichten zu verringern, die wir für die Kommunikation zwischen Arbeitnehmern verwenden usw. Dies sind Funktionen, die wir verwenden. Wir arbeiten daran, Federated Learning für eine Produktionsumgebung vorzubereiten, und wir werden darüber schreiben, sobald sie veröffentlicht werden!\n",
    "\n",
    "Sie sollten jetzt in der Lage sein, Federated Learning selbst durchzuführen! Wenn Ihnen dies gefallen hat und Sie sich der Bewegung zur Wahrung der Privatsphäre, zum dezentralen Besitz von KI und der KI-Lieferkette (Daten) anschließen möchten, können Sie dies auf folgende Weise tun!\n",
    "\n",
    "### Star PySyft auf GitHub\n",
    "\n",
    "Der einfachste Weg, unserer Community zu helfen, besteht darin, die Repositories zu markieren! Dies hilft, das Bewusstsein für die coolen Tools zu schärfen, die wir bauen.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Wählen Sie unsere Tutorials auf GitHub!\n",
    "\n",
    "Wir haben wirklich nette Tutorials gemacht, um ein besseres Verständnis dafür zu bekommen, wie Federated and Privacy-Preserving Learning aussehen sollte und wie wir die Bausteine ​​dafür bauen.\n",
    "\n",
    "- [Überprüfen Sie die PySyft-Tutorials](https://github.com/OpenMined/PySyft/tree/master/examples/tutorials)\n",
    "\n",
    "\n",
    "### Mach mit bei unserem Slack!\n",
    "\n",
    "Der beste Weg, um über die neuesten Entwicklungen auf dem Laufenden zu bleiben, ist, sich unserer Community anzuschließen!\n",
    "\n",
    "- [Join slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Treten Sie einem Code-Projekt bei!\n",
    "\n",
    "Der beste Weg, um zu unserer Community beizutragen, besteht darin, Code-Mitwirkender zu werden! Wenn Sie \"einmalige\" Miniprojekte starten möchten, können Sie auf der Seite PySyft GitHub Issues nach Problemen suchen, die mit \"Good First Issue\" gekennzeichnet sind.\n",
    "\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Spenden\n",
    "\n",
    "Wenn Sie keine Zeit haben, zu unserer Codebasis beizutragen, aber dennoch Unterstützung leisten möchten, können Sie auch Unterstützer unseres Open Collective werden. Alle Spenden fließen in unser Webhosting und andere Community-Ausgaben wie Hackathons und Meetups!\n",
    "\n",
    "- [Spenden Sie über die Open Collective Page von OpenMined](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
