{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "## चरण 3: Syft Keras का उपयोग करते हुए निजी पूर्वानुमान - सेवा (ग्राहक)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अनुवादक - nbTranslate \n",
    "\n",
    "संपादक - Urvashi Raheja - Github: [@raheja](https://github.com/raheja)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "बधाई हो! सामान्य केरस के साथ अपने मॉडल को प्रशिक्षित करने और इसे सैफ्ट केरस के साथ सुरक्षित करने के बाद, आप कुछ निजी भविष्यवाणियों का अनुरोध करने के लिए तैयार हैं।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "## डेटा"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "यहां, हम अपने MNIST डेटा को प्रीप्रोसेस करते हैं। यह उसी तरह है जैसे हमने प्रशिक्षण के दौरान कैसे किया।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "## मॉडल से कनेक्ट करें"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "मॉडल को क्वेरी करने से पहले, आपको बस इसे कनेक्ट करना होगा। ऐसा करने के लिए, आप एक क्लाइंट बना सकते हैं। फिर ठीक उसी तीन TFEWorkers (`alice` , `bob` , और `carol`) और क्लस्टर को परिभाषित करें। अंत में `connect_to_model` को कॉल करें। यह क्लाइंट मॉडल साइड पर एक TFE कतारबद्ध सर्वर बनाता है जो कि `model.serve ()` द्वारा स्थापित कतार सर्वर से जोड़ता है **भाग 13b**। शेयरों को एक पूर्वानुमान अनुरोध में शेयरों को जमा करने से पहले सादा डेटा साझा करने की गुप्त रूप से ज़िम्मेदारी होगी।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (1, 28, 28, 1)\n",
    "output_shape = (1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tf_encrypted:Starting session on target 'grpc://localhost:4000' using config graph_options {\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = sy.TFEWorker()\n",
    "\n",
    "alice = sy.TFEWorker(host='localhost:4000')\n",
    "bob = sy.TFEWorker(host='localhost:4001')\n",
    "carol = sy.TFEWorker(host='localhost:4002')\n",
    "cluster = sy.TFECluster(alice, bob, carol)\n",
    "\n",
    "client.connect_to_model(input_shape, output_shape, cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "## क्वेरी मॉडल"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "आप कुछ निजी भविष्यवाणियां करने के लिए तैयार हैं! `query_model` को कॉल करने से ऊपर बनाई गई कतार में `image` सम्मिलित हो जाएगी, गुप्त रूप से डेटा को स्थानीय रूप से साझा किया जाएगा, और मॉडल सर्वर में शेयरों को **भाग 13 बी** में सबमिट किया जाएगा।"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "num_tests = 3\n",
    "images, expected_labels = x_test[:num_tests], y_test[:num_tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image had label 7 and was correctly classified as 7\n",
      "The image had label 2 and was correctly classified as 2\n",
      "The image had label 1 and was correctly classified as 1\n"
     ]
    }
   ],
   "source": [
    "for image, expected_label in zip(images, expected_labels):\n",
    "\n",
    "    res = client.query_model(image.reshape(1, 28, 28, 1))\n",
    "    predicted_label = np.argmax(res)\n",
    "\n",
    "    print(\"The image had label {} and was {} classified as {}\".format(\n",
    "        expected_label,\n",
    "        \"correctly\" if expected_label == predicted_label else \"wrongly\",\n",
    "        predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "hi"
   },
   "source": [
    "यह भी खूब रही। आप इन तीन छवियों को सही ढंग से वर्गीकृत करने में सक्षम हैं! लेकिन इन पूर्वानुमान के बारे में विशेष बात यह है कि आपने इस सेवा को प्राप्त करने के लिए किसी भी निजी जानकारी का खुलासा नहीं किया है। मॉडल होस्ट ने आपके इनपुट डेटा या आपकी भविष्यवाणियों को कभी नहीं देखा, और आपने कभी मॉडल डाउनलोड नहीं किया। आप एन्क्रिप्टेड मॉडल के साथ एन्क्रिप्टेड डेटा पर निजी पूर्वानुमान प्राप्त करने में सक्षम थे!\n",
    "\n",
    "इससे पहले कि हम अपने स्वयं के ऐप्स में इसे लागू करने के लिए जल्दी से आगे बढ़ें, चलो जल्दी से अपने सेवा मॉडल को साफ करने के लिए **भाग 13 बी** पर जाएं!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "hi"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "hi",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
