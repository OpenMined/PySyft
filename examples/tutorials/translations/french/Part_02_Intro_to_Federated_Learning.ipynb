{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 02 - Intro to Federated Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMgqEzWOkXbi",
        "colab_type": "text"
      },
      "source": [
        "##Partie 2: Introduction à Federated Learning\n",
        "\n",
        "Dans la dernière section, nous avons découvert les PointerTensors, qui créent l'infrastructure sous-jacente dont nous avons besoin pour préserver la confidentialité du Deep Learning. Dans cette section, nous allons voir comment utiliser ces outils de base pour implémenter notre premier algorithme Deep Learning préservant la confidentialité, Federated Learning.\n",
        "\n",
        "Auteurs:\n",
        "* Andrew Trask - Twitter: @iamtrask\n",
        "\n",
        "###Qu'est-ce que Federated Learning?\n",
        "\n",
        "C'est un moyen simple et puissant de former des modèles Deep Learning. Si vous pensez aux données de formation, c'est toujours le résultat d'une sorte de processus de collecte. Les gens (via des appareils) génèrent des données en enregistrant des événements dans le monde réel. Normalement, ces données sont agrégées dans un emplacement central unique afin que vous puissiez former un modèle d'apprentissage automatique. Federated Learning fait tourner la tête!\n",
        "\n",
        "Au lieu d'apporter des données d'entraînement au modèle (un serveur central), vous apportez le modèle aux données d'entraînement (où qu'il se trouve).\n",
        "\n",
        "L'idée est que cela permet à celui qui crée les données de posséder la seule copie permanente, et ainsi de garder le contrôle sur qui y a accès. Assez cool, hein?\n",
        "\n",
        "##Section 2.1 - Un exemple Federated Learning de jouets\n",
        "\n",
        "Commençons par former un modèle de jouet de manière centralisée. Il s'agit d'un simple que les modèles obtiennent. Nous devons d'abord:\n",
        "\n",
        "* un jeu de données jouet\n",
        "* un modèle\n",
        "* une logique de formation de base pour la formation d'un modèle pour ajuster les données.\n",
        "\n",
        "Remarque: Si cette API ne vous est pas familière, rendez-vous sur [fast.ai](https://www.fast.ai) et suivez leur cours avant de continuer dans ce didacticiel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_udnwwGmmYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFcs26JemwXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "# Un modèle de jouet\n",
        "model = nn.Linear(2,1)\n",
        "\n",
        "def train():\n",
        "    # Logique de formation\n",
        "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
        "    for iter in range(20):\n",
        "\n",
        "        # 1) effacer les dégradés précédents (s'ils existent)\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # 2) faire une prédiction\n",
        "        pred = model(data)\n",
        "\n",
        "        # 3) calculer combien nous avons manqué\n",
        "        loss = ((pred - target)**2).sum()\n",
        "\n",
        "        # 4) déterminer quels poids nous ont fait manquer\n",
        "        loss.backward()\n",
        "\n",
        "        # 5) changer ces poids\n",
        "        opt.step()\n",
        "\n",
        "        # 6) imprimer nos progrès\n",
        "        print(loss.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phU6yhFHnmbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCNbrMlbnn_V",
        "colab_type": "text"
      },
      "source": [
        "Et voila! Nous avons formé un modèle de base de manière conventionnelle. Toutes nos données sont agrégées dans notre machine locale et nous pouvons les utiliser pour effectuer des mises à jour de notre modèle. Federated Learning, cependant, ne fonctionne pas de cette façon. Modifions donc cet exemple pour le faire de la manière de Federated Learning!\n",
        "\n",
        "Alors, de quoi avons-nous besoin:\n",
        "\n",
        "* créer un couple de travailleurs\n",
        "\n",
        "* obtenir des conseils sur les données de formation sur chaque travailleur\n",
        "\n",
        "* mise à jour de la logique de formation pour effectuer un apprentissage fédéré\n",
        "\n",
        "Nouvelles étapes de formation:\n",
        "\n",
        "  * envoyer le modèle au bon travailleur\n",
        "\n",
        "  * former sur les données qui s'y trouvent\n",
        "\n",
        "  * récupérer le modèle et répéter avec le prochain travailleur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtsQ_JS5o2_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfaQjzxKo7q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# créer un couple de travailleurs\n",
        "\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llx_IJ-Zo_1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Un jeu de données jouet\n",
        "data = torch.tensor([[0,0],[0,1],[1,0],[1,1.]], requires_grad=True)\n",
        "target = torch.tensor([[0],[0],[1],[1.]], requires_grad=True)\n",
        "\n",
        "# obtenir des conseils sur les données de formation sur chaque travailleur en\n",
        "# envoi de données d'entraînement à bob et alice\n",
        "data_bob = data[0:2]\n",
        "target_bob = target[0:2]\n",
        "\n",
        "data_alice = data[2:]\n",
        "target_alice = target[2:]\n",
        "\n",
        "# Initaliser un modèle de jouet\n",
        "model = nn.Linear(2,1)\n",
        "\n",
        "data_bob = data_bob.send(bob)\n",
        "data_alice = data_alice.send(alice)\n",
        "target_bob = target_bob.send(bob)\n",
        "target_alice = target_alice.send(alice)\n",
        "\n",
        "# organiser les pointeurs dans une liste\n",
        "datasets = [(data_bob,target_bob),(data_alice,target_alice)]\n",
        "\n",
        "opt = optim.SGD(params=model.parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CCMfzg-qR2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    # Logique de formation\n",
        "    opt = optim.SGD(params=model.parameters(),lr=0.1)\n",
        "    for iter in range(10):\n",
        "        \n",
        "        # NOUVEAU) parcourez l'ensemble de données de chaque travailleur\n",
        "        for data,target in datasets:\n",
        "            \n",
        "            # NOUVEAU) envoyer le modèle au bon travailleur\n",
        "            model.send(data.location)\n",
        "\n",
        "            # 1) effacer les dégradés précédents (s'ils existent)\n",
        "            opt.zero_grad()\n",
        "\n",
        "            # 2) faire une prédiction\n",
        "            pred = model(data)\n",
        "\n",
        "            # 3) calculer combien nous avons manqué\n",
        "            loss = ((pred - target)**2).sum()\n",
        "\n",
        "            # 4) déterminer quels poids nous ont fait manquer\n",
        "            loss.backward()\n",
        "\n",
        "            # 5) changer ces poids\n",
        "            opt.step()\n",
        "            \n",
        "            #NOUVEAU) obtenir le modèle (avec des dégradés)\n",
        "            model.get()\n",
        "\n",
        "            # 6) imprimer nos progrès\n",
        "            print(loss.get()) # NOUVEAU) légère modification ... besoin d'appeler .get() en loss \\\n",
        "    \n",
        "# federated averaging"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xohi81DkrWEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_KA4xNrTWx",
        "colab_type": "text"
      },
      "source": [
        "###Bien joué!\n",
        "Et voilà! Nous formons maintenant un modèle de Deep Learning très simple en utilisant Federated Learning! Nous envoyons le modèle à chaque travailleur, générons un nouveau gradient, puis le rapportons à notre serveur local où nous mettons à jour notre modèle global. Jamais dans ce processus, nous ne voyons ou ne demandons l'accès aux données de formation sous-jacentes! Nous préservons l'intimité de Bob et Alice !!!\n",
        "\n",
        "\n",
        "###Lacunes de cet exemple\n",
        "\n",
        "Ainsi, bien que cet exemple soit une belle introduction à Federated Learning, il présente encore quelques lacunes majeures. Plus particulièrement, lorsque nous appelons model.get() et recevons le modèle mis à jour de Bob ou Alice, nous pouvons réellement en apprendre beaucoup sur les données d'entraînement de Bob et Alice en regardant leurs gradients. Dans certains cas, nous pouvons parfaitement restaurer leurs données d'entraînement!\n",
        "\n",
        "Alors, que faire? Eh bien, la première stratégie que les gens utilisent est de faire la moyenne du gradient sur plusieurs individus avant de le télécharger sur le serveur central. Cette stratégie, cependant, nécessitera une utilisation plus sophistiquée des objets PointerTensor. Donc, dans la section suivante, nous allons prendre du temps pour en savoir plus sur les fonctionnalités de pointeur plus avancées, puis nous mettrons à niveau cet exemple Federated Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5v9-IpMsT7m",
        "colab_type": "text"
      },
      "source": [
        "##Toutes nos félicitations!!! - Il est temps de rejoindre la communauté!\n",
        "Félicitations pour avoir terminé ce didacticiel pour ordinateur portable! Si cela vous a plu et que vous souhaitez rejoindre le mouvement vers la préservation de la vie privée, la propriété décentralisée de l'AI et la chaîne d'approvisionnement de l'AI (données), vous pouvez le faire de la manière suivante!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZYXwaEpsU0b",
        "colab_type": "text"
      },
      "source": [
        "##Star PySyft sur GitHub\n",
        "Le moyen le plus simple d'aider notre communauté est simplement de mettre en vedette les dépôts GitHub! Cela permet de faire connaître les outils sympas que nous construisons.\n",
        "\n",
        "* [Star PySyft](https://github.com/OpenMined/PySyft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGo7F_PosZEW",
        "colab_type": "text"
      },
      "source": [
        "##Joindrez notre Slack!\n",
        "La meilleure façon de vous tenir au courant des dernières avancées est de rejoindre notre communauté! Vous pouvez le faire en remplissant le formulaire à http://slack.openmined.org"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZQqSLznsd1I",
        "colab_type": "text"
      },
      "source": [
        "##Joindrez un projet de code!\n",
        "La meilleure façon de contribuer à notre communauté est de devenir un contributeur de code! À tout moment, vous pouvez accéder à la page Problèmes de PySyft GitHub et filtrer pour \"Projects\". Cela vous montrera tous les billets de haut niveau donnant un aperçu des projets que vous pouvez rejoindre! Si vous ne souhaitez pas rejoindre un projet, mais que vous souhaitez faire un peu de codage, vous pouvez également rechercher d'autres mini-projets \"uniques\" en recherchant les problèmes GitHub marqués \"good first issue\".\n",
        "* [PySyft Project](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
        "* [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-2Pp_FbslMz",
        "colab_type": "text"
      },
      "source": [
        "##Faire un don\n",
        "Si vous n'avez pas le temps de contribuer à notre base de code, mais souhaitez tout de même apporter votre soutien, vous pouvez également devenir Backer sur notre Open Collective. Tous les dons vont à notre hébergement Web et à d'autres dépenses de la communauté telles que les hackathons et les rencontres!\n",
        "\n",
        "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGu9SPKJssGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}