{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Part 10 - Federated Learning with Secure Aggregation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQMf9pUTS5ML",
        "colab_type": "text"
      },
      "source": [
        "# Part 10: এনক্রিপ্টেড গ্রেডিয়েন্ট এগ্রিগেশন এর সাথে ফেডারেটেড লার্নিং (Federated Learning with Encrypted Gradient Aggregation)\n",
        "\n",
        "গত কয়েকটি বিভাগে(sections), আমরা কয়েকটি সহজ প্রোগ্রাম তৈরি করে এনক্রিপ্ট করা গণনা সম্পর্কে শিখছি। এই বিভাগে, আমরা ফিরে যাব [Federated Learning Demo of Part 4](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%204%20-%20Federated%20Learning%20via%20Trusted%20Aggregator.ipynb), যেখানে আমাদের একজন \"বিশ্বস্ত এগ্রিগেটর/trusted aggregator\" ছিলেন যিনি একাধিক কর্মী থেকে মডেল আপডেটগুলি গড় করার জন্য দায়বদ্ধ ছিলেন।\n",
        "\n",
        "আমরা এখন এই বিশ্বস্ত সংগ্রহকারীকে সরানোর জন্য এনক্রিপ্ট করা গণনার জন্য আমাদের নতুন সরঞ্জামগুলি ব্যবহার করব কারণ এটি ঠিক আদর্শ পন্থা নয়। এটি ধরে নেয় যে আমরা এই সংবেদনশীল তথ্যে অ্যাক্সেস পাওয়ার জন্য যথেষ্ট বিশ্বাসযোগ্য কাউকে খুঁজে পেতে পারি। যা সবসময় সঠিক নয়।\n",
        "\n",
        "সুতরাং, এই নোটবুকে, আমরা দেখাব যে কীভাবে কেউ সুরক্ষাগ্রহীতা সম্পাদনের জন্য এসএমপিসি(SMPC) ব্যবহার করতে পারে, যেন আমাদের কোনও \"বিশ্বস্ত এগ্রিগ্রেটর\" প্রয়োজন হয় না।\n",
        "\n",
        "Authors:\n",
        "\n",
        "- Theo Ryffel - Twitter: [@theoryffel](https://twitter.com/theoryffel)\n",
        "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSLBVJZ2S5MN",
        "colab_type": "text"
      },
      "source": [
        "অনুবাদক:\n",
        "\n",
        "- Sourav Das - Twitter: [@adventuroussrv](https://twitter.com/adventuroussrv)\n",
        "- Mir Mohammad Jaber - Twitter: [@jabertuhin](https://twitter.com/jabertuhin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGiii27S5MP",
        "colab_type": "text"
      },
      "source": [
        "## Section 1: সাধারণ ফেডারেটেড লার্নিং (Normal Federated Learning)\n",
        "\n",
        "প্রথমত, এখানে এমন কিছু কোড রয়েছে যা বোস্টন হাউজিং ডেটাসেটে(Boston Housing Dataset) ক্লাসিক ফেডারেটেড লার্নিং প্রয়োগ করে। কোডের এই বিভাগটি কয়েকটি বিভাগে বিভক্ত।\n",
        "\n",
        "### প্রতিষ্ঠাপন (Setting Up)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsZF_nPbS5MQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "class Parser:\n",
        "    \"\"\"Parameters for training\"\"\"\n",
        "    def __init__(self):\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.001\n",
        "        self.test_batch_size = 8\n",
        "        self.batch_size = 8\n",
        "        self.log_interval = 10\n",
        "        self.seed = 1\n",
        "    \n",
        "args = Parser()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "kwargs = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF-SNXSzS5Ma",
        "colab_type": "text"
      },
      "source": [
        "## ডেটাসেট লোড হচ্ছে (Loading the Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmvV30nES5Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../data/BostonHousing/boston_housing.pickle','rb') as f:\n",
        "    ((X, y), (X_test, y_test)) = pickle.load(f)\n",
        "\n",
        "X = torch.from_numpy(X).float()\n",
        "y = torch.from_numpy(y).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_test = torch.from_numpy(y_test).float()\n",
        "# preprocessing\n",
        "mean = X.mean(0, keepdim=True)\n",
        "dev = X.std(0, keepdim=True)\n",
        "mean[:, 3] = 0. # the feature at column 3 is binary,\n",
        "dev[:, 3] = 1.  # so we don't standardize it\n",
        "X = (X - mean) / dev\n",
        "X_test = (X_test - mean) / dev\n",
        "train = TensorDataset(X, y)\n",
        "test = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB2zlptqS5Mg",
        "colab_type": "text"
      },
      "source": [
        "## নিউরাল নেটওয়ার্ক স্ট্রাকচার (Neural Network Structure)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeK-iePbS5Mg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(13, 32)\n",
        "        self.fc2 = nn.Linear(32, 24)\n",
        "        self.fc3 = nn.Linear(24, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 13)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BGPAmmAS5Mn",
        "colab_type": "text"
      },
      "source": [
        "## হুকিং পাইটর্চ (Hooking PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFA00xQeS5Mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import syft as sy\n",
        "\n",
        "hook = sy.TorchHook(torch)\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
        "james = sy.VirtualWorker(hook, id=\"james\")\n",
        "\n",
        "compute_nodes = [bob, alice]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuSRg2w_S5Mr",
        "colab_type": "text"
      },
      "source": [
        "**কর্মীদের ডেটা প্রেরণ করুন (Send data to the workers)** <br>\n",
        "সাধারণত তাদের কাছে এটি ইতিমধ্যে থাকত, কেবলমাত্র ডেমো উদ্দেশ্যে আমরা ম্যানুয়ালি এটি প্রেরণ করছি"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKq-fDATS5Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_distributed_dataset = []\n",
        "\n",
        "for batch_idx, (data,target) in enumerate(train_loader):\n",
        "    data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "    target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "    train_distributed_dataset.append((data, target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mYFpT_mS5Mv",
        "colab_type": "text"
      },
      "source": [
        "##  প্রশিক্ষণ ফাংশন (Training Function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTDlNP1kS5Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data,target) in enumerate(train_distributed_dataset):\n",
        "        worker = data.location\n",
        "        model.send(worker)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # update the model\n",
        "        pred = model(data)\n",
        "        loss = F.mse_loss(pred.view(-1), target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get()\n",
        "            \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get()\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * data.shape[0], len(train_loader),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5E1smeBS5M0",
        "colab_type": "text"
      },
      "source": [
        "## টেস্টিং ফাংশন (Testing Function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3afstx6S5M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += F.mse_loss(output.view(-1), target, reduction='sum').item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0cbg3kkS5M4",
        "colab_type": "text"
      },
      "source": [
        "## মডেল প্রশিক্ষণ (Training the Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjrGrm8nS5M4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x8qhywlS5M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = time.time()\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(epoch)\n",
        "\n",
        "    \n",
        "total_time = time.time() - t\n",
        "print('Total', round(total_time, 2), 's')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oCsA1O2S5M_",
        "colab_type": "text"
      },
      "source": [
        "## পারফরম্যান্স গণনা করা হচ্ছে (Calculating Performance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YjSA9T6S5NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzsjVLnJS5ND",
        "colab_type": "text"
      },
      "source": [
        "# Section 2: এনক্রিপ্টেড এগ্রিগেশন যোগ করা\n",
        "\n",
        "এখন আমরা এনক্রিপশন ব্যবহার করে গ্রেডিয়েন্টগুলি এগ্রিগেট করার জন্য এই উদাহরণটি সামান্য পরিবর্তন করতে চলেছি। মূল যে পরিবর্তনটি আসছে তা আসলে কোডের `train()` ফাংশনে ১ বা ২ লাইন , যা আমরা নির্দেশ করব। এই মুহুর্তের জন্য, আসুন আমরা আমাদের ডেটা পুনরায় প্রক্রিয়া করি এবং bob ও alice-এর জন্য একটি মডেল ইনিশিয়ালাইজ করি।"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo9W2r3eS5NE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remote_dataset = (list(),list())\n",
        "\n",
        "train_distributed_dataset = []\n",
        "\n",
        "for batch_idx, (data,target) in enumerate(train_loader):\n",
        "    data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "    target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
        "    remote_dataset[batch_idx % len(compute_nodes)].append((data, target))\n",
        "\n",
        "def update(data, target, model, optimizer):\n",
        "    model.send(data.location)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(data)\n",
        "    loss = F.mse_loss(pred.view(-1), target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return model\n",
        "\n",
        "bobs_model = Net()\n",
        "alices_model = Net()\n",
        "\n",
        "bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr)\n",
        "alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr)\n",
        "\n",
        "models = [bobs_model, alices_model]\n",
        "params = [list(bobs_model.parameters()), list(alices_model.parameters())]\n",
        "optimizers = [bobs_optimizer, alices_optimizer]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbitwcYtS5NI",
        "colab_type": "text"
      },
      "source": [
        "## আমাদের প্রশিক্ষণ যুক্তি তৈরি করি (Building our Training Logic)\n",
        "\n",
        "একমাত্র **আসল** পার্থক্য এই ট্রেন পদ্ধতির অভ্যন্তরে। আসুন ধাপে ধাপে তা দেখে নিই\n",
        "\n",
        "### Part A: শিখান ( Train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrQiBkSuS5NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is selecting which batch to train on\n",
        "data_index = 0\n",
        "# update remote models\n",
        "# we could iterate this multiple times before proceeding, but we're only iterating once per worker here\n",
        "for remote_index in range(len(compute_nodes)):\n",
        "    data, target = remote_dataset[remote_index][data_index]\n",
        "    models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS-sa_XTS5NO",
        "colab_type": "text"
      },
      "source": [
        "### Part B: এঙ্ক্রিপ্টেড এগ্রিগেশন (Encrypted Aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa-9NqpDS5NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a list where we'll deposit our encrypted model average\n",
        "new_params = list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYEJ5glVS5NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterate through each parameter\n",
        "for param_i in range(len(params[0])):\n",
        "\n",
        "    # for each worker\n",
        "    spdz_params = list()\n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "        \n",
        "        # select the identical parameter from each worker and copy it\n",
        "        copy_of_parameter = params[remote_index][param_i].copy()\n",
        "        \n",
        "        # since SMPC can only work with integers (not floats), we need\n",
        "        # to use Integers to store decimal information. In other words,\n",
        "        # we need to use \"Fixed Precision\" encoding.\n",
        "        fixed_precision_param = copy_of_parameter.fix_precision()\n",
        "        \n",
        "        # now we encrypt it on the remote machine. Note that \n",
        "        # fixed_precision_param is ALREADY a pointer. Thus, when\n",
        "        # we call share, it actually encrypts the data that the\n",
        "        # data is pointing TO. This returns a POINTER to the \n",
        "        # MPC secret shared object, which we need to fetch.\n",
        "        encrypted_param = fixed_precision_param.share(bob, alice, crypto_provider=james)\n",
        "        \n",
        "        # now we fetch the pointer to the MPC shared value\n",
        "        param = encrypted_param.get()\n",
        "        \n",
        "        # save the parameter so we can average it with the same parameter\n",
        "        # from the other workers\n",
        "        spdz_params.append(param)\n",
        "\n",
        "    # average params from multiple workers, fetch them to the local machine\n",
        "    # decrypt and decode (from fixed precision) back into a floating point number\n",
        "    new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2\n",
        "    \n",
        "    # save the new averaged parameter\n",
        "    new_params.append(new_param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t31gkx5nS5NU",
        "colab_type": "text"
      },
      "source": [
        "### Part C: পরিষ্করণ (Cleanup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muqXHv8zS5NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    for model in params:\n",
        "        for param in model:\n",
        "            param *= 0\n",
        "\n",
        "    for model in models:\n",
        "        model.get()\n",
        "\n",
        "    for remote_index in range(len(compute_nodes)):\n",
        "        for param_index in range(len(params[remote_index])):\n",
        "            params[remote_index][param_index].set_(new_params[param_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Ts527VS5NZ",
        "colab_type": "text"
      },
      "source": [
        "## সব একসাথে করা যাক (Let's put it all Together!!)\n",
        "\n",
        "এবং এখন যেহেতু আমরা প্রতিটি পদক্ষেপ জানি, আমরা এগুলি একসাথে একটি প্রশিক্ষণ লুপে(loop) রাখতে পারি!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NakQ3hKES5NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    for data_index in range(len(remote_dataset[0])-1):\n",
        "        # update remote models\n",
        "        for remote_index in range(len(compute_nodes)):\n",
        "            data, target = remote_dataset[remote_index][data_index]\n",
        "            models[remote_index] = update(data, target, models[remote_index], optimizers[remote_index])\n",
        "\n",
        "        # encrypted aggregation\n",
        "        new_params = list()\n",
        "        for param_i in range(len(params[0])):\n",
        "            spdz_params = list()\n",
        "            for remote_index in range(len(compute_nodes)):\n",
        "                spdz_params.append(params[remote_index][param_i].copy().fix_precision().share(bob, alice, crypto_provider=james).get())\n",
        "\n",
        "            new_param = (spdz_params[0] + spdz_params[1]).get().float_precision()/2\n",
        "            new_params.append(new_param)\n",
        "\n",
        "        # cleanup\n",
        "        with torch.no_grad():\n",
        "            for model in params:\n",
        "                for param in model:\n",
        "                    param *= 0\n",
        "\n",
        "            for model in models:\n",
        "                model.get()\n",
        "\n",
        "            for remote_index in range(len(compute_nodes)):\n",
        "                for param_index in range(len(params[remote_index])):\n",
        "                    params[remote_index][param_index].set_(new_params[param_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJif8akZS5Nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    models[0].eval()\n",
        "    test_loss = 0\n",
        "    for data, target in test_loader:\n",
        "        output = models[0](data)\n",
        "        test_loss += F.mse_loss(output.view(-1), target, reduction='sum').item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        \n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('Test set: Average loss: {:.4f}\\n'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYHfWa0qS5Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = time.time()\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    print(f\"Epoch {epoch + 1}\")\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    \n",
        "total_time = time.time() - t\n",
        "print('Total', round(total_time, 2), 's')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7i8TTEKS5Nk",
        "colab_type": "text"
      },
      "source": [
        "# অভিনন্দন সম্প্রদায় যোগদানের সময়! (Congratulations!!! - Time to Join the Community!)\n",
        "\n",
        "এই নোটবুক টিউটোরিয়ালটি সম্পন্ন করার জন্য অভিনন্দন! আপনি যদি এটি উপভোগ করেন এবং গোপনীয়তা সংরক্ষণ, AI এবং AI সরবরাহ চেইনের (ডেটা) বিকেন্দ্রীভূত মালিকানার দিকে আন্দোলনে যোগ দিতে চান, আপনি নিম্নলিখিত উপায়ে এটি করতে পারেন!\n",
        "\n",
        "### গিটহাবে পাইসিফ্ট কে স্টার দিন (Star PySyft on GitHub)\n",
        "\n",
        "আমাদের সম্প্রদায়কে সাহায্য করার সবচেয়ে সহজ উপায় হল রিপোসিটোরি গুলোতে ষ্টার করা\n",
        " এটি আমরা যে অসাধারণ সরঞ্জামগুলি তৈরি করছি তার সচেতনতা বাড়াতে সহায়তা করে।\n",
        "\n",
        "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
        "\n",
        "### আমাদের স্ল্যাকে যোগ দিন (Join our Slack!)\n",
        "\n",
        "সর্বশেষতম অগ্রগতিতে আপ টু ডেট রাখার সর্বোত্তম উপায় হ'ল আমাদের সম্প্রদায়ে যোগদান করা! আপনি ফর্মটি পূরণ করে এটি করতে পারেন [http://slack.openmined.org](http://slack.openmined.org)\n",
        "\n",
        "### একটি কোড প্রকল্পে যোগদান করুন! (Join a Code Project!)\n",
        "\n",
        "আমাদের সম্প্রদায়ে অবদান রাখার সর্বোত্তম উপায় হল কোড অবদানকারী হয়ে উঠুন! যে কোনও সময় আপনি পাইসাইফ্ট গিটহাবে ইস্যু পৃষ্ঠাতে যেতে পারেন এবং \"প্রকল্পগুলি\" এর জন্য ফিল্টার করতে পারেন। এটি আপনাকে শীর্ষ স্তরের সমস্ত টিকিট দেখিয়ে দেবে যে আপনি কোন প্রকল্পগুলিতে যোগদান করতে পারেন তার একটি ওভারভিউ দেয়! আপনি যদি কোনও প্রকল্পে যোগ দিতে না চান তবে আপনি কিছুটা কোডিং করতে চান তবে আপনি \"ভাল প্রথম ইস্যু\" চিহ্নিত গিটহাবে ইস্যুগুলি অনুসন্ধান করে আরও \"ওয়ান অফ\" মিনি-প্রকল্পগুলির সন্ধান করতে পারেন।\n",
        "\n",
        "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
        "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
        "\n",
        "### দান করুন (Donate)\n",
        "\n",
        "আপনার যদি আমাদের কোডবেসে অবদান রাখার সময় না থাকে তবে তবুও সমর্থন দিতে চান, আপনি আমাদের ওপেন কালেক্টিভেরও Backer হয়ে উঠতে পারেন। সমস্ত অনুদান আমাদের ওয়েব হোস্টিং এবং অন্যান্য সম্প্রদায় ব্যয় যেমন হ্যাকাথনস এবং মেটআপগুলির (hackathons and meetups!) দিকে যায়!\n",
        "\n",
        "- [OpenMined's Open Collective Page](https://opencollective.com/openmined)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evxED5HES5Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}