{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 - Federated Learning with FederatedDataset\n",
    "\n",
    "Here we introduce a new tool for using federated datasets. We have created a `FederatedDataset` class which is intended to be used like the PyTorch Dataset class, and is given to a federated data loader `FederatedDataLoader` which will iterate on it in a federated fashion.\n",
    "\n",
    "\n",
    "Authors:\n",
    "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)\n",
    "- Th√©o Ryffel - GitHub: [@LaRiffle](https://github.com/LaRiffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the sandbox that we discovered last lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import syft as sy\n",
    "sy.create_sandbox(globals(), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then search for a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_data = grid.search(\"#boston\", \"#data\", verbose=False, return_counter=False)\n",
    "boston_target = grid.search(\"#boston\", \"#target\", verbose=False, return_counter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a model and an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = boston_data['alice'][0].shape[1]\n",
    "n_targets = 1\n",
    "model = th.nn.Linear(n_features, n_targets)\n",
    "optimizer = th.optim.SGD(params=model.parameters(),lr=0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we cast the data fetched in a `FederatedDataset`. See the workers which hold part of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bob', 'theo', 'jason', 'alice', 'andy', 'jon']\n"
     ]
    }
   ],
   "source": [
    "# Cast the result in BaseDatasets\n",
    "datasets = []\n",
    "for worker in boston_data.keys():\n",
    "    dataset = sy.BaseDataset(boston_data[worker][0], boston_target[worker][0])\n",
    "    datasets.append(dataset)\n",
    "\n",
    "# Build the FederatedDataset object\n",
    "dataset = sy.FederatedDataset(datasets)\n",
    "print(dataset.workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put it in a `FederatedDataLoader` and specify options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = sy.FederatedDataLoader(dataset, batch_size=4, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we iterate over epochs. You can see how similar this is compared to pure and local PyTorch training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/127 (0%)]\tLoss: 52030.949219\n",
      "Train Epoch: 1 [80/127 (16%)]\tLoss: 4476.936035\n",
      "Train Epoch: 1 [160/127 (31%)]\tLoss: 3504.968750\n",
      "Train Epoch: 1 [240/127 (47%)]\tLoss: 1739.490845\n",
      "Train Epoch: 1 [320/127 (63%)]\tLoss: 72.340225\n",
      "Train Epoch: 1 [400/127 (79%)]\tLoss: 148.348114\n",
      "Train Epoch: 1 [480/127 (94%)]\tLoss: 10308.703125\n",
      "Total loss 428401.8585510254\n",
      "Train Epoch: 2 [0/127 (0%)]\tLoss: 26.898750\n",
      "Train Epoch: 2 [40/127 (16%)]\tLoss: 35.393768\n",
      "Train Epoch: 2 [80/127 (31%)]\tLoss: 2151.689453\n",
      "Train Epoch: 2 [120/127 (47%)]\tLoss: 1237.475952\n",
      "Train Epoch: 2 [160/127 (63%)]\tLoss: 23.571852\n",
      "Train Epoch: 2 [200/127 (79%)]\tLoss: 182.861404\n",
      "Train Epoch: 2 [240/127 (94%)]\tLoss: 109.622910\n",
      "Total loss 40875.63382220268\n",
      "Train Epoch: 3 [0/127 (0%)]\tLoss: 67.843719\n",
      "Train Epoch: 3 [40/127 (16%)]\tLoss: 42.780453\n",
      "Train Epoch: 3 [80/127 (31%)]\tLoss: 2177.287354\n",
      "Train Epoch: 3 [120/127 (47%)]\tLoss: 1207.351318\n",
      "Train Epoch: 3 [160/127 (63%)]\tLoss: 22.607536\n",
      "Train Epoch: 3 [200/127 (79%)]\tLoss: 179.790268\n",
      "Train Epoch: 3 [240/127 (94%)]\tLoss: 115.630127\n",
      "Total loss 40211.192435741425\n",
      "Train Epoch: 4 [0/127 (0%)]\tLoss: 93.423698\n",
      "Train Epoch: 4 [40/127 (16%)]\tLoss: 47.368439\n",
      "Train Epoch: 4 [80/127 (31%)]\tLoss: 2188.739746\n",
      "Train Epoch: 4 [120/127 (47%)]\tLoss: 1184.075195\n",
      "Train Epoch: 4 [160/127 (63%)]\tLoss: 21.336443\n",
      "Train Epoch: 4 [200/127 (79%)]\tLoss: 177.827911\n",
      "Train Epoch: 4 [240/127 (94%)]\tLoss: 118.501648\n",
      "Total loss 39943.368962705135\n",
      "Train Epoch: 5 [0/127 (0%)]\tLoss: 108.364639\n",
      "Train Epoch: 5 [40/127 (16%)]\tLoss: 50.196434\n",
      "Train Epoch: 5 [80/127 (31%)]\tLoss: 2192.729492\n",
      "Train Epoch: 5 [120/127 (47%)]\tLoss: 1164.677734\n",
      "Train Epoch: 5 [160/127 (63%)]\tLoss: 19.963915\n",
      "Train Epoch: 5 [200/127 (79%)]\tLoss: 176.426956\n",
      "Train Epoch: 5 [240/127 (94%)]\tLoss: 119.673630\n",
      "Total loss 39735.64963555336\n",
      "Train Epoch: 6 [0/127 (0%)]\tLoss: 116.555588\n",
      "Train Epoch: 6 [40/127 (16%)]\tLoss: 52.010288\n",
      "Train Epoch: 6 [80/127 (31%)]\tLoss: 2192.804199\n",
      "Train Epoch: 6 [120/127 (47%)]\tLoss: 1147.622437\n",
      "Train Epoch: 6 [160/127 (63%)]\tLoss: 18.591515\n",
      "Train Epoch: 6 [200/127 (79%)]\tLoss: 175.308624\n",
      "Train Epoch: 6 [240/127 (94%)]\tLoss: 119.931274\n",
      "Total loss 39525.95373892784\n",
      "Train Epoch: 7 [0/127 (0%)]\tLoss: 120.941620\n",
      "Train Epoch: 7 [40/127 (16%)]\tLoss: 53.262096\n",
      "Train Epoch: 7 [80/127 (31%)]\tLoss: 2190.824219\n",
      "Train Epoch: 7 [120/127 (47%)]\tLoss: 1132.102539\n",
      "Train Epoch: 7 [160/127 (63%)]\tLoss: 17.267052\n",
      "Train Epoch: 7 [200/127 (79%)]\tLoss: 174.330597\n",
      "Train Epoch: 7 [240/127 (94%)]\tLoss: 119.693100\n",
      "Total loss 39312.36221027374\n",
      "Train Epoch: 8 [0/127 (0%)]\tLoss: 123.293930\n",
      "Train Epoch: 8 [40/127 (16%)]\tLoss: 54.204990\n",
      "Train Epoch: 8 [80/127 (31%)]\tLoss: 2187.760742\n",
      "Train Epoch: 8 [120/127 (47%)]\tLoss: 1117.685303\n",
      "Train Epoch: 8 [160/127 (63%)]\tLoss: 16.011070\n",
      "Train Epoch: 8 [200/127 (79%)]\tLoss: 173.420319\n",
      "Train Epoch: 8 [240/127 (94%)]\tLoss: 119.180588\n",
      "Total loss 39101.289539813995\n",
      "Train Epoch: 9 [0/127 (0%)]\tLoss: 124.592285\n",
      "Train Epoch: 9 [40/127 (16%)]\tLoss: 54.975727\n",
      "Train Epoch: 9 [80/127 (31%)]\tLoss: 2184.121094\n",
      "Train Epoch: 9 [120/127 (47%)]\tLoss: 1104.129639\n",
      "Train Epoch: 9 [160/127 (63%)]\tLoss: 14.830864\n",
      "Train Epoch: 9 [200/127 (79%)]\tLoss: 172.540955\n",
      "Train Epoch: 9 [240/127 (94%)]\tLoss: 118.510834\n",
      "Total loss 38897.47458434105\n",
      "Train Epoch: 10 [0/127 (0%)]\tLoss: 125.358704\n",
      "Train Epoch: 10 [40/127 (16%)]\tLoss: 55.647301\n",
      "Train Epoch: 10 [80/127 (31%)]\tLoss: 2180.170654\n",
      "Train Epoch: 10 [120/127 (47%)]\tLoss: 1091.292969\n",
      "Train Epoch: 10 [160/127 (63%)]\tLoss: 13.727187\n",
      "Train Epoch: 10 [200/127 (79%)]\tLoss: 171.674194\n",
      "Train Epoch: 10 [240/127 (94%)]\tLoss: 117.746567\n",
      "Total loss 38703.274741888046\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss_accum = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        model.send(data.location)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        loss = ((pred - target)**2).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.get()\n",
    "        loss = loss.get()\n",
    "        \n",
    "        loss_accum += float(loss)\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * data.shape[0], len(train_loader),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            \n",
    "    print('Total loss', loss_accum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
