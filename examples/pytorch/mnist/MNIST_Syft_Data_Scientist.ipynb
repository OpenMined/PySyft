{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Syft Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "sy.VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the data scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server (in their Notebook).\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Let's run the code below and follow the instructions it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Launch a Duet Server and Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "local_transform_1 = tv.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = tv.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = tv.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"batch_size\": 64,\n",
    "}\n",
    "\n",
    "# this is our carefully curated test data which represents the goal of our problem domain\n",
    "test_data = tv.datasets.MNIST('../data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = th.utils.data.DataLoader(test_data,**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"duet\" variable is now your reference to a whole world of remote operations including supported libraries like torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some references to our data owners Duet torch and torchvision\n",
    "torch = duet.torch\n",
    "torchvision = duet.torchvision\n",
    "\n",
    "# \n",
    "transforms = torchvision.transforms\n",
    "datasets = torchvision.datasets\n",
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "optim = torch.optim\n",
    "StepLR = torch.optim.lr_scheduler.StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define our SOTA model to train on the data owners data\n",
    "\n",
    "# note we DO NOT subclass from nn.Module because our custom Net class contains\n",
    "# Pointers to its layers and nonlinearities\n",
    "# class Net(nn.Module):\n",
    "class Net:\n",
    "    modules = []\n",
    "    training = False\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        # add to modules list\n",
    "        self.modules.append(self.conv1)\n",
    "        self.modules.append(self.conv2)\n",
    "        self.modules.append(self.dropout1)\n",
    "        self.modules.append(self.dropout2)\n",
    "        self.modules.append(self.fc1)\n",
    "        self.modules.append(self.fc2)\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        self.training = mode\n",
    "        for module in self.modules:\n",
    "            module.train(mode)\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        return self.train(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.forward(input)\n",
    "\n",
    "    # local list of remote ListPointers of TensorPointers\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        params_list = duet.syft.lib.python.List()\n",
    "        for module in self.modules:\n",
    "            param_pointers = module.parameters()\n",
    "            params_list += param_pointers\n",
    "\n",
    "        return params_list\n",
    "    \n",
    "    def cuda(self, device):\n",
    "        for module in self.modules:\n",
    "            module.cuda(device)\n",
    "    \n",
    "    def cpu(self):\n",
    "        for module in self.modules:\n",
    "            module.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = torch.cuda.is_available()\n",
    "print(has_cuda_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    has_cuda = has_cuda_ptr.get()\n",
    "    print(f\"DO has CUDA: {has_cuda}\")\n",
    "except Exception as e:\n",
    "    print(\"No permission, try .request() first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cuda_ptr.request()\n",
    "print(\"Ask your DO to approve the request and try to .get() the pointer again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    has_cuda = has_cuda_ptr.get()\n",
    "    print(f\"DO has CUDA: {has_cuda}\")\n",
    "except Exception as e:\n",
    "    print(\"No permission, try .request() first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings from original MNIST example command line args\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 14,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "}\n",
    "\n",
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"DO device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our model\n",
    "# this will construct everything inside init on the DO side\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get our parameters for optimization\n",
    "params = model.parameters()\n",
    "print(params, type(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(params, lr=args[\"lr\"])\n",
    "print(optimizer, type(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])\n",
    "print(scheduler, type(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can define a simple training loop very similar to the original PyTorch MNIST example\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    print(\"> Running train\")\n",
    "    model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):  # TODO: this requires tuple support\n",
    "    for batch_idx, tensor_ptr in enumerate(train_loader):  # work around until tuple support\n",
    "        data, target = tensor_ptr[0], tensor_ptr[1]        # work around until tuple support\n",
    "        # data, target = data.to(device), target.to(device)  # TODO: wont accept device pointer from this side?\n",
    "\n",
    "        # TODO: temp workaround\n",
    "        data_ptr = torch.Tensor(data)\n",
    "        data_ptr = data.send(duet)\n",
    "        target_ptr = torch.Tensor(target)\n",
    "        target_ptr = target.send(duet)\n",
    "        # end temp workaround\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = F.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        # TODO: we need to batch or block these requests so the loop doesnt break\n",
    "        local_loss = loss_item.get()\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            if args[\"dry_run\"]:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same for our test training loop except we will need to send our data over for inference\n",
    "def test(model, device, test_loader):\n",
    "    print(\"> Running test\")\n",
    "    model.eval()\n",
    "    test_loss = duet.syft.lib.python.Float(0)\n",
    "    correct_ptr = duet.syft.lib.python.Float(0)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # data, target = data.to(device), target.to(device)\n",
    "    \n",
    "            # Are we sending these each time or some other way?\n",
    "            data_ptr = data.send(duet)\n",
    "            target_ptr = target.send(duet)\n",
    "\n",
    "            output = model(data_ptr)\n",
    "            loss = F.nll_loss(output, target_ptr, reduction='sum').item()\n",
    "            test_loss = test_loss + loss\n",
    "\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target_ptr).sum().item()\n",
    "            correct_ptr += total\n",
    "\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "\n",
    "    accuracy = correct_ptr / test_loader.__len__()\n",
    "    # we need to batch or block these requests so the loop doesnt break\n",
    "    result = accuracy.get()\n",
    "    print(\"Test Set Average Loss:\", 100 * result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be a pointer to the remote dataset\n",
    "# TODO: temp hack send over training data until DataLoader pointer\n",
    "train_data = tv.datasets.MNIST('../data', train=True, download=True, transform=local_transforms)\n",
    "train_loader = th.utils.data.DataLoader(train_data,**kwargs)\n",
    "# end temp hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"dry_run\"] = True\n",
    "\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image):\n",
    "    image_tensor_ptr = torch.Tensor(prep_for_inference(image_1))\n",
    "    image_tensor_ptr = image_tensor_ptr.to(device)\n",
    "    \n",
    "    output = model(image_tensor_ptr)\n",
    "    \n",
    "    preds = torch.exp(output)\n",
    "    local_y = th.Tensor(preds.get())\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = th.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    print(int(class_num))\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab something from the test set\n",
    "index = 100\n",
    "count = 0\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if index == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "image_1 = data[0].reshape((28, 28))\n",
    "label_1 = target[0]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num, preds = classify(image_1)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
