{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.0201]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5718], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Support fetch plan + AST tensor\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "plan_func = False\n",
    "\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "charlie = sy.VirtualWorker(hook, id=\"charlie\")\n",
    "dan = sy.VirtualWorker(hook, id=\"dan\")\n",
    "\n",
    "if plan_func:\n",
    "    @sy.func2plan(args_shape=[(1,)], state={\"bias\": th.tensor([3.0])})\n",
    "    def plan_mult_3(x, state):\n",
    "        bias = state.read(\"bias\")\n",
    "        x = x + bias\n",
    "        return x\n",
    "else:\n",
    "    class Net(sy.Plan):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__(id=\"net\")\n",
    "            self.fc1 = nn.Linear(1, 1)\n",
    "            self.add_to_state([\"fc1\"])\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.fc1(x)\n",
    "    \n",
    "    plan_mult_3 = Net()\n",
    "    plan_mult_3.build(th.tensor(1))\n",
    "    \n",
    "print([p for p in plan_mult_3.parameters()])\n",
    "sent_plan = plan_mult_3.send(alice).fix_prec().share(bob, charlie, crypto_provider=dan)\n",
    "\n",
    "# Fetch plan\n",
    "fetched_plan = alice.fetch_plan(sent_plan.id)\n",
    "x = th.tensor([1.])\n",
    "x_ptr = x.fix_prec().share(bob, charlie, crypto_provider=dan)\n",
    "\n",
    "# TODO: this should be stored automatically\n",
    "me._objects[x_ptr.id] = x_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should be done internally\n",
    "id0, id1 = fetched_plan.state_ids\n",
    "\n",
    "# TODO: we should not have direct access to the weights\n",
    "a_sh = me._objects[id0].fix_prec().share(bob, charlie, crypto_provider=dan)\n",
    "b_sh = me._objects[id1].fix_prec().share(bob, charlie, crypto_provider=dan)\n",
    "\n",
    "# TODO: this should be stored automatically\n",
    "me._objects[a_sh.id] = a_sh\n",
    "me._objects[b_sh.id] = b_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state_ids = [a_sh.id, b_sh.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_plan.replace_ids(fetched_plan.state_ids, new_state_ids)\n",
    "fetched_plan.state_ids = new_state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5510])\n"
     ]
    }
   ],
   "source": [
    "print(fetched_plan(x_ptr).get().float_prec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4098], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Support fetching a plan\n",
    "\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "plan_func = False\n",
    "\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "\n",
    "if plan_func:\n",
    "    @sy.func2plan(args_shape=[(1,)], state={\"bias\": th.tensor([3.0])})\n",
    "    def plan_mult_3(x, state):\n",
    "        bias = state.read(\"bias\")\n",
    "        x = x * bias\n",
    "        return x\n",
    "else:\n",
    "    class Net(sy.Plan):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(1, 1)\n",
    "            self.add_to_state([\"fc1\"])\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.fc1(x)\n",
    "    \n",
    "    plan_mult_3 = Net()\n",
    "    plan_mult_3.build(th.tensor(1))\n",
    "\n",
    "sent_plan = plan_mult_3.send(alice)\n",
    "\n",
    "# Fetch plan\n",
    "fetched_plan = alice.fetch_plan(sent_plan.id)\n",
    "\n",
    "x = th.tensor([1.])\n",
    "print(fetched_plan(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
