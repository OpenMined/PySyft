{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:125: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating 🗃️ (MemoryStore) {}\n",
      "> Creating 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪>\n"
     ]
    }
   ],
   "source": [
    "# we need this to make a local tensor to send instead of using primitives locally\n",
    "import torch as local_torch\n",
    "\n",
    "alice = sy.VirtualMachine(name=\"alice\")\n",
    "alice_client = alice.get_root_client()\n",
    "alice.root_verify_key = alice_client.verify_key  # inject 📡🔑 as 📍🗝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imports from remote client\n",
    "torch = alice_client.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], dtype=torch.uint8) <class 'torch.Tensor'>\n",
      "> Creating ✉️  (SaveObjectAction) <UID:🚰🚧>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing ✉️  (SaveObjectAction) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚰🚧>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating ✉️  (SaveObjectAction) <UID:🚇🙼>\n"
     ]
    }
   ],
   "source": [
    "# send a tensor so we can use the pointer for tensor creation here\n",
    "# because we cant yet serialize primitives\n",
    "aone = local_torch.tensor([1], dtype=local_torch.uint8)\n",
    "print(aone, type(aone))\n",
    "xone = aone.send(alice_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  > <UID:4581403d-a6a5-4725-97cc-9aed710454e1> <UID:🚁🙎> => 🗂️ (StorableObject) (tensor([1], dtype=torch.uint8) can_read: ['🜣', '🜥'])\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(alice.store.peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call torch.Generator on client <VirtualMachineClient id:alice Client>\n",
      "> Creating ✉️  (RunFunctionOrConstructorAction) <UID:🚱🚸>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing ✉️  (RunFunctionOrConstructorAction) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚱🚸>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating ✉️  (RunFunctionOrConstructorAction) <UID:🚱🚸>\n"
     ]
    }
   ],
   "source": [
    "a = torch.Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UID:5e5982d3-3d75-4712-86a9-ece7e297010b> abc.GeneratorPointer\n",
      "> Creating RunClassMethodAction(torch.Generator.get_state) <UID:🚋🚴>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing RunClassMethodAction(torch.Generator.get_state) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚋🚴>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating RunClassMethodAction(torch.Generator.get_state) <UID:🚋🚴>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<UID:5fe3bb2f-07f4-4c30-bc5b-184a55be54fb>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.id_at_location, type(a))\n",
    "x = a.get_state()\n",
    "x.id_at_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating GetObjectAction(<UID:5fe3bb2f-07f4-4c30-bc5b-184a55be54fb>) <UID:🙺🚋>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing GetObjectAction(<UID:5fe3bb2f-07f4-4c30-bc5b-184a55be54fb>) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithReply) <UID:🙺🚋>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating GetObjectAction(<UID:5fe3bb2f-07f4-4c30-bc5b-184a55be54fb>) <UID:🙺🚋>\n",
      "> Creating ✉️  (GetObjectResponseMessage) <UID:🚇🛢>\n",
      "> Signing with 🜣\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚇🛢>\n",
      "> 🍰 alice (VirtualMachine)@<UID:🚱🚪> Signing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) with 🜣\n",
      "> Creating ✉️  (GetObjectResponseMessage) <UID:🚇🛢>\n"
     ]
    }
   ],
   "source": [
    "c = x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1, 209, 156,  ...,   0,   0,   0], dtype=torch.uint8)\n",
      "<class 'torch.Tensor'>\n",
      "<UID:a1d93b56-8430-45e3-87a1-b562ebf0edf8>\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print(type(c))\n",
    "print(c.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = c + 1\n",
    "# print(type(d))\n",
    "# print(d.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating ✉️  (SaveObjectAction) <UID:🚵🚳>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing ✉️  (SaveObjectAction) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚵🚳>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating ✉️  (SaveObjectAction) <UID:🚉🚰>\n"
     ]
    }
   ],
   "source": [
    "cx = c.send(alice_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  > <UID:4581403d-a6a5-4725-97cc-9aed710454e1> <UID:🚁🙎> => 🗂️ (StorableObject) (tensor([1], dtype=torch.uint8) can_read: ['🜣', '🜥'])\n",
      "\n",
      "  > <UID:5e5982d3-3d75-4712-86a9-ece7e297010b> <UID:🙵🚉> => 🗂️ (StorableObject) (<torch._C.Generator object at 0x1302591e0>)\n",
      "\n",
      "  > <UID:a1d93b56-8430-45e3-87a1-b562ebf0edf8> <UID:🛩🛟> => 🗂️ (StorableObject) (tensor([  1, 209, 156,  ...,   0,   0,   0], dtype=torch.uint8) can_read: ['🜣', '🜥'])\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(alice.store.peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call torch.manual_seed on client <VirtualMachineClient id:alice Client>\n",
      "> Creating ✉️  (RunFunctionOrConstructorAction) <UID:🚅🚊>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing ✉️  (RunFunctionOrConstructorAction) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🚅🚊>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating ✉️  (RunFunctionOrConstructorAction) <UID:🚅🚊>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<abc.GeneratorPointer at 0x13041b048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from MNIST we need to run:\n",
    "# torch.manual_seed(args.seed)\n",
    "\n",
    "xseed = torch.manual_seed(xone)\n",
    "xseed\n",
    "# print(xseed.id_at_location, type(xseed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating RunClassMethodAction(torch.Generator.get_state) <UID:🙽🚳>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing RunClassMethodAction(torch.Generator.get_state) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🙽🚳>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating RunClassMethodAction(torch.Generator.get_state) <UID:🙽🚳>\n",
      "> Creating GetObjectAction(<UID:929a339d-6e66-4d5e-a249-458b3eb09d58>) <UID:🚌🙸>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing GetObjectAction(<UID:929a339d-6e66-4d5e-a249-458b3eb09d58>) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithReply) <UID:🚌🙸>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating GetObjectAction(<UID:929a339d-6e66-4d5e-a249-458b3eb09d58>) <UID:🚌🙸>\n",
      "> Creating ✉️  (GetObjectResponseMessage) <UID:🛟🚅>\n",
      "> Signing with 🜣\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🛟🚅>\n",
      "> 🍰 alice (VirtualMachine)@<UID:🚱🚪> Signing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) with 🜣\n",
      "> Creating ✉️  (GetObjectResponseMessage) <UID:🛟🚅>\n",
      "tensor([1, 0, 0,  ..., 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "statex = xseed.get_state()\n",
    "tensor_state = statex.get()\n",
    "print(tensor_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Creating RunClassMethodAction(torch.Generator.set_state) <UID:🙽🙖>\n",
      "> 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> Signing RunClassMethodAction(torch.Generator.set_state) with 🜥\n",
      "> Signing with 🜥\n",
      "> Creating Signed ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) <UID:🙽🙖>\n",
      "> Sending ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) 📡 [🍰] alice Client (VirtualMachineClient)@<UID:🚱🚪> ➡️  💠 [🍰] alice Client (Address)\n",
      "> Routing ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) via 🛣️  (SoloRoute)\n",
      "> Received ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Processing 📨 ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply) @ 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Recipient Found ✉️ 🔏 (SignedImmediateSyftMessageWithoutReply)@<UID:🚱🚪> == 🍰 alice (VirtualMachine)@<UID:🚱🚪>\n",
      "> Creating RunClassMethodAction(torch.Generator.set_state) <UID:🙽🙖>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<abc.GeneratorPointer at 0x13041b390>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xseed.set_state(cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  > <UID:4581403d-a6a5-4725-97cc-9aed710454e1> <UID:🚁🙎> => 🗂️ (StorableObject) (tensor([1], dtype=torch.uint8) can_read: ['🜣', '🜥'])\n",
      "\n",
      "  > <UID:5e5982d3-3d75-4712-86a9-ece7e297010b> <UID:🙵🚉> => 🗂️ (StorableObject) (<torch._C.Generator object at 0x1302591e0>)\n",
      "\n",
      "  > <UID:a1d93b56-8430-45e3-87a1-b562ebf0edf8> <UID:🛩🛟> => 🗂️ (StorableObject) (tensor([  1, 209, 156,  ...,   0,   0,   0], dtype=torch.uint8) can_read: ['🜣', '🜥'])\n",
      "\n",
      "  > <UID:454b61f9-8e65-4aea-88a2-2aa675e2d116> <UID:🙾🚅> => 🗂️ (StorableObject) (<torch._C.Generator object at 0x11fd81c30> can_read: ['🜣', '🜥'])\n",
      "\n",
      "  > <UID:3d52dec8-4b94-445c-8cd7-c245ee6f57b9> <UID:🚉🛨> => 🗂️ (StorableObject) (<torch._C.Generator object at 0x11fd81c30> can_read: ['🜥', '🜣'])\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(alice.store.peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Module' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2eaca526b1e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Module' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(9216, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(args, model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % args.log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "#             if args.dry_run:\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, device, test_loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     # Training settings\n",
    "#     parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "#     parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "#                         help='input batch size for training (default: 64)')\n",
    "#     parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "#                         help='input batch size for testing (default: 1000)')\n",
    "#     parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "#                         help='number of epochs to train (default: 14)')\n",
    "#     parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "#                         help='learning rate (default: 1.0)')\n",
    "#     parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "#                         help='Learning rate step gamma (default: 0.7)')\n",
    "#     parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "#                         help='disables CUDA training')\n",
    "#     parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "#                         help='quickly check a single pass')\n",
    "#     parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "#                         help='random seed (default: 1)')\n",
    "#     parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "#                         help='how many batches to wait before logging training status')\n",
    "#     parser.add_argument('--save-model', action='store_true', default=False,\n",
    "#                         help='For Saving the current Model')\n",
    "#     args = parser.parse_args()\n",
    "#     use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "#     torch.manual_seed(args.seed)\n",
    "\n",
    "#     device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "#     kwargs = {'batch_size': args.batch_size}\n",
    "#     if use_cuda:\n",
    "#         kwargs.update({'num_workers': 1,\n",
    "#                        'pin_memory': True,\n",
    "#                        'shuffle': True},\n",
    "#                      )\n",
    "\n",
    "#     transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ])\n",
    "#     dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "#                        transform=transform)\n",
    "#     dataset2 = datasets.MNIST('../data', train=False,\n",
    "#                        transform=transform)\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset1,**kwargs)\n",
    "#     test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n",
    "\n",
    "#     model = Net().to(device)\n",
    "#     optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "#     scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "#     for epoch in range(1, args.epochs + 1):\n",
    "#         train(args, model, device, train_loader, optimizer, epoch)\n",
    "#         test(model, device, test_loader)\n",
    "#         scheduler.step()\n",
    "\n",
    "#     if args.save_model:\n",
    "#         torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
