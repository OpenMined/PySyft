{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "# Federated Learning Training Plan: Execute Plan\n",
    "\n",
    "Here we load and execute Plan and Model params created earlier in \"Create Plan\" notebook. \n",
    "\n",
    "This represents PySyft (python) worker."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0527 13:48:11.935419 18544 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'D:\\Anaconda3\\envs\\syft\\lib\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
      "W0527 13:48:11.996123 18544 deprecation_wrapper.py:119] From D:\\Anaconda3\\envs\\syft\\lib\\site-packages\\tf_encrypted\\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import syft as sy\n",
    "import torch as th\n",
    "from torchvision import datasets, transforms\n",
    "from syft.serde import protobuf\n",
    "from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB\n",
    "from syft_proto.execution.v1.state_pb2 import State as StatePB\n",
    "from syft import PlaceHolder\n",
    "from syft.execution.state import State\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sy.make_hook(globals())\n",
    "# force protobuf serialization for tensors\n",
    "hook.local_worker.framework = None"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utility func that unserializes file contents into PySyft classes.\n",
    "Note that we must know file contents beforehand to use specific protobuf class for deserialization."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def deserializeFromBin(worker, filename, pb):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        bin = f.read()\n",
    "    pb.ParseFromString(bin)\n",
    "    return protobuf.serde._unbufferize(worker, pb)\n",
    "\n",
    "def serializeToBinPb(worker, obj, filename):\n",
    "    pb = protobuf.serde._bufferize(worker, obj)\n",
    "    bin = pb.SerializeToString()\n",
    "    print(\"Writing %s to %s/%s\" % (obj.__class__.__name__, os.getcwd(), filename))\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(bin)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Unserialize Plan & Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded syft plan: def training_plan(arg_1, arg_2, arg_3, arg_4, arg_5, arg_6, arg_7, arg_8):\n",
      "    2 = arg_1.dim()\n",
      "    var_0 = arg_5.t()\n",
      "    var_1 = arg_1.matmul(var_0)\n",
      "    var_2 = arg_6.add(var_1)\n",
      "    var_3 = var_2.relu()\n",
      "    2 = var_3.dim()\n",
      "    var_4 = arg_7.t()\n",
      "    var_5 = var_3.matmul(var_4)\n",
      "    var_6 = arg_8.add(var_5)\n",
      "    var_7 = var_6.max()\n",
      "    var_8 = var_6.sub(var_7)\n",
      "    var_9 = var_8.exp()\n",
      "    var_10 = var_9.sum(dim=1, keepdim=True)\n",
      "    var_11 = var_10.log()\n",
      "    var_12 = var_8.sub(var_11)\n",
      "    var_13 = arg_2.mul(var_12)\n",
      "    var_14 = var_13.sum()\n",
      "    var_15 = var_14.neg()\n",
      "    out_1 = var_15.div(arg_3)\n",
      "    var_16 = out_1.mul(0)\n",
      "    var_17 = var_16.add(1)\n",
      "    var_18 = var_17.div(arg_3)\n",
      "    var_19 = var_18.mul(-1)\n",
      "    var_20 = var_13.mul(0)\n",
      "    var_21 = var_20.add(1)\n",
      "    var_22 = var_21.mul(var_19)\n",
      "    var_23 = var_22.mul(var_12)\n",
      "    var_24 = var_22.mul(arg_2)\n",
      "    var_25 = var_23.copy()\n",
      "    var_26 = var_24.add(0)\n",
      "    var_27 = var_24.mul(-1)\n",
      "    var_28 = var_27.sum(dim=[1], keepdim=True)\n",
      "    var_29 = var_26.add(0)\n",
      "    var_30 = var_26.mul(-1)\n",
      "    var_31 = var_30.sum(dim=[1, 0])\n",
      "    var_32 = var_29.add(0)\n",
      "    var_33 = var_29.add(0)\n",
      "    var_34 = var_32.sum(dim=[0])\n",
      "    var_35 = var_34.copy()\n",
      "    var_36 = var_4.t()\n",
      "    var_37 = var_33.matmul(var_36)\n",
      "    var_38 = var_3.t()\n",
      "    var_39 = var_38.matmul(var_33)\n",
      "    var_40 = var_2.mul(0)\n",
      "    var_41 = var_2.__gt__(var_40)\n",
      "    var_42 = var_41.mul(var_37)\n",
      "    var_43 = var_42.add(0)\n",
      "    var_44 = var_42.add(0)\n",
      "    var_45 = var_43.sum(dim=[0])\n",
      "    var_46 = var_45.copy()\n",
      "    var_47 = var_0.t()\n",
      "    var_48 = var_44.matmul(var_47)\n",
      "    var_49 = arg_1.t()\n",
      "    var_50 = var_49.matmul(var_44)\n",
      "    var_51 = var_48.copy()\n",
      "    var_52 = var_50.t()\n",
      "    var_53 = var_52.copy()\n",
      "    var_54 = var_39.t()\n",
      "    var_55 = var_54.copy()\n",
      "    var_56 = var_31.copy()\n",
      "    var_57 = var_10.__rtruediv__(1)\n",
      "    var_58 = var_28.mul(var_57)\n",
      "    var_59 = var_9.mul(0)\n",
      "    var_60 = var_59.add(1)\n",
      "    var_61 = var_60.mul(var_58)\n",
      "    var_62 = var_8.exp()\n",
      "    var_63 = var_61.mul(var_62)\n",
      "    var_64 = var_63.add(0)\n",
      "    var_65 = var_63.mul(-1)\n",
      "    var_66 = var_65.sum(dim=[1, 0])\n",
      "    var_67 = var_64.add(0)\n",
      "    var_68 = var_64.add(0)\n",
      "    var_69 = var_67.sum(dim=[0])\n",
      "    var_70 = var_35.add_(var_69)\n",
      "    var_71 = var_4.t()\n",
      "    var_72 = var_68.matmul(var_71)\n",
      "    var_73 = var_3.t()\n",
      "    var_74 = var_73.matmul(var_68)\n",
      "    var_75 = var_2.mul(0)\n",
      "    var_76 = var_2.__gt__(var_75)\n",
      "    var_77 = var_76.mul(var_72)\n",
      "    var_78 = var_77.add(0)\n",
      "    var_79 = var_77.add(0)\n",
      "    var_80 = var_78.sum(dim=[0])\n",
      "    var_81 = var_46.add_(var_80)\n",
      "    var_82 = var_0.t()\n",
      "    var_83 = var_79.matmul(var_82)\n",
      "    var_84 = arg_1.t()\n",
      "    var_85 = var_84.matmul(var_79)\n",
      "    var_86 = var_51.add_(var_83)\n",
      "    var_87 = var_85.t()\n",
      "    var_88 = var_53.add_(var_87)\n",
      "    var_89 = var_74.t()\n",
      "    var_90 = var_55.add_(var_89)\n",
      "    var_91 = var_56.add_(var_66)\n",
      "    var_92 = arg_4.mul(var_53)\n",
      "    out_3 = arg_5.sub(var_92)\n",
      "    var_93 = arg_4.mul(var_46)\n",
      "    out_4 = arg_6.sub(var_93)\n",
      "    var_94 = arg_4.mul(var_55)\n",
      "    out_5 = arg_7.sub(var_94)\n",
      "    var_95 = arg_4.mul(var_35)\n",
      "    out_6 = arg_8.sub(var_95)\n",
      "    var_96 = torch.argmax(var_6, dim=1)\n",
      "    var_97 = torch.argmax(arg_2, dim=1)\n",
      "    var_98 = var_96.eq(var_97)\n",
      "    var_99 = var_98.sum()\n",
      "    var_100 = var_99.float()\n",
      "    out_2 = var_100.div(arg_3)\n",
      "    return out_1, out_2, out_3, out_4, out_5, out_6\n",
      "Loaded torchscript plan code: def forward(self,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: Tensor,\n",
      "    argument_5: List[Tensor]) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0, _1, _2, _3, = argument_5\n",
      "  _4 = torch.add(_1, torch.matmul(argument_1, torch.t(_0)), alpha=1)\n",
      "  _5 = torch.relu(_4)\n",
      "  _6 = torch.t(_2)\n",
      "  _7 = torch.add(_3, torch.matmul(_5, _6), alpha=1)\n",
      "  _8 = torch.sub(_7, torch.max(_7), alpha=1)\n",
      "  _9 = torch.exp(_8)\n",
      "  _10 = torch.sum(_9, [1], True, dtype=None)\n",
      "  _11 = torch.sub(_8, torch.log(_10), alpha=1)\n",
      "  _12 = torch.mul(argument_2, _11)\n",
      "  _13 = torch.div(torch.neg(torch.sum(_12, dtype=None)), argument_3)\n",
      "  _14 = torch.add(torch.mul(_13, CONSTANTS.c0), CONSTANTS.c1, alpha=1)\n",
      "  _15 = torch.mul(torch.div(_14, argument_3), CONSTANTS.c2)\n",
      "  _16 = torch.add(torch.mul(_12, CONSTANTS.c0), CONSTANTS.c1, alpha=1)\n",
      "  _17 = torch.mul(torch.mul(_16, _15), argument_2)\n",
      "  _18 = torch.add(_17, CONSTANTS.c0, alpha=1)\n",
      "  _19 = torch.sum(torch.mul(_17, CONSTANTS.c2), [1], True, dtype=None)\n",
      "  _20 = torch.add(_18, CONSTANTS.c0, alpha=1)\n",
      "  _21 = torch.add(_20, CONSTANTS.c0, alpha=1)\n",
      "  _22 = torch.add(_20, CONSTANTS.c0, alpha=1)\n",
      "  _23 = torch.sum(_21, [0], False, dtype=None)\n",
      "  _24 = torch.matmul(_22, torch.t(_6))\n",
      "  _25 = torch.matmul(torch.t(_5), _22)\n",
      "  _26 = torch.gt(_4, torch.mul(_4, CONSTANTS.c0))\n",
      "  _27 = torch.mul(_26, _24)\n",
      "  _28 = torch.add(_27, CONSTANTS.c0, alpha=1)\n",
      "  _29 = torch.add(_27, CONSTANTS.c0, alpha=1)\n",
      "  _30 = torch.sum(_28, [0], False, dtype=None)\n",
      "  _31 = torch.matmul(torch.t(argument_1), _29)\n",
      "  _32 = torch.t(_31)\n",
      "  _33 = torch.t(_25)\n",
      "  _34 = torch.mul(torch.reciprocal(_10), CONSTANTS.c1)\n",
      "  _35 = torch.mul(_19, _34)\n",
      "  _36 = torch.add(torch.mul(_9, CONSTANTS.c0), CONSTANTS.c1, alpha=1)\n",
      "  _37 = torch.mul(torch.mul(_36, _35), torch.exp(_8))\n",
      "  _38 = torch.add(_37, CONSTANTS.c0, alpha=1)\n",
      "  _39 = torch.add(_38, CONSTANTS.c0, alpha=1)\n",
      "  _40 = torch.add(_38, CONSTANTS.c0, alpha=1)\n",
      "  _41 = torch.sum(_39, [0], False, dtype=None)\n",
      "  _42 = torch.add_(_23, _41, alpha=1)\n",
      "  _43 = torch.matmul(_40, torch.t(_6))\n",
      "  _44 = torch.matmul(torch.t(_5), _40)\n",
      "  _45 = torch.gt(_4, torch.mul(_4, CONSTANTS.c0))\n",
      "  _46 = torch.mul(_45, _43)\n",
      "  _47 = torch.add(_46, CONSTANTS.c0, alpha=1)\n",
      "  _48 = torch.add(_46, CONSTANTS.c0, alpha=1)\n",
      "  _49 = torch.sum(_47, [0], False, dtype=None)\n",
      "  _50 = torch.add_(_30, _49, alpha=1)\n",
      "  _51 = torch.matmul(torch.t(argument_1), _48)\n",
      "  _52 = torch.add_(_32, torch.t(_51), alpha=1)\n",
      "  _53 = torch.add_(_33, torch.t(_44), alpha=1)\n",
      "  _54 = torch.sub(_0, torch.mul(argument_4, _52), alpha=1)\n",
      "  _55 = torch.sub(_1, torch.mul(argument_4, _50), alpha=1)\n",
      "  _56 = torch.sub(_2, torch.mul(argument_4, _53), alpha=1)\n",
      "  _57 = torch.sub(_3, torch.mul(argument_4, _42), alpha=1)\n",
      "  _58 = torch.eq(torch.argmax(_7, 1, False), torch.argmax(argument_2, 1, False))\n",
      "  _59 = torch.to(torch.sum(_58, dtype=None), 6, False, False, None)\n",
      "  _60 = (_13, torch.div(_59, argument_3), _54, _55, _56, _57)\n",
      "  return _60\n",
      "\n",
      "Loaded params count: 4\n",
      "Params shapes: [torch.Size([392, 784]), torch.Size([392]), torch.Size([10, 392]), torch.Size([10])]\n"
     ]
    }
   ],
   "source": [
    "training_plan = deserializeFromBin(hook.local_worker, \"tp_full.pb\", PlanPB())\n",
    "model_params_state = deserializeFromBin(hook.local_worker, \"model_params.pb\", StatePB())\n",
    "# unwrap tensors from State\n",
    "model_params = model_params_state.tensors()\n",
    "\n",
    "print(\"Loaded syft plan:\", training_plan.code)\n",
    "print(\"Loaded torchscript plan code:\", training_plan.torchscript.code)\n",
    "print(\"Loaded params count:\", len(model_params))\n",
    "print(\"Params shapes:\", [p.shape for p in model_params])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Train!\n",
    "\n",
    "Define the full training procedure that uses Plan as one training step on a batch of data. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "mnist = th.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "def execute_training_plan(data, plan, model_params, epochs=1, batch_size=th.tensor(batch_size), lr=th.tensor(0.001)):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        for batch_idx, (X, y) in enumerate(data):\n",
    "            X = X.view(X.shape[0], -1)\n",
    "            y_oh = th.nn.functional.one_hot(y, 10)\n",
    "            loss, acc, *model_params = plan(X, y_oh, batch_size, lr, model_params)\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(acc.item())\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(\"Batch %d, loss: %f, accuracy: %f\" % (batch_idx, loss, acc), end=\"\\r\")\n",
    "        print('Epoch %d, avg loss: %f, avg training accuracy: %f' % (epoch, np.mean(losses), np.mean(accuracies)))\n",
    "    return model_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To show both variants of plans work, first we run training with \"list of ops\" Plan and get updated model weights,\n",
    "then execute training with torchscript Plan starting with updated weights and get further updated weights :)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, avg loss: 2.194609, avg training accuracy: 0.431253\n"
     ]
    }
   ],
   "source": [
    "# Plain Plan\n",
    "training_plan.validate_input_types = False\n",
    "updated_model_params = execute_training_plan(mnist, training_plan, model_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, avg loss: 1.956141, avg training accuracy: 0.675856\n"
     ]
    }
   ],
   "source": [
    "# Torchscript Plan\n",
    "# NOTE that execution point is `.torchscript` property\n",
    "updated_model_params = execute_training_plan(mnist, training_plan.torchscript, updated_model_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6: Create Diff\n",
    "\n",
    "Naive diff is just a difference between original model weights and updated model weights. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([392, 784]), torch.Size([392]), torch.Size([10, 392]), torch.Size([10])]\n"
     ]
    }
   ],
   "source": [
    "diff = [ model_params[i] - updated_model_params[i] for i in range(len(model_params)) ]\n",
    "\n",
    "print([ item.shape for item in diff ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's wrap it in State to serialize."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing State to D:\\projects\\openmined\\PySyft\\examples\\experimental\\FL Training Plan/diff.pb\n"
     ]
    }
   ],
   "source": [
    "diff_state = State(\n",
    "    state_placeholders=[PlaceHolder().instantiate(param) for param in diff]\n",
    ")\n",
    "serializeToBinPb(hook.local_worker, diff_state, 'diff.pb')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}