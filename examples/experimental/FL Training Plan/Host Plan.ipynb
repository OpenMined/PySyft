{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Federated Learning Training Plan: Host Plan & Model\n",
    "\n",
    "Here we load Plan and Model params created earlier in \"Create Plan\" notebook, host them to PyGrid, \n",
    "and run sample syft.js app that executes them.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.13.1.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import websockets\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "import syft as sy\n",
    "from syft.grid.grid_client import GridClient\n",
    "from syft.serde import protobuf\n",
    "from syft_proto.execution.v1.plan_pb2 import Plan as PlanPB\n",
    "from syft_proto.execution.v1.state_pb2 import State as StatePB\n",
    "\n",
    "sy.make_hook(globals())\n",
    "# force protobuf serialization for tensors\n",
    "hook.local_worker.framework = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "async def sendWsMessage(data):\n",
    "    async with websockets.connect('ws://' + gatewayWsUrl) as websocket:\n",
    "        await websocket.send(json.dumps(data))\n",
    "        message = await websocket.recv()\n",
    "        return json.loads(message)\n",
    "\n",
    "def deserializeFromBin(worker, filename, pb):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        bin = f.read()\n",
    "    pb.ParseFromString(bin)\n",
    "    return protobuf.serde._unbufferize(worker, pb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4a: Host in PyGrid\n",
    "\n",
    "Here we load \"ops list\" Plan.\n",
    "PyGrid should translate it to other types (e.g. torchscript) automatically. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load files with protobuf created in \"Create Plan\" notebook.\n",
    "training_plan = deserializeFromBin(hook.local_worker, \"tp_full.pb\", PlanPB())\n",
    "model_params_state = deserializeFromBin(hook.local_worker, \"model_params.pb\", StatePB())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Follow PyGrid README.md to build `openmined/grid-gateway` image from the latest `dev` branch \n",
    "and spin up PyGrid using `docker-compose up --build`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Default gateway address when running locally \n",
    "gatewayWsUrl = \"127.0.0.1:5000\"\n",
    "grid = GridClient(id=\"test\", address=gatewayWsUrl, secure=False)\n",
    "grid.connect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define name, version, configs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# These name/version you use in worker\n",
    "name = \"mnist\"\n",
    "version = \"1.0.0\"\n",
    "client_config = {\n",
    "            \"name\": name,  \n",
    "            \"version\": version,\n",
    "            \"batch_size\": 64,\n",
    "            \"lr\": 0.01,\n",
    "            \"max_updates\": 100  # custom syft.js option that limits number of training loops per worker\n",
    "        }\n",
    "\n",
    "server_config = {\n",
    "            \"min_workers\": 3,  # temporarily this plays role \"min # of worker's diffs\" for triggering cycle end event\n",
    "            \"max_workers\": 3,\n",
    "            \"pool_selection\": \"random\",\n",
    "            \"num_cycles\": 5,\n",
    "            \"do_not_reuse_workers_until_cycle\": 4,\n",
    "            \"cycle_length\": 28800,\n",
    "            \"minimum_upload_speed\": 0,\n",
    "            \"minimum_download_speed\": 0\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shoot!\n",
    "\n",
    "If everything's good, success is returned.\n",
    "If the name/version already exists in PyGrid, change them above or cleanup PyGrid db by re-creating docker containers (e.g. `docker-compose up --force-recreate`). \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host response: {'type': 'federated/host-training', 'data': {'status': 'success'}}\n"
     ]
    }
   ],
   "source": [
    "response = grid.host_federated_training(\n",
    "    model=model_params_state,\n",
    "    client_plans={'training_plan': training_plan},\n",
    "    client_protocols={},\n",
    "    server_averaging_plan=None,\n",
    "    client_config=client_config,\n",
    "    server_config=server_config\n",
    ")\n",
    "\n",
    "print(\"Host response:\", response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's double-check that data is loaded by requesting a cycle.\n",
    "\n",
    "(Request is made directly, will be methods on grid client in the future)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auth response:  {\n",
      "  \"type\": \"federated/authenticate\",\n",
      "  \"data\": {\n",
      "    \"status\": \"success\",\n",
      "    \"worker_id\": \"f95bf0b9-de40-4eba-9ac2-4a39f49769dd\"\n",
      "  }\n",
      "}\n",
      "Cycle response: {\n",
      "  \"type\": \"federated/cycle-request\",\n",
      "  \"data\": {\n",
      "    \"status\": \"accepted\",\n",
      "    \"request_key\": \"f82850aac99516de92f3b9f14dffc0a3bbf058c8f92fe7bab869340c282daf2f\",\n",
      "    \"version\": \"1.0.0\",\n",
      "    \"model\": \"mnist\",\n",
      "    \"plans\": {\n",
      "      \"training_plan\": 2\n",
      "    },\n",
      "    \"protocols\": {},\n",
      "    \"client_config\": {\n",
      "      \"name\": \"mnist\",\n",
      "      \"version\": \"1.0.0\",\n",
      "      \"batch_size\": 64,\n",
      "      \"lr\": 0.01,\n",
      "      \"max_updates\": 100\n",
      "    },\n",
      "    \"model_id\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "auth_request = {\n",
    "    \"type\": \"federated/authenticate\",\n",
    "    \"data\": {}\n",
    "}\n",
    "auth_response = await sendWsMessage(auth_request)\n",
    "print('Auth response: ', json.dumps(auth_response, indent=2))\n",
    "\n",
    "cycle_request = {\n",
    "    \"type\": \"federated/cycle-request\",\n",
    "    \"data\": {\n",
    "        \"worker_id\": auth_response['data']['worker_id'],\n",
    "        \"model\": name,\n",
    "        \"version\": version,\n",
    "        \"ping\": 1,\n",
    "        \"download\": 10000,\n",
    "        \"upload\": 10000,\n",
    "    }\n",
    "}\n",
    "cycle_response = await sendWsMessage(cycle_request)\n",
    "print('Cycle response:', json.dumps(cycle_response, indent=2))\n",
    "\n",
    "worker_id = auth_response['data']['worker_id']\n",
    "request_key = cycle_response['data']['request_key']\n",
    "model_id = cycle_response['data']['model_id'] \n",
    "training_plan_id = cycle_response['data']['plans']['training_plan']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's download model and plan (both versions) and check they are actually workable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<State: PlaceHolder[Tags:]>tensor([[-0.0545, -0.0268, -0.0234,  ..., -0.0366,  0.0367, -0.0069],\n",
      "        [-0.0172,  0.0025,  0.0130,  ...,  0.0187, -0.0071,  0.0256],\n",
      "        [-0.0751, -0.0244,  0.0076,  ...,  0.0527, -0.0103,  0.0087],\n",
      "        ...,\n",
      "        [-0.0342,  0.0394, -0.0270,  ...,  0.0038, -0.0150,  0.0195],\n",
      "        [-0.0166,  0.0126,  0.0174,  ..., -0.0004,  0.0120,  0.0872],\n",
      "        [ 0.0269,  0.0080,  0.0367,  ...,  0.0404, -0.0204, -0.0162]])\n",
      "\tDescription: ...\n",
      "\tShape: torch.Size([392, 784]) PlaceHolder[Tags:]>tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\tDescription: ...\n",
      "\tShape: torch.Size([392]) PlaceHolder[Tags:]>tensor([[ 0.0149, -0.0279,  0.0105,  ..., -0.0063, -0.0202,  0.1158],\n",
      "        [-0.0571, -0.0277,  0.0440,  ..., -0.0077,  0.0501,  0.0601],\n",
      "        [ 0.0465, -0.0464, -0.0382,  ...,  0.0703, -0.0700, -0.0036],\n",
      "        ...,\n",
      "        [ 0.0015, -0.0540, -0.0205,  ...,  0.0319,  0.0343, -0.0008],\n",
      "        [-0.0738,  0.0321, -0.0010,  ..., -0.0083, -0.0316, -0.0052],\n",
      "        [ 0.0269,  0.0357, -0.0417,  ..., -0.0773, -0.0456, -0.0344]])\n",
      "\tDescription: ...\n",
      "\tShape: torch.Size([10, 392]) PlaceHolder[Tags:]>tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\tDescription: ...\n",
      "\tShape: torch.Size([10])>\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "req = requests.get(f\"http://{gatewayWsUrl}/federated/get-model?worker_id={worker_id}&request_key={request_key}&model_id={model_id}\")\n",
    "model_data = req.content\n",
    "pb = StatePB()\n",
    "pb.ParseFromString(req.content)\n",
    "model_params_downloaded = protobuf.serde._unbufferize(hook.local_worker, pb)\n",
    "print(model_params_downloaded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<syft.execution.computation.ComputationAction object at 0x0000018BDD4BEEB8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4A2FD0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4A2EF0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4A27F0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4A2CF8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4A2240>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4A2C18>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4C25F8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4C2588>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4C2B38>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4C2A58>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4C2D68>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6560F0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD4C21D0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6562B0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656390>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6564A8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656588>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656668>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656748>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6567F0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656908>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6569B0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656A58>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656B70>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656C88>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656DD8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656F28>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6570B8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657208>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657358>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6574A8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD6575F8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD656BA8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657748>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657978>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657AC8>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657BE0>, <syft.execution.computation.ComputationAction object at 0x0000018BDD657C88>]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Plan \"list of ops\"\n",
    "req = requests.get(f\"http://{gatewayWsUrl}/federated/get-plan?worker_id={worker_id}&request_key={request_key}&plan_id={training_plan_id}&receive_operations_as=list\")\n",
    "pb = PlanPB()\n",
    "pb.ParseFromString(req.content)\n",
    "plan_ops = protobuf.serde._unbufferize(hook.local_worker, pb)\n",
    "print(plan_ops.role.actions)\n",
    "print(plan_ops.torchscript)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "def forward(self,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: Tensor,\n",
      "    argument_5: Tensor,\n",
      "    argument_6: Tensor,\n",
      "    argument_7: Tensor,\n",
      "    argument_8: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0 = torch.matmul(argument_1, torch.t(argument_5))\n",
      "  _1 = torch.add(_0, argument_6, alpha=1)\n",
      "  _2 = torch.relu(_1)\n",
      "  _3 = torch.add(torch.matmul(_2, torch.t(argument_7)), argument_8, alpha=1)\n",
      "  _4 = torch.softmax(_3, 1, None)\n",
      "  _5 = torch.mean(torch.mul(argument_2, torch.log(_4)), dtype=None)\n",
      "  _6 = torch.neg(_5)\n",
      "  _7 = torch.div(torch.sub(_4, argument_2, alpha=1), torch.mul(argument_3, CONSTANTS.c0))\n",
      "  _8 = torch.matmul(_7, argument_7)\n",
      "  _9 = torch.to(torch.gt(_1, 0), 6, False, False, None)\n",
      "  _10 = torch.mul(_8, _9)\n",
      "  _11 = torch.matmul(torch.t(_10), argument_1)\n",
      "  _12 = torch.sum(_10, [0], False, dtype=None)\n",
      "  _13 = torch.matmul(torch.t(_7), _2)\n",
      "  _14 = torch.sum(_7, [0], False, dtype=None)\n",
      "  _15 = torch.sub(argument_5, torch.mul(_11, argument_4), alpha=1)\n",
      "  _16 = torch.sub(argument_6, torch.mul(_12, argument_4), alpha=1)\n",
      "  _17 = torch.sub(argument_7, torch.mul(_13, argument_4), alpha=1)\n",
      "  _18 = torch.sub(argument_8, torch.mul(_14, argument_4), alpha=1)\n",
      "  _19 = torch.eq(torch.argmax(_4, 1, False), torch.argmax(argument_2, 1, False))\n",
      "  _20 = torch.sum(torch.to(_19, 6, False, False, None), dtype=None)\n",
      "  _21 = (_6, torch.div(_20, argument_3), _15, _16, _17, _18)\n",
      "  return _21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plan \"torchscript\"\n",
    "req = requests.get(f\"http://{gatewayWsUrl}/federated/get-plan?worker_id={worker_id}&request_key={request_key}&plan_id={training_plan_id}&receive_operations_as=torchscript\")\n",
    "pb = PlanPB()\n",
    "pb.ParseFromString(req.content)\n",
    "plan_ts = protobuf.serde._unbufferize(hook.local_worker, pb)\n",
    "print(plan_ts.role.actions)\n",
    "print(plan_ts.torchscript.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5a: Train\n",
    "\n",
    "Start and open \"with-grid\" example in syft.js project (http://localhost:8080 by default), \n",
    "enter model name and version and start FL training.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6a: Submit diff\n",
    "\n",
    "This emulates submitting worker's diff (created earlier in Execute Plan notebook) to PyGrid.\n",
    "After several diffs submitted, PyGrid will end the cycle and create new model checkpoint and cycle. \n",
    "(Request is made directly, will be methods on grid client in the future)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report response: {\n",
      "  \"type\": \"federated/report\",\n",
      "  \"data\": {\n",
      "    \"status\": \"success\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"diff.pb\", \"rb\") as f:\n",
    "    diff = f.read()\n",
    "\n",
    "report_request = {\n",
    "    \"type\": \"federated/report\",\n",
    "    \"data\": {\n",
    "        \"worker_id\": auth_response['data']['worker_id'],\n",
    "        \"request_key\": cycle_response['data']['request_key'],\n",
    "        \"diff\": base64.b64encode(diff).decode(\"utf-8\")\n",
    "    }\n",
    "}\n",
    "\n",
    "report_response = await sendWsMessage(report_request)\n",
    "print('Report response:', json.dumps(report_response, indent=2)) "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}