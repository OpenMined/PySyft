{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Federated Learning Training Plan: Create Plan\n",
    "\n",
    "Let's try to make protobuf-serializable Training Plan and Model that work after deserializing :)\n",
    "\n",
    "Current list of problems:\n",
    " * No support for autograd in Plan tracing (.backward() doesn't work inside the Plan).\n",
    " * `tensor.shape` value seem to be recorded as constant during Plan tracing, so we need to pass `batch_size`, can't take it from tensor itself.\n",
    " * Plan needs a list of all Model params in the argument list, it would be nicer if this list is figured out automatically so you just pass the Model (not sure it's solvable jit might not accept the model as ScriptModule input?)\n",
    " * Since loops aren't supported inside Plan, working with Model params (i.e. weights update) is awkward. \n",
    " * others? \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'C:\\Users\\Vova\\AppData\\Local\\conda\\conda\\envs\\pysyft\\lib\\site-packages\\tf_encrypted/operations/secure_random/secure_random_module_tf_1.13.1.so'\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Setting up Sandbox...\n",
      "Done!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2b0896b3cb0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import syft as sy\n",
    "import torch as th\n",
    "from torch import jit\n",
    "from syft.serde import protobuf\n",
    "import base64\n",
    "import os\n",
    "from syft.messaging.plan.state import State\n",
    "from syft.frameworks.torch.tensors.interpreters.placeholder import PlaceHolder\n",
    "\n",
    "\n",
    "sy.hook(globals())\n",
    "th.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This utility function will serialize any object to protobuf binary, \n",
    "encode to base64 and save to a file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def serializeToBase64Pb(worker, obj, filename):\n",
    "    pb = protobuf.serde._bufferize(worker, obj)\n",
    "    bin = pb.SerializeToString()\n",
    "    b64 = base64.b64encode(bin).decode('utf-8')\n",
    "    print(\"Writing %s to %s/%s\" % (obj.__class__.__name__, os.getcwd(), filename))\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(b64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define the model\n",
    "\n",
    "This model will train on MNIST data, it's very simple yet can demonstrate learning process.\n",
    "There're 2 linear layers: \n",
    "\n",
    "* Linear 784x392\n",
    "* ReLU\n",
    "* Linear 392x10 \n",
    "\n",
    "Not using nn.Module or nn.Linear for now, just vanilla class and tensors.\n",
    "No autograd, gradients are hand-coded. \n",
    "\n",
    "As no loops supported inside Plan, \n",
    "we can't iterate over parameters so everything that works with params\n",
    "(get/set, step) is moved into the model to make Plan code more generic.  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Net():\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.W1 = th.randn(392, 784) / th.sqrt(th.tensor(784.))\n",
    "        self.b1 = th.zeros(392)\n",
    "        self.W2 = th.randn(10, 392) / th.sqrt(th.tensor(392.))\n",
    "        self.b2 = th.zeros(10)\n",
    "        self.update_fn = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.Z1 = X @ self.W1.t() + self.b1\n",
    "        self.A1 = th.nn.functional.relu(self.Z1)\n",
    "        self.Z2 = self.A1 @ self.W2.t() + self.b2\n",
    "        return self.Z2\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.W1, self.b1, self.W2, self.b2\n",
    "\n",
    "    def set_params(self, *model_params):\n",
    "        self.W1, self.b1, self.W2, self.b2 = model_params\n",
    "\n",
    "    def grad(self, X, error):\n",
    "        Z1_grad = (error @ self.W2) * (self.Z1 > 0).float()\n",
    "        W1_grad = Z1_grad.t() @ X\n",
    "        b1_grad = Z1_grad.sum(0)\n",
    "        W2_grad = error.t() @ self.A1 \n",
    "        b2_grad = error.sum(0)\n",
    "        return W1_grad, b1_grad, W2_grad, b2_grad\n",
    "\n",
    "    def update_weights(self, *grads, **update_kwargs):\n",
    "        W1_grad, b1_grad, W2_grad, b2_grad = grads\n",
    "        self.update_fn(self.W1, W1_grad, **update_kwargs)\n",
    "        self.update_fn(self.b1, b1_grad, **update_kwargs)\n",
    "        self.update_fn(self.W2, W2_grad, **update_kwargs)\n",
    "        self.update_fn(self.b2, b2_grad, **update_kwargs)\n",
    "\n",
    "model = Net()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define Training Plan\n",
    "### Loss function \n",
    "Batch size needs to be passed because otherwise `target.shape[0]` will be saved as `1` constant during Plan trace with dummy data.\n",
    "Grad is also returned here. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def cross_entropy_with_logits(output, target, batch_size):\n",
    "    probs = th.nn.functional.softmax(output, dim=1)\n",
    "    loss = -(target * th.log(probs)).mean()\n",
    "    loss_grad = (probs - target) / (batch_size * target.shape[1])\n",
    "    return probs, loss, loss_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimization function\n",
    " \n",
    "Just updates weights with grad*lr.\n",
    "\n",
    "Adding it into a Model is a way to decouple\n",
    "Plan from dealing with param update directly,\n",
    "so that only Model knows about its weights."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def naive_sgd(param, grad, **kwargs):\n",
    "    param.add_(-grad * kwargs['lr'])\n",
    "\n",
    "model.update_fn = naive_sgd\n",
    "   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training Plan procedure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[(Operation (('t', PlaceHolder[Tags:#1 #input-4], (), {}), PlaceHolder[Tags:#2])), (Operation (('__matmul__', PlaceHolder[Tags:#3 #input-0], (PlaceHolder[Tags:#2],), {}), PlaceHolder[Tags:#4])), (Operation (('__add__', PlaceHolder[Tags:#4], (PlaceHolder[Tags:#5 #input-5],), {}), PlaceHolder[Tags:#6])), (Operation (('torch.nn.functional.relu', None, (PlaceHolder[Tags:#6],), {}), PlaceHolder[Tags:#7])), (Operation (('t', PlaceHolder[Tags:#input-6 #8], (), {}), PlaceHolder[Tags:#9])), (Operation (('__matmul__', PlaceHolder[Tags:#7], (PlaceHolder[Tags:#9],), {}), PlaceHolder[Tags:#10])), (Operation (('__add__', PlaceHolder[Tags:#10], (PlaceHolder[Tags:#input-7 #11],), {}), PlaceHolder[Tags:#12])), (Operation (('torch.nn.functional.softmax', None, (PlaceHolder[Tags:#12],), {'dim': 1}), PlaceHolder[Tags:#13])), (Operation (('torch.log', None, (PlaceHolder[Tags:#13],), {}), PlaceHolder[Tags:#14])), (Operation (('__mul__', PlaceHolder[Tags:#15 #input-1], (PlaceHolder[Tags:#14],), {}), PlaceHolder[Tags:#16])), (Operation (('mean', PlaceHolder[Tags:#16], (), {}), PlaceHolder[Tags:#17])), (Operation (('__neg__', PlaceHolder[Tags:#17], (), {}), PlaceHolder[Tags:#output-4 #18])), (Operation (('__sub__', PlaceHolder[Tags:#13], (PlaceHolder[Tags:#15 #input-1],), {}), PlaceHolder[Tags:#19])), (Operation (('__mul__', PlaceHolder[Tags:#input-2 #20], (10,), {}), PlaceHolder[Tags:#21])), (Operation (('__truediv__', PlaceHolder[Tags:#19], (PlaceHolder[Tags:#21],), {}), PlaceHolder[Tags:#22])), (Operation (('__matmul__', PlaceHolder[Tags:#22], (PlaceHolder[Tags:#input-6 #8],), {}), PlaceHolder[Tags:#23])), (Operation (('__gt__', PlaceHolder[Tags:#6], (0,), {}), PlaceHolder[Tags:#24])), (Operation (('float', PlaceHolder[Tags:#24], (), {}), PlaceHolder[Tags:#25])), (Operation (('__mul__', PlaceHolder[Tags:#23], (PlaceHolder[Tags:#25],), {}), PlaceHolder[Tags:#26])), (Operation (('t', PlaceHolder[Tags:#26], (), {}), PlaceHolder[Tags:#27])), (Operation (('__matmul__', PlaceHolder[Tags:#27], (PlaceHolder[Tags:#3 #input-0],), {}), PlaceHolder[Tags:#28])), (Operation (('sum', PlaceHolder[Tags:#26], (0,), {}), PlaceHolder[Tags:#29])), (Operation (('t', PlaceHolder[Tags:#22], (), {}), PlaceHolder[Tags:#30])), (Operation (('__matmul__', PlaceHolder[Tags:#30], (PlaceHolder[Tags:#7],), {}), PlaceHolder[Tags:#31])), (Operation (('sum', PlaceHolder[Tags:#22], (0,), {}), PlaceHolder[Tags:#32])), (Operation (('__neg__', PlaceHolder[Tags:#28], (), {}), PlaceHolder[Tags:#33])), (Operation (('__mul__', PlaceHolder[Tags:#33], (PlaceHolder[Tags:#input-3 #34],), {}), PlaceHolder[Tags:#35])), (Operation (('add_', PlaceHolder[Tags:#1 #input-4], (PlaceHolder[Tags:#35],), {}), PlaceHolder[Tags:#1 #input-4])), (Operation (('__neg__', PlaceHolder[Tags:#29], (), {}), PlaceHolder[Tags:#36])), (Operation (('__mul__', PlaceHolder[Tags:#36], (PlaceHolder[Tags:#input-3 #34],), {}), PlaceHolder[Tags:#37])), (Operation (('add_', PlaceHolder[Tags:#5 #input-5], (PlaceHolder[Tags:#37],), {}), PlaceHolder[Tags:#5 #input-5])), (Operation (('__neg__', PlaceHolder[Tags:#31], (), {}), PlaceHolder[Tags:#38])), (Operation (('__mul__', PlaceHolder[Tags:#38], (PlaceHolder[Tags:#input-3 #34],), {}), PlaceHolder[Tags:#39])), (Operation (('add_', PlaceHolder[Tags:#input-6 #8], (PlaceHolder[Tags:#39],), {}), PlaceHolder[Tags:#input-6 #8])), (Operation (('__neg__', PlaceHolder[Tags:#32], (), {}), PlaceHolder[Tags:#40])), (Operation (('__mul__', PlaceHolder[Tags:#40], (PlaceHolder[Tags:#input-3 #34],), {}), PlaceHolder[Tags:#41])), (Operation (('add_', PlaceHolder[Tags:#input-7 #11], (PlaceHolder[Tags:#41],), {}), PlaceHolder[Tags:#input-7 #11])), (Operation (('torch.argmax', None, (PlaceHolder[Tags:#13],), {'dim': 1}), PlaceHolder[Tags:#42])), (Operation (('torch.argmax', None, (PlaceHolder[Tags:#15 #input-1],), {'dim': 1}), PlaceHolder[Tags:#43])), (Operation (('eq', PlaceHolder[Tags:#42], (PlaceHolder[Tags:#43],), {}), PlaceHolder[Tags:#44])), (Operation (('float', PlaceHolder[Tags:#44], (), {}), PlaceHolder[Tags:#45])), (Operation (('sum', PlaceHolder[Tags:#45], (), {}), PlaceHolder[Tags:#46])), (Operation (('__truediv__', PlaceHolder[Tags:#46], (PlaceHolder[Tags:#input-2 #20],), {}), PlaceHolder[Tags:#output-5 #47]))]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model_params = model.get_params()\n",
    "\n",
    "# define plan input dimensions\n",
    "X_size = (-1, 784)\n",
    "y_size = (-1, 10)\n",
    "scalar_size = (1,)\n",
    "model_params_shapes = [p.shape for p in model_params]\n",
    "\n",
    "args_shape = [\n",
    "    X_size,  # X\n",
    "    y_size,  # y\n",
    "    scalar_size,  # batch_size\n",
    "    scalar_size,  # lr\n",
    "    *model_params_shapes  # *model_params\n",
    "]\n",
    "\n",
    "@sy.func2plan(args_shape=args_shape)\n",
    "def training_plan(X, y, batch_size, lr, *model_params):\n",
    "    # inject params into model\n",
    "    model.set_params(*model_params)\n",
    "\n",
    "    # forward pass\n",
    "    output = model.forward(X)\n",
    "    \n",
    "    # loss\n",
    "    probs, loss, loss_grad = cross_entropy_with_logits(output, y, batch_size)\n",
    "\n",
    "    # backprop\n",
    "    grads = model.grad(X, loss_grad)\n",
    "\n",
    "    # step\n",
    "    model.update_weights(*grads, lr=lr)\n",
    "\n",
    "    # accuracy\n",
    "    pred = th.argmax(probs, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).float().sum() / batch_size\n",
    "\n",
    "    return (\n",
    "        *model_params,\n",
    "        loss,\n",
    "        acc,\n",
    "    )\n",
    "\n",
    "# check that operations look good\n",
    "print(training_plan.operations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: JIT Trace Training Plan\n",
    "\n",
    "Note: Plan expects everything to be a tensor.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "def __call__(argument_0: Tensor,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: Tensor,\n",
      "    argument_5: Tensor,\n",
      "    argument_6: Tensor,\n",
      "    argument_7: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0 = torch.matmul(argument_0, torch.t(argument_4))\n",
      "  _1 = torch.add(_0, argument_5, alpha=1)\n",
      "  _2 = torch.relu(_1)\n",
      "  _3 = torch.add(torch.matmul(_2, torch.t(argument_6)), argument_7, alpha=1)\n",
      "  _4 = torch.softmax(_3, 1, None)\n",
      "  _5 = torch.mean(torch.mul(argument_1, torch.log(_4)), dtype=None)\n",
      "  _6 = torch.neg(_5)\n",
      "  _7 = ops.prim.NumToTensor(torch.size(argument_1, 1))\n",
      "  _8 = torch.div(torch.sub(_4, argument_1, alpha=1), torch.mul(argument_2, _7))\n",
      "  _9 = torch.matmul(_8, argument_6)\n",
      "  _10 = torch.to(torch.gt(_1, 0), 6, False, False, None)\n",
      "  _11 = torch.mul(_9, _10)\n",
      "  _12 = torch.matmul(torch.t(_11), argument_0)\n",
      "  _13 = torch.sum(_11, [0], False, dtype=None)\n",
      "  _14 = torch.matmul(torch.t(_8), _2)\n",
      "  _15 = torch.sum(_8, [0], False, dtype=None)\n",
      "  _16 = torch.eq(torch.argmax(_4, 1, False), torch.argmax(argument_1, 1, False))\n",
      "  _17 = torch.sum(torch.to(_16, 6, False, False, None), dtype=None)\n",
      "  _18 = torch.add_(argument_4, torch.mul(torch.neg(_12), argument_3), alpha=1)\n",
      "  _19 = torch.add_(argument_5, torch.mul(torch.neg(_13), argument_3), alpha=1)\n",
      "  _20 = torch.add_(argument_6, torch.mul(torch.neg(_14), argument_3), alpha=1)\n",
      "  _21 = torch.add_(argument_7, torch.mul(torch.neg(_15), argument_3), alpha=1)\n",
      "  _22 = (_18, _19, _20, _21, _6, torch.div(_17, argument_2))\n",
      "  return _22\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "X_trace = th.randn(2, 784)\n",
    "y_trace = th.randn(2, 10)\n",
    "lr = th.tensor(0.001)\n",
    "batch_size = th.tensor(32)\n",
    "\n",
    "# jit trace\n",
    "training_plan_torchscript = th.jit.trace(training_plan.__call__, (X_trace, y_trace, batch_size, lr, *model_params))\n",
    "\n",
    "# Let's see\n",
    "print(training_plan_torchscript.code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Serialize!\n",
    "\n",
    "Note that we don't serialize full Model, only weights.\n",
    "State is suitable protobuf class to wrap list of Model params tensors. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Writing Plan to e:\\ml/tp_ops.b64\n",
      "Writing ScriptFunction to e:\\ml/tp_ts.b64\n",
      "Writing State to e:\\ml/model_params.b64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "serializeToBase64Pb(hook.local_worker, training_plan, \"tp_ops.b64\")\n",
    "serializeToBase64Pb(hook.local_worker, training_plan_torchscript, \"tp_ts.b64\")\n",
    "\n",
    "# wrap weights in State to serialize\n",
    "model_params_state = State(\n",
    "    owner=hook.local_worker,\n",
    "    state_placeholders=[PlaceHolder().instantiate(param) for param in model_params]\n",
    ")\n",
    "\n",
    "serializeToBase64Pb(hook.local_worker, model_params_state, \"model_params.b64\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In next notebook, we load and execute this plan."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}