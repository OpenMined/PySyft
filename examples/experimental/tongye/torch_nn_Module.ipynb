{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "from syft.lib.python.collections import OrderedDict\n",
    "import collections\n",
    "from syft.lib.torch.module import ModelExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-26T13:24:40.864048+0800][CRITICAL][logger]][6370] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.1\n",
      "[2021-03-26T13:24:40.864417+0800][CRITICAL][logger]][6370] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.1\n",
      "[2021-03-26T13:24:40.864679+0800][CRITICAL][logger]][6370] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.1\n",
      "[2021-03-26T13:24:40.864942+0800][CRITICAL][logger]][6370] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.1\n",
      "[2021-03-26T13:24:40.865178+0800][CRITICAL][logger]][6370] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.1\n",
      "[2021-03-26T13:24:40.865437+0800][CRITICAL][logger]][6370] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.1\n"
     ]
    }
   ],
   "source": [
    "alice = sy.VirtualMachine()\n",
    "alice_client = alice.get_root_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----fc_ptr----\n",
      "<syft.proxy.torch.nn.LinearPointer object at 0x7f20c3d6c0a0>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f21680f2b50>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[-0.0977, -1.2203]], requires_grad=True)\n",
      "\n",
      "----fc_ptr.get().state_dict()----\n",
      "OrderedDict([('weight', tensor([[-0.0598, -0.3301,  0.2567,  0.4625],\n",
      "        [-0.1558,  0.3708,  0.2388, -0.0500]])), ('bias', tensor([ 0.1444, -0.4406]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('weight', tensor([[-0.0598, -0.3301,  0.2567,  0.4625],\n",
      "        [-0.1558,  0.3708,  0.2388, -0.0500]])), ('bias', tensor([ 0.1444, -0.4406]))])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/github/PySyft/src/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "fc = th.nn.Linear(4,2)\n",
    "\n",
    "# send\n",
    "fc_ptr = fc.send(alice_client)\n",
    "print(f\"----fc_ptr----\\n{fc_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = fc_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(th.nn.Linear(4,2).state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "fc_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----fc_ptr.get().state_dict()----\\n{fc_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----relu_ptr----\n",
      "<syft.proxy.torch.nn.ReLUPointer object at 0x7f20c3e78610>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f21680ed460>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.1456, 0.7297, 0.4326, 0.7943]])\n",
      "\n",
      "----relu_ptr.get()----\n",
      "ReLU(inplace=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "relu = th.nn.ReLU(inplace=True)\n",
    "\n",
    "# send\n",
    "relu_ptr = relu.send(alice_client)\n",
    "print(f\"----relu_ptr----\\n{relu_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = relu_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# get\n",
    "print(f\"----relu_ptr.get()----\\n{relu_ptr.get()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----seq_ptr----\n",
      "<syft.proxy.torch.nn.SequentialPointer object at 0x7f20c3e7f7c0>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f20c3e7f910>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[-0.5462]], requires_grad=True)\n",
      "\n",
      "----seq_ptr.get().state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.4491,  0.2435, -0.2609, -0.1847],\n",
      "        [ 0.2243,  0.3964, -0.3445,  0.3832]])), ('fc1.bias', tensor([-0.2109, -0.1567])), ('fc2.weight', tensor([[-0.2227, -0.6645]])), ('fc2.bias', tensor([-0.2591]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.4491,  0.2435, -0.2609, -0.1847],\n",
      "        [ 0.2243,  0.3964, -0.3445,  0.3832]])), ('fc1.bias', tensor([-0.2109, -0.1567])), ('fc2.weight', tensor([[-0.2227, -0.6645]])), ('fc2.bias', tensor([-0.2591]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sequential\n",
    "seq = th.nn.Sequential()\n",
    "seq.add_module(\"fc1\", th.nn.Linear(4,2))\n",
    "seq.add_module(\"fc2\", th.nn.Linear(2,1))\n",
    "\n",
    "# send\n",
    "seq_ptr = seq.send(alice_client)\n",
    "print(f\"----seq_ptr----\\n{seq_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = seq_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(\n",
    "    th.nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            (\"fc1\", th.nn.Linear(4,2)),\n",
    "            (\"fc2\", th.nn.Linear(2,1))\n",
    "        ])\n",
    "    ).state_dict()\n",
    ")\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "seq_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----seq_ptr.get().state_dict()----\\n{seq_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----executor(m, x)----\n",
      "tensor([[0.5898]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "----m_ptr----\n",
      "<syft.proxy.torch.nn.ModulePointer object at 0x7f20c3e0dac0>\n",
      "\n",
      "----executor(m_ptr, x_ptr)).get()----\n",
      "tensor([[0.5898]], requires_grad=True)\n",
      "\n",
      "----m_ptr.get().state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[-0.3409, -0.2359,  0.0482, -0.4663],\n",
      "        [-0.2913, -0.1367,  0.3507,  0.1707]])), ('fc1.bias', tensor([-0.1072,  0.0722])), ('fc2.weight', tensor([[ 0.0962, -0.4331]])), ('fc2.bias', tensor([0.5019]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[-0.3409, -0.2359,  0.0482, -0.4663],\n",
      "        [-0.2913, -0.1367,  0.3507,  0.1707]])), ('fc1.bias', tensor([-0.1072,  0.0722])), ('fc2.weight', tensor([[ 0.0962, -0.4331]])), ('fc2.bias', tensor([0.5019]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user defined model\n",
    "class M(th.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        self.fc1 = th.nn.Linear(4,2)\n",
    "        self.fc2 = th.nn.Linear(2,1)\n",
    "        \n",
    "    @staticmethod\n",
    "    def forward(model, x):\n",
    "        x = model.fc1(x)\n",
    "        x = model.fc2(x)\n",
    "        return x\n",
    "        \n",
    "m = M()\n",
    "\n",
    "# local call\n",
    "executor = ModelExecutor(m)\n",
    "x = th.rand(1,4)\n",
    "print(f\"----executor(m, x)----\\n{executor(m, x)}\\n\")\n",
    "\n",
    "# send\n",
    "m_ptr = m.send(alice_client)\n",
    "print(f\"----m_ptr----\\n{m_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "x_ptr = x.send(alice_client)\n",
    "print(f\"----executor(m_ptr, x_ptr)).get()----\\n{executor(m_ptr, x_ptr).get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(M().state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "m_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----m_ptr.get().state_dict()----\\n{m_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
