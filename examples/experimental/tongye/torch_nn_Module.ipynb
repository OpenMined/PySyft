{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "from syft.lib.python.collections import OrderedDict\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-15T14:42:38.295348+0800][CRITICAL][logger]][1001] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.1\n",
      "[2021-04-15T14:42:38.296090+0800][CRITICAL][logger]][1001] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.1\n",
      "[2021-04-15T14:42:38.297014+0800][CRITICAL][logger]][1001] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.1\n",
      "[2021-04-15T14:42:38.297641+0800][CRITICAL][logger]][1001] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.1\n",
      "[2021-04-15T14:42:38.298456+0800][CRITICAL][logger]][1001] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.1\n",
      "[2021-04-15T14:42:38.299100+0800][CRITICAL][logger]][1001] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.1\n"
     ]
    }
   ],
   "source": [
    "alice = sy.VirtualMachine()\n",
    "alice_client = alice.get_root_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----fc_ptr----\n",
      "<syft.proxy.torch.nn.LinearPointer object at 0x7f7e619d2a30>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f7e6194e7f0>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.3768, 0.2239]], requires_grad=True)\n",
      "\n",
      "----fc_ptr.get().state_dict()----\n",
      "OrderedDict([('weight', tensor([[-0.1867, -0.1446,  0.3949, -0.4263],\n",
      "        [-0.3738, -0.0338,  0.4329, -0.0855]])), ('bias', tensor([-0.3970, -0.4864]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('weight', tensor([[-0.1867, -0.1446,  0.3949, -0.4263],\n",
      "        [-0.3738, -0.0338,  0.4329, -0.0855]])), ('bias', tensor([-0.3970, -0.4864]))])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/github/PySyft/src/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "fc = th.nn.Linear(4,2)\n",
    "\n",
    "# send\n",
    "fc_ptr = fc.send(alice_client)\n",
    "print(f\"----fc_ptr----\\n{fc_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = fc_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(th.nn.Linear(4,2).state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "fc_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----fc_ptr.get().state_dict()----\\n{fc_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----relu_ptr----\n",
      "<syft.proxy.torch.nn.ReLUPointer object at 0x7f7e619d2250>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f7e618a14f0>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.1065, 0.2725, 0.9136, 0.3703]])\n",
      "\n",
      "----relu_ptr.get()----\n",
      "ReLU(inplace=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "relu = th.nn.ReLU(inplace=True)\n",
    "\n",
    "# send\n",
    "relu_ptr = relu.send(alice_client)\n",
    "print(f\"----relu_ptr----\\n{relu_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = relu_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# get\n",
    "print(f\"----relu_ptr.get()----\\n{relu_ptr.get()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----seq_ptr----\n",
      "<syft.proxy.torch.nn.SequentialPointer object at 0x7f7f014f2370>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f7e6194e7f0>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.2109]], requires_grad=True)\n",
      "\n",
      "----seq_ptr.get().state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.0035,  0.4069, -0.4324, -0.4882],\n",
      "        [ 0.3855,  0.1846,  0.3832,  0.2659]])), ('fc1.bias', tensor([-0.4026,  0.4498])), ('fc2.weight', tensor([[-0.1285,  0.3856]])), ('fc2.bias', tensor([0.2325]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.0035,  0.4069, -0.4324, -0.4882],\n",
      "        [ 0.3855,  0.1846,  0.3832,  0.2659]])), ('fc1.bias', tensor([-0.4026,  0.4498])), ('fc2.weight', tensor([[-0.1285,  0.3856]])), ('fc2.bias', tensor([0.2325]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sequential\n",
    "seq = th.nn.Sequential()\n",
    "seq.add_module(\"fc1\", th.nn.Linear(4,2))\n",
    "seq.add_module(\"fc2\", th.nn.Linear(2,1))\n",
    "\n",
    "# send\n",
    "seq_ptr = seq.send(alice_client)\n",
    "print(f\"----seq_ptr----\\n{seq_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = seq_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(\n",
    "    th.nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            (\"fc1\", th.nn.Linear(4,2)),\n",
    "            (\"fc2\", th.nn.Linear(2,1))\n",
    "        ])\n",
    "    ).state_dict()\n",
    ")\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "seq_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----seq_ptr.get().state_dict()----\\n{seq_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-15T14:42:38.459331+0800][CRITICAL][logger]][1001] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: 09d2b078e1fa4788a2211e3d29f2bf6b>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----m(m)----\n",
      "tensor([[-0.1710]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "----m_ptr----\n",
      "<syft.proxy.torch.nn.ModulePointer object at 0x7f7e61a5ce20>\n",
      "\n",
      "----m_ptr(x=x_ptr)).get()----\n",
      "tensor([[-0.1710]], requires_grad=True)\n",
      "\n",
      "----m_get.state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.3132, -0.3550, -0.4005, -0.0776],\n",
      "        [ 0.3409,  0.0481, -0.2663, -0.3465]])), ('fc1.bias', tensor([-0.3148,  0.3046])), ('fc2.weight', tensor([[-0.6934, -0.4875]])), ('fc2.bias', tensor([-0.2427]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.3132, -0.3550, -0.4005, -0.0776],\n",
      "        [ 0.3409,  0.0481, -0.2663, -0.3465]])), ('fc1.bias', tensor([-0.3148,  0.3046])), ('fc2.weight', tensor([[-0.6934, -0.4875]])), ('fc2.bias', tensor([-0.2427]))])\n",
      "\n",
      "----type(m_get)----\n",
      "<class '__main__.M'>\n"
     ]
    }
   ],
   "source": [
    "# user defined model\n",
    "class M(th.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        self.fc1 = th.nn.Linear(4,2)\n",
    "        self.fc2 = th.nn.Linear(2,1)\n",
    "\n",
    "    def forward(model, x=th.rand(4), th=th):\n",
    "        x = model.fc1(x)\n",
    "        x = model.fc2(x)\n",
    "        return x\n",
    "        \n",
    "m = M()\n",
    "\n",
    "# local call\n",
    "x = th.rand(1,4)\n",
    "print(f\"----m(m)----\\n{m(x)}\\n\")\n",
    "\n",
    "# send\n",
    "m_ptr = m.send(alice_client)\n",
    "print(f\"----m_ptr----\\n{m_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "x_ptr = x.send(alice_client)\n",
    "print(f\"----m_ptr(x=x_ptr)).get()----\\n{m_ptr(x=x_ptr).get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(M().state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "m_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "m_get = m_ptr.get()\n",
    "print(f\"----m_get.state_dict()----\\n{m_get.state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")\n",
    "print(f\"----type(m_get)----\\n{type(m_get)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
