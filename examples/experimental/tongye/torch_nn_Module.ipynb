{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "from syft.lib.python.collections import OrderedDict\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-25T12:32:07.142311+0800][CRITICAL][logger]][2012] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.1\n",
      "[2021-03-25T12:32:07.142690+0800][CRITICAL][logger]][2012] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.1\n",
      "[2021-03-25T12:32:07.142919+0800][CRITICAL][logger]][2012] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.1\n",
      "[2021-03-25T12:32:07.143149+0800][CRITICAL][logger]][2012] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.1\n",
      "[2021-03-25T12:32:07.143352+0800][CRITICAL][logger]][2012] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.1\n",
      "[2021-03-25T12:32:07.143586+0800][CRITICAL][logger]][2012] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.1\n"
     ]
    }
   ],
   "source": [
    "alice = sy.VirtualMachine()\n",
    "alice_client = alice.get_root_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----fc_ptr----\n",
      "<syft.proxy.torch.nn.LinearPointer object at 0x7f497d470eb0>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f497d2d7430>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[-0.2959, -0.1966]], requires_grad=True)\n",
      "\n",
      "----fc_ptr.get().state_dict()----\n",
      "OrderedDict([('weight', tensor([[-0.3971,  0.1255,  0.4036, -0.4374],\n",
      "        [-0.4251, -0.1996,  0.0949,  0.4059]])), ('bias', tensor([ 0.3382, -0.2079]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('weight', tensor([[-0.3971,  0.1255,  0.4036, -0.4374],\n",
      "        [-0.4251, -0.1996,  0.0949,  0.4059]])), ('bias', tensor([ 0.3382, -0.2079]))])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/github/PySyft/src/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "fc = th.nn.Linear(4,2)\n",
    "\n",
    "# send\n",
    "fc_ptr = fc.send(alice_client)\n",
    "print(f\"----fc_ptr----\\n{fc_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = fc_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(th.nn.Linear(4,2).state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "fc_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----fc_ptr.get().state_dict()----\\n{fc_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-25T12:32:07.222155+0800][CRITICAL][logger]][2012] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: 7429e149c60b4e2bb82cc4644fafa290>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----relu_ptr----\n",
      "<syft.proxy.torch.nn.ReLUPointer object at 0x7f497d4707f0>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f497d470b80>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.4721, 0.4538, 0.9168, 0.7360]])\n",
      "\n",
      "----relu_ptr.get()----\n",
      "ReLU(inplace=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "relu = th.nn.ReLU(inplace=True)\n",
    "\n",
    "# send\n",
    "relu_ptr = relu.send(alice_client)\n",
    "print(f\"----relu_ptr----\\n{relu_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = relu_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# get\n",
    "print(f\"----relu_ptr.get()----\\n{relu_ptr.get()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-25T12:32:07.247627+0800][CRITICAL][logger]][2012] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: 1fe0147a02d24e42813e80025dcbb63b>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----seq_ptr----\n",
      "<syft.proxy.torch.nn.SequentialPointer object at 0x7f497d2e2a60>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f497d2e2c10>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[-0.3808]], requires_grad=True)\n",
      "\n",
      "----seq_ptr.get().state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.3297, -0.4574,  0.2042, -0.1967],\n",
      "        [ 0.1805, -0.1045, -0.4810, -0.2268]])), ('fc1.bias', tensor([ 0.2125, -0.1886])), ('fc2.weight', tensor([[ 0.2118, -0.0745]])), ('fc2.bias', tensor([-0.3214]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.3297, -0.4574,  0.2042, -0.1967],\n",
      "        [ 0.1805, -0.1045, -0.4810, -0.2268]])), ('fc1.bias', tensor([ 0.2125, -0.1886])), ('fc2.weight', tensor([[ 0.2118, -0.0745]])), ('fc2.bias', tensor([-0.3214]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sequential\n",
    "seq = th.nn.Sequential()\n",
    "seq.add_module(\"fc1\", th.nn.Linear(4,2))\n",
    "seq.add_module(\"fc2\", th.nn.Linear(2,1))\n",
    "\n",
    "# send\n",
    "seq_ptr = seq.send(alice_client)\n",
    "print(f\"----seq_ptr----\\n{seq_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = seq_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(\n",
    "    th.nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            (\"fc1\", th.nn.Linear(4,2)),\n",
    "            (\"fc2\", th.nn.Linear(2,1))\n",
    "        ])\n",
    "    ).state_dict()\n",
    ")\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "seq_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----seq_ptr.get().state_dict()----\\n{seq_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----m_ptr----\n",
      "<syft.proxy.torch.nn.ModulePointer object at 0x7f497d470400>\n",
      "\n",
      "----m_ptr.get().state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[-0.2391, -0.1312, -0.1402,  0.1597],\n",
      "        [-0.4168,  0.0742, -0.0980, -0.2954]])), ('fc1.bias', tensor([ 0.4642, -0.0963])), ('fc2.weight', tensor([[-0.2088, -0.0624]])), ('fc2.bias', tensor([-0.4275]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[-0.2391, -0.1312, -0.1402,  0.1597],\n",
      "        [-0.4168,  0.0742, -0.0980, -0.2954]])), ('fc1.bias', tensor([ 0.4642, -0.0963])), ('fc2.weight', tensor([[-0.2088, -0.0624]])), ('fc2.bias', tensor([-0.4275]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user defined model\n",
    "class M(th.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        self.fc1 = th.nn.Linear(4,2)\n",
    "        self.fc2 = th.nn.Linear(2,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "m = M()\n",
    "\n",
    "# send\n",
    "m_ptr = m.send(alice_client)\n",
    "print(f\"----m_ptr----\\n{m_ptr}\\n\")\n",
    "\n",
    "# TODO: remote call\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(M().state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "m_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----m_ptr.get().state_dict()----\\n{m_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
