{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrypTen - Private Model Inference using Plans\n",
    "\n",
    "\n",
    "We will do a simple inference on an encrypted neural network that is not known by the local worker.\n",
    "The workers that known the model structure are deployed as [GridNodes](https://github.com/OpenMined/PyGridNode). For this we will be using Plans and we will be using CrypTen as a backend for SMPC. \n",
    "\n",
    "\n",
    "Authors:\n",
    " - George Muraru - Twitter: [@gmuraru](https://twitter.com/georgemuraru)\n",
    " - Ayoub Benaissa - Twitter: [@y0uben11](https://twitter.com/y0uben11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Download/install needed repos\n",
    "* Install PySyft from the [`crypten` branch](https://github.com/OpenMined/PySyft/tree/crypten).\n",
    "* Clone the [GridNode repository](https://github.com/OpenMined/GridNode)\n",
    "  * we need this because *alice* and *bob* are two different GridNodes\n",
    "\n",
    "### Run the grid nodes\n",
    "* In two separate terminals run:\n",
    "    * ```python -m gridnode --id alice --port 3000```\n",
    "    * ```python -m gridnode --id bob --port 30001```\n",
    "    \n",
    "This will start two workers, *alice* and *bob* and we will connect to them using the port 3000 and 30001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import crypten\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "\n",
    "import syft as sy\n",
    "\n",
    "from syft.workers.node_client import NodeClient\n",
    "from syft.frameworks.crypten.context import run_multiworkers\n",
    "\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network that will be known only to the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExampleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 100)\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 16 * 12 * 12)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the workers and send them the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have the two GridNodes workers running.\n",
    "\n",
    "In our current scenario we are sending the serialized model to the workers that are taking part in the computation, but in a real life situation this sending part should not exist - we only need to know that we have the same model on all the workers.\n",
    "\n",
    "### Scenario\n",
    "* The local worker wants to run inference on the data that is hosted on *alice* machine.\n",
    "* The model is known only by *alice* and *bob*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syft workers\n",
    "print(\"[%] Connecting to workers...\")\n",
    "ALICE = NodeClient(hook, \"ws://localhost:3000\")\n",
    "BOB = NodeClient(hook, \"ws://localhost:3001\")\n",
    "print(\"[+] Connected to workers\")\n",
    "\n",
    "print(\"[%] Create the serialized model object...\")\n",
    "dummy_input = th.empty(1, 1, 28, 28)\n",
    "pytorch_model = ExampleNet(\n",
    "model = OnnxModel.fromModel(pytorch_model, dummy_input).tag(\"crypten_model\")\n",
    "print(\"[+] Serialized model created\")\n",
    "    \n",
    "print(\"[%] Sending the serialized model...\")\n",
    "alice_model_ptr = model.send(alice)\n",
    "bob_model_ptr = model.send(bob)\n",
    "print(\"[+] Model sent to alice and bob\")\n",
    "    \n",
    "print(\"[%] Create some dummy data and send it to alice...\")\n",
    "data = th.tensor(dummy_input).tag(\"crypten_data\")\n",
    "data_ptr_alice = data.send(alice)\n",
    "print(\"[+] Data sent to alice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the CrypTen computation\n",
    "\n",
    "We need to specify for the ```run_multiworkers``` decorater:\n",
    "* the workers that will take part in the computation\n",
    "* the master address, this will be used for communication\n",
    "\n",
    "We will use the ```func2plan``` decorator to:\n",
    "* trace the operations from our function\n",
    "* sending the plan operations to *alice* and *bob* - the plans operations will act as the function\n",
    "* run the plans operations on both workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@run_multiworkers(\n",
    "    [ALICE, BOB], master_addr=\"127.0.0.1\"\n",
    ")\n",
    "@sy.func2plan()\n",
    "def run_encrypted_inference(crypten=crypten):\n",
    "    data = crypten.load(\"crypten_data\", 0)\n",
    "\n",
    "    # This should load the crypten model that is found at all parties\n",
    "    model = crypten.load_model(\"crypten_model\")\n",
    "\n",
    "    model.encrypt()\n",
    "    out = model(data)\n",
    "    model.decrypt()\n",
    "    out = out.get_plain_text()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the CrypTen computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the returned values\n",
    "# key 0 - return values for alice\n",
    "# key 1 - return values for bob\n",
    "print(\"[%] Starting computation\")\n",
    "func_ts = time()\n",
    "result = run_encryptend_inference()[0]\n",
    "func_te = time()\n",
    "print(f\"[+] run_encrypted_inference() took {int(func_te - func_ts)}s\")\n",
    "\n",
    "print(f\"The label for data is {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22Good+first+issue+%3Amortar_board%3A%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
