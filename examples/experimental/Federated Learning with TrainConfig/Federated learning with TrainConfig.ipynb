{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Federated learning with TrainConfig\n",
    "\n",
    "This notebook will go through the steps to run a federated learning via websocket workers. We will use federated averaging to join the remotely trained models. \n",
    "\n",
    "Authors:\n",
    "- [mari-linhares](https://github.com/mari-linhares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: start the websocket server workers\n",
    "\n",
    "Each worker is represented by two parts, a local handle (websocket client worker) and the remote instance that holds the data and performs the computations. The remote part is called a websocket server worker.\n",
    "\n",
    "So first, we need to create the remote workers. For this, you need to run in a terminal (not possible from the notebook):\n",
    "\n",
    "```bash\n",
    "python examples/experimental/Federated\\ Learning\\ with\\ TrainConfig/run_websocket_server.py --port 8777 --id alice\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the websocket client workers (all these cells are from the FL websocket tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to perform the imports and setup some arguments and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import syft as sy\n",
    "from syft.workers import WebsocketClientWorker\n",
    "from syft.frameworks.torch.federated import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_cuda = th.cuda.is_available()\n",
    "th.manual_seed(1)\n",
    "device = th.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's instantiate the websocket client workers, our local access point to the remote workers.\n",
    "Note that **this step will fail, if the websocket server workers are not running**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(th)\n",
    "\n",
    "kwargs_websocket = {\"host\": \"localhost\", \"hook\": hook, \"verbose\": False}\n",
    "alice = WebsocketClientWorker(id=\"alice\", port=8777, **kwargs_websocket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Star is (almost) born: TrainConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 0: alice's loss: tensor(0.0483, requires_grad=True)\n",
      "--------------------------------------------------\n",
      "Iteration 1: alice's loss: tensor(0.0483, requires_grad=True)\n",
      "--------------------------------------------------\n",
      "Iteration 2: alice's loss: tensor(0.0483, requires_grad=True)\n",
      "--------------------------------------------------\n",
      "Iteration 3: alice's loss: tensor(0.0483, requires_grad=True)\n",
      "--------------------------------------------------\n",
      "Iteration 4: alice's loss: tensor(0.0483, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# TODO: maybe by default is_client_worker could be False?\n",
    "# for plans the client_worker needs to be able to register tensors\n",
    "# since it needs to build the plan.\n",
    "hook.local_worker.is_client_worker = False\n",
    "me = hook.local_worker\n",
    "\n",
    "# Loss function\n",
    "@sy.func2plan\n",
    "def loss_fn(real, pred):\n",
    "    return ((real - pred) ** 2).mean()\n",
    "\n",
    "# Model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)\n",
    "        self.fc2 = nn.Linear(3, 2)\n",
    "        self.fc3 = nn.Linear(2, 1)\n",
    "\n",
    "    @sy.method2plan\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Force build\n",
    "# TODO: this should be done automatically\n",
    "loss_fn(th.tensor([1.0]), th.tensor([1.0]))\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# TODO: this line should not be needed at all.\n",
    "model.send(me)\n",
    "\n",
    "# Force build\n",
    "# TODO: this should be done automatically\n",
    "model(th.tensor([1.0, 2]))\n",
    "\n",
    "\n",
    "# TODO: this line should not be needed at all.\n",
    "model.get()\n",
    "\n",
    "# Create and send train config\n",
    "train_config = sy.TrainConfig(model=model, loss_plan=loss_fn, batch_size=1)\n",
    "train_config.send(alice)\n",
    "\n",
    "# TODO: Returns a tensor when it should actually return a Pointer to the result Tensor.\n",
    "for epoch in range(5):\n",
    "    loss = alice.fit(dataset_key=\"vectors\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Iteration %s: alice's loss: %s\" % (epoch, loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
