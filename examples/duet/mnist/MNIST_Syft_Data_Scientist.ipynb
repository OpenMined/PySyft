{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Syft Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "sy.LOG_FILE = \"syft_ds.log\"\n",
    "_ = sy.logger.add(sy.LOG_FILE, enqueue=True, colorize=False, diagnose=True, backtrace=True, level=\"TRACE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the data scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server (in their Notebook).\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Let's run the code below and follow the instructions it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duet = sy.join_duet(network_url=\"http://localhost:5000\")\n",
    "duet = sy.join_duet(network_url=\"http://localhost:5000\", loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Launch a Duet Server and Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = duet.syft.lib.python.Int(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sy.logger.critical(\"Start requesting\")\n",
    "if len(duet.store) > 0:\n",
    "    t = duet.store[0].get(\n",
    "        request_block=True,\n",
    "        timeout_secs=15,\n",
    "        request_name=\"age_data\",\n",
    "        reason=\"I want to see the age data\",\n",
    "        delete_obj=False\n",
    "    )\n",
    "    sy.logger.critical(\"Finished requesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some references to our data owners Duet torch and torchvision\n",
    "torch = duet.torch\n",
    "torchvision = duet.torchvision\n",
    "\n",
    "# these are the same as the original mnist example\n",
    "transforms = torchvision.transforms\n",
    "datasets = torchvision.datasets\n",
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "optim = torch.optim\n",
    "StepLR = torch.optim.lr_scheduler.StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "local_transform_1 = tv.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = tv.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = tv.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings from original MNIST example command line args\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 14,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "# this is our carefully curated test data which represents the goal of our problem domain\n",
    "test_data = tv.datasets.MNIST('../data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = th.utils.data.DataLoader(test_data,**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)\n",
    "\n",
    "# test_data_length_ptr = duet.syft.lib.python.Int(test_data_length)\n",
    "# print(test_data_length_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data, type(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"duet\" variable is now your reference to a whole world of remote operations including supported libraries like torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO replace with local inference so this doesn't need to be on the DO side\n",
    "# test_data_ptr = torchvision.datasets.MNIST('../data', train=False, download=True, transform=transforms)\n",
    "# print(test_data_ptr)\n",
    "\n",
    "# test_loader_ptr = torch.utils.data.DataLoader(test_data_ptr,**test_kwargs)\n",
    "# print(test_loader_ptr)\n",
    "# # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 32, 3, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32, 64, 3, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     nn.Dropout2d(0.25),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(9216, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout2d(0.5),\n",
    "#     nn.Linear(128, 10),\n",
    "#     nn.LogSoftmax(dim=1),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net:\n",
    "#     modules = []\n",
    "#     training = False\n",
    "\n",
    "#     def __init__(self) -> None:\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(9216, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#         # add to modules list\n",
    "#         self.modules.append(self.conv1)\n",
    "#         self.modules.append(self.conv2)\n",
    "#         self.modules.append(self.dropout1)\n",
    "#         self.modules.append(self.dropout2)\n",
    "#         self.modules.append(self.fc1)\n",
    "#         self.modules.append(self.fc2)\n",
    "\n",
    "#     def train(self, mode: bool = True):\n",
    "#         self.training = mode\n",
    "#         for module in self.modules:\n",
    "#             module.train(mode)\n",
    "#         return self\n",
    "\n",
    "#     def eval(self):\n",
    "#         return self.train(False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "\n",
    "#     def __call__(self, input):\n",
    "#         return self.forward(input)\n",
    "\n",
    "#     # local list of remote ListPointers of TensorPointers\n",
    "#     def parameters(self, recurse: bool = True):\n",
    "#         params_list = duet.syft.lib.python.List()\n",
    "#         for module in self.modules:\n",
    "#             param_pointers = module.parameters()\n",
    "#             params_list += param_pointers\n",
    "\n",
    "#         return params_list\n",
    "\n",
    "#     def cuda(self, device) -> \"Net\":\n",
    "#         for module in self.modules:\n",
    "#             module.cuda(device)\n",
    "#         return self\n",
    "\n",
    "#     def cpu(self) -> \"Net\":\n",
    "#         for module in self.modules:\n",
    "#             module.cpu()\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define our SOTA model to train on the data owners data\n",
    "# note we subclass from sy.Module not nn.Module\n",
    "fc1_scaling_factor = 0.25  # this can let us scale the fc1 layer down a bit\n",
    "class SyNet(sy.Module):\n",
    "    def __init__(self):\n",
    "        super(SyNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, int(64 * fc1_scaling_factor), 3, 1)  # keep fc1 size down\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(int(9216 * fc1_scaling_factor), 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets define our SOTA model to train on the data owners data\n",
    "# note we subclass from sy.Module not nn.Module\n",
    "# WARNING: be extra careful to use th. not the torch from duet here\n",
    "class LocalSyNet(sy.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalSyNet, self).__init__()\n",
    "        self.conv1 = th.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = th.nn.Conv2d(32, int(64 * fc1_scaling_factor), 3, 1)\n",
    "        self.dropout1 = th.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = th.nn.Dropout2d(0.5)\n",
    "        self.fc1 = th.nn.Linear(int(9216 * fc1_scaling_factor), 128)\n",
    "        self.fc2 = th.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "        x = th.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = th.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = th.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SmallSyNet(sy.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SmallSyNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(784, 392)\n",
    "#         self.fc2 = nn.Linear(392, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LocalSmallSyNet(sy.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LocalSmallSyNet, self).__init__()\n",
    "#         self.fc1 = th.nn.Linear(784, 392)\n",
    "#         self.fc2 = th.nn.Linear(392, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = th.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = th.nn.functional.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = torch.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    request_name=\"cuda_is_available\",\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=30,  # change to something slower\n",
    "))\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"DO device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our model\n",
    "# this will construct everything inside init on the DO side\n",
    "# model = Net()\n",
    "model = SyNet()\n",
    "# model = seq_model\n",
    "# model = SmallSyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.modules))\n",
    "print(model.modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = LocalSyNet()\n",
    "# local_model = LocalSmallSyNet()\n",
    "local_model.zero_layers()  # so we can confirm that the weight download works\n",
    "local_model.sum_layers()\n",
    "print(local_model.modules)\n",
    "# assert local_model.fc1.in_features == int(9216 * fc1_scaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model.copy_remote_state(\n",
    "    remote_model=model,\n",
    "    request_name=\"model_download\",\n",
    "    reason=\"test evaluation\",\n",
    "    timeout_secs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")\n",
    "local_model.sum_layers()\n",
    "# %%time\n",
    "# skip_layers = []\n",
    "# # warning fc1 is 9216x128 and stalls on copy, even a tensor size 9216x96 takes 45 seconds\n",
    "# # skip_layers.append(\"fc1\") # fc1 is too big???\n",
    "# # warning fc1 at 4608x128 takes about 25 seconds\n",
    "# local_model.copy_remote_state(remote_model=model, skip_layers=skip_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the weights were copied\n",
    "# local_model.sum_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get our parameters for optimization\n",
    "# params_list required for remote list concatenation\n",
    "params = model.parameters(params_list=duet.syft.lib.python.List())\n",
    "print(params, type(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(params, lr=args[\"lr\"])\n",
    "print(optimizer, type(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])\n",
    "print(scheduler, type(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can define a simple training loop very similar to the original PyTorch MNIST example\n",
    "@sy.logger.catch\n",
    "def train(args, model, device, train_loader, optimizer, epoch, train_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    #train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    train_batches = 100\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "#         time.sleep(1)\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = F.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.syft.lib.python.Float(0)\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = loss_item.get(\n",
    "                request_name=\"loss\",\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=30\n",
    "            )\n",
    "            # local_loss = None\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO replace with local inference and local test set\n",
    "# # the same for our test training loop except we will need to send our data over for inference\n",
    "# def test(model, device, test_loader, test_data_length):\n",
    "#     # + 0.5 lets us math.ceil without the import\n",
    "#     test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "#     print(f\"> Running test in {test_batches} batches\")\n",
    "#     model.eval()\n",
    "#     test_loss = duet.syft.lib.python.Float(0)\n",
    "#     correct_ptr = duet.syft.lib.python.Float(0)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, data in enumerate(test_loader):\n",
    "#             data_ptr, target_ptr = data[0], data[1]\n",
    "#             output = model(data_ptr)\n",
    "#             loss = F.nll_loss(output, target_ptr, reduction='sum').item()\n",
    "#             test_loss = test_loss + loss\n",
    "\n",
    "#             pred = output.argmax(dim=1)\n",
    "#             total = pred.eq(target_ptr).sum().item()\n",
    "#             correct_ptr += total\n",
    "\n",
    "#             if args[\"dry_run\"]:\n",
    "#                 break\n",
    "                \n",
    "#             if batch_idx >= test_batches - 1:\n",
    "#                 print(\"batch_idx >= test_batches, breaking\")\n",
    "#                 break\n",
    "\n",
    "#     accuracy = correct_ptr / test_data_length\n",
    "#     # we need to batch or block these requests so the loop doesnt break\n",
    "#     result = None\n",
    "# #     result = accuracy.get(\n",
    "# #         request_block=True,\n",
    "# #         timeout_secs=0,\n",
    "# #         request_name=\"accuracy\",\n",
    "# #         reason=\"To see the accuracy on DO's test set\"\n",
    "# #     )\n",
    "#     if result is not None:\n",
    "#         print(\"Test Set Average Loss:\", 100 * result)\n",
    "#     else:\n",
    "#         print(\"Test Set Average Loss: ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace with local inference and local test set\n",
    "# the same for our test training loop except we will need to send our data over for inference\n",
    "@sy.logger.catch\n",
    "def test_local(model, remote_model, test_loader, test_data_length):\n",
    "    # download remote model\n",
    "    model.copy_remote_state(\n",
    "        remote_model=remote_model,\n",
    "        request_name=\"model_download\",\n",
    "        reason=\"test evaluation\",\n",
    "        timeout_secs=30\n",
    "    )\n",
    "    # visually check the weights have changed\n",
    "    model.sum_layers()\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#             time.sleep(1)\n",
    "            output = model(data)\n",
    "            iter_loss = th.nn.functional.nll_loss(output, target, reduction='sum').item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(\"Test Set Average Loss:\", 100 * accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "print(type(transform_1), type(transform_2))\n",
    "\n",
    "remote_list = duet.syft.lib.python.List()\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = torchvision.datasets.MNIST('../data', train=True, download=True, transform=transforms)\n",
    "print(train_data_ptr)\n",
    "train_loader_ptr = torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\n",
    "print(train_loader_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_length(train_data_ptr):\n",
    "    train_length_ptr = train_data_ptr.__len__()\n",
    "    train_data_length = train_length_ptr.get(\n",
    "        request_block=True,\n",
    "        request_name=\"train_size\",\n",
    "        reason=\"To write the training loop\",\n",
    "        timeout_secs=30,\n",
    "    )\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "# sequential CPU times: user 39.2 s, sys: 390 ms, total: 39.6s per epoch\n",
    "# sy.module CPU times: user 1min 28s, sys: 645 ms, total: 1min 28s per epoch\n",
    "# vanilla class CPU times: user 3min 5s, sys: 3.01 s, total: 3min 8s per epoch\n",
    "\n",
    "args[\"dry_run\"] = False\n",
    "sy.logger.trace(\"Start Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train(args, model, device, train_loader_ptr, optimizer, epoch, train_data_length)\n",
    "    #test(model, device, test_loader_ptr, test_data_length_ptr)\n",
    "    test_local(local_model, model, test_loader, test_data_length)  # real local data and model\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    break\n",
    "sy.logger.trace(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(image):\n",
    "    image_tensor = th.Tensor(prep_for_inference(image))\n",
    "    print(\"1\", type(image_tensor))\n",
    "    output = local_model(image_tensor)\n",
    "    print(\"2\", type(output))\n",
    "    preds = th.exp(output)\n",
    "    print(\"3\", type(preds))\n",
    "    local_y = preds\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = th.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image):\n",
    "    image_tensor_ptr = torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor_ptr)\n",
    "    preds = torch.exp(output)\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        request_name=\"inference\",\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, th.Tensor([-1])\n",
    "    else:\n",
    "        local_y = th.Tensor(preds_result)\n",
    "        local_y = local_y.squeeze()\n",
    "        pos = local_y == max(local_y)\n",
    "        index = th.nonzero(pos, as_tuple=False)\n",
    "        class_num = index.squeeze()\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab something from the test set\n",
    "import random\n",
    "total_images = test_data_length # 10000\n",
    "index = random.randint(0, total_images)\n",
    "print(\"Random Test Image:\", index)\n",
    "count = 0\n",
    "batch = index // test_kwargs[\"batch_size\"]\n",
    "batch_index = index % int(total_images / len(test_loader))\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if batch == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(f\"Displaying {index} == {batch_index} in Batch: {batch}/{len(test_loader)}\")\n",
    "image_1 = data[batch_index].reshape((28, 28))\n",
    "label_1 = target[batch_index]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classify remote\n",
    "# sy.logger.trace(\"Before running classify\")\n",
    "# class_num, preds = classify(image_1)\n",
    "# print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify local\n",
    "sy.logger.trace(\"Before running classify\")\n",
    "class_num, preds = classify_local(image_1)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error with recv_immediate_msg_with_reply. 'generator' object has no attribute 'serialize'\n",
    "# remote_model_params_ptr = model.parameters()\n",
    "# remote_model_params = remote_model_params_ptr.get(\n",
    "#     request_block=True,\n",
    "#     request_name=\"copy_model\",\n",
    "#     reason=\"To run test and inference locally\",\n",
    "#     timeout_secs=10,\n",
    "#     delete_obj=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(remote_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
