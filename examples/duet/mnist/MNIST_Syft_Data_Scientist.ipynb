{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Syft Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "sy.LOG_FILE = \"syft_ds.log\"\n",
    "_ = sy.logger.add(sy.LOG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the data scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server (in their Notebook).\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Let's run the code below and follow the instructions it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Launch a Duet Server and Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some references to our data owners Duet torch and torchvision\n",
    "torch = duet.torch\n",
    "torchvision = duet.torchvision\n",
    "\n",
    "# these are the same as the original mnist example\n",
    "transforms = torchvision.transforms\n",
    "datasets = torchvision.datasets\n",
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "optim = torch.optim\n",
    "StepLR = torch.optim.lr_scheduler.StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has_cuda_ptr = torch.cuda.is_available()\n",
    "# try:\n",
    "#     has_cuda = has_cuda_ptr.get(\n",
    "#         request_block=True,\n",
    "#         request_name=\"cuda.is_available()\",\n",
    "#         reason=\"If you have CUDA I will enable it to speed up training.\"\n",
    "#     )\n",
    "#     print(f\"DO has CUDA: {has_cuda}\")\n",
    "# except Exception as e:\n",
    "#     print(\"No permission, try requesting again.\")\n",
    "    \n",
    "# print(\"Result of Blocking Request\", has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "local_transform_1 = tv.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = tv.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = tv.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings from original MNIST example command line args\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 14,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "# this is our carefully curated test data which represents the goal of our problem domain\n",
    "test_data = tv.datasets.MNIST('../data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = th.utils.data.DataLoader(test_data,**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)\n",
    "\n",
    "test_data_length_ptr = duet.syft.lib.python.Int(test_data_length)\n",
    "print(test_data_length_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data, type(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"duet\" variable is now your reference to a whole world of remote operations including supported libraries like torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "print(type(transform_1), type(transform_2))\n",
    "\n",
    "remote_list = duet.syft.lib.python.List()\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = torchvision.transforms.Compose(remote_list)\n",
    "print(type(transforms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace with local inference so this doesn't need to be on the DO side\n",
    "test_data_ptr = torchvision.datasets.MNIST('../data', train=False, download=True, transform=transforms)\n",
    "print(test_data_ptr)\n",
    "\n",
    "test_loader_ptr = torch.utils.data.DataLoader(test_data_ptr,**test_kwargs)\n",
    "print(test_loader_ptr)\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 32, 3, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32, 64, 3, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     nn.Dropout2d(0.25),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(9216, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout2d(0.5),\n",
    "#     nn.Linear(128, 10),\n",
    "#     nn.Softmax(),\n",
    "#     #nn.LogSoftmax(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    modules = []\n",
    "    training = False\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        # add to modules list\n",
    "        self.modules.append(self.conv1)\n",
    "        self.modules.append(self.conv2)\n",
    "        self.modules.append(self.dropout1)\n",
    "        self.modules.append(self.dropout2)\n",
    "        self.modules.append(self.fc1)\n",
    "        self.modules.append(self.fc2)\n",
    "\n",
    "    def train(self, mode: bool = True):\n",
    "        self.training = mode\n",
    "        for module in self.modules:\n",
    "            module.train(mode)\n",
    "        return self\n",
    "\n",
    "    def eval(self):\n",
    "        return self.train(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "    def __call__(self, input):\n",
    "        return self.forward(input)\n",
    "\n",
    "    # local list of remote ListPointers of TensorPointers\n",
    "    def parameters(self, recurse: bool = True):\n",
    "        params_list = duet.syft.lib.python.List()\n",
    "        for module in self.modules:\n",
    "            param_pointers = module.parameters()\n",
    "            params_list += param_pointers\n",
    "\n",
    "        return params_list\n",
    "\n",
    "    def cuda(self, device) -> \"Net\":\n",
    "        for module in self.modules:\n",
    "            module.cuda(device)\n",
    "        return self\n",
    "\n",
    "    def cpu(self) -> \"Net\":\n",
    "        for module in self.modules:\n",
    "            module.cpu()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets define our SOTA model to train on the data owners data\n",
    "# # note we subclass from sy.Module not nn.Module\n",
    "# class SyNet(sy.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SyNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(9216, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "# has_cuda_ptr = torch.cuda.is_available()\n",
    "# has_cuda = bool(has_cuda_ptr.get(request_block=True))\n",
    "# print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"DO device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our model\n",
    "# this will construct everything inside init on the DO side\n",
    "model = Net()\n",
    "# model = SyNet()\n",
    "#model = seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get our parameters for optimization\n",
    "params = model.parameters()\n",
    "print(params, type(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(params, lr=args[\"lr\"])\n",
    "print(optimizer, type(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])\n",
    "print(scheduler, type(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can define a simple training loop very similar to the original PyTorch MNIST example\n",
    "def train(args, model, device, train_loader, optimizer, epoch, train_data_lenth):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_lenth / args[\"batch_size\"]) + 0.5)\n",
    "\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):  # TODO: this requires tuple support\n",
    "    for batch_idx, data in enumerate(train_loader):  # work around until tuple support\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = F.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.syft.lib.python.Float(0)\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "#             local_loss = loss_item.get(\n",
    "#                 request_name=\"loss\",\n",
    "#                 reason=\"To evaluate training progress\",\n",
    "#                 request_block=True,\n",
    "#                 timeout_secs=0\n",
    "#             )\n",
    "            local_loss = None\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace with local inference and local test set\n",
    "# the same for our test training loop except we will need to send our data over for inference\n",
    "def test(model, device, test_loader, test_data_lenth):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test in {test_batches} batches\")\n",
    "    model.eval()\n",
    "    test_loss = duet.syft.lib.python.Float(0)\n",
    "    correct_ptr = duet.syft.lib.python.Float(0)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):  # work around until tuple support\n",
    "            data_ptr, target_ptr = data[0], data[1]\n",
    "            output = model(data_ptr)\n",
    "            loss = F.nll_loss(output, target_ptr, reduction='sum').item()\n",
    "            test_loss = test_loss + loss\n",
    "\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target_ptr).sum().item()\n",
    "            correct_ptr += total\n",
    "\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct_ptr / test_data_length_ptr\n",
    "    # we need to batch or block these requests so the loop doesnt break\n",
    "    result = None\n",
    "#     result = accuracy.get(\n",
    "#         request_block=True,\n",
    "#         timeout_secs=0,\n",
    "#         request_name=\"accuracy\",\n",
    "#         reason=\"To see the accuracy on DO's test set\"\n",
    "#     )\n",
    "    if result is not None:\n",
    "        print(\"Test Set Average Loss:\", 100 * result)\n",
    "    else:\n",
    "        print(\"Test Set Average Loss: ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = torchvision.datasets.MNIST('../data', train=True, download=True, transform=transforms)\n",
    "print(train_data_ptr)\n",
    "train_loader_ptr = torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\n",
    "print(train_loader_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lenth_ptr = train_data_ptr.__len__()\n",
    "print(train_lenth_ptr)\n",
    "train_data_lenth = train_lenth_ptr.get(\n",
    "    request_block=True,\n",
    "    request_name=\"train_size\",\n",
    "    reason=\"To write the training loop\"\n",
    ")\n",
    "print(f\"Training Dataset size is: {train_data_lenth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "# sequential CPU times: user 39.2 s, sys: 390 ms, total: 39.6 s per epoch\n",
    "# sy.module CPU times: user 1min 28s, sys: 645 ms, total: 1min 28s\n",
    "# vanilla class \n",
    "args[\"dry_run\"] = False\n",
    "\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train(args, model, device, train_loader_ptr, optimizer, epoch, train_data_lenth)\n",
    "    test(model, device, test_loader_ptr, test_data_length)\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image):\n",
    "    print(\"1\")\n",
    "    image_tensor_ptr = torch.Tensor(prep_for_inference(image_1))\n",
    "    print(\"2\")\n",
    "    # image_tensor_ptr = image_tensor_ptr.to(device)\n",
    "    print(\"3\")\n",
    "    output = model(image_tensor_ptr)\n",
    "    print(\"4\")\n",
    "    preds = torch.exp(output)\n",
    "    print(\"5\")\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        request_name=\"inference_prediction\",\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, th.Tensor([-1])\n",
    "    else:\n",
    "        local_y = th.Tensor(preds.get())\n",
    "        print(\"6\")\n",
    "        local_y = local_y.squeeze()\n",
    "        print(\"7\")\n",
    "        pos = local_y == max(local_y)\n",
    "        print(\"8\")\n",
    "        index = th.nonzero(pos, as_tuple=False)\n",
    "        print(\"9\")\n",
    "        class_num = index.squeeze()\n",
    "        print(\"10\")\n",
    "        print(int(class_num))\n",
    "        print(\"11\")\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab something from the test set\n",
    "import random\n",
    "total_images = test_data_length # 10000\n",
    "index = random.randint(0, total_images)\n",
    "print(\"Random Test Image:\", index)\n",
    "count = 0\n",
    "batch = index // test_kwargs[\"batch_size\"]\n",
    "batch_index = index % int(total_images / len(test_loader))\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if batch == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(f\"Displaying {index} == {batch_index} in Batch: {batch}/{len(test_loader)}\")\n",
    "image_1 = data[batch_index].reshape((28, 28))\n",
    "label_1 = target[batch_index]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num, preds = classify(image_1)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote_model_params = model.parameters()\n",
    "# remote_model_params.request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_params = remote_model_params.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
