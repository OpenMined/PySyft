{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Syft Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# this only runs in colab and clones the code sets it up and fixes a few issues\n",
    "import sys\n",
    "if \"google.colab\" in sys.modules:\n",
    "    branch = \"demo\"    # change to the branch you want\n",
    "    ! git clone --single-branch --branch $branch https://github.com/OpenMined/PySyft.git\n",
    "    ! cd PySyft && ./scripts/colab.sh.     # fixes some colab python issues\n",
    "    sys.path.append(\"/content/PySyft/src\") # prevents needing restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "sy.LOG_FILE = \"syft_ds.log\"\n",
    "_ = sy.logger.add(sy.LOG_FILE, enqueue=True, colorize=False, diagnose=True, backtrace=True, level=\"TRACE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the data scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server (in their Notebook).\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Let's run the code below and follow the instructions it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duet = sy.join_duet(loopback=True)\n",
    "duet = sy.duet('e47f546963b1d213a20c7520d5174c3e')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Launch a Duet Server and Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = duet.store[\"age_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = duet.syft.lib.python.Int(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sy.logger.critical(\"Start requesting\")\n",
    "if len(duet.store) > 0:\n",
    "    t = duet.store[\"size_1\"].get(\n",
    "        request_block=True,\n",
    "        timeout_secs=15,\n",
    "        name=\"age_data\",\n",
    "        reason=\"I want to see the age data\",\n",
    "        delete_obj=False\n",
    "    )\n",
    "    sy.logger.critical(\"Finished requesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some references to our data owners Duet torch and torchvision\n",
    "torch = duet.torch\n",
    "torchvision = duet.torchvision\n",
    "\n",
    "# these are the same as the original mnist example\n",
    "transforms = torchvision.transforms\n",
    "datasets = torchvision.datasets\n",
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "optim = torch.optim\n",
    "StepLR = torch.optim.lr_scheduler.StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "local_transform_1 = tv.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = tv.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = tv.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings from original MNIST example command line args\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 14,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "# this is our carefully curated test data which represents the goal of our problem domain\n",
    "test_data = tv.datasets.MNIST('../data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = th.utils.data.DataLoader(test_data,**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)\n",
    "\n",
    "# test_data_length_ptr = duet.syft.lib.python.Int(test_data_length)\n",
    "# print(test_data_length_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data, type(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"duet\" variable is now your reference to a whole world of remote operations including supported libraries like torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO replace with local inference so this doesn't need to be on the DO side\n",
    "# test_data_ptr = torchvision.datasets.MNIST('../data', train=False, download=True, transform=transforms)\n",
    "# print(test_data_ptr)\n",
    "\n",
    "# test_loader_ptr = torch.utils.data.DataLoader(test_data_ptr,**test_kwargs)\n",
    "# print(test_loader_ptr)\n",
    "# # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "#         print(f\"modal is local: {self.is_local} running with torch_ref\", type(torch_ref))\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(f\"modal is local: {self.is_local} forward called with {self}, {x}\")\n",
    "#         print(f\"modal is local: {self.is_local} getting data\", type(x))\n",
    "#         print(f\"modal is local: {self.is_local} using layer conv1\", type(self.conv1))\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "#         print(f\"modal is local: {self.is_local} producing output of type\", type(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = SyNet(th)\n",
    "local_model.debug_sum_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_model.conv2.state_dict()[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = local_model.send(duet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.conv2.state_dict().get()[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(remote.is_local)\n",
    "# print(remote.duet)\n",
    "# print(type(remote.torch_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remote weights will be 0\n",
    "# remote.conv1.state_dict().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.modules)\n",
    "# print(remote.modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = torch.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    name=\"cuda_is_available\",\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=30,  # change to something slower\n",
    "))\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"DO device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get our parameters for optimization\n",
    "# params_list required for remote list concatenation\n",
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adadelta(params, lr=args[\"lr\"])\n",
    "print(optimizer, type(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])\n",
    "print(scheduler, type(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.conv2.state_dict().get()[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can define a simple training loop very similar to the original PyTorch MNIST example\n",
    "# @sy.logger.catch\n",
    "def train(args, model, device, train_loader, optimizer, epoch, train_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    train_batches = 100\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = F.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.syft.lib.python.Float(0)\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "#             local_loss = loss_item.get(\n",
    "#                 name=\"loss\",\n",
    "#                 reason=\"To evaluate training progress\",\n",
    "#                 request_block=True,\n",
    "#                 timeout_secs=30\n",
    "#             )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace with local inference and local test set\n",
    "# the same for our test training loop except we will need to send our data over for inference\n",
    "# @sy.logger.catch\n",
    "def test_local(remote_model, test_loader, test_data_length):\n",
    "    # download remote model\n",
    "    if not remote_model.is_local:\n",
    "        local_model = remote_model.get()\n",
    "\n",
    "#         local_model = remote_model.get(\n",
    "#             request_block=False,\n",
    "#             name=\"model_download\",\n",
    "#             reason=\"test evaluation\",\n",
    "#             timeout_secs=30\n",
    "#         )\n",
    "    else:\n",
    "        local_model = remote_model\n",
    "        \n",
    "    # visually check the weights have changed\n",
    "    local_model.debug_sum_layers()\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    local_model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = local_model(data)\n",
    "            iter_loss = th.nn.functional.nll_loss(output, target, reduction='sum').item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(f\"Test Set Accuracy: {100 * accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "print(type(transform_1), type(transform_2))\n",
    "\n",
    "remote_list = duet.syft.lib.python.List()\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = torchvision.datasets.MNIST('../data', train=True, download=True, transform=transforms)\n",
    "print(train_data_ptr)\n",
    "train_loader_ptr = torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\n",
    "print(train_loader_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_length(train_data_ptr):\n",
    "    train_length_ptr = train_data_ptr.__len__()\n",
    "    train_data_length = train_length_ptr.get(\n",
    "        request_block=True,\n",
    "        name=\"train_size\",\n",
    "        reason=\"To write the training loop\",\n",
    "        timeout_secs=30,\n",
    "    )\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "# sequential CPU times: user 39.2 s, sys: 390 ms, total: 39.6s per epoch\n",
    "# sy.module CPU times: user 1min 28s, sys: 645 ms, total: 1min 28s per epoch\n",
    "# vanilla class CPU times: user 3min 5s, sys: 3.01 s, total: 3min 8s per epoch\n",
    "\n",
    "args[\"dry_run\"] = False\n",
    "sy.logger.trace(\"Start Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train(args, model, device, train_loader_ptr, optimizer, epoch, train_data_length)\n",
    "    test_local(model, test_loader, test_data_length)  # real local data and model\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    break\n",
    "sy.logger.trace(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.is_local)\n",
    "# model.debug_sum_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = model.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l.debug_sum_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(image, model):\n",
    "    if not model.is_local:\n",
    "        print(\"model is remote try .get()\")\n",
    "        return -1, th.Tensor([-1])\n",
    "    image_tensor = th.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor)\n",
    "    preds = th.exp(output)\n",
    "    local_y = preds\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = th.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_remote(image, model):\n",
    "    if model.is_local:\n",
    "        print(\"model is local try .send()\")\n",
    "        return -1, th.Tensor([-1])\n",
    "    image_tensor_ptr = torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor_ptr)\n",
    "    preds = torch.exp(output)\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        name=\"inference\",\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, th.Tensor([-1])\n",
    "    else:\n",
    "        local_y = th.Tensor(preds_result)\n",
    "        local_y = local_y.squeeze()\n",
    "        pos = local_y == max(local_y)\n",
    "        index = th.nonzero(pos, as_tuple=False)\n",
    "        class_num = index.squeeze()\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab something from the test set\n",
    "import random\n",
    "total_images = test_data_length # 10000\n",
    "index = random.randint(0, total_images)\n",
    "print(\"Random Test Image:\", index)\n",
    "count = 0\n",
    "batch = index // test_kwargs[\"batch_size\"]\n",
    "batch_index = index % int(total_images / len(test_loader))\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if batch == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(f\"Displaying {index} == {batch_index} in Batch: {batch}/{len(test_loader)}\")\n",
    "image_1 = data[batch_index].reshape((28, 28))\n",
    "label_1 = target[batch_index]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify remote\n",
    "sy.logger.trace(\"Before running classify\")\n",
    "class_num, preds = classify_remote(image_1, model)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = model.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify local\n",
    "sy.logger.trace(\"Before running classify\")\n",
    "class_num, preds = classify_local(image_1, local_model)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import os\n",
    "def classify_url_image(image_url):\n",
    "    filename = os.path.basename(image_url)\n",
    "    !curl -O $image_url\n",
    "    im = Image.open(filename)\n",
    "    im = PIL.ImageOps.invert(im)\n",
    "#     im = im.resize((28,28), Image.ANTIALIAS)\n",
    "    im = im.convert('LA')\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    im = enhancer.enhance(3)\n",
    "\n",
    "\n",
    "    print(im.size)\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im, cmap=\"gray\", interpolation=\"none\")\n",
    "    \n",
    "    # classify local\n",
    "    class_num, preds = classify_local(image_1, local_model)\n",
    "    print(f\"Prediction: {class_num}\")\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://raw.githubusercontent.com/kensanata/numbers/master/0018_CHXX/0/number-100.png\"\n",
    "classify_url_image(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
