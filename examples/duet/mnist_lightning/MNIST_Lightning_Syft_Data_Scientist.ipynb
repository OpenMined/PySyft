{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Lightning âš¡ï¸ Syft Duet - Data Scientist ðŸ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the Data Scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server in their Notebook.\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. The code will look like this, importantly with their real Server ID.\n",
    "\n",
    "```\n",
    "import syft as sy\n",
    "duet = sy.duet('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "```\n",
    "\n",
    "This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Paste the code or Server ID that the Data Owner gives you and run it in the cell below. It will return your Client ID which you must send to the Data Owner to enter into Duet so it can pair your notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "duet = sy.join_duet(loopback=True)\n",
    "sy.logger.add(sink=\"./syft_ds.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Setting up a Model and our Data\n",
    "The majority of the code below has been adapted closely from the original PyTorch MNIST example which is available in the `original` directory with these notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `duet` variable is now your reference to a whole world of remote operations including supported libraries like torch.\n",
    "\n",
    "Lets take a look at the duet.torch attribute.\n",
    "```\n",
    "duet.torch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from types import ModuleType\n",
    "from typing import Any\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Union\n",
    "\n",
    "# third party\n",
    "import pytest\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.experimental.plugins.secure.pysyft import SyLightningModule\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# syft absolute\n",
    "import syft as sy\n",
    "from syft.ast.module import Module\n",
    "from torch import nn\n",
    "from syft.util import get_root_data_path\n",
    "\n",
    "SyModuleProxyType = Union[ModuleType, Module]\n",
    "SyModelProxyType = Union[nn.Module, sy.Module]\n",
    "\n",
    "# cant use lib_ast during test search time\n",
    "TorchTensorPointerType = Any  # sy.lib_ast.torch.Tensor.pointer_type\n",
    "TorchDataLoaderPointerType = Any  # sy.lib_ast.torch.utils.data.DataLoader\n",
    "SyTensorProxyType = Union[torch.Tensor, TorchTensorPointerType]  # type: ignore\n",
    "SyDataLoaderProxyType = Union[torch.utils.data.DataLoader, TorchDataLoaderPointerType]  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a model just like the one in the MNIST example. We do this in almost the exact same way as in PyTorch. The main difference is we inherit from sy.Module instead of nn.Module and we need to pass in a variable called torch_ref which we will use internally for any calls that would normally be to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref: SyModuleProxyType) -> None:\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x: SyTensorProxyType) -> SyTensorProxyType:\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities.imports import is_syft_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_syft_initialized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bookkeeping\n",
    "sy.client_cache[\"duet\"] = duet\n",
    "\n",
    "class LiftSyLightningModule(SyLightningModule):\n",
    "    def __init__(self, module: sy.Module, duet: Any) -> None:\n",
    "        super().__init__(module, duet)\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: SyTensorProxyType, batch_idx: Optional[int]\n",
    "    ) -> SyTensorProxyType:\n",
    "        data_ptr = batch\n",
    "        output = self.forward(data_ptr)\n",
    "        return self.torch.nn.functional.mse_loss(\n",
    "            output, self.torch.ones_like(output)\n",
    "        )\n",
    "\n",
    "    def test_step(self, batch: SyTensorProxyType, batch_idx: Optional[int]) -> None:\n",
    "        output = self.forward(batch)\n",
    "        loss = self.loss(output, self.torch.ones_like(output))\n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self) -> List:\n",
    "        optimizer = self.torch.optim.SGD(self.model.parameters(), lr=0.1)  # type: ignore\n",
    "        return [optimizer]\n",
    "    \n",
    "    @property\n",
    "    def torchvision(self) -> SyModuleProxyType:\n",
    "        return duet.torchvision if self.is_remote() else torchvision\n",
    "    \n",
    "    def get_transforms(self) -> type(transforms.transforms.Compose):  # type: ignore\n",
    "        current_list = duet.python.List if self.is_remote() else list\n",
    "        transforms = current_list()\n",
    "        transforms.append(self.torchvision.transforms.ToTensor())  # type: ignore\n",
    "        transforms.append(self.torchvision.transforms.Normalize(0.1307, 0.3081))  # type: ignore\n",
    "        return self.torchvision.transforms.Compose(transforms)  # type: ignore\n",
    "\n",
    "    def train_dataloader(self) -> SyDataLoaderProxyType:\n",
    "        transforms = self.get_transforms()\n",
    "        train_data_ptr = self.torchvision.datasets.MNIST(  # type: ignore\n",
    "            str(get_root_data_path()),\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms,\n",
    "        )\n",
    "        train_loader_ptr = self.torch.utils.data.DataLoader(  # type: ignore\n",
    "            train_data_ptr, batch_size=1\n",
    "        )\n",
    "        return train_loader_ptr\n",
    "\n",
    "    def test_dataloader(self) -> SyDataLoaderProxyType:\n",
    "        transforms = self.get_transforms()\n",
    "        test_data = self.torchvision.datasets.MNIST(  # type: ignore\n",
    "            str(get_root_data_path()),\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms,\n",
    "        )\n",
    "        test_loader = self.torch.utils.data.DataLoader(test_data, batch_size=1)  # type: ignore\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = SyNet(torch)\n",
    "model = LiftSyLightningModule(module=module, duet=duet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    default_root_dir=tmpdir,\n",
    "    max_epochs=1,\n",
    "    limit_train_batches=2,\n",
    "    limit_test_batches=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)\n",
    "trainer.test()\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LiftSyLightningModule.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path, module=module, duet=duet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
