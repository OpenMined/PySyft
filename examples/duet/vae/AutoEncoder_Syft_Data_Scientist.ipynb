{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "weekly-thompson",
   "metadata": {},
   "source": [
    "# VAE - Syft Duet - Data Scientist\n",
    "\n",
    "This example trains a VAE network on the MNIST dataset with Syft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-truth",
   "metadata": {},
   "source": [
    "\n",
    "## PART 1: Connect to a Remote Duet Server\n",
    "As the Data Scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server in their Notebook.\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. The code will look like this, importantly with their real Server ID.\n",
    "\n",
    "import syft as sy\n",
    "duet = sy.duet('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Paste the code or Server ID that the Data Owner gives you and run it in the cell below. It will return your Client ID which you must send to the Data Owner to enter into Duet so it can pair your notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "duet = sy.duet('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-cartoon",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 0 : Now STOP and run the Data Owner notebook until Checkpoint 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "try:\n",
    "    # make notebook progress bars nicer\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    print(f\"Unable to import tqdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = True\n",
    "epochs = 1\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 128,\n",
    "    \"no_cuda\": True,\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": epochs,\n",
    "    \"dry_run\": dry_run,\n",
    "    \"log_interval\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-jordan",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.util import get_root_data_path\n",
    "\n",
    "# we need some transforms for the MNIST data set\n",
    "remote_torchvision = duet.torchvision\n",
    "\n",
    "transform_1 = (\n",
    "    remote_torchvision.transforms.ToTensor()\n",
    ")  # this converts PIL images to Tensors\n",
    "\n",
    "remote_list = duet.python.List()  # create a remote list to add the transforms to\n",
    "remote_list.append(transform_1)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = remote_torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\"batch_size\": config[\"batch_size\"], \"shuffle\": True}\n",
    "train_data_ptr = remote_torchvision.datasets.MNIST(\n",
    "    str(get_root_data_path()), train=True, download=True, transform=transforms\n",
    ")\n",
    "train_loader_ptr = remote_torch.utils.data.DataLoader(train_data_ptr, **train_kwargs)\n",
    "\n",
    "test_data_ptr = remote_torchvision.datasets.MNIST(\n",
    "    str(get_root_data_path()), train=False, download=True, transform=transforms\n",
    ")\n",
    "test_loader_ptr = remote_torch.utils.data.DataLoader(test_data_ptr, **train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_length = train_data_ptr.__len__()\n",
    "    return train_length\n",
    "\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "except NameError:\n",
    "    train_data_length = get_train_length(train_data_ptr)\n",
    "\n",
    "try:\n",
    "    if test_data_length is None:\n",
    "        test_data_length = get_train_length(test_data_ptr)\n",
    "except NameError:\n",
    "    test_data_length = get_train_length(test_data_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")\n",
    "print(f\"Training Dataset size is: {test_data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_length = train_loader_ptr.len().get(request_block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-matter",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_cuda = False\n",
    "has_cuda_ptr = remote_torch.cuda.is_available().get(request_block=True)\n",
    "\n",
    "# lets ask to see if our Data Owner has CUDA\n",
    "print(\"Is cuda available ? : \", has_cuda)\n",
    "\n",
    "use_cuda = not config[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "remote_torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "device = remote_torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# print(f\"Data Owner device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-width",
   "metadata": {},
   "source": [
    "## Define and Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(VAE, self).__init__(torch_ref=torch_ref)\n",
    "\n",
    "        self.fc1 = self.torch_ref.nn.Linear(784, 400)\n",
    "        self.fc21 = self.torch_ref.nn.Linear(400, 20)\n",
    "        self.fc22 = self.torch_ref.nn.Linear(400, 20)\n",
    "        self.fc3 = self.torch_ref.nn.Linear(20, 400)\n",
    "        self.fc4 = self.torch_ref.nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.torch_ref.nn.ReLU()(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = remote_torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn(config[\"batch_size\"], 20)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.torch_ref.nn.ReLU()(self.fc3(z))\n",
    "        return self.torch_ref.nn.Sigmoid()(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_vae = VAE(torch)\n",
    "vae = local_vae.send(duet)\n",
    "\n",
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    vae.cuda(device)\n",
    "else:\n",
    "    vae.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not vae.is_local, \"Training requires remote model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = remote_torch.optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = remote_torch.nn.BCELoss(reduction=\"sum\")(recon_x, x.view(-1, 784))\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * remote_torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader_ptr):\n",
    "        data_ptr = remote_torch.Tensor(data[0]).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = vae(data_ptr)\n",
    "        loss = loss_function(recon_batch, data_ptr, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item().get(request_block=True)\n",
    "        if batch_loss is not None:\n",
    "            train_loss += batch_loss\n",
    "            if batch_idx % config[\"log_interval\"] == 0:\n",
    "                print(\n",
    "                    \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                        epoch,\n",
    "                        batch_idx * config[\"batch_size\"],\n",
    "                        train_data_length,\n",
    "                        100.0 * (batch_idx / train_loader_length),\n",
    "                        batch_loss / config[\"batch_size\"],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        if config[\"dry_run\"]:\n",
    "            break\n",
    "\n",
    "    print(\n",
    "        \"====> Epoch: {} Average loss: {:.4f}\".format(\n",
    "            epoch, train_loss / train_data_length\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    vae.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader_ptr):\n",
    "            data_ptr = remote_torch.Tensor(data[0]).to(device)\n",
    "            recon_batch, mu, logvar = vae(data_ptr)\n",
    "            batch_loss = loss_function(recon_batch, data_ptr, mu, logvar).get(\n",
    "                request_block=True\n",
    "            )\n",
    "            if batch_loss is not None:\n",
    "                test_loss += batch_loss / test_data_length\n",
    "\n",
    "            if config[\"dry_run\"]:\n",
    "                break\n",
    "\n",
    "    print(f\"====> Test set loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-sitting",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, config[\"epochs\"] + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, 20).to(\"cuda\" if use_cuda else \"cpu\")\n",
    "        sample = vae.decode(sample).cpu()\n",
    "        sample_image = sample.get(request_block=True)\n",
    "        save_image(sample_image.view(64, 1, 28, 28), \"sample_\" + str(epoch) + \".png\")\n",
    "\n",
    "    if config[\"dry_run\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-algeria",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "sample = torch.randn(64, 20).to(\"cuda\" if use_cuda else \"cpu\")\n",
    "sample = vae.decode(sample).cpu()\n",
    "sample_image = sample.get(request_block=True)\n",
    "\n",
    "save_image(sample_image.view(64, 1, 28, 28), \"output.png\")\n",
    "\n",
    "# PIL.Image.open(\"output.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-knock",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 1 : Now STOP and run the Data Owner notebook until the next checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-roller",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
