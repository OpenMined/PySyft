{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow_federated.python.program import value_reference\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_federated.proto.v0 import computation_pb2 as pb\n",
    "\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 5\n",
    "SHUFFLE_BUFFER = 100\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def map_fn(element):\n",
    "    return [tf.reshape(element['pixels'], [-1, 784]),\n",
    "        tf.reshape(element['label'], [-1, 1])]\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).map(map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
    "    emnist_train.client_ids[0])\n",
    "preprocessed_example_dataset = preprocess(example_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "  ])\n",
    "  \n",
    "def model_fn():\n",
    "  keras_model = create_keras_model()\n",
    "  return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=preprocessed_example_dataset.element_spec,\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(1, 784), dtype=tf.float32, name=None), TensorSpec(shape=(1, 1), dtype=tf.int32, name=None))\n",
      "(TensorSpec(shape=(1, 784), dtype=tf.float32, name=None), TensorSpec(shape=(1, 1), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "model = create_keras_model()\n",
    "\n",
    "input_spec = (tf.TensorSpec(shape=(1,784), dtype=tf.float32, name=None), \n",
    "              tf.TensorSpec(shape=(1,1), dtype=tf.int32, name=None))\n",
    "print(input_spec)\n",
    "print(preprocessed_example_dataset.element_spec)\n",
    "\n",
    "functional_model = tff.learning.models.functional_model_from_keras(keras_model=model, loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),input_spec=input_spec)\n",
    "\n",
    "def tff_model_fn() -> tff.learning.Model:\n",
    "    return tff.learning.models.model_from_functional(functional_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `flat_predict_on_batch` contains input name(s) Identity, Identity_1 with unsupported characters which will be renamed to identity, identity_1 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_dir/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_dir/assets\n"
     ]
    }
   ],
   "source": [
    "tf.config.optimizer.set_experimental_options({'disable_meta_optimizer': True})\n",
    "\n",
    "tff.learning.models.save_functional_model(functional_model=functional_model, path='tmp_dir')\n",
    "saved_functional_model = tff.learning.models.load_functional_model(\n",
    "                \"tmp_dir\"\n",
    "            )\n",
    "\n",
    "def saved_tff_model_fn() -> tff.learning.Model:\n",
    "    \n",
    "    return tff.learning.models.model_from_functional(saved_functional_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTPUT_DIR = 'some_dir'\n",
    "train_output_managers = [tff.program.LoggingReleaseManager()]\n",
    "evaluation_output_managers = [tff.program.LoggingReleaseManager()]\n",
    "model_output_manager = tff.program.LoggingReleaseManager()\n",
    "\n",
    "# # there is an issue with this, it causes and error for some reason\n",
    "# summary_dir = os.path.join(OUTPUT_DIR, \"summary\")\n",
    "# tensorboard_manager = tff.program.TensorBoardReleaseManager(summary_dir)\n",
    "# train_output_managers.append(tensorboard_manager)\n",
    "\n",
    "# # there is an issue with this, it causes and error for some reason\n",
    "# csv_path = os.path.join(OUTPUT_DIR, \"evaluation_metrics.csv\")\n",
    "# csv_manager = tff.program.CSVFileReleaseManager(csv_path)\n",
    "# evaluation_output_managers.append(csv_manager)\n",
    "\n",
    "# # there is an issue with this, it causes and error for some reason\n",
    "# program_state_dir = os.path.join(OUTPUT_DIR, \"program_state\")\n",
    "# program_state_manager = tff.program.FileProgramStateManager(program_state_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset element_spec=(TensorSpec(shape=(1, 784), dtype=tf.float32, name=None), TensorSpec(shape=(1, 1), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#emnist_train, emnist_test\n",
    "preprocessed_example_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clients = 3 \n",
    "total_rounds = 10\n",
    "train_datasets = [preprocess(emnist_train.create_tf_dataset_for_client(i)) for i in emnist_train.client_ids]\n",
    "test_datasets = [preprocess(emnist_test.create_tf_dataset_for_client(i)) for i in emnist_test.client_ids]\n",
    "train_data_source = tff.program.DatasetDataSource(train_datasets)\n",
    "evaluation_data_source = tff.program.DatasetDataSource(test_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from tensorflow_federated.python.program import value_reference\n",
    "\n",
    "\n",
    "async def tff_train_federated(\n",
    "    initialize: tff.Computation,\n",
    "    train: tff.Computation,\n",
    "    train_data_source: tff.program.FederatedDataSource,\n",
    "    evaluation: tff.Computation,\n",
    "    evaluation_data_source: tff.program.FederatedDataSource,\n",
    "    total_rounds: int,\n",
    "    number_of_clients: int,\n",
    "    train_output_managers,\n",
    "    evaluation_output_managers,\n",
    "    model_output_manager: tff.program.ReleaseManager,\n",
    "    program_state_manager: tff.program.ProgramStateManager,\n",
    ") -> None:\n",
    "    tff.program.check_in_federated_context()\n",
    "\n",
    "    # The program state manager is not working but maybe we could drop it\n",
    "    if program_state_manager is not None:\n",
    "        structure = initialize()\n",
    "        program_state, version = await program_state_manager.load_latest(structure)\n",
    "    else:\n",
    "        program_state = None\n",
    "\n",
    "    if program_state is not None:\n",
    "\n",
    "        state, start_round = program_state\n",
    "    else:\n",
    "        state = initialize()\n",
    "        start_round = 1\n",
    "\n",
    "    # state = initialize()\n",
    "    # start_round = 1\n",
    "    async with tff.async_utils.ordered_tasks() as tasks:\n",
    "\n",
    "        train_data_iterator = train_data_source.iterator()\n",
    "\n",
    "        for round_number in range(start_round, total_rounds + 1):\n",
    "            tasks.add_callable(\n",
    "                functools.partial(\n",
    "                    print, f\"Running round {round_number} of training\" \n",
    "                )\n",
    "            )\n",
    "\n",
    "            train_data = train_data_iterator.select(number_of_clients)\n",
    "            output = train(state, train_data)\n",
    "            state = output.state\n",
    "            metrics = output.metrics\n",
    "\n",
    "            # if train_output_managers is not None:\n",
    "            #     _, metrics_type = train.type_signature.result\n",
    "                # tasks.add_all(\n",
    "                #     *[m.release(metrics, metrics_type, round_number) for m in train_output_managers]\n",
    "                # )\n",
    "                # materialized_value = await value_reference.materialize_value(metrics)\n",
    "\n",
    "                # tasks.add_callable(\n",
    "                #     functools.partial(\n",
    "                #         print, str(materialized_value) \n",
    "                #     )\n",
    "                # )\n",
    "\n",
    "            # This is not working\n",
    "            # if program_state_manager is not None:\n",
    "            #     program_state = (state, start_round)\n",
    "            #     tasks.add(program_state_manager.save(program_state, round_number))\n",
    "\n",
    "        # evaluation_data_iterator = evaluation_data_source.iterator()\n",
    "        # evaluation_data = evaluation_data_iterator.select(number_of_clients)\n",
    "        # evaluation_metrics = evaluation(state, evaluation_data)\n",
    "\n",
    "        # if evaluation_output_managers is not None:\n",
    "        #     evaluation_metrics_type = evaluation.type_signature.result\n",
    "        #     tasks.add_all(*[\n",
    "        #         m.release(evaluation_metrics, evaluation_metrics_type, round_number)\n",
    "        #         for m in train_output_managers\n",
    "        #     ])\n",
    "\n",
    "        if model_output_manager is not None:\n",
    "            state_type, _ = train.type_signature.result\n",
    "            tasks.add(model_output_manager.release(state, state_type))\n",
    "    state = await value_reference.materialize_value(state)\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-bcfc5e284c6d>:50: RuntimeWarning: coroutine '_create_structure_of_coro_references.<locals>._get_item' was never awaited\n",
      "  metrics = output.metrics\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<ipython-input-15-bcfc5e284c6d>:50: RuntimeWarning: coroutine '_create_structure_of_coro_references.<locals>._to_structure' was never awaited\n",
      "  metrics = output.metrics\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running round 1 of training\n",
      "Running round 2 of training\n",
      "Running round 3 of training\n",
      "Running round 4 of training\n",
      "Running round 5 of training\n",
      "Running round 6 of training\n",
      "Running round 7 of training\n",
      "Running round 8 of training\n",
      "Running round 9 of training\n",
      "Running round 10 of training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-fb41c990793b>:15: RuntimeWarning: coroutine 'materialize_value' was never awaited\n",
      "  state = asyncio.run(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# FUNCTIONAL KERAS MODEL FROM A SAVED MODEL\n",
    "import asyncio\n",
    "context = tff.backends.native.create_local_async_python_execution_context()\n",
    "context = tff.program.NativeFederatedContext(context)\n",
    "tff.framework.set_default_context(context)\n",
    "\n",
    "iterative_process = tff.learning.algorithms.build_unweighted_fed_avg(\n",
    "    saved_tff_model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
    "initialize = iterative_process.initialize\n",
    "train = iterative_process.next\n",
    "evaluation = tff.learning.build_federated_evaluation(saved_tff_model_fn)\n",
    "\n",
    "state = asyncio.run(\n",
    "        tff_train_federated(\n",
    "            initialize=initialize,\n",
    "            train=train,\n",
    "            train_data_source=train_data_source,\n",
    "            evaluation=evaluation,\n",
    "            evaluation_data_source=evaluation_data_source,\n",
    "            total_rounds=total_rounds,\n",
    "            number_of_clients=number_of_clients,\n",
    "            train_output_managers=train_output_managers,\n",
    "            evaluation_output_managers=evaluation_output_managers,\n",
    "            model_output_manager=model_output_manager,\n",
    "            program_state_manager=None,\n",
    "            # program_state_manager=program_state_manager,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_federated.python.learning.model_utils import ModelWeights \n",
    "\n",
    "new_weights = ModelWeights(list(state.global_model_weights.trainable),list(state.global_model_weights.non_trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_saved_functional_model = tff.learning.models.load_functional_model(\n",
    "                \"tmp_dir\"\n",
    "            )\n",
    "new_model = tff.learning.models.model_from_functional(new_saved_functional_model)\n",
    "# new_model = create_keras_model()\n",
    "state.global_model_weights.assign_weights_to(new_model)\n",
    "state.global_model_weights.non_trainable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('PySyTFF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67856bda971e2a654274dbee4a8f60d8877ae51b472a8acc4dc577a3ea0a55e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
