{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04340893-0af3-4601-90d3-8b8bdf130a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syft absolute\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2ce6d2-f6c6-439a-b56e-b71675d62efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging Protocol Changes...\n",
      "Starting test-domain-1 server on 0.0.0.0:18048\n",
      "Waiting for server to start."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [99151]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:18048 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "WARNING: private key is based on node name: test-domain-1 in dev_mode. Don't run this in production.\n",
      "Creating default worker image with tag='local-dev'\n",
      "Building default worker image with tag=local-dev\n",
      "Setting up worker poolname=default-pool workers=1 image_uid=4c9dc528c8774fa7bf90259b3d710215 in_memory=True\n",
      "Default worker pool error. Invalid number of workers: 0\n",
      "Data Migrated to latest version !!!\n",
      "INFO:     127.0.0.1:54230 - \"GET /api/v2/metadata HTTP/1.1\" 200 OK\n",
      " Done.\n",
      "INFO:     127.0.0.1:54232 - \"GET /api/v2/metadata HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54232 - \"GET /api/v2/metadata HTTP/1.1\" 200 OK\n",
      "Logged into <test-domain-1: High-side Domain> as GUEST\n",
      "INFO:     127.0.0.1:54232 - \"POST /api/v2/login HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54232 - \"GET /api/v2/api?verify_key=aec6ea4dfc049ceacaeeebc493167a88a200ddc367b1fa32da652444b635d21f&communication_protocol=dev HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54234 - \"POST /api/v2/api_call HTTP/1.1\" 200 OK\n",
      "Logged into <test-domain-1: High side Domain> as <info@openmined.org>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert-warning\" style=\"padding:5px;\"><strong>SyftWarning</strong>: You are using a default password. Please change the password using `[your_client].me.set_password([new_password])`.</div><br />"
      ],
      "text/plain": [
       "SyftWarning: You are using a default password. Please change the password using `[your_client].me.set_password([new_password])`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node = sy.orchestra.launch(\n",
    "    name=\"test-domain-1\",\n",
    "    port=\"auto\",\n",
    "    dev_mode=True,\n",
    "    n_consumers=1,\n",
    "    create_producer=True,\n",
    ")\n",
    "domain_client = node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bda208-46c9-4bac-a18b-d14cdcabf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sy.api_endpoint(\n",
    "#     path=\"vertex.run\",\n",
    "#     settings={\"SERVICE_ACCOUNT\": SERVICE_ACCOUNT},\n",
    "\n",
    "# )\n",
    "\n",
    "\n",
    "def gemma_2b(\n",
    "    context,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 50,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 1.0,\n",
    "    top_k: int = 1,\n",
    "    raw_response: bool = False,\n",
    ") -> str:\n",
    "    # context.state = [\"jimmy@caltech.edu\": {\"n_calls\":3, \"period_secs\":60}]\n",
    "\n",
    "    # use helper function rate limiter\n",
    "    # is_allowed = allowed(context.state, context.user.email)\n",
    "\n",
    "    # third party\n",
    "    from google.cloud import aiplatform\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_info(\n",
    "            context.settings[\"SERVICE_ACCOUNT\"]\n",
    "        )\n",
    "\n",
    "        PROJECT_ID = \"project-enigma-415021\"\n",
    "        REGION = \"us-west1\"\n",
    "        ENDPOINT_ID = \"3213239169291649024\"\n",
    "        aip_endpoint_name = (\n",
    "            f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    "        )\n",
    "        endpoint_vllm = aiplatform.Endpoint(aip_endpoint_name, credentials=credentials)\n",
    "        default_kwargs = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k,\n",
    "            \"raw_response\": raw_response,\n",
    "        }\n",
    "        instances = [\n",
    "            default_kwargs,\n",
    "        ]\n",
    "        response = endpoint_vllm.predict(instances=instances)\n",
    "        prediction = response.predictions[0]\n",
    "    except Exception as e:\n",
    "        prediction = f\"Error: Please try again? {e}\"\n",
    "    return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece59c29-0b62-415d-86a6-6f502cece866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @sy.api_endpoint(\n",
    "#     path=\"vertex.run\",\n",
    "#     settings={\"SERVICE_ACCOUNT\": SERVICE_ACCOUNT},\n",
    "\n",
    "# )\n",
    "\n",
    "\n",
    "def gemma_7b(\n",
    "    context,\n",
    "    prompt: str,\n",
    "    max_tokens: int = 50,\n",
    "    temperature: float = 0.1,\n",
    "    top_p: float = 1.0,\n",
    "    top_k: int = 1,\n",
    "    raw_response: bool = False,\n",
    ") -> str:\n",
    "    # context.state = [\"jimmy@caltech.edu\": {\"n_calls\":3, \"period_secs\":60}]\n",
    "\n",
    "    # use helper function rate limiter\n",
    "    # is_allowed = allowed(context.state, context.user.email)\n",
    "\n",
    "    # third party\n",
    "    from google.cloud import aiplatform\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    try:\n",
    "        credentials = service_account.Credentials.from_service_account_info(\n",
    "            context.settings[\"SERVICE_ACCOUNT\"]\n",
    "        )\n",
    "\n",
    "        PROJECT_ID = \"project-enigma-415021\"\n",
    "        REGION = \"us-west1\"\n",
    "        ENDPOINT_ID = \"3213239169291649024\"\n",
    "        aip_endpoint_name = (\n",
    "            f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    "        )\n",
    "        endpoint_vllm = aiplatform.Endpoint(aip_endpoint_name, credentials=credentials)\n",
    "        default_kwargs = {\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k,\n",
    "            \"raw_response\": raw_response,\n",
    "        }\n",
    "        instances = [\n",
    "            default_kwargs,\n",
    "        ]\n",
    "        response = endpoint_vllm.predict(instances=instances)\n",
    "        prediction = response.predictions[0]\n",
    "    except Exception as e:\n",
    "        prediction = f\"Error: Please try again? {e}\"\n",
    "    return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6186d12-d5aa-4a92-bb59-7e84e73592ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.api.services.api.delete(endpoint_path=\"vertex.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f726e-7b66-48f3-b7ac-255ff619d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.api.services.api.add(endpoint=public_endpoint_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd10f9d-983c-4061-9422-1126a5c65c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sy.Model(name=\"Gemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41dfe7a-b60f-4a07-86af-bef135dfe37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_description(\n",
    "    \"Gemma is a set of lightweight, generative artificial intelligence (AI) open models. Gemma models are available to run in your applications and on your hardware, mobile devices, or hosted services. You can also customize these models using tuning techniques so that they excel at performing tasks that matter to you and your users. Gemma models are based on Gemini models and are intended for the AI development community to extend and take further.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a63213-dcf7-422c-8d9b-4af69abe5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add_citation(\"Person, place or thing\")\n",
    "# model.add_url(\n",
    "#     \"https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-gemma\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8c99a-fadd-4647-a542-76a4829cb948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add_contributor(\n",
    "#     name=\"Thomas Mesnard\",\n",
    "#     email=\"thomas@email.com\",\n",
    "#     note=\"This paper was fun!\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5769637-937c-4525-ae01-e03563fa893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = sy.Asset(name=\"2b_Pretrained\")\n",
    "asset.set_description(\n",
    "    \"Gemma 2B, 2.2 billion - Input: Text, Output: Text, Pretrained, Mobile devices and laptops\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761b111c-b83e-4252-abd7-b8877c3a422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model list\n",
    "# name, description, asset key, kwargs, example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520fa24-3f98-4d6b-865a-66d3729ffaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the model entries / assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c806f20-f001-4906-b4c5-344ec6cb6115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bd1ce-ace5-40ca-a4f0-e6624093f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.api_endpoint(settings=SERVICE_ACCOUNT)\n",
    "def call_vertex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbad95-1650-4fa9-8cb0-41b438b5bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.api_endpoint(\n",
    "    code=[call_vertex], path=\"gemma.2b\", user_settings={}\n",
    "):\n",
    "def gemma_2b():\n",
    "    call_vertex(endpoint_id=\"34q23rafsfas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f1a02-80ad-4b78-9a8e-03042ec972c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset.set_api(gemma_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce56e6-8bb2-48a8-8105-0d48c8dc0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_asset(asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad35dff-6adf-4234-b070-ac9dd1d857c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = sy.Asset(name=\"7b_Pretrained\")\n",
    "asset.set_description(\n",
    "    \"Gemma 7B, 7 billion - Input: Text, Output: Text, Pretrained, Desktop computers and small servers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fed7a-9597-49a5-b74d-7d81695d7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.add_asset(asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ddada-729d-4c79-9d0c-289610fa253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.upload_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270e470-29c6-4416-900f-66f900754c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can list all the datasets on the Domain Server by invoking the following\n",
    "datasets = domain_client.datasets.get_all()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2921d83-bd3d-400c-a023-39c6bf3ea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.models[\"Gemma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a6922-7e0c-4a55-8afe-25041fe3a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.models[\"Gemma\"][\"2b_Pretrained\"](prompt=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ae1cd-fded-4309-9760-30368fc5b1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2f5cc-bee2-4d85-a75d-eba8ae011a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c634a387-6db3-402a-9e94-8083190bc25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339719ec-271e-46b2-a73b-02ec932073f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
