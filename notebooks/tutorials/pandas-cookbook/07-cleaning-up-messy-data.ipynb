{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Cleaning up messy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYFT_VERSION = \">=0.9,<1.0.0\"\n",
    "package_string = f'\"syft{SYFT_VERSION}\"'\n",
    "# %pip install {package_string} -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# syft absolute\n",
    "import syft as sy\n",
    "\n",
    "sy.requires(SYFT_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server = sy.orchestra.launch(name=\"pandas-test-datasite-7\", port=9087, reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Data owner: Upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_datasite_client = server.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The usual preamble\n",
    "%matplotlib inline\n",
    "\n",
    "# third party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# syft absolute\n",
    "from syft.service.project.project import Project\n",
    "from syft.util.util import PANDAS_DATA\n",
    "from syft.util.util import autocache\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "\n",
    "# This is necessary to show lots of columns in pandas 0.12.\n",
    "# Not necessary in pandas 0.13.\n",
    "pd.set_option(\"display.width\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "One of the main problems with messy data is: how do you know if it's messy or not?\n",
    "\n",
    "We're going to use the NYC 311 service request dataset again here, since it's big and a bit unwieldy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Create mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_requests = pd.read_csv(\n",
    "    autocache(f\"{PANDAS_DATA}/311-service-requests.csv\"), dtype=\"unicode\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(service_requests) == 111069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_requests.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_with_dashes = service_requests[\"Incident Zip\"].str.contains(\"-\").fillna(False)\n",
    "service_requests[rows_with_dashes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import random\n",
    "\n",
    "\n",
    "def get_unique_key():\n",
    "    return random.randint(0, 1000000)\n",
    "\n",
    "\n",
    "def get_mock_location():\n",
    "    return random.uniform(-90, 90)\n",
    "\n",
    "\n",
    "def get_zip_code():\n",
    "    zip = random.randint(10000, 11000)\n",
    "    if zip > 10990:\n",
    "        zip = str(zip) + \"-1234\"\n",
    "    return str(zip)\n",
    "\n",
    "\n",
    "def get_mock_row(i):\n",
    "    res = {}\n",
    "    for k, function in mock_functions.items():\n",
    "        res[k] = function()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service_requests.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make mock as close to the original data as possible!!\n",
    "# TODO: Make it the same as the OG dataframe\n",
    "mock_functions = {\n",
    "    \"Unique Key\": lambda: get_unique_key(),\n",
    "    \"Longitude\": lambda: random.uniform(-90, 90),\n",
    "    \"Latitude\": lambda: random.uniform(-90, 90),\n",
    "    \"Incident Zip\": lambda: get_zip_code(),\n",
    "    \"City\": lambda: random.choice([\"BROOKLYN\", \"NEW YORK\", \"BRONX\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mock = pd.DataFrame(\n",
    "    data=[get_mock_row(i) for i in range(len(service_requests))],\n",
    "    columns=service_requests.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Upload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = sy.Dataset(\n",
    "    name=\"test\",\n",
    "    asset_list=[\n",
    "        sy.Asset(\n",
    "            name=\"service_requests\",\n",
    "            data=service_requests,\n",
    "            mock=mock,\n",
    "            mock_is_real=False,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "root_datasite_client.upload_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Create user account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user = root_datasite_client.register(\n",
    "    name=\"Jane Doe\",\n",
    "    email=\"jane@caltech.edu\",\n",
    "    password=\"abc123\",\n",
    "    password_verify=\"abc123\",\n",
    "    institution=\"Caltech\",\n",
    "    website=\"https://www.caltech.edu/\",\n",
    ")\n",
    "# todo: give user data scientist role\n",
    "guest_datasite_client = server.client\n",
    "guest_client = guest_datasite_client.login(email=\"jane@caltech.edu\", password=\"abc123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Data scientist: create syft_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Summary\n",
    "By the end of this chapter, we're going to have downloaded all of Canada's weather data for 2012, and saved it to a CSV.\n",
    "\n",
    "We'll do this by downloading it one month at a time, and then combining all the months together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Get mocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = guest_client.datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asset = ds.assets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests = asset.mock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## How do we know if it's messy?\n",
    "We're going to look at a few columns here. I know already that there are some problems with the zip code, so let's look at that first.\n",
    "\n",
    "To get a sense for whether a column has problems, I usually use `.unique()` to look at all its values. If it's a numeric column, I'll instead plot a histogram to get a sense of the distribution.\n",
    "\n",
    "When we look at the unique values in \"Incident Zip\", it quickly becomes clear that this is a mess.\n",
    "\n",
    "Some of the problems:\n",
    "\n",
    "- Some have been parsed as strings, and some as floats\n",
    "- There are `nans`\n",
    "- Some of the zip codes are `29616-0759` or `83`\n",
    "- There are some N/A values that pandas didn't recognize, like 'N/A' and 'NO CLUE'\n",
    "\n",
    "What we can do:\n",
    "\n",
    "- Normalize 'N/A' and 'NO CLUE' into regular nan values\n",
    "- Look at what's up with the 83, and decide what to do\n",
    "- Make everything strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[\"Incident Zip\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Fixing the nan values and string/float confusion\n",
    "We can pass a na_values option to pd.read_csv to clean this up a little bit. We can also specify that the type of Incident Zip is a string, not a float.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "na_values = [\"NO CLUE\", \"N/A\", \"0\"]\n",
    "requests.replace(na_values, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[\"Incident Zip\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## What's up with the dashes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows_with_dashes = requests[\"Incident Zip\"].str.contains(\"-\").fillna(False)\n",
    "len(requests[rows_with_dashes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[rows_with_dashes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "I thought these were missing data and originally deleted them like this:\n",
    "\n",
    "`requests['Incident Zip'][rows_with_dashes] = np.nan`\n",
    "\n",
    "But then my friend Dave pointed out that 9-digit zip codes are normal. Let's look at all the zip codes with more than 5 digits, make sure they're okay, and then truncate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_zip_codes = requests[\"Incident Zip\"].str.len() > 5\n",
    "requests[\"Incident Zip\"][long_zip_codes].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Those all look okay to truncate to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[\"Incident Zip\"] = requests[\"Incident Zip\"].str.slice(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Done.\n",
    "\n",
    "Earlier I thought 00083 was a broken zip code, but turns out Central Park's zip code 00083! Shows what I know. I'm still concerned about the 00000 zip codes, though: let's look at that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[requests[\"Incident Zip\"] == \"00000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "This looks bad to me. Let's set these to nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_zips = requests[\"Incident Zip\"] == \"00000\"\n",
    "requests.loc[zero_zips, \"Incident Zip\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Great. Let's see where we are now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_zips = requests[\"Incident Zip\"].unique()\n",
    "unique_zips.sort()\n",
    "unique_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "Amazing! This is much cleaner. There's something a bit weird here, though -- I looked up 77056 on Google maps, and that's in Texas.\n",
    "\n",
    "Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zips = requests[\"Incident Zip\"]\n",
    "\n",
    "# Let's say the zips starting with '0' and '1' are okay, for now.\n",
    "# (this isn't actually true -- 13221 is in Syracuse, and why?)\n",
    "is_close = zips.str.startswith(\"0\") | zips.str.startswith(\"1\")\n",
    "\n",
    "# There are a bunch of NaNs, but we're not interested in them right now, so we'll say they're False\n",
    "is_far = ~(is_close) & zips.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zips[is_far]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "Okay, there really are requests coming from LA and Houston! Good to know. Filtering by zip code is probably a bad way to handle this -- we should really be looking at the city instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "requests[\"City\"].str.upper().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "It looks like these are legitimate complaints, so we'll just leave them alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Putting it together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Now we want to request the full code execution.\n",
    "\n",
    "Let's put all that together, to prove how easy it is. 6 lines of magical pandas!\n",
    "\n",
    "If you want to play around, try changing sum to max, numpy.median, or any other function you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@sy.syft_function(\n",
    "    input_policy=sy.ExactMatch(df=ds.assets[0]),\n",
    "    output_policy=sy.SingleExecutionExactOutput(),\n",
    ")\n",
    "def zip_codes(df):\n",
    "    # third party\n",
    "    import numpy as np\n",
    "\n",
    "    # na_values = [\"NO CLUE\", \"N/A\", \"0\"]\n",
    "\n",
    "    def fix_zip_codes(zips):\n",
    "        # Truncate everything to length 5\n",
    "        zips = zips.str.slice(0, 5)\n",
    "\n",
    "        # Set 00000 zip codes to nan\n",
    "        zero_zips = zips == \"00000\"\n",
    "        zips[zero_zips] = np.nan\n",
    "\n",
    "        return zips\n",
    "\n",
    "    df[\"Incident Zip\"] = fix_zip_codes(df[\"Incident Zip\"])\n",
    "    result = df[\"Incident Zip\"].unique()\n",
    "    # todo, we are adding list(result) here to fix serialization errors\n",
    "    return list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Create and submit project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_project = sy.Project(\n",
    "    name=\"Pandas Chapter 7\",\n",
    "    description=\"Hi, I would like to get some insights about the zip codes of the complaints\",\n",
    "    members=[guest_client],\n",
    ")\n",
    "new_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = new_project.send()\n",
    "assert isinstance(project, sy.service.project.project.Project)\n",
    "project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project.create_code_request(zip_codes, guest_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(guest_client.code.get_all()) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(project.events) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert isinstance(project.events[0], sy.service.project.project.ProjectRequest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "# Data owner: approve request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# syft absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasite_client = server.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "# Get notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notifications = datasite_client.notifications.get_all_unread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_notification = [\n",
    "    x for x in notifications if issubclass(x.linked_obj.object_type, Project)\n",
    "][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = project_notification.link.events[0].request\n",
    "func = request.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zip_codes = func.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_data = datasite_client.datasets[0].assets[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_result = zip_codes(df=real_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = request.approve()\n",
    "assert isinstance(result, sy.SyftSuccess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "# Data scientist: compute result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asset = guest_client.datasets[0].assets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "guest_client.code[0].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_ptr = guest_client.code.zip_codes(df=asset)\n",
    "real_result = result_ptr.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "server.land()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
