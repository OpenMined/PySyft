{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX 101 - 04 Advanced Automatic Differentiation\n",
    "Link to the original JAX tutorial: https://jax.readthedocs.io/en/latest/jax-101/04-advanced-autodiff.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0 - Data Owner Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kj/filesystem-disk-unix.c++:1703: warning: PWD environment variable doesn't match current directory; pwd = /\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ The installed version of syft==0.8.1b3 matches the requirement >=0.8 and the requirement <0.9\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import syft as sy\n",
    "sy.requires(\">=0.8,<0.9\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Store Path:\n",
      "!open file:///var/folders/sz/hkfsnn612hq56r7cs5rd540r0000gn/T/7bca415d13ed4ec881f0d0aede098dbb.sqlite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Launch the domain\n",
    "node = sy.orchestra.launch(name=\"test-domain-1\", reset=True, dev_mode=True)\n",
    "data_owner_client = node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite Store Path:\n",
      "!open file:///var/folders/sz/hkfsnn612hq56r7cs5rd540r0000gn/T/7bca415d13ed4ec881f0d0aede098dbb.sqlite\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<SyftClient - test-domain-1 <7bca415d13ed4ec881f0d0aede098dbb>: PythonConnection>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register a client to the domain\n",
    "node = sy.orchestra.launch(name=\"test-domain-1\")\n",
    "data_scientist_client = node.client\n",
    "data_scientist_client.register(name=\"Jane Doe\", email=\"jane@caltech.edu\", password=\"abc123\", institution=\"Caltech\", website=\"https://www.caltech.edu/\")\n",
    "data_scientist_client.login(email=\"jane@caltech.edu\", password=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for code execution\n",
    "# ATTENTION: ALL LIBRARIES USED SHOULD BE DEFINED INSIDE THE FUNCTION CONTEXT!!!\n",
    "\n",
    "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def higher_order_derivatives():\n",
    "    import jax\n",
    "    f = lambda x: x**3 + 2*x**2 - 3*x + 1\n",
    "\n",
    "    dfdx = jax.grad(f)\n",
    "    d2fdx = jax.grad(dfdx)\n",
    "    d3fdx = jax.grad(d2fdx)\n",
    "    d4fdx = jax.grad(d3fdx)\n",
    "    \n",
    "    print(dfdx(1.))\n",
    "    print(d2fdx(1.))\n",
    "    print(d3fdx(1.))\n",
    "    print(d4fdx(1.))\n",
    "\n",
    "\n",
    "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def stopping_gradients():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    \n",
    "    # Value function and initial parameters\n",
    "    value_fn = lambda theta, state: jnp.dot(theta, state)\n",
    "    theta = jnp.array([0.1, -0.1, 0.])\n",
    "    \n",
    "    # An example transition.\n",
    "    s_tm1 = jnp.array([1., 2., -1.])\n",
    "    r_t = jnp.array(1.)\n",
    "    s_t = jnp.array([2., 1., 0.])\n",
    "\n",
    "    def td_loss(theta, s_tm1, r_t, s_t):\n",
    "        v_tm1 = value_fn(theta, s_tm1)\n",
    "        target = r_t + value_fn(theta, s_t)\n",
    "        return (target - v_tm1) ** 2\n",
    "\n",
    "    td_update = jax.grad(td_loss)\n",
    "    delta_theta = td_update(theta, s_tm1, r_t, s_t)\n",
    "\n",
    "    print(\"Pseudo naive loss\", delta_theta)\n",
    "    \n",
    "    def td_loss(theta, s_tm1, r_t, s_t):\n",
    "        v_tm1 = value_fn(theta, s_tm1)\n",
    "        target = r_t + value_fn(theta, s_t)\n",
    "        return (jax.lax.stop_gradient(target) - v_tm1) ** 2\n",
    "\n",
    "    td_update = jax.grad(td_loss)\n",
    "    delta_theta = td_update(theta, s_tm1, r_t, s_t)\n",
    "\n",
    "    print(\"Correct loss\", delta_theta)\n",
    "    \n",
    "    perex_grads = jax.jit(jax.vmap(jax.grad(td_loss), in_axes=(None, 0, 0, 0)))\n",
    "\n",
    "    # Test it:\n",
    "    batched_s_tm1 = jnp.stack([s_tm1, s_tm1])\n",
    "    batched_r_t = jnp.stack([r_t, r_t])\n",
    "    batched_s_t = jnp.stack([s_t, s_t])\n",
    "\n",
    "    print(\"Per example grads\", perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t))\n",
    "\n",
    "    dtdloss_dtheta = jax.grad(td_loss)\n",
    "\n",
    "    print(\"Gradient loss on unbatched inputs\", dtdloss_dtheta(theta, s_tm1, r_t, s_t))\n",
    "\n",
    "    almost_perex_grads = jax.vmap(dtdloss_dtheta)\n",
    "\n",
    "    batched_theta = jnp.stack([theta, theta])\n",
    "    member_gradient = almost_perex_grads(batched_theta, batched_s_tm1, batched_r_t, batched_s_t)\n",
    "    print(\"Gradient for on member of a batch\", member_gradient)\n",
    "\n",
    "    inefficient_perex_grads = jax.vmap(dtdloss_dtheta, in_axes=(None, 0, 0, 0))\n",
    "    grads = inefficient_perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t)\n",
    "    print(\"Inefficient gradients\", grads)\n",
    "    \n",
    "    perex_grads = jax.jit(inefficient_perex_grads)\n",
    "    grads = perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t)\n",
    "    print(\"Efficient gradients\", grads)\n",
    "    \n",
    "    %timeit inefficient_perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t).block_until_ready()\n",
    "    %timeit perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t).block_until_ready()\n",
    "\n",
    "\n",
    "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def straight_through_estimator():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    \n",
    "    def f(x):\n",
    "        return jnp.round(x)  # non-differentiable\n",
    "\n",
    "    def straight_through_f(x):\n",
    "        # Create an exactly-zero expression with Sterbenz lemma that has\n",
    "        # an exactly-one gradient.\n",
    "        zero = x - jax.lax.stop_gradient(x)\n",
    "        return zero + jax.lax.stop_gradient(f(x))\n",
    "\n",
    "    print(\"f(x): \", f(3.2))\n",
    "    print(\"straight_through_f(x):\", straight_through_f(3.2))\n",
    "\n",
    "    print(\"grad(f)(x):\", jax.grad(f)(3.2))\n",
    "    print(\"grad(straight_through_f)(x):\", jax.grad(straight_through_f)(3.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "10.0\n",
      "6.0\n",
      "0.0\n",
      "Pseudo naive loss [ 2.4 -2.4  2.4]\n",
      "Correct loss [-2.4 -4.8  2.4]\n",
      "Per example grads [[-2.4 -4.8  2.4]\n",
      " [-2.4 -4.8  2.4]]\n",
      "Gradient loss on unbatched inputs [-2.4 -4.8  2.4]\n",
      "Gradient for on member of a batch [[-2.4 -4.8  2.4]\n",
      " [-2.4 -4.8  2.4]]\n",
      "Inefficient gradients [[-2.4 -4.8  2.4]\n",
      " [-2.4 -4.8  2.4]]\n",
      "Efficient gradients [[-2.4 -4.8  2.4]\n",
      " [-2.4 -4.8  2.4]]\n",
      "4.03 ms ¬± 42.2 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n",
      "6.15 ¬µs ¬± 125 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)\n",
      "f(x):  3.0\n",
      "straight_through_f(x): 3.0\n",
      "grad(f)(x): 0.0\n",
      "grad(straight_through_f)(x): 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test our function locally \n",
    "higher_order_derivatives()\n",
    "stopping_gradients()\n",
    "straight_through_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "class Request:\n",
       "  id: str = a6faa675879d48308d92829dfb258e73\n",
       "  requesting_user_verify_key: str = c5dc97891534f57b6030b4eecd2a5d95976e393e3e2f41d15fec7ebbf518a9d7\n",
       "  approving_user_verify_key: str = None\n",
       "  request_time: str = 2023-05-29 06:23:13\n",
       "  approval_time: str = None\n",
       "  status: str = RequestStatus.PENDING\n",
       "  node_uid: str = 7bca415d13ed4ec881f0d0aede098dbb\n",
       "  request_hash: str = \"3059373cddc0bdee707154cc110710fb6fee5a73f23619d079ce1fdeea5254da\"\n",
       "  changes: str = [syft.service.request.request.UserCodeStatusChange]\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "syft.service.request.request.Request"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit the function for code execution\n",
    "data_scientist_client.api.services.code.request_code_execution(higher_order_derivatives)\n",
    "data_scientist_client.api.services.code.request_code_execution(stopping_gradients)\n",
    "data_scientist_client.api.services.code.request_code_execution(straight_through_estimator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Data Owner Reviewing and Approving Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_owner_client = node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "List - Size: 3\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>linked_obj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>syft.service.message.messages.Message</td>\n",
       "      <td>ecd9f02838ec4987a9135a7274617a8a</td>\n",
       "      <td>Approval Request</td>\n",
       "      <td>MessageStatus.UNDELIVERED</td>\n",
       "      <td>2023-05-29 06:23:13</td>\n",
       "      <td>&lt;&lt;class 'syft.service.request.request.Request'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>syft.service.message.messages.Message</td>\n",
       "      <td>b3ec0d138e4b4c3ba7fe30e090624a49</td>\n",
       "      <td>Approval Request</td>\n",
       "      <td>MessageStatus.UNDELIVERED</td>\n",
       "      <td>2023-05-29 06:23:13</td>\n",
       "      <td>&lt;&lt;class 'syft.service.request.request.Request'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>syft.service.message.messages.Message</td>\n",
       "      <td>d55fd935cf204a97b7b0c01e0424bfc8</td>\n",
       "      <td>Approval Request</td>\n",
       "      <td>MessageStatus.UNDELIVERED</td>\n",
       "      <td>2023-05-29 06:23:13</td>\n",
       "      <td>&lt;&lt;class 'syft.service.request.request.Request'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[syft.service.message.messages.Message,\n",
       " syft.service.message.messages.Message,\n",
       " syft.service.message.messages.Message]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get messages from domain\n",
    "messages = data_owner_client.api.services.messages.get_all()\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "straight_through_estimator\n",
      "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
      "                  output_policy=sy.SingleExecutionExactOutput())\n",
      "def straight_through_estimator():\n",
      "    import jax\n",
      "    import jax.numpy as jnp\n",
      "    \n",
      "    def f(x):\n",
      "        return jnp.round(x)  # non-differentiable\n",
      "\n",
      "    def straight_through_f(x):\n",
      "        # Create an exactly-zero expression with Sterbenz lemma that has\n",
      "        # an exactly-one gradient.\n",
      "        zero = x - jax.lax.stop_gradient(x)\n",
      "        return zero + jax.lax.stop_gradient(f(x))\n",
      "\n",
      "    print(\"f(x): \", f(3.2))\n",
      "    print(\"straight_through_f(x):\", straight_through_f(3.2))\n",
      "\n",
      "    print(\"grad(f)(x):\", jax.grad(f)(3.2))\n",
      "    print(\"grad(straight_through_f)(x):\", jax.grad(straight_through_f)(3.2))\n",
      "\n",
      "WARNING: This code was submitted by a User and could be UNSAFE.\n",
      "syft.service.code.user_code.UserCodeExecutionResult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exec_result=syft.service.code.user_code.UserCodeExecutionResult\n",
      "action_object=Pointer:\n",
      "syft.service.code.user_code.UserCodeExecutionResult\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message='Request a6faa675879d48308d92829dfb258e73 changes applied'\n",
      "higher_order_derivatives\n",
      "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
      "                  output_policy=sy.SingleExecutionExactOutput())\n",
      "def higher_order_derivatives():\n",
      "    import jax\n",
      "    f = lambda x: x**3 + 2*x**2 - 3*x + 1\n",
      "\n",
      "    dfdx = jax.grad(f)\n",
      "    d2fdx = jax.grad(dfdx)\n",
      "    d3fdx = jax.grad(d2fdx)\n",
      "    d4fdx = jax.grad(d3fdx)\n",
      "    \n",
      "    print(dfdx(1.))\n",
      "    print(d2fdx(1.))\n",
      "    print(d3fdx(1.))\n",
      "    print(d4fdx(1.))\n",
      "\n",
      "WARNING: This code was submitted by a User and could be UNSAFE.\n",
      "syft.service.code.user_code.UserCodeExecutionResult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exec_result=syft.service.code.user_code.UserCodeExecutionResult\n",
      "action_object=Pointer:\n",
      "syft.service.code.user_code.UserCodeExecutionResult\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message='Request c33c7abf37884e10a2cd9c98e87b7e99 changes applied'\n",
      "stopping_gradients\n",
      "@sy.syft_function(input_policy=sy.ExactMatch(),\n",
      "                  output_policy=sy.SingleExecutionExactOutput())\n",
      "def stopping_gradients():\n",
      "    import jax\n",
      "    import jax.numpy as jnp\n",
      "    \n",
      "    # Value function and initial parameters\n",
      "    value_fn = lambda theta, state: jnp.dot(theta, state)\n",
      "    theta = jnp.array([0.1, -0.1, 0.])\n",
      "    \n",
      "    # An example transition.\n",
      "    s_tm1 = jnp.array([1., 2., -1.])\n",
      "    r_t = jnp.array(1.)\n",
      "    s_t = jnp.array([2., 1., 0.])\n",
      "\n",
      "    def td_loss(theta, s_tm1, r_t, s_t):\n",
      "        v_tm1 = value_fn(theta, s_tm1)\n",
      "        target = r_t + value_fn(theta, s_t)\n",
      "        return (target - v_tm1) ** 2\n",
      "\n",
      "    td_update = jax.grad(td_loss)\n",
      "    delta_theta = td_update(theta, s_tm1, r_t, s_t)\n",
      "\n",
      "    print(\"Pseudo naive loss\", delta_theta)\n",
      "    \n",
      "    def td_loss(theta, s_tm1, r_t, s_t):\n",
      "        v_tm1 = value_fn(theta, s_tm1)\n",
      "        target = r_t + value_fn(theta, s_t)\n",
      "        return (jax.lax.stop_gradient(target) - v_tm1) ** 2\n",
      "\n",
      "    td_update = jax.grad(td_loss)\n",
      "    delta_theta = td_update(theta, s_tm1, r_t, s_t)\n",
      "\n",
      "    print(\"Correct loss\", delta_theta)\n",
      "    \n",
      "    perex_grads = jax.jit(jax.vmap(jax.grad(td_loss), in_axes=(None, 0, 0, 0)))\n",
      "\n",
      "    # Test it:\n",
      "    batched_s_tm1 = jnp.stack([s_tm1, s_tm1])\n",
      "    batched_r_t = jnp.stack([r_t, r_t])\n",
      "    batched_s_t = jnp.stack([s_t, s_t])\n",
      "\n",
      "    print(\"Per example grads\", perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t))\n",
      "\n",
      "    dtdloss_dtheta = jax.grad(td_loss)\n",
      "\n",
      "    print(\"Gradient loss on unbatched inputs\", dtdloss_dtheta(theta, s_tm1, r_t, s_t))\n",
      "\n",
      "    almost_perex_grads = jax.vmap(dtdloss_dtheta)\n",
      "\n",
      "    batched_theta = jnp.stack([theta, theta])\n",
      "    member_gradient = almost_perex_grads(batched_theta, batched_s_tm1, batched_r_t, batched_s_t)\n",
      "    print(\"Gradient for on member of a batch\", member_gradient)\n",
      "\n",
      "    inefficient_perex_grads = jax.vmap(dtdloss_dtheta, in_axes=(None, 0, 0, 0))\n",
      "    grads = inefficient_perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t)\n",
      "    print(\"Inefficient gradients\", grads)\n",
      "    \n",
      "    perex_grads = jax.jit(inefficient_perex_grads)\n",
      "    grads = perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t)\n",
      "    print(\"Efficient gradients\", grads)\n",
      "    \n",
      "    get_ipython().run_line_magic('timeit', 'inefficient_perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t).block_until_ready()')\n",
      "    get_ipython().run_line_magic('timeit', 'perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t).block_until_ready()')\n",
      "\n",
      "WARNING: This code was submitted by a User and could be UNSAFE.\n",
      "syft.service.code.user_code.UserCodeExecutionResult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exec_result=syft.service.code.user_code.UserCodeExecutionResult\n",
      "action_object=Pointer:\n",
      "syft.service.code.user_code.UserCodeExecutionResult\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message='Request c7ad57e183ed4c259eadf87c02fe9e53 changes applied'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helpers import review_request, run_submitted_function, accept_request\n",
    "\n",
    "for message in messages:\n",
    "    review_request(message)\n",
    "    real_result = run_submitted_function(message)\n",
    "    accept_request(message, real_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Downloading the Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial complete üëè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_scientist_client.api.services.code.higher_order_derivatives()\n",
    "assert not isinstance(result, sy.SyftError)\n",
    "\n",
    "result = data_scientist_client.api.services.code.stopping_gradients()\n",
    "assert not isinstance(result, sy.SyftError)\n",
    "\n",
    "result = data_scientist_client.api.services.code.straight_through_estimator()\n",
    "assert not isinstance(result, sy.SyftError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if node.node_type.value == \"python\":\n",
    "    node.land()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
