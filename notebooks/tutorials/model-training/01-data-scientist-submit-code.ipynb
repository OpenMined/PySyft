{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# syft absolute\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. DS logins to the domain with the credentials created by the DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = sy.orchestra.launch(name=\"mnist-domain\", dev_mode=True)\n",
    "ds_client = node.login(email=\"sheldon@caltech.edu\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Inspect the datasets on the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ds_client.datasets.get_all()\n",
    "assert len(datasets) == 1\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = datasets[0].assets\n",
    "assert len(assets) == 2\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = assets[0]\n",
    "training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = assets[1]\n",
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### The DS can not access the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert training_images.data is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### The DS can only access the mock data, which is some random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_images = training_images.mock\n",
    "plt.imshow(np.reshape(mock_images[0], (28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### We need the pointers to the mock data to construct a `syft` function (later in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_images_ptr = training_images.pointer\n",
    "mock_images_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mock_images_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_labels = training_labels.mock\n",
    "mock_labels_ptr = training_labels.pointer\n",
    "mock_labels_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 2. The DS prepare the training code and experiment on the mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_3_linear_layers(mnist_images, mnist_labels):\n",
    "    # import the packages\n",
    "    # stdlib\n",
    "    import itertools\n",
    "    import time\n",
    "\n",
    "    # third party\n",
    "    from jax import grad\n",
    "    from jax import jit\n",
    "    from jax import random\n",
    "    from jax.example_libraries import optimizers\n",
    "    from jax.example_libraries import stax\n",
    "    from jax.example_libraries.stax import Dense\n",
    "    from jax.example_libraries.stax import LogSoftmax\n",
    "    from jax.example_libraries.stax import Relu\n",
    "    import jax.numpy as jnp\n",
    "    import numpy.random as npr\n",
    "\n",
    "    # define the neural network\n",
    "    init_random_params, predict = stax.serial(\n",
    "        Dense(1024), Relu, Dense(1024), Relu, Dense(10), LogSoftmax\n",
    "    )\n",
    "\n",
    "    # initialize the random parameters\n",
    "    rng = random.PRNGKey(0)\n",
    "    _, init_params = init_random_params(rng, (-1, 784))\n",
    "\n",
    "    # the hyper parameters\n",
    "    num_epochs = 10\n",
    "    batch_size = 4\n",
    "    num_train = mnist_images.shape[0]\n",
    "    num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "    num_batches = num_complete_batches + bool(leftover)\n",
    "    step_size = 0.001\n",
    "    momentum_mass = 0.9\n",
    "\n",
    "    # initialize the optimizer\n",
    "    opt_init, opt_update, get_params = optimizers.momentum(\n",
    "        step_size, mass=momentum_mass\n",
    "    )\n",
    "    opt_state = opt_init(init_params)\n",
    "    itercount = itertools.count()\n",
    "\n",
    "    @jit\n",
    "    def update(i, opt_state, batch):\n",
    "        params = get_params(opt_state)\n",
    "        return opt_update(i, grad(loss)(params, batch), opt_state)\n",
    "\n",
    "    def data_stream():\n",
    "        \"\"\"\n",
    "        Create a batch of data picked randomly\n",
    "        \"\"\"\n",
    "        rng = npr.RandomState(0)\n",
    "        while True:\n",
    "            perm = rng.permutation(num_train)\n",
    "            for i in range(num_batches):\n",
    "                batch_idx = perm[i * batch_size : (i + 1) * batch_size]\n",
    "                yield mnist_images[batch_idx], mnist_labels[batch_idx]\n",
    "\n",
    "    def loss(params, batch):\n",
    "        inputs, targets = batch\n",
    "        preds = predict(params, inputs)\n",
    "        return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "\n",
    "    def accuracy(params, batch):\n",
    "        inputs, targets = batch\n",
    "        target_class = jnp.argmax(targets, axis=1)\n",
    "        predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
    "        return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "    batches = data_stream()\n",
    "    train_accs = []\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_batches):\n",
    "            opt_state = update(next(itercount), opt_state, next(batches))\n",
    "        epoch_time = time.time() - start_time\n",
    "        params = get_params(opt_state)\n",
    "        train_acc = accuracy(params, (mnist_images, mnist_labels))\n",
    "        print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
    "        print(f\"Training set accuracy {train_acc}\")\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "    return train_accs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs, params = mnist_3_linear_layers(\n",
    "    mnist_images=mock_images, mnist_labels=mock_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Inspect the training accuracies and the shape of the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 3. Now that the code works on mock data, the DS submits the code request for execution to the DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### First the DS wraps the training function with the `@sy.syft_function` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.syft_function(\n",
    "    input_policy=sy.ExactMatch(\n",
    "        mnist_images=mock_images_ptr, mnist_labels=mock_labels_ptr\n",
    "    ),\n",
    "    output_policy=sy.SingleExecutionExactOutput(),\n",
    ")\n",
    "def mnist_3_linear_layers(mnist_images, mnist_labels):\n",
    "    # import the packages\n",
    "    # stdlib\n",
    "    import itertools\n",
    "    import time\n",
    "\n",
    "    # third party\n",
    "    from jax import grad\n",
    "    from jax import jit\n",
    "    from jax import random\n",
    "    from jax.example_libraries import optimizers\n",
    "    from jax.example_libraries import stax\n",
    "    from jax.example_libraries.stax import Dense\n",
    "    from jax.example_libraries.stax import LogSoftmax\n",
    "    from jax.example_libraries.stax import Relu\n",
    "    import jax.numpy as jnp\n",
    "    import numpy.random as npr\n",
    "\n",
    "    # define the neural network\n",
    "    init_random_params, predict = stax.serial(\n",
    "        Dense(1024), Relu, Dense(1024), Relu, Dense(10), LogSoftmax\n",
    "    )\n",
    "\n",
    "    # initialize the random parameters\n",
    "    rng = random.PRNGKey(0)\n",
    "    _, init_params = init_random_params(rng, (-1, 784))\n",
    "\n",
    "    # the hyper parameters\n",
    "    num_epochs = 10\n",
    "    batch_size = 4\n",
    "    num_train = mnist_images.shape[0]\n",
    "    num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "    num_batches = num_complete_batches + bool(leftover)\n",
    "    step_size = 0.001\n",
    "    momentum_mass = 0.9\n",
    "\n",
    "    # initialize the optimizer\n",
    "    opt_init, opt_update, get_params = optimizers.momentum(\n",
    "        step_size, mass=momentum_mass\n",
    "    )\n",
    "    opt_state = opt_init(init_params)\n",
    "    itercount = itertools.count()\n",
    "\n",
    "    @jit\n",
    "    def update(i, opt_state, batch):\n",
    "        params = get_params(opt_state)\n",
    "        return opt_update(i, grad(loss)(params, batch), opt_state)\n",
    "\n",
    "    def data_stream():\n",
    "        \"\"\"\n",
    "        Create a batch of data picked randomly\n",
    "        \"\"\"\n",
    "        rng = npr.RandomState(0)\n",
    "        while True:\n",
    "            perm = rng.permutation(num_train)\n",
    "            for i in range(num_batches):\n",
    "                batch_idx = perm[i * batch_size : (i + 1) * batch_size]\n",
    "                yield mnist_images[batch_idx], mnist_labels[batch_idx]\n",
    "\n",
    "    def loss(params, batch):\n",
    "        inputs, targets = batch\n",
    "        preds = predict(params, inputs)\n",
    "        return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "\n",
    "    def accuracy(params, batch):\n",
    "        inputs, targets = batch\n",
    "        target_class = jnp.argmax(targets, axis=1)\n",
    "        predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
    "        return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "    batches = data_stream()\n",
    "    train_accs = []\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_batches):\n",
    "            opt_state = update(next(itercount), opt_state, next(batches))\n",
    "        epoch_time = time.time() - start_time\n",
    "        params = get_params(opt_state)\n",
    "        train_acc = accuracy(params, (mnist_images, mnist_labels))\n",
    "        print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
    "        print(f\"Training set accuracy {train_acc}\")\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "    return train_accs, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Then the DS creates a new project with relevant name and description, as well as specify itself as a member of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project = sy.Project(\n",
    "    name=\"Training a 3-layer jax neural network on MNIST data\",\n",
    "    description=\"\"\"Hi, I would like to train my neural network on your MNIST data \n",
    "                (I can download it online too but I just want to use Syft coz it's cool)\"\"\",\n",
    "    members=[ds_client],\n",
    ")\n",
    "new_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Add a code request to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project.create_code_request(obj=mnist_3_linear_layers, client=ds_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_client.code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### Start the project which will notifies the DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = new_project.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.requests[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### ðŸ““ Now switch to the [second DO's notebook](./02-data-owner-review-approve-code.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
