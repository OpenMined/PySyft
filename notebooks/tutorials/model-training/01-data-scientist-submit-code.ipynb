{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56b58a",
   "metadata": {},
   "source": [
    "## 1. DS logins to the domain with the credentials created by the DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7afb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = sy.orchestra.launch(name=\"mnist-domain\", dev_mode=True)\n",
    "ds_client = node.login(email=\"sheldon@caltech.edu\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43dfc3",
   "metadata": {},
   "source": [
    "### Inspect the datasets on the domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d096e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ds_client.datasets.get_all()\n",
    "assert len(datasets) == 1\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = datasets[0].assets\n",
    "assert len(assets) == 2\n",
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = assets[0]\n",
    "training_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = assets[1]\n",
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb7c304",
   "metadata": {},
   "source": [
    "#### The DS can not access the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert training_images.data == None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47a014",
   "metadata": {},
   "source": [
    "#### The DS can only access the mock data, which is some random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_images = training_images.mock\n",
    "plt.imshow(np.reshape(mock_images[0], (28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348580ea",
   "metadata": {},
   "source": [
    "#### We need the pointers to the mock data to construct a `syft` function (later in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19010ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_images_ptr = training_images.pointer\n",
    "mock_images_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mock_images_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2291a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_labels = training_labels.mock\n",
    "mock_labels_ptr = training_labels.pointer\n",
    "mock_labels_ptr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c87701",
   "metadata": {},
   "source": [
    "## 2. The DS prepare the training code and experiment on the mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_3_linear_layers(mnist_images, mnist_labels):\n",
    "    # import the packages\n",
    "    import jax\n",
    "    from jax.example_libraries import stax\n",
    "    from jax.example_libraries.stax import Dense, Relu, LogSoftmax\n",
    "    import time\n",
    "    from jax.example_libraries import optimizers\n",
    "    import itertools\n",
    "    import jax.numpy as jnp\n",
    "    import numpy.random as npr\n",
    "    from jax import jit, grad, random\n",
    "    \n",
    "    # define the neural network\n",
    "    init_random_params, predict = stax.serial(\n",
    "        Dense(1024), Relu,\n",
    "        Dense(1024), Relu,\n",
    "        Dense(10), LogSoftmax)\n",
    "    \n",
    "    # initialize the random parameters\n",
    "    rng = random.PRNGKey(0)\n",
    "    _, init_params = init_random_params(rng, (-1, 784))\n",
    "    \n",
    "    # the hyper parameters\n",
    "    num_epochs = 10\n",
    "    batch_size = 4\n",
    "    num_train = mnist_images.shape[0]\n",
    "    num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "    num_batches = num_complete_batches + bool(leftover)\n",
    "    step_size = 0.001\n",
    "    momentum_mass = 0.9\n",
    "    \n",
    "    # initialize the optimizer\n",
    "    opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
    "    opt_state = opt_init(init_params)\n",
    "    itercount = itertools.count()\n",
    "\n",
    "    @jit\n",
    "    def update(i, opt_state, batch):\n",
    "        params = get_params(opt_state)\n",
    "        return opt_update(i, grad(loss)(params, batch), opt_state)\n",
    "    \n",
    "    def data_stream():\n",
    "        \"\"\"\n",
    "        Create a batch of data picked randomly \n",
    "        \"\"\"\n",
    "        rng = npr.RandomState(0)\n",
    "        while True:\n",
    "            perm = rng.permutation(num_train)\n",
    "            for i in range(num_batches):\n",
    "                batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
    "                yield mnist_images[batch_idx], mnist_labels[batch_idx]\n",
    "        \n",
    "    def loss(params, batch):\n",
    "        inputs, targets = batch\n",
    "        preds = predict(params, inputs)\n",
    "        return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "\n",
    "\n",
    "    def accuracy(params, batch):\n",
    "        inputs, targets = batch\n",
    "        target_class = jnp.argmax(targets, axis=1)\n",
    "        predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
    "        return jnp.mean(predicted_class == target_class)\n",
    "    \n",
    "    batches = data_stream()\n",
    "    train_accs = []\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_batches):\n",
    "            opt_state = update(next(itercount), opt_state, next(batches))\n",
    "        epoch_time = time.time() - start_time\n",
    "        params = get_params(opt_state)\n",
    "        train_acc = accuracy(params, (mnist_images, mnist_labels))\n",
    "        print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
    "        print(f\"Training set accuracy {train_acc}\")\n",
    "        train_accs.append(train_acc)\n",
    "    \n",
    "    return train_accs, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca738a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs, params = mnist_3_linear_layers(mnist_images=mock_images, mnist_labels=mock_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549d5c4",
   "metadata": {},
   "source": [
    "#### Inspect the training accuracies and the shape of the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053eb09",
   "metadata": {},
   "source": [
    "## 3. Now that the code works on mock data, the DS submits the code request for execution to the DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42850f6c",
   "metadata": {},
   "source": [
    "#### First the DS wraps the training function with the `@sy.syft_function` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f478f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sy.syft_function(input_policy=sy.ExactMatch(mnist_images=mock_images_ptr, mnist_labels=mock_labels_ptr),\n",
    "                  output_policy=sy.SingleExecutionExactOutput())\n",
    "def mnist_3_linear_layers(mnist_images, mnist_labels):\n",
    "    # import the packages\n",
    "    import jax\n",
    "    from jax.example_libraries import stax\n",
    "    from jax.example_libraries.stax import Dense, Relu, LogSoftmax\n",
    "    import time\n",
    "    from jax.example_libraries import optimizers\n",
    "    import itertools\n",
    "    import jax.numpy as jnp\n",
    "    import numpy.random as npr\n",
    "    from jax import jit, grad, random\n",
    "    \n",
    "    # define the neural network\n",
    "    init_random_params, predict = stax.serial(\n",
    "        Dense(1024), Relu,\n",
    "        Dense(1024), Relu,\n",
    "        Dense(10), LogSoftmax)\n",
    "    \n",
    "    # initialize the random parameters\n",
    "    rng = random.PRNGKey(0)\n",
    "    _, init_params = init_random_params(rng, (-1, 784))\n",
    "    \n",
    "    # the hyper parameters\n",
    "    num_epochs = 10\n",
    "    batch_size = 4\n",
    "    num_train = mnist_images.shape[0]\n",
    "    num_complete_batches, leftover = divmod(num_train, batch_size)\n",
    "    num_batches = num_complete_batches + bool(leftover)\n",
    "    step_size = 0.001\n",
    "    momentum_mass = 0.9\n",
    "    \n",
    "    # initialize the optimizer\n",
    "    opt_init, opt_update, get_params = optimizers.momentum(step_size, mass=momentum_mass)\n",
    "    opt_state = opt_init(init_params)\n",
    "    itercount = itertools.count()\n",
    "\n",
    "    @jit\n",
    "    def update(i, opt_state, batch):\n",
    "        params = get_params(opt_state)\n",
    "        return opt_update(i, grad(loss)(params, batch), opt_state)\n",
    "    \n",
    "    def data_stream():\n",
    "        \"\"\"\n",
    "        Create a batch of data picked randomly \n",
    "        \"\"\"\n",
    "        rng = npr.RandomState(0)\n",
    "        while True:\n",
    "            perm = rng.permutation(num_train)\n",
    "            for i in range(num_batches):\n",
    "                batch_idx = perm[i * batch_size:(i + 1) * batch_size]\n",
    "                yield mnist_images[batch_idx], mnist_labels[batch_idx]\n",
    "        \n",
    "    def loss(params, batch):\n",
    "        inputs, targets = batch\n",
    "        preds = predict(params, inputs)\n",
    "        return -jnp.mean(jnp.sum(preds * targets, axis=1))\n",
    "\n",
    "\n",
    "    def accuracy(params, batch):\n",
    "        inputs, targets = batch\n",
    "        target_class = jnp.argmax(targets, axis=1)\n",
    "        predicted_class = jnp.argmax(predict(params, inputs), axis=1)\n",
    "        return jnp.mean(predicted_class == target_class)\n",
    "    \n",
    "    batches = data_stream()\n",
    "    train_accs = []\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_batches):\n",
    "            opt_state = update(next(itercount), opt_state, next(batches))\n",
    "        epoch_time = time.time() - start_time\n",
    "        params = get_params(opt_state)\n",
    "        train_acc = accuracy(params, (mnist_images, mnist_labels))\n",
    "        print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
    "        print(f\"Training set accuracy {train_acc}\")\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "    return train_accs, params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30c56b",
   "metadata": {},
   "source": [
    "#### Then the DS creates a new project with relevant name and description, as well as specify itself as a member of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project = sy.Project(\n",
    "    name=\"Training a 3-layer jax neural network on MNIST data\",\n",
    "    description=\"\"\"Hi, I would like to train my neural network on your MNIST data \n",
    "                (I can download it online too but I just want to use Syft coz it's cool)\"\"\",\n",
    "    members=[ds_client],\n",
    ") \n",
    "new_project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689429a",
   "metadata": {},
   "source": [
    "#### Add a code request to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_project.create_code_request(obj=mnist_3_linear_layers, client=ds_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da70a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_client.code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3633d2",
   "metadata": {},
   "source": [
    "#### Start the project which will notifies the DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6931df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = new_project.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3951e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.requests[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987026f3",
   "metadata": {},
   "source": [
    "### 📓 Now switch to the [second DO's notebook](./02-data-owner-review-approve-code.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47383099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
