{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22259e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/envs/syft/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CHANGE YOUR USERNAME AND PASSWORD!!! \n",
      "\n",
      "Anyone can login as an admin to your node right now because your password is still the default PySyft username and password!!!\n",
      "\n",
      "Connecting to localhost... done! \t Logging into mystifying_sophia... done!\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "\n",
    "domain_client = sy.login(\n",
    "    email=\"info@openmined.org\",\n",
    "    password=\"changethis\",\n",
    "    port=8081\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3e54d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "                #myInput {\n",
       "                  background-position: 10px 12px; /* Position the search icon */\n",
       "                  background-repeat: no-repeat; /* Do not repeat the icon image */\n",
       "                  background-color: #bbb;\n",
       "                  width: 98%; /* Full-width */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                  padding: 12px 20px 12px 40px; /* Add some padding */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  margin-bottom: 12px; /* Add some space below the input */\n",
       "                }\n",
       "\n",
       "                #myTable {\n",
       "                  border-collapse: collapse; /* Collapse borders */\n",
       "                  width: 100%; /* Full-width */\n",
       "                  border: 1px solid #ddd; /* Add a grey border */\n",
       "                  font-size: 14px; /* Increase font-size */\n",
       "                }\n",
       "\n",
       "                #myTable th, #myTable td {\n",
       "                  text-align: left; /* Left-align text */\n",
       "                  padding: 10px; /* Add padding */\n",
       "                }\n",
       "\n",
       "                #myTable tr {\n",
       "                  /* Add a bottom border to all table rows */\n",
       "                  border-bottom: 1px solid #ddd;\n",
       "                }\n",
       "\n",
       "                #myTable tr.header, #myTable tr:hover {\n",
       "                  /* Add a grey background color to the table header and on hover */\n",
       "                  background-color: #777;\n",
       "                }\n",
       "                </style>\n",
       "\n",
       "                <table id=\"myTable\" style=\"width:1000px\">\n",
       "                  <tr class=\"header\">\n",
       "                    <th style=\"width:30px\">Idx</th>\n",
       "                    <th style=\"width:20%;\">Name</th>\n",
       "                    <th style=\"width:35%;\">Description</th>\n",
       "                    <th style=\"width:20%;\">Assets</th>\n",
       "                    <th style=\"width:300px;\">Id</th>\n",
       "                  </tr>\n",
       "                \n",
       "\n",
       "          <tr>\n",
       "            <td>[0]</td>\n",
       "            <td>BreastCancerDataset</td>\n",
       "            <td>Invasive Ductal Carcinoma (IDC) is the most common subtype of all breast cancers.     The modified dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x.     Patches of size 50 x 50 were extracted from the original image. The labels 0 is non-IDC and 1 is IDC.</td>\n",
       "            <td>[\"train_images\"] -> <class 'syft.core.tensor.tensor.Tensor'><br /><br />[\"train_labels\"] -> <class 'syft.core.tensor.tensor.Tensor'><br /><br /></td>\n",
       "            <td>bc534f80-df34-4475-b385-96ed41d02d38</td>\n",
       "          </tr>\n",
       "\n",
       "          <tr>\n",
       "            <td>[1]</td>\n",
       "            <td>BreastCancerDataset2</td>\n",
       "            <td>Invasive Ductal Carcinoma (IDC) is the most common subtype of all breast cancers.     The modified dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x.     Patches of size 50 x 50 were extracted from the original image. The labels 0 is non-IDC and 1 is IDC.</td>\n",
       "            <td>[\"train_images\"] -> <class 'syft.core.tensor.tensor.Tensor'><br /><br />[\"train_labels\"] -> <class 'syft.core.tensor.tensor.Tensor'><br /><br /></td>\n",
       "            <td>31378d5d-98c3-431f-ad47-8c815b91f93f</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "\n",
       "        <script>\n",
       "        function myFunction() {\n",
       "          // Declare variables\n",
       "          var input, filter, table, tr, td, i, txtValue;\n",
       "          input = document.getElementById(\"myInput\");\n",
       "          filter = input.value.toUpperCase();\n",
       "          table = document.getElementById(\"myTable\");\n",
       "          tr = table.getElementsByTagName(\"tr\");\n",
       "\n",
       "          // Loop through all table rows, and hide those who don't match the search query\n",
       "          for (i = 0; i < tr.length; i++) {\n",
       "            name_td = tr[i].getElementsByTagName(\"td\")[1];\n",
       "            desc_td = tr[i].getElementsByTagName(\"td\")[2];\n",
       "            asset_td = tr[i].getElementsByTagName(\"td\")[3];\n",
       "            id_td = tr[i].getElementsByTagName(\"td\")[4];\n",
       "            if (name_td || desc_td || asset_td || id_td) {\n",
       "              name_txtValue = name_td.textContent || name_td.innerText;\n",
       "              desc_txtValue = desc_td.textContent || name_td.innerText;\n",
       "              asset_txtValue = asset_td.textContent || name_td.innerText;\n",
       "              id_txtValue = id_td.textContent || name_td.innerText;\n",
       "              name_bool = name_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              desc_bool = desc_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              asset_bool = asset_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              id_bool = id_txtValue.toUpperCase().indexOf(filter) > -1;\n",
       "              if (name_bool || desc_bool || asset_bool || id_bool) {\n",
       "                tr[i].style.display = \"\";\n",
       "              } else {\n",
       "                tr[i].style.display = \"none\";\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<syft.core.node.common.client_manager.dataset_api.DatasetRequestAPI at 0x7fd04adc3d00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_client.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b261a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = domain_client.datasets[1][\"train_images\"]\n",
    "labels = domain_client.datasets[1][\"train_labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e660bfe1",
   "metadata": {},
   "source": [
    "## User Flows for Remote Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc9682",
   "metadata": {},
   "source": [
    "### I. Create Whole Model Remotely\n",
    "\n",
    "1. User creates a remote model. This sends an empty model class to domain and returns a model pointer.\n",
    "\n",
    "```python\n",
    "from syft.core.tensor import nn\n",
    "\n",
    "model_ptr = nn.Model(to=domain)\n",
    "```\n",
    "\n",
    "2. All operations here now are on the model pointer. Each operation results in a new pointer\n",
    "\n",
    "```python\n",
    "model_ptr.add(nn.Convolution(1, (3, 3), input_shape=(None, 1, 28, 28)))\n",
    "model_ptr.add(nn.MaxPool((2, 2)))\n",
    "model_ptr.add(nn.Convolution(2, (4, 4)))\n",
    "model_ptr.add(nn.MaxPool((2, 2)))\n",
    "model_ptr = model_ptr.compile(to=domain, loss=BinaryCrossEntropy(), optimizer=Adamax())\n",
    "```\n",
    "\n",
    "3. User calls .fit method on the model pointer and passes image_ptr and label_ptr as inputs\n",
    "\n",
    "```python\n",
    "model_ptr.fit(X_train_ptr, y_train_ptr, max_iter=10, validation_split=0.1, batch_size=100)\n",
    "```\n",
    "4. User call .weights methods to get weights pointer\n",
    "\n",
    "```python\n",
    "model_weights_ptr = model_ptr.weights()\n",
    "published_weights = model_weights.publish()\n",
    "public_weights = published_weights.get()\n",
    "```\n",
    "\n",
    "#### Pros and Cons\n",
    "------------------\n",
    "- One drawback is that this will be computationally costly in terms of requests time, since we will be sending a new request each time we perfom an operation like adding layers, compile, fit, etc. on the model_ptr. And serialization and deserialization of the model stored in database w.r.t to the model pointer would be addon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d892665",
   "metadata": {},
   "source": [
    "### II. Create Model locally and train remotely\n",
    "\n",
    "1. User creates the model locally\n",
    "\n",
    "```python\n",
    "from syft.core.tensor import nn\n",
    "\n",
    "model_net = nn.Model()\n",
    "model_net.add(nn.Convolution(1, (3, 3), input_shape=(None, 1, 28, 28)))\n",
    "model_net.add(nn.MaxPool((2, 2)))\n",
    "model_net.add(nn.Convolution(2, (4, 4)))\n",
    "model_net.add(nn.MaxPool((2, 2)))\n",
    "```\n",
    "\n",
    "2. User call .compile to initialize model. This sends the model to domain and returns a model pointer.\n",
    "\n",
    "```python\n",
    "model_ptr = model_net.compile(to=domain, loss=BinaryCrossEntropy(), optimizer=Adamax())\n",
    "```\n",
    "\n",
    "3. User calls .fit method on the model pointer and passes image_ptr and label_ptr as inputs\n",
    "```python\n",
    "model_ptr.fit(X_train_ptr, y_train_ptr, max_iter=10, validation_split=0.1, batch_size=100)\n",
    "```\n",
    "\n",
    "4. Monitor training progress. This prints information like {\"loss\": \"\", \"epoch\": \"\", .....}\n",
    "```python\n",
    "model_ptr.progress()\n",
    "```\n",
    "\n",
    "\n",
    "5. User call .weights methods to get weights pointer\n",
    "\n",
    "```python\n",
    "model_weights_ptr = model_ptr.weights()\n",
    "published_weights = model_weights.publish()\n",
    "public_weights = published_weights.get()\n",
    "```\n",
    "\n",
    "\n",
    "#### Pros and Cons\n",
    "-----------------\n",
    "- User creates the model locally, so changes to model is faster. And they only send the model to domain (to receive a model ptr) when they call .compile ( which is equivalent to model weights initialization).\n",
    "- We may need to track progress of each remote epoch and convey the same to the user during .fit operation. One easy way is to save details of each epoch in DB and create a progress endpoint to access it to via the python client, which we can poll from at regular intervals.\n",
    "- The .fit method hides all code complexity, so more niche customization will be not possible. Although, we may extend this later. So building a high level APIs like keras and later providing more low level, later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea243e3b",
   "metadata": {},
   "source": [
    "### III. Create Model locally and train remote but only per epoch\n",
    "\n",
    "1. User creates the model locally.\n",
    "\n",
    "```python\n",
    "from syft.core.tensor import nn\n",
    "\n",
    "model_net = nn.Model()\n",
    "model_net.add(nn.Convolution(1, (3, 3), input_shape=(None, 1, 28, 28)))\n",
    "model_net.add(nn.MaxPool((2, 2)))\n",
    "model_net.add(nn.Convolution(2, (4, 4)))\n",
    "model_net.add(nn.MaxPool((2, 2)))\n",
    "```\n",
    "\n",
    "2. User call .compile to initialize model. This sends the model to domain and returns a model pointer.\n",
    "\n",
    "```python\n",
    "model_ptr = model_net.compile(to=domain)\n",
    "```\n",
    "\n",
    "3. User calls .step method on the model pointer and loops through batches of data. Each step call will predict, calculate loss, backpropogate and update optimizer but only for one image. We keep track of total loss and total predictions, we can return them later.\n",
    "\n",
    "```python\n",
    "\n",
    "batch_size = 32\n",
    "rows = train_Y.public_shape[0]\n",
    "epochs = 10\n",
    "\n",
    "loss, preds = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(rows // batch_size):\n",
    "        batch_begin = i * batch_size\n",
    "        batch_end = batch_begin + batch_size\n",
    "        x_batch_ptr = train_X_ptr[batch_begin:batch_end]\n",
    "        y_batch_ptr = train_Y_ptr[batch_begin:batch_end]\n",
    "\n",
    "        loss, preds_ptr = model_ptr.step(\n",
    "            x_batch_ptr, \n",
    "            y_batch_ptr, \n",
    "            validation_split=0.1, \n",
    "            batch_size=100\n",
    "        )\n",
    "        loss.append(loss)\n",
    "```\n",
    "4. User call .weights methods to get weights pointer\n",
    "\n",
    "```python\n",
    "model_weights_ptr = model_ptr.weights()\n",
    "published_weights = model_weights.publish()\n",
    "public_weights = published_weights.get()\n",
    "```\n",
    "\n",
    "#### Pros and Cons\n",
    "-----------------\n",
    "- User has more control on till what point they want to train their model.\n",
    "- User creates the model locally, so changes to model is faster. And they only send the model to domain (to receive a model ptr) when they call .compile ( which is equivalent to model weights initialization).\n",
    "- No need to track progress.\n",
    "- Getting predictions at each stage, user can select which predictions to keep.\n",
    "- Tracking total_preds and total_loss will add to storage.\n",
    "- Added networking overload at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35116b",
   "metadata": {},
   "source": [
    "### Make publish fast on model weights download: Dynamic PB Tracking of Model Weights\n",
    "\n",
    "- Instead of calculating PB and everything at model_weights.publish i.e. the end, which will be computationally expensive, we can keep tracking the privacy budget at each step.\n",
    "- We will keep of PB spend against the model weights at each backprop in the database.\n",
    "- So when the user calls model_weights_ptr.publish(), we can simply deduct the PB and return the weights. Which would be quick.\n",
    "\n",
    "This is similar to adding items to your cart in Amazon. Let's assume items are model weights and PB is cost of an item. For now assume, we either buy all items or None of them. Adding an item to your cart is like equivalent to running one round of forward and backward prop and calculating PB spent for one round against the model weights.\n",
    "So, we may add x items to the cart (run model for x iterations) but never choose to checkout (never perform publish on the model_weights, in which case the calculated PB is never used). But if user chooses to do checkout we can quickly calculate total amount because we already have calculated the amount on each item addition. (In case of model training, we already have PB calculated at each step, so final step PB is quick and fast).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dbae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
