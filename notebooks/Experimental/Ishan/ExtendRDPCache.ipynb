{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc607758-e523-4a53-baf7-235bf8203ae1",
   "metadata": {},
   "source": [
    "The goal of this notebook is to extend the RDP cache. At the moment the minimum possible PB spend for a query is 7.766, which is far too high.\n",
    "\n",
    "Constraints:\n",
    "- 300k values in an .npy file = 2.3MB. Assuming it scales linearly, we could probably offer 1.2M cached values in ~9.2MB.\n",
    "    - 10,000 numbers between rdp_constant of 0 and 1, 10,000 between 1 and 2, this should let us get to a max RDP_constant of around 1.2e6/1e4 = 120 which corresponds to an epsilon spend of ~200\n",
    "    - however at this point the differences between adjacent integer epsilon values is >1% (i.e. rdp of 118 = 197.858, 119 = 199.195, of 120 = 200.530)\n",
    "- We want very high coverage of epsilon values from 0 to ~5 as these queries would have very strong privacy\n",
    "    - the difference in epsilon spent at high RDP Constants seems to be very small (i.e. for an RDP constant of 120, the epsilon spent is 200.53. For 119, it's 119.195, for 121, it's 201.86). So perhaps we could have regions with variable levels of granularity/resolution (i.e., cache is more populated for smaller RDP constants, and rounds to the nearest integer for higher RDP constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf8e073-2d63-4e1a-bb47-ff93218ae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a3bcd-e2f7-4deb-8a09-433ae3a76bb8",
   "metadata": {},
   "source": [
    "## Find rough ballpark numbers\n",
    "\n",
    "Let's find at which RDP constants the epsilon spend exceeds -> 0.1, 1, 5, 10, 100, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330d4dba-757b-4bb3-8561-2ac06fd58c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n"
     ]
    }
   ],
   "source": [
    "current_cache = np.load(\"/home/e/PycharmProjects/PySyft/packages/syft/src/syft/cache/constant2epsilon_300k.npy\")\n",
    "print(len(current_cache))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afa4a4e0-2a71-44f2-9053-fdfb63de7696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsilon spend >= 10 in index=1 with a value=11.688596249354894'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowest_index_with_epsilon_spend_of(eps_spend):\n",
    "    for index, value in enumerate(current_cache):\n",
    "        if value > eps_spend:\n",
    "            return f\"epsilon spend >= {eps_spend} in index={index} with a value={value}\"\n",
    "lowest_index_with_epsilon_spend_of(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ac70d40d-2705-408d-884e-b8033e6795c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsilon spend >= 100 in index=49 with a value=100.68990516105823'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_index_with_epsilon_spend_of(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5191544d-ae8d-465c-9cc2-e85bf70bd784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsilon spend >= 200 in index=120 with a value=200.53014130518943'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_index_with_epsilon_spend_of(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf14148-1d37-486a-a898-b92c6d79270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.core.adp.data_subject_ledger import DataSubjectLedger as DSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f3ae00-629e-4aea-a419-840a7603c1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[syft.core.adp.data_subject_ledger.DataSubjectLedger,\n",
       " syft.core.adp.abstract_ledger_store.AbstractDataSubjectLedger,\n",
       " object]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSL.mro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b1cc5d9-59ed-4e65-a7f6-59453e2b693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future\n",
    "from __future__ import annotations\n",
    "\n",
    "# stdlib\n",
    "from functools import partial\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Any\n",
    "from typing import Callable\n",
    "from typing import Optional\n",
    "from typing import TYPE_CHECKING\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc5b0ce-0f39-49dd-9340-0e1a5cc27f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "from typing_extensions import Final\n",
    "\n",
    "# relative\n",
    "# from ...logger import info\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    # stdlib\n",
    "    from dataclasses import dataclass\n",
    "else:\n",
    "    from flax.struct import dataclass\n",
    "\n",
    "# third party\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from nacl.signing import VerifyKey\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4082ac-3215-4c6e-a7d0-29a2505f74e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# relative\n",
    "from ...core.node.common.node_manager.user_manager import RefreshBudgetException\n",
    "from ...lib.numpy.array import capnp_deserialize\n",
    "from ...lib.numpy.array import capnp_serialize\n",
    "from ..common.serde.capnp import CapnpModule\n",
    "from ..common.serde.capnp import get_capnp_schema\n",
    "from ..common.serde.capnp import serde_magic_header\n",
    "from ..common.serde.serializable import serializable\n",
    "from .abstract_ledger_store import AbstractDataSubjectLedger\n",
    "from .abstract_ledger_store import AbstractLedgerStore\n",
    "\n",
    "\n",
    "def get_cache_path(cache_filename: str) -> str:\n",
    "    here = os.path.dirname(__file__)\n",
    "    root_dir = Path(here) / \"..\" / \"..\" / \"cache\"\n",
    "    return os.path.abspath(root_dir / cache_filename)\n",
    "\n",
    "\n",
    "def load_cache(filename: str) -> np.ndarray:\n",
    "    CACHE_PATH = get_cache_path(filename)\n",
    "    if not os.path.exists(CACHE_PATH):\n",
    "        raise Exception(f\"Cannot load {CACHE_PATH}\")\n",
    "    cache_array = np.load(CACHE_PATH)\n",
    "    info(f\"Loaded constant2epsilon cache of size: {cache_array.shape}\")\n",
    "    return cache_array\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RDPParams:\n",
    "    sigmas: jnp.array\n",
    "    l2_norms: jnp.array\n",
    "    l2_norm_bounds: jnp.array\n",
    "    Ls: jnp.array\n",
    "    coeffs: jnp.array\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        res = \"RDPParams:\"\n",
    "        res = f\"{res}\\n sigmas:{self.sigmas}\"\n",
    "        res = f\"{res}\\n l2_norms:{self.l2_norms}\"\n",
    "        res = f\"{res}\\n l2_norm_bounds:{self.l2_norm_bounds}\"\n",
    "        res = f\"{res}\\n Ls:{self.Ls}\"\n",
    "        res = f\"{res}\\n coeffs:{self.coeffs}\"\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=3, donate_argnums=(1, 2))\n",
    "def first_try_branch(\n",
    "    constant: jax.numpy.DeviceArray,\n",
    "    rdp_constants: np.ndarray,\n",
    "    entity_ids_query: np.ndarray,\n",
    "    max_entity: int,\n",
    ") -> jax.numpy.DeviceArray:\n",
    "    summed_constant = constant.take(entity_ids_query) + rdp_constants.take(\n",
    "        entity_ids_query\n",
    "    )\n",
    "    if max_entity < len(rdp_constants):\n",
    "        return rdp_constants.at[entity_ids_query].set(summed_constant)\n",
    "    else:\n",
    "        pad_length = max_entity - len(rdp_constants) + 1\n",
    "        rdp_constants = jnp.concatenate([rdp_constants, jnp.zeros(shape=pad_length)])\n",
    "        summed_constant = constant + rdp_constants.take(entity_ids_query)\n",
    "        return rdp_constants.at[entity_ids_query].set(summed_constant)\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=1)\n",
    "def compute_rdp_constant(rdp_params: RDPParams, private: bool) -> jax.numpy.DeviceArray:\n",
    "    squared_Ls = rdp_params.Ls**2\n",
    "    squared_sigma = rdp_params.sigmas**2\n",
    "\n",
    "    if private:\n",
    "        # this is calculated on the private true values\n",
    "        squared_l2 = rdp_params.l2_norms**2\n",
    "    else:\n",
    "        # bounds is computed on the metadata\n",
    "        squared_l2 = rdp_params.l2_norm_bounds**2\n",
    "\n",
    "    return (squared_Ls * squared_l2 / (2 * squared_sigma)) * rdp_params.coeffs\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_budgets_and_mask(\n",
    "    epsilon_spend: jnp.array, user_budget: jnp.float64\n",
    ") -> Tuple[float, float, jax.numpy.DeviceArray]:\n",
    "    # Function to vectorize the result of the budget computation.\n",
    "    mask = jnp.ones_like(epsilon_spend) * user_budget < epsilon_spend\n",
    "    # get the highest value which was under budget and represented by False in the mask\n",
    "    highest_possible_spend = jnp.max(epsilon_spend * (1 - mask))\n",
    "    return (highest_possible_spend, user_budget, mask)\n",
    "\n",
    "\n",
    "@serializable(capnp_bytes=True)\n",
    "class DataSubjectLedger(AbstractDataSubjectLedger):\n",
    "    \"\"\"for a particular data subject, this is the list\n",
    "    of all mechanisms releasing informationo about this\n",
    "    particular subject, stored in a vectorized form\"\"\"\n",
    "\n",
    "    CONSTANT2EPSILSON_CACHE_FILENAME = \"constant2epsilon_300k.npy\"\n",
    "    _cache_constant2epsilon = load_cache(filename=CONSTANT2EPSILSON_CACHE_FILENAME)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        constants: Optional[np.ndarray] = None,\n",
    "        update_number: int = 0,\n",
    "        timestamp_of_last_update: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        self._rdp_constants = (\n",
    "            constants if constants is not None else np.array([], dtype=np.float64)\n",
    "        )\n",
    "        self._update_number = update_number\n",
    "        self._timestamp_of_last_update = (\n",
    "            timestamp_of_last_update\n",
    "            if timestamp_of_last_update is not None\n",
    "            else time.time()\n",
    "        )\n",
    "        self._pending_save = False\n",
    "\n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, DataSubjectLedger):\n",
    "            return self == other\n",
    "        return (\n",
    "            self._update_number == other._update_number\n",
    "            and self._timestamp_of_last_update == other._timestamp_of_last_update\n",
    "            and all(self._rdp_constants == other._rdp_constants)\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def delta(self) -> float:\n",
    "        FIXED_DELTA: Final = 1e-6\n",
    "        return FIXED_DELTA  # WARNING: CHANGING DELTA INVALIDATES THE CACHE\n",
    "\n",
    "    def bind_to_store_with_key(\n",
    "        self, store: AbstractLedgerStore, user_key: VerifyKey\n",
    "    ) -> None:\n",
    "        self.store = store\n",
    "        self.user_key = user_key\n",
    "\n",
    "    @staticmethod\n",
    "    def get_or_create(\n",
    "        store: AbstractLedgerStore, user_key: VerifyKey\n",
    "    ) -> Optional[AbstractDataSubjectLedger]:\n",
    "        ledger: Optional[AbstractDataSubjectLedger] = None\n",
    "        try:\n",
    "            # todo change user_key or uid?\n",
    "            ledger = store.get(key=user_key)\n",
    "            ledger.bind_to_store_with_key(store=store, user_key=user_key)\n",
    "        except KeyError:\n",
    "            print(\"Creating new Ledger\")\n",
    "            ledger = DataSubjectLedger()\n",
    "            ledger.bind_to_store_with_key(store=store, user_key=user_key)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read ledger from ledger store. {e}\")\n",
    "\n",
    "        return ledger\n",
    "\n",
    "    def get_entity_overbudget_mask_for_epsilon_and_append(\n",
    "        self,\n",
    "        unique_entity_ids_query: np.ndarray,\n",
    "        rdp_params: RDPParams,\n",
    "        get_budget_for_user: Callable,\n",
    "        deduct_epsilon_for_user: Callable,\n",
    "        private: bool = True,\n",
    "    ) -> np.ndarray:\n",
    "        # coerce to np.int64\n",
    "        entity_ids_query: np.ndarray = unique_entity_ids_query.astype(np.int64)\n",
    "        # calculate constants\n",
    "        rdp_constants = self._get_batch_rdp_constants(\n",
    "            entity_ids_query=entity_ids_query, rdp_params=rdp_params, private=private\n",
    "        )\n",
    "\n",
    "        # here we iteratively attempt to calculate the overbudget mask and save\n",
    "        # changes to the database\n",
    "        mask = self._get_overbudgeted_entities(\n",
    "            get_budget_for_user=get_budget_for_user,\n",
    "            deduct_epsilon_for_user=deduct_epsilon_for_user,\n",
    "            rdp_constants=rdp_constants,\n",
    "        )\n",
    "\n",
    "        # at this point we are confident that the database budget field has been updated\n",
    "        # so now we should flush the _rdp_constants that we have calculated to storage\n",
    "        if self._write_ledger():\n",
    "            return mask\n",
    "\n",
    "    def _write_ledger(self) -> bool:\n",
    "\n",
    "        self._update_number += 1\n",
    "        try:\n",
    "            self._pending_save = False\n",
    "            self.store.set(key=self.user_key, value=self)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self._pending_save = True\n",
    "            print(f\"Failed to write ledger to ledger store. {e}\")\n",
    "            raise e\n",
    "\n",
    "    def _increase_max_cache(self, new_size: int) -> None:\n",
    "        new_entries = []\n",
    "        current_size = len(self._cache_constant2epsilon)\n",
    "        new_alphas = []\n",
    "        for i in range(new_size - current_size):\n",
    "            alph, eps = self._get_optimal_alpha_for_constant(\n",
    "                constant=i + 1 + current_size\n",
    "            )\n",
    "            new_entries.append(eps)\n",
    "            new_alphas.append(alph)\n",
    "\n",
    "        self._cache_constant2epsilon = np.concatenate(\n",
    "            [self._cache_constant2epsilon, np.array(new_entries)]\n",
    "        )\n",
    "\n",
    "    def _get_fake_rdp_func(self, constant: int) -> Callable:\n",
    "        def func(alpha: float) -> float:\n",
    "            return alpha * constant\n",
    "\n",
    "        return func\n",
    "\n",
    "    def _get_alpha_search_function(self, rdp_compose_func: Callable) -> Callable:\n",
    "        log_delta = np.log(self.delta)\n",
    "\n",
    "        def fun(alpha: float) -> float:  # the input is the RDP's \\alpha\n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha - 1\n",
    "                return np.maximum(\n",
    "                    rdp_compose_func(alpha)\n",
    "                    + np.log(alpha_minus_1 / alpha)\n",
    "                    - (log_delta + np.log(alpha)) / alpha_minus_1,\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "        return fun\n",
    "\n",
    "    def _get_optimal_alpha_for_constant(\n",
    "        self, constant: int = 3\n",
    "    ) -> Tuple[np.ndarray, Callable]:\n",
    "        f = self._get_fake_rdp_func(constant=constant)\n",
    "        f2 = self._get_alpha_search_function(rdp_compose_func=f)\n",
    "        results = minimize_scalar(\n",
    "            f2, method=\"Brent\", bracket=(1, 2), bounds=[1, np.inf]\n",
    "        )\n",
    "\n",
    "        return results.x, results.fun\n",
    "\n",
    "    def _get_batch_rdp_constants(\n",
    "        self, entity_ids_query: jnp.ndarray, rdp_params: RDPParams, private: bool = True\n",
    "    ) -> jnp.ndarray:\n",
    "        constant = compute_rdp_constant(rdp_params, private)\n",
    "        if self._rdp_constants.size == 0:\n",
    "            self._rdp_constants = np.zeros_like(np.asarray(constant, constant.dtype))\n",
    "        print(\"constant: \", constant)\n",
    "        print(\"_rdp_constants: \", self._rdp_constants)\n",
    "        print(\"entity ids query\", entity_ids_query)\n",
    "        print(jnp.max(entity_ids_query))\n",
    "        self._rdp_constants = first_try_branch(\n",
    "            constant,\n",
    "            self._rdp_constants,\n",
    "            entity_ids_query,\n",
    "            int(jnp.max(entity_ids_query)),\n",
    "        )\n",
    "        return constant\n",
    "\n",
    "    def _get_epsilon_spend(self, rdp_constants: np.ndarray) -> np.ndarray:\n",
    "        rdp_constants_lookup = (rdp_constants - 1).astype(np.int64)\n",
    "        try:\n",
    "            # needed as np.int64 to use take\n",
    "            eps_spend = jax.jit(jnp.take)(\n",
    "                self._cache_constant2epsilon, rdp_constants_lookup\n",
    "            )\n",
    "        except IndexError:\n",
    "            print(f\"Cache missed the value at {max(rdp_constants_lookup)}\")\n",
    "            self._increase_max_cache(int(max(rdp_constants_lookup) * 1.1))\n",
    "            eps_spend = jax.jit(jnp.take)(\n",
    "                self._cache_constant2epsilon, rdp_constants_lookup\n",
    "            )\n",
    "        return eps_spend\n",
    "\n",
    "    def _calculate_mask_for_current_budget(\n",
    "        self, get_budget_for_user: Callable, epsilon_spend: np.ndarray\n",
    "    ) -> Tuple[float, float, np.ndarray]:\n",
    "        user_budget = get_budget_for_user(verify_key=self.user_key)\n",
    "        # create a mask of True and False where true is over current user_budget\n",
    "        return get_budgets_and_mask(epsilon_spend, user_budget)\n",
    "\n",
    "    def _get_overbudgeted_entities(\n",
    "        self,\n",
    "        get_budget_for_user: Callable,\n",
    "        deduct_epsilon_for_user: Callable,\n",
    "        rdp_constants: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray]:\n",
    "        \"\"\"TODO:\n",
    "        In our current implementation, user_budget is obtained by querying the\n",
    "        Adversarial Accountant's entity2ledger with the Data Scientist's User Key.\n",
    "        When we replace the entity2ledger with something else, we could perhaps directly\n",
    "        add it into this method\n",
    "        \"\"\"\n",
    "        epsilon_spend = self._get_epsilon_spend(rdp_constants=rdp_constants)\n",
    "\n",
    "        # try first time\n",
    "        (\n",
    "            highest_possible_spend,\n",
    "            user_budget,\n",
    "            mask,\n",
    "        ) = self._calculate_mask_for_current_budget(\n",
    "            get_budget_for_user=get_budget_for_user, epsilon_spend=epsilon_spend\n",
    "        )\n",
    "\n",
    "        mask = np.array(mask, copy=False)\n",
    "        highest_possible_spend = float(highest_possible_spend)\n",
    "        user_budget = float(user_budget)\n",
    "        print(\"Epsilon spend \", epsilon_spend)\n",
    "        print(\"Highest possible spend \", highest_possible_spend)\n",
    "        if highest_possible_spend > 0:\n",
    "            # go spend it in the db\n",
    "            attempts = 0\n",
    "            while attempts < 5:\n",
    "                print(\n",
    "                    f\"Attemping to spend epsilon: {highest_possible_spend}. Try: {attempts}\"\n",
    "                )\n",
    "                attempts += 1\n",
    "                try:\n",
    "                    user_budget = self.spend_epsilon(\n",
    "                        deduct_epsilon_for_user=deduct_epsilon_for_user,\n",
    "                        epsilon_spend=highest_possible_spend,\n",
    "                        old_user_budget=user_budget,\n",
    "                    )\n",
    "                    break\n",
    "                except RefreshBudgetException:  # nosec\n",
    "                    # this is the only exception we allow to retry\n",
    "                    (\n",
    "                        highest_possible_spend,\n",
    "                        user_budget,\n",
    "                        mask,\n",
    "                    ) = self._calculate_mask_for_current_budget(\n",
    "                        get_budget_for_user=get_budget_for_user,\n",
    "                        epsilon_spend=epsilon_spend,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Problem spending epsilon. {e}\")\n",
    "                    raise e\n",
    "\n",
    "        if user_budget is None:\n",
    "            raise Exception(\"Failed to spend_epsilon\")\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def spend_epsilon(\n",
    "        self,\n",
    "        deduct_epsilon_for_user: Callable,\n",
    "        epsilon_spend: float,\n",
    "        old_user_budget: float,\n",
    "    ) -> float:\n",
    "        # get the budget\n",
    "        print(\"got user budget\", old_user_budget, \"epsilon_spent\", epsilon_spend)\n",
    "        deduct_epsilon_for_user(\n",
    "            verify_key=self.user_key,\n",
    "            old_budget=old_user_budget,\n",
    "            epsilon_spend=epsilon_spend,\n",
    "        )\n",
    "        # return the budget we used\n",
    "        return old_user_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2977441-ec61-4252-924b-79e3f5eee797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSL_dummy:\n",
    "    def __init__(self):\n",
    "        self._cache_constant2epsilon = np.zeros(0)\n",
    "        self.delta = 1e-6\n",
    "    def _increase_max_cache(self, new_size: int) -> None:\n",
    "        new_entries = []\n",
    "        current_size = len(self._cache_constant2epsilon)\n",
    "        new_alphas = []\n",
    "        for i in range(new_size - current_size):\n",
    "            current_constant = i + 1 + current_size\n",
    "            alph, eps = self._get_optimal_alpha_for_constant(\n",
    "                constant=current_constant\n",
    "            )\n",
    "            print(f\"current_constant={current_constant}, alpha={alph}, eps={eps}\")\n",
    "            new_entries.append(eps)\n",
    "            new_alphas.append(alph)\n",
    "\n",
    "        self._cache_constant2epsilon = np.concatenate(\n",
    "            [self._cache_constant2epsilon, np.array(new_entries)]\n",
    "        )\n",
    "\n",
    "    def _get_fake_rdp_func(self, constant: int) -> Callable:\n",
    "        def func(alpha: float) -> float:\n",
    "            return alpha * constant\n",
    "\n",
    "        return func\n",
    "\n",
    "    def _get_alpha_search_function(self, rdp_compose_func: Callable) -> Callable:\n",
    "        log_delta = np.log(self.delta)\n",
    "\n",
    "        def fun(alpha: float) -> float:  # the input is the RDP's \\alpha\n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha - 1\n",
    "                return np.maximum(\n",
    "                    rdp_compose_func(alpha)\n",
    "                    + np.log(alpha_minus_1 / alpha)\n",
    "                    - (log_delta + np.log(alpha)) / alpha_minus_1,\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "        return fun\n",
    "\n",
    "    def _get_optimal_alpha_for_constant(\n",
    "        self, constant: int = 3\n",
    "    ) -> Tuple[np.ndarray, Callable]:\n",
    "        f = self._get_fake_rdp_func(constant=constant)\n",
    "        f2 = self._get_alpha_search_function(rdp_compose_func=f)\n",
    "        results = minimize_scalar(\n",
    "            f2, method=\"Brent\", bracket=(1, 2), bounds=[1, np.inf]\n",
    "        )\n",
    "\n",
    "        return results.x, results.fun\n",
    "\n",
    "dsl = DSL_dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12cf4840-59e0-4298-a91f-21600ec38395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_constant=1, alpha=4.508496357814772, eps=7.766216625311721\n",
      "current_constant=2, alpha=3.5060933368492333, eps=11.688596249354894\n",
      "current_constant=3, alpha=3.0573417104696294, eps=14.947919164492593\n",
      "current_constant=4, alpha=2.7881643639977356, eps=17.861121033014\n",
      "current_constant=5, alpha=2.6036578950410423, eps=20.551948814041253\n",
      "current_constant=6, alpha=2.4669985432838435, eps=23.08419874777858\n",
      "current_constant=7, alpha=2.360495652447485, eps=25.495916596130975\n",
      "current_constant=8, alpha=2.2744494959477497, eps=27.811968501910776\n",
      "current_constant=9, alpha=2.2030366150496095, eps=30.049671251820154\n",
      "current_constant=10, alpha=2.1425203717085815, eps=32.2216609490976\n"
     ]
    }
   ],
   "source": [
    "dsl._increase_max_cache(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f60cf6f6-0dd7-4b7c-beaf-5246572f23f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.76621663, 11.68859625, 14.94791916, 17.86112103, 20.55194881,\n",
       "       23.08419875, 25.4959166 , 27.8119685 , 30.04967125, 32.22166095])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsl._cache_constant2epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ffc1311-d69b-43cd-b519-af8827ef8744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_constant=1, alpha=4.508496357814772, eps=7.766216625311721\n",
      "current_constant=2, alpha=3.5060933368492333, eps=11.688596249354894\n",
      "current_constant=3, alpha=3.0573417104696294, eps=14.947919164492593\n",
      "current_constant=4, alpha=2.7881643639977356, eps=17.861121033014\n",
      "current_constant=5, alpha=2.6036578950410423, eps=20.551948814041253\n",
      "current_constant=6, alpha=2.4669985432838435, eps=23.08419874777858\n",
      "current_constant=7, alpha=2.360495652447485, eps=25.495916596130975\n",
      "current_constant=8, alpha=2.2744494959477497, eps=27.811968501910776\n",
      "current_constant=9, alpha=2.2030366150496095, eps=30.049671251820154\n",
      "current_constant=10, alpha=2.1425203717085815, eps=32.2216609490976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e/anaconda3/envs/Hagrid/lib/python3.9/site-packages/scipy/optimize/optimize.py:2621: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n"
     ]
    }
   ],
   "source": [
    "class DSL_dummy:\n",
    "    def __init__(self):\n",
    "        self._cache_constant2epsilon = np.zeros(0)\n",
    "        self.delta = 1e-6\n",
    "    def generate_cache(self, new_size: int) -> None:\n",
    "        new_entries = []\n",
    "        current_size = len(self._cache_constant2epsilon)\n",
    "        new_alphas = []\n",
    "        for i in range(new_size - current_size):\n",
    "            current_constant = i + 1 + current_size\n",
    "            alph, eps = self._get_optimal_alpha_for_constant(\n",
    "                constant=current_constant\n",
    "            )\n",
    "            print(f\"current_constant={current_constant}, alpha={alph}, eps={eps}\")\n",
    "            new_entries.append(eps)\n",
    "            new_alphas.append(alph)\n",
    "\n",
    "        self._cache_constant2epsilon = np.concatenate(\n",
    "            [self._cache_constant2epsilon, np.array(new_entries)]\n",
    "        )\n",
    "\n",
    "    def _get_fake_rdp_func(self, constant: int) -> Callable:\n",
    "        def func(alpha: float) -> float:\n",
    "            return alpha * constant\n",
    "\n",
    "        return func\n",
    "\n",
    "    def _get_alpha_search_function(self, rdp_compose_func: Callable) -> Callable:\n",
    "        log_delta = np.log(self.delta)\n",
    "\n",
    "        def fun(alpha: float) -> float:  # the input is the RDP's \\alpha\n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha - 1\n",
    "                return np.maximum(\n",
    "                    rdp_compose_func(alpha)\n",
    "                    + np.log(alpha_minus_1 / alpha)\n",
    "                    - (log_delta + np.log(alpha)) / alpha_minus_1,\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "        return fun\n",
    "\n",
    "    def _get_optimal_alpha_for_constant(\n",
    "        self, constant: int = 3\n",
    "    ) -> Tuple[np.ndarray, Callable]:\n",
    "        f = self._get_fake_rdp_func(constant=constant)\n",
    "        f2 = self._get_alpha_search_function(rdp_compose_func=f)\n",
    "        results = minimize_scalar(\n",
    "            f2, method=\"Brent\", bracket=(1, 2), bounds=[1, np.inf]\n",
    "        )\n",
    "\n",
    "        return results.x, results.fun\n",
    "\n",
    "dsl = DSL_dummy()\n",
    "dsl.generate_cache(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5702b25f-cc3a-40c7-870b-0f2420ceb751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[286.6113345763701, 206.94946372761132, 171.03566817267512, 149.39888177623587, 134.5200190425928, 123.47110612221316, 114.84171780748302, 107.85682934365019, 102.05028906097073, 97.12251083101317] [4.510027823812622, 4.5098575600812385, 4.509687321577367, 4.509517108285959, 4.509346920217402, 4.509176824091769, 4.509006619684135, 4.50883650720463, 4.508666419920537, 4.508496357814772]\n",
      "Epsilon values\n",
      "[0.05372712063485988, 0.07773597369831031, 0.09645750759431188, 0.11240310981848231, 0.12655841098879092, 0.13943329329185075, 0.15133263525161025, 0.16245613111787732, 0.17294310302157573, 0.1828953771900762] [7.762158289561581, 7.762609283833006, 7.763060261079307, 7.7635112213030055, 7.763962164506623, 7.764413090692681, 7.764863999863702, 7.765314892022202, 7.765765767170702, 7.766216625311721]\n"
     ]
    }
   ],
   "source": [
    "dsl = DSL_dummy()\n",
    "alphas = []\n",
    "epsilons = []\n",
    "\n",
    "# This will also serve as our step size\n",
    "min_val = 0.0001\n",
    "\n",
    "for i in np.arange(min_val, 1 + min_val, min_val):\n",
    "    alpha, eps = dsl._get_optimal_alpha_for_constant(i)\n",
    "    alphas.append(alpha)\n",
    "    epsilons.append(eps)\n",
    "\n",
    "print(alphas[:10], alphas[-10:])\n",
    "print(\"Epsilon values\")\n",
    "print(epsilons[:10], epsilons[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce4063-dd3d-4b38-a456-08bfb902c487",
   "metadata": {},
   "source": [
    "Okay so now we can generate cache values for any RDP constant!\n",
    "\n",
    "Now we need a mapping from:\n",
    "{arbitrary RDP constant} (float) -> index of cache (integer)\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "What could we try:\n",
    "\n",
    "1. scaling by a constant factor of 10,000 \n",
    "\n",
    "This means that a given index i in the cache corresponds to an epsilon value for an RDP constant of i/10,000: \n",
    "\n",
    "<table>\n",
    "<th>\n",
    "    <tr>\n",
    "        <th>index</th>\n",
    "        <th>rdp</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 0 </td>\n",
    "        <td> 0 </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td> 1 </td>\n",
    "        <td> 0.0001 </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td> 2 </td>\n",
    "        <td> 0.0002 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> ... </td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "            <td> <i>i</i> </td>\n",
    "            <td> <i>i/1000</i> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "    \n",
    "So if I'm trying to check the epsilon spend for an RDP constant of 80, that would be an index of 80*10_000 = 800,000.\n",
    "\n",
    "Extending the cache could be very slow at this point- imagine having to extend the cache to support an RDP constant query of 300; you'd have to perform (300*1000) searches\n",
    "- I wonder if we could approximate a search? Like find a simple polynomial to fit it and see how the % difference changes as i -> infinity, and see if we could use that as a reasonable substitution for manually conducting polynomial searches at high RDP constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc19e26-d7ee-4d54-96a2-5c9816dd013a",
   "metadata": {},
   "source": [
    "2. get floating point bitwise representation, convert it to integer representation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32983f70-3899-4806-816b-9a222fa0af46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SCALING BY 10,000\n",
    "1/10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95bdbcd6-2133-46f6-89d0-0f24bac8fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.0001 1.0\n",
      "[286.6113345763701, 206.94946372761132, 171.03566817267512, 149.39888177623587, 134.5200190425928, 123.47110612221316, 114.84171780748302, 107.85682934365019, 102.05028906097073, 97.12251083101317] [4.510027823812622, 4.5098575600812385, 4.509687321577367, 4.509517108285959, 4.509346920217402, 4.509176824091769, 4.509006619684135, 4.50883650720463, 4.508666419920537, 4.508496357814772]\n",
      "Epsilon values\n",
      "[0.05372712063485988, 0.07773597369831031, 0.09645750759431188, 0.11240310981848231, 0.12655841098879092, 0.13943329329185075, 0.15133263525161025, 0.16245613111787732, 0.17294310302157573, 0.1828953771900762] [7.762158289561581, 7.762609283833006, 7.763060261079307, 7.7635112213030055, 7.763962164506623, 7.764413090692681, 7.764863999863702, 7.765314892022202, 7.765765767170702, 7.766216625311721]\n"
     ]
    }
   ],
   "source": [
    "min_val = 0.0001\n",
    "rdp_constants = np.arange(min_val, 1 + min_val, min_val)\n",
    "print(len(rdp_constants), rdp_constants[0], rdp_constants[-1])\n",
    "\n",
    "dsl = DSL_dummy()\n",
    "alphas = []\n",
    "epsilons = []\n",
    "\n",
    "# This will also serve as our step size\n",
    "\n",
    "\n",
    "for i in rdp_constants:\n",
    "    alpha, eps = dsl._get_optimal_alpha_for_constant(i)\n",
    "    alphas.append(alpha)\n",
    "    epsilons.append(eps)\n",
    "\n",
    "print(alphas[:10], alphas[-10:])\n",
    "print(\"Epsilon values\")\n",
    "print(epsilons[:10], epsilons[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17020f76-5eb8-4b11-aa71-7b04afcec91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200000 0.0001 700050.0\n"
     ]
    }
   ],
   "source": [
    "min_val = 0.0001\n",
    "rdp_constants = np.concatenate((np.arange(min_val, 50 + min_val, min_val),np.arange(51, 700_051)))\n",
    "print(len(rdp_constants), rdp_constants[0], rdp_constants[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f323a2e1-8089-4ece-bd78-42a9c19d987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.00000000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdp_constants[500_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "583aba10-c3ce-4e00-8dee-e39073ff3fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                             | 0/1200000 [00:00<?, ?it/s]/home/e/anaconda3/envs/Hagrid/lib/python3.9/site-packages/scipy/optimize/optimize.py:2621: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200000/1200000 [04:41<00:00, 4265.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dsl = DSL_dummy()\n",
    "epsilons = []\n",
    "\n",
    "# This will also serve as our step size\n",
    "\n",
    "\n",
    "for i in tqdm(rdp_constants):\n",
    "    _, eps = dsl._get_optimal_alpha_for_constant(i)\n",
    "    epsilons.append(eps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab5ad2e-9d53-487d-8d9d-b3a491d0fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05372712063485988,\n",
       " 0.07773597369831031,\n",
       " 0.09645750759431188,\n",
       " 0.11240310981848231,\n",
       " 0.12655841098879092]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5892426-8bbd-4972-b6b1-9bd1b5c92b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[706259.3859365697,\n",
       " 706260.3903782812,\n",
       " 706261.3948199897,\n",
       " 706262.3992616949,\n",
       " 706263.403703397]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ca98c9a-c63a-422e-b6e9-d4e3ef8761fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True]\n",
      "[1]\n",
      "sub50:  [10000]\n",
      "gt50:  [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.766667466447775"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons[convert_constants_to_indices(np.array([1]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "126954d7-f3c2-41cf-ba78-407f71c9e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('constant2epsilon_1200k.npy', epsilons) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bfafbe7b-82f2-419f-8e33-299d2fb4a621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsilon spend >= 25 in index=6 with a value=25.495916596130975'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_index_with_epsilon_spend_of(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fded9b13-4b7c-418b-87ed-709c1ace8bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsilon spend >= 50 in index=19 with a value=51.719404463000245'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_index_with_epsilon_spend_of(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f3d8e-239e-4015-a066-41a8def98ff6",
   "metadata": {},
   "source": [
    "Perhaps we could have 10,000 values between RDP_Constant from 0 to 50- resulting in 50 * 10,000 = 500,000 values\n",
    "\n",
    "Then we could use 700,000 values to support RDP_constants from 50 to 750,000?\n",
    "\n",
    "So our cache would look like:\n",
    "\n",
    "\n",
    "<table>\n",
    "<th>\n",
    "    <tr>\n",
    "        <th>index</th>\n",
    "        <th>rdp</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 0 </td>\n",
    "        <td> 0.0001 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 1 </td>\n",
    "        <td> 0.0002 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 2 </td>\n",
    "        <td> 0.0003 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> ... </td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> <i>rdp_constant*10_000 - 1</i> </td>\n",
    "        <td> <i>rdp_constant less than 50 </i> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> ... </td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 500,000 </td>\n",
    "        <td> 50 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 500,001 </td>\n",
    "        <td> 51 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 500,002 </td>\n",
    "        <td> 52 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> rdp_constant - 50 + 500,000 </td>\n",
    "        <td> rdp_constant greater than 50 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> ... </td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td> 1,200,000 </td>\n",
    "        <td> 700,050 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "This would let us support a minimum PB query of 0.05, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3715e5f-2e5d-4b26-9844-67a0cade24db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51.71940446, 53.52268593, 55.30736617, 57.07468954, 58.82576726,\n",
       "       60.56159652, 62.28307625, 63.9910202 , 65.6861678 , 67.36919338])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_cache[19:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "abbd9116-496f-455a-9318-b430fe28e75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8130347005616798, 51.719404463000245)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsl._get_optimal_alpha_for_constant(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef4c79d5-709a-434a-bc98-12307bdb002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_constants_to_indices(rdp_constant_array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given an array of RDP Constants, this will return an array of the same size/shape telling you which indices in the DataSubjectLedger's cache you need to query.\n",
    "    \n",
    "    This currently assumes the cache generated on May 4th 2022, where there are 1.2M values in total.\n",
    "    - 500,000 of these correspond to RDP constants between 0 and 50 (10,000 between any two consecutive integers)\n",
    "    - 700,000 of these correspond to RDP constants between 50 and 700,050    \n",
    "    \n",
    "    An easy way to check if you're using the right cache is that the very first value in the cache should be 0.05372712063485988\n",
    "    \n",
    "    MAKE SURE THERE ARE NO ZEROS IN THE CACHE!!\n",
    "    \"\"\"\n",
    "    # Find indices for all RDP constants <= 50\n",
    "    sub50_mask = rdp_constant_array <= 50\n",
    "    sub50_indices = (((rdp_constant_array - 1) * sub50_mask) * 10_000).astype(int)\n",
    "    \n",
    "    # Find indices for all RDP constants > 50\n",
    "    gt50_mask = rdp_constant_array > 50\n",
    "    gt50_indices = ((rdp_constant_array - 51 + 500_000) * gt50_mask ).astype(int)\n",
    "    \n",
    "    # We should be able to do a straight addition because \n",
    "    return sub50_indices + gt50_indices\n",
    "    \n",
    "    \n",
    "\n",
    "def get_epsilon_spent(rdp_constant_array: np.ndarray, cache: np.ndarray) -> np.ndarray:\n",
    "    indices = convert_constants_to_indices(rdp_constant_array)\n",
    "    epsilon_spent = cache.take(indices)\n",
    "    return epsilon_spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37dffed7-335d-49b8-bc07-94bcf15e2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our mock constants are\n",
      "[71 41 19 64  9 51 22 87 10 61]\n",
      "[False  True  True False  True False  True False  True False]\n",
      "[ 0 41 19  0  9  0 22  0 10  0]\n",
      "sub50:  [     0 410000 190000      0  90000      0 220000      0 100000      0]\n",
      "gt50:  [500021      0      0 500014      0 500001      0 500037      0 500011]\n",
      "These were turned into indices of:\n",
      "[500021 410000 190000 500014  90000 500001 220000 500037 100000 500011]\n"
     ]
    }
   ],
   "source": [
    "mock_constants = np.random.randint(low=1, high=100, size=(10))\n",
    "print(\"Our mock constants are\")\n",
    "print(mock_constants)\n",
    "\n",
    "idx = convert_constants_to_indices(mock_constants)\n",
    "print(\"These were turned into indices of:\")\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc33883-8a1d-42dc-a43e-7091941e8d7d",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Make sure 0 is not in the cached array!!! otherwise infinite data leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a204c42c-b7a0-4baf-8e35-a1cb5e6a2563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
