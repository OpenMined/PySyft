{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext jupyter_black\n",
    "\n",
    "# stdlib\n",
    "import ast\n",
    "from random import randint\n",
    "\n",
    "# third party\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# third party\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "hide_output",
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# stdlib\n",
    "# TODO move to https://github.com/OpenMined/datasets\n",
    "# and use a helper util to download and `autocache`\n",
    "# should we use a huge dataframe for the first example, could we at least use zip or  parquet or something?\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"ages_dataset.csv\"):\n",
    "    !curl -O https://openminedblob.blob.core.windows.net/csvs/ages_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ages_dataset.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.dropna(how=\"any\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Id\"].nunique())\n",
    "print(df[\"Name\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of unique Occupations:\", df[\"Occupation\"].nunique())\n",
    "df[\"Occupation\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of unique combinations of Countries:\", df[\"Associated Countries\"].nunique())\n",
    "df[\"Associated Countries\"].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert <string> type list of strings to python <list> type\n",
    "df[\"Associated Countries\"] = df[\"Associated Countries\"].apply(ast.literal_eval)\n",
    "\n",
    "df[\"Associated Country Coordinates (Lat/Lon)\"] = df[\n",
    "    \"Associated Country Coordinates (Lat/Lon)\"\n",
    "].apply(ast.literal_eval)\n",
    "\n",
    "df[\"Associated Country Life Expectancy\"] = df[\n",
    "    \"Associated Country Life Expectancy\"\n",
    "].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate countries from lists and calculate their individual value_counts() which will be\n",
    "# used by random.choice function later as distributions\n",
    "\n",
    "\n",
    "def value_counts_of_lists(series_with_lists):\n",
    "    # Concatenate all the lists in the Series into a single list\n",
    "    unpacked_list = [item for sublist in series_with_lists for item in sublist]\n",
    "\n",
    "    # Create a new Series from the unpacked list\n",
    "    unpacked_series = pd.Series(unpacked_list)\n",
    "\n",
    "    # Use value_counts to get the count of unique values\n",
    "    value_counts = unpacked_series.value_counts()\n",
    "\n",
    "    return unpacked_list, value_counts\n",
    "\n",
    "\n",
    "# Create a dictionary where each unique country from all the lists in Associated Countries\n",
    "# are keys and the corresponding (Lat,Long) tuples are the values\n",
    "\n",
    "unpacked_cnt_list, cnt_value_counts = value_counts_of_lists(\n",
    "    df[\"Associated Countries\"].values\n",
    ")\n",
    "\n",
    "unpacked_exp_list, exp_value_counts = value_counts_of_lists(\n",
    "    df[\"Associated Country Life Expectancy\"].values\n",
    ")\n",
    "\n",
    "print(len(unpacked_cnt_list))\n",
    "print(len(unpacked_exp_list))\n",
    "\n",
    "cnt_dict = dict.fromkeys(unpacked_cnt_list, None)\n",
    "\n",
    "for i in range(len(unpacked_exp_list)):\n",
    "    if cnt_dict[unpacked_cnt_list[i]] is None:\n",
    "        cnt_dict[unpacked_cnt_list[i]] = unpacked_exp_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_ROWS = df.shape[0]  # 10000\n",
    "\n",
    "Faker.seed(0)\n",
    "faker = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_encode_dict = {\n",
    "    \"Male\": \"Gender 1\",\n",
    "    \"Female\": \"Gender 2\",\n",
    "    \"Transgender Female\": \"Gender 3\",\n",
    "    \"Transgender Male\": \"Gender 4\",\n",
    "    \"Intersex\": \"Gender 5\",\n",
    "    \"Eunuch; Male\": \"Gender 6; Gender 1\",\n",
    "    \"Transgender Female; Female\": \"Gender 3; Gender 2\",\n",
    "}\n",
    "\n",
    "\n",
    "def generate_random_choice_columns(df, num):\n",
    "    # Generate Id\n",
    "    id_list = np.arange(1, num + 2000)\n",
    "    fake_id = np.random.choice(id_list, size=num, replace=False)\n",
    "    fake_id = pd.Series(fake_id).apply(lambda x: \"Q\" + str(x))\n",
    "\n",
    "    # Generate Gender\n",
    "    gender_dist = df[\"Gender\"].value_counts(normalize=True)\n",
    "    gender = np.random.choice(\n",
    "        df[\"Gender\"].unique().tolist(),\n",
    "        size=num,\n",
    "        replace=True,\n",
    "        p=gender_dist,  # probability\n",
    "    )\n",
    "    gender = pd.Series(gender).replace(gender_encode_dict)\n",
    "\n",
    "    # Generate Age of death, add noise by adding random int between(-5,5) to fake age\n",
    "    age_of_death_dist = df[\"Age of death\"].value_counts(normalize=True)\n",
    "    age_of_death = np.random.choice(\n",
    "        df[\"Age of death\"].unique().tolist(),\n",
    "        size=num,\n",
    "        replace=True,\n",
    "        p=age_of_death_dist,  # probability\n",
    "    )\n",
    "    age_of_death = (\n",
    "        pd.Series(age_of_death).apply(lambda x: x + randint(-5, 5)).astype(\"float64\")\n",
    "    )\n",
    "\n",
    "    # Generate Associated Countries\n",
    "    assc_cnt_dist = df[\"Associated Countries\"].value_counts(normalize=True)\n",
    "    assc_cnt = np.random.choice(\n",
    "        df[\"Associated Countries\"].astype(str).value_counts().keys().tolist(),\n",
    "        size=num,\n",
    "        replace=True,\n",
    "        p=assc_cnt_dist,  # probability\n",
    "    )\n",
    "    assc_cnt = pd.Series(assc_cnt).apply(ast.literal_eval)\n",
    "\n",
    "    # Generate Life Expectency using the dictionary created above\n",
    "    assc_life_exp = pd.Series(assc_cnt).apply(lambda x: [cnt_dict[i] for i in x])\n",
    "\n",
    "    # Generate Manner of death\n",
    "    manner_of_death_dist = df[\"Manner of death\"].value_counts(normalize=True)\n",
    "    manner_of_death = np.random.choice(\n",
    "        df[\"Manner of death\"].unique().tolist(),\n",
    "        size=num,\n",
    "        replace=True,\n",
    "        p=manner_of_death_dist,  # probability\n",
    "    )\n",
    "    manner_of_death = pd.Series(manner_of_death)\n",
    "\n",
    "    return fake_id, gender, age_of_death, assc_cnt, assc_life_exp, manner_of_death\n",
    "\n",
    "\n",
    "def make_faker_data(num):\n",
    "    fake_data = [\n",
    "        {\n",
    "            \"Name\": faker.name(),\n",
    "            \"Short description\": faker.paragraph(nb_sentences=2),\n",
    "            \"Occupation\": faker.job(),\n",
    "            \"Death year\": float(faker.year()),\n",
    "        }\n",
    "        for x in range(num)\n",
    "    ]\n",
    "\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_df = pd.DataFrame()\n",
    "(\n",
    "    mock_df[\"Id\"],\n",
    "    mock_df[\"Gender\"],\n",
    "    mock_df[\"Age of death\"],\n",
    "    mock_df[\"Associated Countries\"],\n",
    "    mock_df[\"Associated Country Life Expectancy\"],\n",
    "    mock_df[\"Manner of death\"],\n",
    ") = generate_random_choice_columns(df, num=NUM_OF_ROWS)\n",
    "\n",
    "fake_data = pd.DataFrame(make_faker_data(num=NUM_OF_ROWS))\n",
    "\n",
    "for col in fake_data.columns.to_list():\n",
    "    mock_df[col] = fake_data[col]\n",
    "\n",
    "# Generate Birth year by subtracting Age of death from Death year\n",
    "mock_df[\"Birth year\"] = mock_df[\"Death year\"].astype(int) - mock_df[\n",
    "    \"Age of death\"\n",
    "].astype(int)\n",
    "\n",
    "print(mock_df.shape)\n",
    "mock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_df[\"Country\"] = [\"Not Available\"] * mock_df.shape[0]\n",
    "mock_df[\"Associated Country Coordinates (Lat/Lon)\"] = [\"Not Available\"] * mock_df.shape[\n",
    "    0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mock_df.shape)\n",
    "mock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_df.to_csv(\"ages_mock_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = mock_df.columns\n",
    "df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_df[cols].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_df[cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Manner of death\"].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_df[\"Manner of death\"].value_counts()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"gpt2-medium\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, pad_token_id=tokenizer.eos_token_id\n",
    ").to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Approach\n",
    "# Directly asking the model to generate texts in response to a cue.\n",
    "\n",
    "\n",
    "def generate_reviews(prompt, product, n_texts):\n",
    "    for _ in range(n_texts):\n",
    "        model_inputs = tokenizer(prompt, return_tensors=\"pt\").to(torch_device)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=100,\n",
    "            do_sample=True,\n",
    "            top_k=10,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        review = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        product_names.append(product)\n",
    "        reviews.append(review.splitlines()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    \"64 inch Sony television\",\n",
    "    \"Amazon Kindle\",\n",
    "    \"Honda SUV car\",\n",
    "    \"Dyson vacuum cleaner\",\n",
    "]\n",
    "product_names = []\n",
    "reviews = []\n",
    "\n",
    "# TODO: Shorten this loop for testing to like 1 row or something\n",
    "for product in products[0:1]:\n",
    "    # for product in products:\n",
    "    # generate positive reviews\n",
    "    prompt_pos = f\"Recently I bought a {product}. I am happy with the purchase because\"\n",
    "    generate_reviews(prompt_pos, product, n_texts=2)\n",
    "\n",
    "    # generate negative reviews\n",
    "    prompt_neg = (\n",
    "        f\"Recently I bought a {product}. I am disappointed with the purchase because\"\n",
    "    )\n",
    "    generate_reviews(prompt_neg, product, n_texts=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_review_df = pd.DataFrame()\n",
    "mock_review_df[\"product\"] = product_names\n",
    "mock_review_df[\"review\"] = reviews\n",
    "print(mock_review_df.shape)\n",
    "mock_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"datificate/gpt2-small-spanish\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, pad_token_id=tokenizer.eos_token_id\n",
    ").to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    \"Televisión Sony de 64 pulgadas\",\n",
    "    \"Amazon Kindle\",\n",
    "    \"auto SUV Honda\",\n",
    "    \"aspiradora Dyson\",\n",
    "]\n",
    "product_names = []\n",
    "reviews = []\n",
    "\n",
    "# TODO: Shorten this loop for testing to like 1 row or something\n",
    "# for product in products:\n",
    "for product in products[0:1]:\n",
    "    # generate generic reviews\n",
    "    prompt = f\"Ayer compré un {product}. Fue\"\n",
    "    generate_reviews(prompt, product, n_texts=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_review_df = pd.DataFrame()\n",
    "mock_review_df[\"product\"] = product_names\n",
    "mock_review_df[\"review\"] = reviews\n",
    "print(mock_review_df.shape)\n",
    "mock_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip in CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install medigan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import glob\n",
    "\n",
    "# third party\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from medigan import Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = Generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# generate 3 samples with model 19 (00019_PGGAN_CHEST_XRAY).\n",
    "# Also, auto-install required model dependencies.\n",
    "\n",
    "generators.generate(model_id=19, num_samples=3, install_dependencies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(out_dir):\n",
    "    \"\"\"plot images from generator output\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "    # get the most recent output\n",
    "    img_folder = sorted(glob.glob(f\"{out_dir}/*/*/\"), reverse=True)[0]\n",
    "\n",
    "    for i in range(3):\n",
    "        img_path = f\"{img_folder}batch_0_{str(i)}.png\"\n",
    "        img = Image.open(img_path)\n",
    "        print(img_path)\n",
    "\n",
    "        # plotting images\n",
    "        ax[i].axis(\"off\")\n",
    "        ax[i].imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./models ./config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
