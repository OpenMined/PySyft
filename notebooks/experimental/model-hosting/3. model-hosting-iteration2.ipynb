{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857b463-184e-400c-85b8-f90d9a520aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install --upgrade uvicorn watchfiles jupyterlab jupyter-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d79416-ad45-4bc3-b95c-54079551ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install -U transformers huggingface_hub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea648e1-ad93-4730-8e3a-c8392d9d34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syft absolute\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b22bc8-f0d2-48f8-bb0d-bc63fda3516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1dd20-f75f-44d5-a594-31dc3d63e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sy.enable_autoreload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb41cbe-d56e-4a68-bad0-9436a23e00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the domain nodes we setup in the previous notebook\n",
    "canada_node = sy.orchestra.launch(\n",
    "    name=\"canada-domain\", port='auto', dev_mode=True, reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08686129-f5a6-492c-8a5d-8870e27b066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client = canada_node.login(email=\"info@openmined.org\", password=\"changethis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c81dc-3635-4ac8-bd22-943a98dfb7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sy.Model(name=\"Gemma\", model_code=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0cdec-8d07-4635-9bae-811fc1819927",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_description(\n",
    "    \"Gemma is a set of lightweight, generative artificial intelligence (AI) open models. Gemma models are available to run in your applications and on your hardware, mobile devices, or hosted services. You can also customize these models using tuning techniques so that they excel at performing tasks that matter to you and your users. Gemma models are based on Gemini models and are intended for the AI development community to extend and take further.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36830324-06a0-44f2-844c-b428d91a7e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_citation(\"Person, place or thing\")\n",
    "model.add_url(\n",
    "    \"https://cloud.google.com/vertex-ai/generative-ai/docs/open-models/use-gemma\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506dd918-8318-4645-866d-840d600eae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_contributor(\n",
    "    name=\"Thomas Mesnard\",\n",
    "    email=\"thomas@email.com\",\n",
    "    note=\"This paper was fun!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c50ad-6f0f-4d92-add1-e0a5c09c2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"./gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063da85-c986-4beb-b3f4-3b17b6983dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"openai-community/gpt2\",\n",
    "    ignore_patterns=[\"*.tflite\", \"*.msgpack\", \"*.bin\", \"*.ot\", \"*.h5\", \"onnx/*\"],\n",
    "    local_dir=model_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5098c0-3ec1-4272-9e37-7545c6bb48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = sy.SyftFolder.from_dir(name=\"gpt2\", path=model_folder)\n",
    "model_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0d839-b35e-45ea-ad1f-544bb2cd1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f81dcb-4890-4d34-8b2f-562b0387f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = sy.ModelAsset(name=\"weights\", data=model_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35049b25-6da9-4463-b2ef-0f7e8817dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_asset(asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db817b63-75d6-480c-9843-e9a5aac6a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.upload_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88de6a-620d-47df-9236-c6f62aaf7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66e379-7f00-4964-9675-b671923c560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66952f28-b121-4be8-96fc-99a39845d909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc6590-57ca-4664-b3a3-b78bc74e6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload evals dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59017b-1d2d-4d2c-9a1b-4e437d38aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ptr = None\n",
    "evals_ptr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf215d-ed1c-4b38-97ec-9b332b247092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e0a19-3c02-4304-916d-62d9aaee4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before passing in model\n",
    "# get model_code and eval\n",
    "# run __init__\n",
    "# pass in inited model object to func\n",
    "\n",
    "\n",
    "@sy.syft_function_single_use(model=model_ptr, evals=evals_ptr)\n",
    "def run_eval(model, evals):\n",
    "    results = []\n",
    "    for prompt in evals:\n",
    "        result = model.inference(prompt)\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3036a6c-48b5-4dc8-846b-a666fc372aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b91f3b-07b4-4980-8cfb-b6b2d273b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"GPT2 is a model developed by OpenAI.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc3102-62d4-4f8f-804f-d40152c28538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d487b5c-4c4b-4f50-bec3-b75077c06e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdf2e7-0742-4fdf-bbe3-27fb3e3fc120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadaad3-06f8-477c-ac3a-d4b33c97ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089e519-1c7d-4cc1-83aa-9353cd77d85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542bd52-1a64-49cd-9015-a65ea6ca3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelAssets:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c575c-7060-489b-bbcf-cefcef3d96b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46effd2d-80b4-4b65-b8cc-9f44f97cc413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36efc184-2903-4ee3-85a4-4cb3ce08e323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8784e-aff3-425e-af11-45ee360b2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61146c1d-280f-4aff-bb6b-fc6e1ff95b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyftModelClass:\n",
    "    def __init__(self, assets) -> None:\n",
    "        self.__user_init__(assets)\n",
    "\n",
    "    def __user_init__(self, assets) -> None:\n",
    "        pass\n",
    "\n",
    "    def inference(self) -> Any:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25b4e6-cc4f-49d1-a722-c06f9c24fa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8e308-0ae5-4e64-8af6-486674327c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc5f42-03ed-452b-a556-55aae31987d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2Model(SyftModelClass):\n",
    "    def __user_init__(self, assets) -> None:\n",
    "        syft_files = assets[0]\n",
    "        model_folder = syft_files.model_folder\n",
    "\n",
    "        # third party\n",
    "        from transformers import AutoModelForCausalLM\n",
    "        from transformers import AutoTokenizer\n",
    "\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_folder)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_folder)\n",
    "\n",
    "    def inference(self, prompt: str) -> Any:\n",
    "        input_ids = self.tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        gen_tokens = self.model.generate(\n",
    "            input_ids,\n",
    "            do_sample=True,\n",
    "            temperature=0.9,\n",
    "            max_length=100,\n",
    "        )\n",
    "        return gen_tokens\n",
    "        gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "        return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67d681-55fc-4a47-8740-e52301275483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ed9e60-a988-43f4-8bae-2895b13527db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757a1cf-9b51-4dfa-aa6d-b84116f67062",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.inference(\"What is a dog?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b7dfc-377a-4097-8037-0678b211d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd2a76-ec13-497c-8e9f-5bcaf6e5edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sy.serialize(a, to_bytes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f21197-c4d2-4370-9453-0556c231f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa322849-a531-4bfb-9a6f-99654060b33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5cc9f-8b27-4afa-adb1-5313b396d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817d950-ab10-4c54-8b46-b6fe8b9e44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(weights):\n",
    "    # pointer to weights\n",
    "    # copy and paste huge 1000 line model class\n",
    "    for i in range(dataset):\n",
    "        result = model.inference(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6006b4-54de-493a-88f4-29b4a6c1682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(model):\n",
    "    for i in range(dataset):\n",
    "        result = model.inference(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8ed24-e564-4752-b892-d5ec82c1171b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4693fc-9df9-4e98-b8ed-bc05d681722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_to_zip_bytes(folder_path):\n",
    "    # stdlib\n",
    "    from io import BytesIO\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    # Create a BytesIO object to hold the zip file in memory\n",
    "    zip_buffer = BytesIO()\n",
    "    \n",
    "    # Create a zip file in the BytesIO object\n",
    "    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "        # Walk the directory structure\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Create the full file path\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Write the file to the zip file with the proper relative path\n",
    "                relative_path = os.path.relpath(file_path, folder_path)\n",
    "                zip_file.write(file_path, relative_path)\n",
    "    \n",
    "    # Seek to the beginning of the BytesIO object to read its content\n",
    "    zip_buffer.seek(0)\n",
    "    return zip_buffer.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc0ad1-fd77-421d-a04a-346b1dad7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip_bytes_to_folder(zip_bytes, extract_folder_path):\n",
    "    # stdlib\n",
    "    from io import BytesIO\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    os.makedirs(extract_folder_path, exist_ok=True)\n",
    "\n",
    "    # Create a BytesIO object from the zip bytes\n",
    "    zip_buffer = BytesIO(zip_bytes)\n",
    "    \n",
    "    # Open the zip file from the BytesIO object\n",
    "    with zipfile.ZipFile(zip_buffer, 'r') as zip_file:\n",
    "        # Extract all files to the specified folder\n",
    "        zip_file.extractall(extract_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c54312-07c5-417b-ac78-28f25ef7331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_to_action_obj(folder_path, keep_files=None):\n",
    "    zip_bytes = folder_to_zip_bytes(folder_path, keep_files)\n",
    "    zip_action_obj = sy.ActionObject.from_obj(zip_bytes)\n",
    "    return zip_action_obj\n",
    "\n",
    "\n",
    "def get_serde_size(obj):\n",
    "    p = sy.serialize(obj, to_bytes=True)\n",
    "    return len(p) / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683ff5f-8e6f-48e8-8194-f6552bbce935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9bfbd-bdd4-432e-87ab-1ffa7a2a62f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9191f-af4a-4778-9ba9-2994a99c3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2dc6f7-2e22-4127-9f2b-6cd88bd32ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914feda1-fa91-4a2f-8942-affe3a141709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
