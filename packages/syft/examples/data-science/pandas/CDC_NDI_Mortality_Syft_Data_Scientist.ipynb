{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-catholic",
   "metadata": {},
   "source": [
    "# CDC NDI Mortality - Syft Duet - Data Scientist ü•Å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-rebecca",
   "metadata": {},
   "source": [
    "This worksheet is intended to illustrate functionality of a shared statistical platform, using a partially synthetic public-use dataset that mirrors the restricted-use dataset. Ultimately, these processes would apply to the restricted-use data.\n",
    "\n",
    "Sample data compiled from the public-use linked mortality files share at https://www.cdc.gov/nchs/data-linkage/mortality.htm provided by the National Center for Health Statistics (NCHS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-cache",
   "metadata": {},
   "source": [
    "## PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the Data Scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server in their Notebook.\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. The code will look like this, importantly with their real Server ID.\n",
    "\n",
    "```\n",
    "import syft as sy\n",
    "duet = sy.duet('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "```\n",
    "\n",
    "This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Paste the code or Server ID that the Data Owner gives you and run it in the cell below. It will return your Client ID which you must send to the Data Owner to enter into Duet so it can pair your notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels\n",
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-synthesis",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 0 : Now STOP and run the Data Owner notebook until the next checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ptr = duet.store[\"df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_ptr = df_ptr[(df_ptr[\"UCOD_LEADING\"] == 2) & (df_ptr[\"ELIGSTAT\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_ptr = df_ptr[(df_ptr[\"UCOD_LEADING\"] == 1) & (df_ptr[\"ELIGSTAT\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute simple means and for the cancer and heart subgroups that had diabetes\n",
    "# listed as a multiple cause of death\n",
    "cancer_mean_ptr = cancer_ptr[\"DIABETES\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute simple means and standard deviations for the cancer and heart subgroups\n",
    "# that had diabetes as a multiple cause of death\n",
    "heart_mean_ptr = heart_ptr[\"DIABETES\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_mean = cancer_mean_ptr.get(request_block=True, delete_obj=False)\n",
    "cancer_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_mean = heart_mean_ptr.get(request_block=True, delete_obj=False)\n",
    "heart_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample means data should account for weights. Write a custom function that uses the weights.\n",
    "\n",
    "\n",
    "def weighted_mean(dx, key, weight_key=\"WGT_NEW\"):\n",
    "    w = dx[weight_key]\n",
    "    v = dx[key]\n",
    "    return (w * v).sum() / w.sum()\n",
    "\n",
    "\n",
    "cancer_wm_ptr = weighted_mean(cancer_ptr, \"DIABETES\")\n",
    "heart_wm_ptr = weighted_mean(heart_ptr, \"DIABETES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a small subgroup (sample size = 6)\n",
    "# Cancer-deaths from males aged 47 who died in 2015\n",
    "# We should check for small cell sizes here\n",
    "subgroup = cancer_ptr[\n",
    "    (cancer_ptr[\"SEX\"] == 1)\n",
    "    & (cancer_ptr[\"AGE_P\"] == 47)\n",
    "    & (cancer_ptr[\"DODYEAR\"] == 2015)\n",
    "]\n",
    "print(subgroup[\"DIABETES\"].mean().get(request_block=True, delete_obj=False))\n",
    "print(weighted_mean(subgroup, \"DIABETES\").get(request_block=True, delete_obj=False))\n",
    "print(len(subgroup))\n",
    "\n",
    "# These stats are problematic, as the subgroup is too small to report (n=6)\n",
    "subgroup.get(request_block=True, delete_obj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# from statsmodels.genmod.generalized_linear_model import GLM\n",
    "# from statsmodels.genmod.families import Binomial\n",
    "\n",
    "# # Drop any missing values in the dataset (those under 18)\n",
    "# df = df.dropna(subset=[\"MORTSTAT\"])\n",
    "# # Keep only the eligible portion\n",
    "# df = df[df.ELIGSTAT == 1]\n",
    "\n",
    "# # Ignore people > 80\n",
    "# df = df[df.AGE_P <= 80]\n",
    "\n",
    "# # A person is alive if MORTSTAT==0\n",
    "# df[\"is_alive\"] = df.MORTSTAT == 0\n",
    "\n",
    "# # Assign a helpful column for sex (0==male, 1==female)\n",
    "# df[\"sex\"] = \"male\"\n",
    "# df.loc[df.SEX == 2, \"sex\"] = \"female\"\n",
    "\n",
    "# x = df[\"AGE_P\"]\n",
    "# _x = sm.add_constant(x)\n",
    "# _y = df[\"is_alive\"]\n",
    "\n",
    "# results = GLM(_y, _x, family=Binomial()).fit()\n",
    "# print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see available remote statsmodel API\n",
    "duet.statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any missing values in the dataset (those under 18)\n",
    "df = df_ptr.dropna(subset=[\"MORTSTAT\"])\n",
    "# Keep only the eligible portion\n",
    "df = df[df[\"ELIGSTAT\"] == 1]\n",
    "\n",
    "# Ignore people > 80\n",
    "df = df[df[\"AGE_P\"] <= 80]\n",
    "\n",
    "# A person is alive if MORTSTAT==0\n",
    "df[\"is_alive\"] = df[\"MORTSTAT\"] == 0\n",
    "\n",
    "# Assign a helpful column for sex (0==male, 1==female)\n",
    "df[\"sex\"] = \"male\"\n",
    "df.loc[df[\"SEX\"] == 2, \"sex\"] = \"female\"\n",
    "\n",
    "x_ptr = df[\"AGE_P\"]\n",
    "_x_ptr = duet.statsmodels.api.add_constant(x_ptr)\n",
    "_y_ptr = df[\"is_alive\"]\n",
    "\n",
    "model = duet.statsmodels.genmod.generalized_linear_model.GLM(\n",
    "    _y_ptr, _x_ptr, family=duet.statsmodels.genmod.families.Binomial()\n",
    ")\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_summary = results.get(request_block=True, delete_obj=False)\n",
    "print(remote_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "summary_df = pd.read_csv(io.StringIO(remote_summary), names=[1, 2, 3, 4, 5, 6, 7])\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_ptr.get(request_block=True, delete_obj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = _y_ptr.get(request_block=True, delete_obj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = df[\"sex\"].get(request_block=True, delete_obj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO finish adding range and dynamic object attributes for remote invocation\n",
    "predict_x = range(x.min(), x.max() + 1, 1)\n",
    "# preds = results.predict(sm.add_constant(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request the results.predict calculation and retrieve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = duet.store[\"preds\"].get(request_block=True, delete_obj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df[\"AGE_P\"] = x\n",
    "plot_df[\"is_alive\"] = _y\n",
    "plot_df[\"sex\"] = sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pylab as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(predict_x, preds, \"k\", lw=3, label=\"Best Fit for all data\")\n",
    "    sns.lineplot(data=plot_df, x=\"AGE_P\", y=\"is_alive\", hue=\"sex\", err_style=\"bars\")\n",
    "    sns.despine()\n",
    "except ImportError:\n",
    "    print(\"Cant import seaborn try:\\n!pip install seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-shame",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
