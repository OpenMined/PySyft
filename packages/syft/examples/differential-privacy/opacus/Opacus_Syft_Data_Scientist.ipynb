{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opacus - Syft Duet - Data Scientist ü•Å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Connect to a Remote Duet Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "sy.load(\"opacus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 0 : Now STOP and run the Data Owner notebook until Checkpoint 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 16, 8, 2, padding=3)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(16, 32, 4, 2) \n",
    "        self.fc1 = self.torch_ref.nn.Linear(32 * 4 * 4, 32)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        F = self.torch_ref.nn.functional\n",
    "        # x of shape [B, 1, 28, 28]\n",
    "        x = F.relu(self.conv1(x))  # -> [B, 16, 14, 14]\n",
    "        x = F.max_pool2d(x, 2, 1)  # -> [B, 16, 13, 13]\n",
    "        x = F.relu(self.conv2(x))  # -> [B, 32, 5, 5]\n",
    "        x = F.max_pool2d(x, 2, 1)  # -> [B, 32, 4, 4]\n",
    "        x = x.view(-1, 32 * 4 * 4)  # -> [B, 512]\n",
    "        x = F.relu(self.fc1(x))  # -> [B, 32]\n",
    "        x = self.fc2(x)  # -> [B, 10]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import torch and torchvision just as we normally would\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can create the model and pass in our local copy of torch\n",
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can get our MNIST Test Set ready using our local copy of torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for the MNIST data set\n",
    "local_transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = torchvision.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a few settings which are from the original Opacus MNIST example args\n",
    "# TODO: support secure_rng\n",
    "batch_size = 64\n",
    "test_batch_size = 1024\n",
    "args = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"test_batch_size\": test_batch_size,\n",
    "    \"epochs\": 10,\n",
    "    \"n_runs\": 1,\n",
    "    \"lr\": 0.1,\n",
    "    \"sigma\": 1.0,\n",
    "    \"max_per_sample_grad_norm\": 1.0,\n",
    "    \"delta\": 1e-5,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": True,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "    \"disable_dp\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.util import get_root_data_path\n",
    "# we will configure the test set here locally since we want to know if our Data Owner's\n",
    "# private training dataset will help us reach new SOTA results for our benchmark test set\n",
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(str(get_root_data_path()), train=False, download=True, transform=local_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,**test_kwargs)\n",
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to send the model to our partner‚Äôs Duet Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can load normal torch model weights before sending your model.\n",
    "Try training the model and saving it at the end of the notebook and then coming back and\n",
    "reloading the weights here, or you can train the same model one using the original script\n",
    "in `original` dir and load it here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_auth issues?\n",
    "model = local_model.send(duet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create an alias for our partner‚Äôs torch called `remote_torch` so we can refer to the local torch as `torch` and any operation we want to do remotely as `remote_torch`. Remember, the return values from `remote_torch` are `Pointers`, not the real objects. They mostly act the same when using them with other `Pointers` but you can't mix them with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets ask to see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = remote_torch.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=5,  # change to something slower\n",
    "))\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "remote_torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = remote_torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Data Owner device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get our params, setup an optimizer and a scheduler just the same as the PyTorch MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = remote_torch.optim.SGD(params, lr=args[\"lr\"], momentum=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_opacus = duet.opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we give to Opacus because its a real nn.ModulePointer on the other side\n",
    "# and has all the real methods for searching layers and attaching to them\n",
    "model.real_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 60000\n",
    "noise_multiplier = 1.0\n",
    "max_grad_norm = 1.0\n",
    "privacy_engine_ptr = remote_opacus.privacy_engine.PrivacyEngine(\n",
    "    model.real_module, batch_size=args[\"batch_size\"], sample_size=sample_size,\n",
    "    noise_multiplier=noise_multiplier, max_grad_norm=max_grad_norm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_engine_ptr.attach(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a training loop so we can improve our remote model. Since we want to train on remote data we should first check if the model is remote since we will be using remote_torch in this function. To check if a model is local or remote simply use the `.is_local` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length, privacy_engine_ptr):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    \n",
    "    model.train()\n",
    "    criterion = torch_ref.nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    for _batch_idx, data_tuple in enumerate(train_loader):\n",
    "        data, target = data_tuple[0], data_tuple[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item_ptr = loss.item()\n",
    "        local_loss = loss_item_ptr.get(\n",
    "            reason=\"To evaluate training progress\",\n",
    "            request_block=True,\n",
    "            timeout_secs=5\n",
    "        )\n",
    "\n",
    "        if local_loss is not None:\n",
    "            losses.append(local_loss)\n",
    "\n",
    "        if not args[\"disable_dp\"]:\n",
    "            epsilon_tuple = privacy_engine_ptr.get_privacy_spent(args[\"delta\"])\n",
    "            epsilon_ptr = epsilon_tuple[0].resolve_pointer_type()\n",
    "            best_alpha_ptr = epsilon_tuple[1].resolve_pointer_type()\n",
    "\n",
    "            epsilon = epsilon_ptr.get(\n",
    "                reason=\"So we dont go over it\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            best_alpha = best_alpha_ptr.get(\n",
    "                reason=\"So we dont go over it\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "\n",
    "            loss_mean = float(\"-inf\")\n",
    "            if len(losses) > 0:\n",
    "                loss_mean = sum(losses) / len(losses)\n",
    "            if epsilon is None:\n",
    "                epsilon = float(\"-inf\")\n",
    "            if best_alpha is None:\n",
    "                best_alpha = float(\"-inf\")\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch} \\t\"\n",
    "                f\"Loss: {loss_mean:.6f} \"\n",
    "                f\"(Œµ = {epsilon:.2f}, Œ¥ = {args['delta']}) for Œ± = {best_alpha}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Train Epoch: {epoch} \\t Loss: {loss_mean:.6f}\")\n",
    "            \n",
    "        if args[\"dry_run\"]:\n",
    "            break\n",
    "    \n",
    "        if _batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a simple test loop very similar to the original PyTorch MNIST example.\n",
    "This function should expect a remote model from our outer epoch loop, so internally we can call `get` to download the weights to do an evaluation on our machine with our local test set. Remember, if we have trained on private data, our model will require permission to download, so we should use request_block=True and make sure the Data Owner approves our requests. For the rest of this function, we will use local `torch` as we normally would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local(model, torch_ref, test_loader, test_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "\n",
    "    # download remote model\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "\n",
    "    local_model.eval()\n",
    "    criterion = torch_ref.nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = local_model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n\".format(\n",
    "            test_loss,\n",
    "            correct,\n",
    "            len(test_loader.dataset),\n",
    "            100.0 * correct / len(test_loader.dataset),\n",
    "        )\n",
    "    )\n",
    "    return correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally just for demonstration purposes, we will get the built-in MNIST dataset but on the Data Owners side from `remote_torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for the MNIST data set\n",
    "remote_torchvision = duet.torchvision\n",
    "\n",
    "transform_1 = remote_torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = remote_torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "remote_list = duet.python.List()  # create a remote list to add the transforms to\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = remote_torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = remote_torchvision.datasets.MNIST(str(get_root_data_path()), train=True, download=True, transform=transforms)\n",
    "train_loader_ptr = remote_torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_length = 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# args[\"dry_run\"] = False  # uncomment to do a full train\n",
    "print(\"Starting Training\")\n",
    "\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    # remote training on model with remote_torch\n",
    "    train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length, privacy_engine_ptr)\n",
    "    # local testing on model with local torch\n",
    "    test_local(model, torch, test_loader, test_data_length)\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    if args[\"dry_run\"]:\n",
    "        break\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = None\n",
    "if args[\"save_model\"]:\n",
    "    local_model = model.get(\n",
    "        request_block=True,\n",
    "        reason=\"test evaluation\",\n",
    "        timeout_secs=5\n",
    "    ).save(\"./duet_mnist.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model would be no fun without the ability to do inference. The following code shows some examples on how we can do this either remotely or locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(image, model):\n",
    "    if not model.is_local:\n",
    "        print(\"model is remote try .get()\")\n",
    "        return -1, torch.Tensor([-1])\n",
    "    image_tensor = torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor)\n",
    "    preds = torch.exp(output)\n",
    "    local_y = preds\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = torch.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_remote(image, model):\n",
    "    if model.is_local:\n",
    "        print(\"model is local try .send()\")\n",
    "        return -1, remote_torch.Tensor([-1])\n",
    "    image_tensor_ptr = remote_torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor_ptr)\n",
    "    preds = remote_torch.exp(output)\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, torch.Tensor([-1])\n",
    "    else:\n",
    "        # now we have the local tensor we can use local torch\n",
    "        local_y = torch.Tensor(preds_result)\n",
    "        local_y = local_y.squeeze()\n",
    "        pos = local_y == max(local_y)\n",
    "        index = torch.nonzero(pos, as_tuple=False)\n",
    "        class_num = index.squeeze()\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab something from the test set\n",
    "import random\n",
    "total_images = test_data_length # 10000\n",
    "index = random.randint(0, total_images)\n",
    "print(\"Random Test Image:\", index)\n",
    "count = 0\n",
    "batch = index // test_kwargs[\"batch_size\"]\n",
    "batch_index = index % int(total_images / len(test_loader))\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if batch == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(f\"Displaying {index} == {batch_index} in Batch: {batch}/{len(test_loader)}\")\n",
    "if batch_index > len(data):\n",
    "    batch_index = 0\n",
    "image_1 = data[batch_index].reshape((28, 28))\n",
    "label_1 = target[batch_index]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify remote\n",
    "class_num, preds = classify_remote(image_1, model)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_model is None:\n",
    "    local_model = model.get(\n",
    "        request_block=True,\n",
    "        reason=\"To run test and inference locally\",\n",
    "        timeout_secs=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify local\n",
    "class_num, preds = classify_local(image_1, local_model)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also download an image from the web and run inference on that\n",
    "from PIL import Image, ImageEnhance\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import os\n",
    "def classify_url_image(image_url):\n",
    "    filename = os.path.basename(image_url)\n",
    "    os.system(f'curl -O {image_url}')\n",
    "    im = Image.open(filename)\n",
    "    im = PIL.ImageOps.invert(im)\n",
    "#     im = im.resize((28,28), Image.ANTIALIAS)\n",
    "    im = im.convert('LA')\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    im = enhancer.enhance(3)\n",
    "\n",
    "\n",
    "    print(im.size)\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im, cmap=\"gray\", interpolation=\"none\")\n",
    "    \n",
    "    # classify local\n",
    "    class_num, preds = classify_local(image_1, local_model)\n",
    "    print(f\"Prediction: {class_num}\")\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_url = \"https://raw.githubusercontent.com/kensanata/numbers/master/0018_CHXX/0/number-100.png\"\n",
    "# classify_url_image(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 1 : Now STOP and run the Data Owner notebook until the next checkpoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
