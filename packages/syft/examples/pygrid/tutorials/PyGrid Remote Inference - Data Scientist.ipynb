{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd0200d4",
   "metadata": {},
   "source": [
    "# PyGrid: Remote Inference - Data Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277a1e3",
   "metadata": {},
   "source": [
    "<img src=\"../../../docs/img/pygrid_logo.png\" align=\"center\"/>\n",
    "\n",
    "The ability to evaluate custom models, using private datasets without having access to them; is a powerful idea that will change the way we interact with data during a machine learning workflow. PySyft and PyGrid offer the ability to run inferences remotely by using a variety of technologies and applications.\n",
    "\n",
    "In this notebook series, we'll be covering all the nuances of this process, showing how to send private datasets _(as Data Owner)_, and how to perform remote computation using private environments _(as Data Scientist)_.\n",
    "\n",
    "The main goal of these notebooks is to explore different techniques and technologies that can finally make **private data _\"accessible\"_ to Data Scientists, while also providing Data Owners with total control of their data.**\n",
    "\n",
    "**NOTE**: _This notebook was designed to be executed in pair with the [PyGrid Remote Inference - Data Owner](./PyGrid%20Remote%20Inference%20-%20Data%20Owner.ipynb) notebook. In order to reproduce it properly, follow the checkpoints and instructions described in the next sections._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3300b7b3",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "- [**Creating User Accounts**](#creating-user-accounts)\n",
    "- [**Remote Datasets**](#remote-datasets)\n",
    "- [**Train a Local Model**](#train-local-model)\n",
    "- [**PyGrid Workers**](#setting-computing-environment)\n",
    "- [**Remote Inference + Differencial Privacy**](#remote-inference)\n",
    "- [**Data Retrieval**](#data-access-request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ca1f0",
   "metadata": {},
   "source": [
    "<a id=\"creating-user-accounts\"></a>\n",
    "## Creating User Accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88538d",
   "metadata": {},
   "source": [
    "#### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.grid.client.client import connect  # Method used to connect with the domain.\n",
    "from syft.grid.client.grid_connection import (\n",
    "    GridHTTPConnection,\n",
    ")  # Protocol used to talk with the domain\n",
    "\n",
    "import syft as sy\n",
    "import torch as th\n",
    "\n",
    "# Set logging level\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import pydp\n",
    "\n",
    "sy.load(\"pydp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f776d3",
   "metadata": {},
   "source": [
    "#### Create User account\n",
    "In this scenario, we're assuming that the data scientist will start from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYGRID_PORT = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we still don't have our own account,\n",
    "# we can connect with the domain without credentials.\n",
    "unauthenticated_client = connect(\n",
    "    url=f\"http://localhost:{PYGRID_PORT}\",  # Domain Address\n",
    "    conn_type=GridHTTPConnection,\n",
    ")  # HTTP Connection Protocol\n",
    "\n",
    "unauthenticated_client.users.create(\n",
    "    email=\"scientist@researchorg.edu\", password=\"pwd123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can finally log-in using our credentials.\n",
    "domain_client = connect(\n",
    "    url=f\"http://localhost:{PYGRID_PORT}\",  # Domain Address\n",
    "    credentials={\"email\": \"scientist@researchorg.edu\", \"password\": \"pwd123\"},\n",
    "    conn_type=GridHTTPConnection,\n",
    ")  # HTTP Connection Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54fda53",
   "metadata": {},
   "source": [
    "Done! We have an User account!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbc053",
   "metadata": {},
   "source": [
    "<a id=\"remote-datasets\"></a>\n",
    "## Remote Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b66e5",
   "metadata": {},
   "source": [
    "### Checking for available datasets\n",
    "Now, let's take a look at the domain repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decbe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.datasets.all(pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset = domain_client.datasets[\"b76f9a38-ecc4-43ca-86cd-d232ee22cc7a\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d76194",
   "metadata": {},
   "source": [
    "As we can see, we have a dataset available to be used. Datasets are robust grid structures that were designed to point to several remote data, obeying the structure of those who created it,  they can represent csv files, images, or even the abstraction of train/test datasets. In this example, we'll be covering a dataset composed by different CSV files. _Although, they will no longer being stored as CSV files inside of the domain_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb4dae",
   "metadata": {},
   "source": [
    "### Exploring the metadata\n",
    "As you probably know, we can't have access to the real values of the dataset. It's private and remote! However, we can explore its metadata information in order to understand how the data has been organized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296386c",
   "metadata": {},
   "source": [
    "#### Manifest\n",
    "Dataset manifest is a document commonly used to describe the data meaning. Here, we expect to know the meaning of each column, their object types and the purpose of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679058d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remote_dataset.manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0341df",
   "metadata": {},
   "source": [
    "#### Tags\n",
    "Commonly used to give an overview about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70316e03",
   "metadata": {},
   "source": [
    "#### Dataset Pandas\n",
    "Used to understand how the dataset pointers are organized, what's their types, shape and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074947d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_dataset.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74030e",
   "metadata": {},
   "source": [
    "\n",
    "_PS: At the time this notebook has been written, the domain was only supporting compressed \"tar.gz\" files  as a dataset. Contact the author of this article to find out the current status of this feature._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a1a79",
   "metadata": {},
   "source": [
    "<a id=\"train-local-model\"></a>\n",
    "## Train a Local Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89060fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diabetes_model_training import train_diabetes_model, plot_training_acc\n",
    "\n",
    "model, loss, acc, epochs_list = train_diabetes_model(th)\n",
    "plot_training_acc(acc, loss, epochs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e0219",
   "metadata": {},
   "source": [
    "<a id=\"setting-computing-environment\"></a>\n",
    "## PyGrid Workers\n",
    "\n",
    "PyGrid aims to provide a custom and private environment for the users to perform their computation. That way, the user is empowered to choose their computing resources. We're currently supporting **Azure**, **GCP** and **AWS**. In this notebook we'll be using Azure as a cloud platform since it provides an additional secure layer based in a Trusted Execution Environment (TEE). That way, the data owner can protect his data from the user and also from the infrastructure where the domain lives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db52fda1",
   "metadata": {},
   "source": [
    "#### Get Instance type\n",
    "First, we need to know what instances are available to be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2aa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.workers.instance_type(pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bafd0",
   "metadata": {},
   "source": [
    "#### Create a worker\n",
    "Once we have decided about the vm instance, we can request for the domain to create one for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.workers.create(instance_type=\"t2.large\")\n",
    "domain_client.workers.all(pandas=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f29ab24",
   "metadata": {},
   "source": [
    "Then, with the worker deployed, we can get a proxy client which will be used to send messages to the environment through the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = domain_client.workers[1]\n",
    "print(\"Worker Provider: \", worker.provider)\n",
    "print(\"Worker Instance Type: \", worker.instance_type)\n",
    "print(\"Worker Region:\", worker.region)\n",
    "print(\"Worker Syft (Logic) Address\", worker.address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2977b30",
   "metadata": {},
   "source": [
    "#### Loading private dataset\n",
    "Ok, now we have the worker able to perform remote computation, but it's still empty. In order to transfer private datasets and tensors we must use the _load_ method. This method will get a pointer of an object that lives in the domain, and send it to our worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf288f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Let's choose one of those dataset pointers to be our data sample during the remote inference\n",
    "private_data_sample = remote_dataset.files[0]\n",
    "print(\"Dataset Name: \", private_data_sample.name)\n",
    "print(\"Dataset Shape: \", private_data_sample.shape)\n",
    "print(\"Dataset Type: \", private_data_sample.dtype)\n",
    "print(\"Dataset Pointer: \", private_data_sample.pointer)\n",
    "\n",
    "# 2 - Then we can load it from the domain to our own worker.\n",
    "domain_client.load(private_data_sample.pointer, worker.address)\n",
    "\n",
    "# 3 - Finally, we can see the data inside the worker store\n",
    "worker.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c4356",
   "metadata": {},
   "source": [
    "#### Loading a model\n",
    "Let's do the same thing with our model trained locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44205812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS: Since we're transfering the model from our own machine to our Virtual Machine\n",
    "# we'll be using \"send\" instead of load\n",
    "remote_model = model.send(worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095363d",
   "metadata": {},
   "source": [
    "<a id=\"remote-inference\"></a>\n",
    "## Remote Inference + Differential Privacy\n",
    "**Finally!** We have everything ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a541082",
   "metadata": {},
   "source": [
    "#### Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the private data set into features and labels\n",
    "feature = worker.store[0][0:, 0:8]\n",
    "labels = worker.store[0][0:, 8]\n",
    "\n",
    "predicted = remote_model(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2b6bd",
   "metadata": {},
   "source": [
    "#### Computing accuracy\n",
    "Now, we need to compare the predicted results with the private dataset labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef221e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (predicted.reshape(-1).round() == labels).int().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f0662",
   "metadata": {},
   "source": [
    "#### Adding noise\n",
    "To increase the data security we'll be adding a small noise on our result by using Differential Privacy techniques. <br><br>\n",
    "Since we intend to compute the accuracy of our prediction, we can just perform a private mean which can vary from 0 to 1. For this example we're defining our privacy budget equals to 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f79228",
   "metadata": {},
   "outputs": [],
   "source": [
    "BoundedMean = worker.pydp.algorithms.laplacian.BoundedMean\n",
    "mean_ptr = BoundedMean(0.8, lower_bound=0.01, upper_bound=1.0, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fe613",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_result = mean_ptr.quick_result(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd26afb",
   "metadata": {},
   "source": [
    "#### Saving the results\n",
    "Before deleting our ephemeral instance we must save the result of our computation. We can do it by using the _save_ command. This command will send a data from our worker to the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Sending from worker to domain\n",
    "worker.save(acc_result)\n",
    "\n",
    "# 2 - Deleting our Virtual Machine\n",
    "# del domain_client.workers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30301a1b",
   "metadata": {},
   "source": [
    "<a id=\"data-access-request\"></a>\n",
    "## Data Retrieval\n",
    "The last step is to request the compliance officer for data access permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_client.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ptr = domain_client.store[\"0cbd040781a04559ba40e983723d8d2c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df447cc",
   "metadata": {},
   "source": [
    "Done! We have an accuracy data stored somewhere inside of our domain. Now let's finally request the data access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85259470",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ptr.request(reason=\"I'd like to have access to my accuracy result!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5a3d5",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint : Now STOP and run the Data Owner notebook until the next checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ptr.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500d9a1",
   "metadata": {},
   "source": [
    "**_Voilà!_** This is our accuracy result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a941773",
   "metadata": {},
   "source": [
    "## Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Take our FREE Video Course \"The Private AI Series\"\n",
    "Learn how privacy technology is changing our world and how you can lead the charge.\n",
    "We cover non technical concepts about structured transparency, as well as deep dive into the technical aspects of various Cryptographic technologies and how to use them with Syft and Grid.\n",
    "* [📺 Video Course](https://courses.openmined.org/)\n",
    "\n",
    "### Star PySyft and PyGrid on GitHub\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "* [⭐️ Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "* [⭐️ Star PyGrid](https://github.com/OpenMined/PyGrid)\n",
    "\n",
    "### Join our Slack!\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at http://slack.openmined.org\n",
    "\n",
    "### Join a Code Project!\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "* [PySyft Good First Issue Tickets](https://github.com/OpenMined/PySyft/labels/Good%20first%20issue%20%3Amortar_board%3A)\n",
    "* [PyGrid Good First Issue Tickets](https://github.com/OpenMined/PyGrid/labels/good%20first%20issue)\n",
    "\n",
    "### Donate\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "* [OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-building",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
