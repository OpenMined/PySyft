{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-session",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duet1 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-knife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duet2 = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_ptr = duet1.store[0]\n",
    "data2_ptr = duet2.store[0]\n",
    "\n",
    "print(data1_ptr)\n",
    "print(data2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-personal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.linear = self.torch_ref.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data_ptr)\n",
    "\n",
    "        loss = torch_ref.nn.functional.mse_loss(output, target_ptr)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\",\n",
    "            request_block=True,\n",
    "            timeout_secs=5,\n",
    "        )\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-partner",
   "metadata": {},
   "source": [
    "Train on Data Owner 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model1 = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = local_model1.send(duet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch\n",
    "params = remote_model1.parameters()\n",
    "optim1 = remote_torch1.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-spirit",
   "metadata": {},
   "source": [
    "Dummy target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1_ptr = th.FloatTensor(np.array([5, 10, 15, 22, 30, 38]).reshape(-1, 1))\n",
    "target1_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = train(iteration, remote_model1, remote_torch1, optim1, data1_ptr, target1_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-election",
   "metadata": {},
   "source": [
    "Train on Data Owner 2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model2 = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2 = local_model2.send(duet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch\n",
    "params = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-material",
   "metadata": {},
   "source": [
    "Dummy Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2_ptr = th.FloatTensor(np.array([35, 40, 45, 55, 60]).reshape(-1, 1))\n",
    "target2_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make THIS server the coordinator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Little sanity check!\n",
    "\n",
    "param1 = remote_model1.parameters().get(request_block=True)\n",
    "param2 = remote_model2.parameters().get(request_block=True)\n",
    "\n",
    "print(\"Local model1 parameters:\")\n",
    "print(local_model1.parameters())\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Local model2 parameters:\")\n",
    "print(local_model2.parameters())\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"linear.weight\"] = (\n",
    "    remote_model1_updates[\"linear.weight\"] + remote_model2_updates[\"linear.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"linear.bias\"] = (\n",
    "    remote_model1_updates[\"linear.bias\"] + remote_model2_updates[\"linear.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
