{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSequence - Syft Duet - Data Owner ðŸŽ¸\n",
    "\n",
    "Contributed by [@Koukyosyumei](https://github.com/Koukyosyumei)\n",
    "\n",
    "## PART 1: Launch a Duet Server and Connect\n",
    "\n",
    "As a Data Owner, you want to allow someone else to perform data science on data that you own and likely want to protect.\n",
    "\n",
    "In order to do this, we must load our data into a locally running server within this notebook. We call this server a \"Duet\".\n",
    "\n",
    "To begin, you must launch Duet and help your Duet \"partner\" (a Data Scientist) connect to this server.\n",
    "\n",
    "You do this by running the code below and sending the code snippet containing your unique Server ID to your partner and following the instructions it gives!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "from typing import List as TypeList\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "from syft import SyModule\n",
    "from syft.core.plan.plan_builder import ROOT_CLIENT, make_plan\n",
    "\n",
    "try:\n",
    "    # make notebook progress bars nicer\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    print(f\"Unable to import tqdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "\n",
    "duet = sy.launch_duet(loopback=True)\n",
    "sy.logger.add(sink=\"./syft_do.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handler with no tags accepts everything. Better handlers coming soon.\n",
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 5  # original number is 20\n",
    "L = 100  # original number is 1000\n",
    "N = 100\n",
    "\n",
    "x = np.empty((N, L), \"int64\")\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin(x / 1.0 / T).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.Tensor(data)\n",
    "data_tensor.tag(\"data\")\n",
    "data_tensor.send(duet, pointable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_ptr = sy.lib.python.Int(L)\n",
    "L_ptr.tag(\"L\")\n",
    "L_ptr.send(duet, pointable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = data_tensor[3:, :-1]\n",
    "input.tag(\"input\")\n",
    "input.send(duet, pointable=True)\n",
    "\n",
    "target = data_tensor[3:, 1:]\n",
    "target.tag(\"target\")\n",
    "target.send(duet, pointable=True)\n",
    "\n",
    "test_input = data_tensor[:3, :-1]\n",
    "test_input.tag(\"test_input\")\n",
    "test_input.send(duet, pointable=True)\n",
    "\n",
    "test_target = data_tensor[:3, 1:]\n",
    "test_target.tag(\"test_target\")\n",
    "test_target.send(duet, pointable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_0 = sy.lib.python.Int(input.size()[0])\n",
    "input_size_0.tag(\"input_size_0\")\n",
    "input_size_0.send(duet, pointable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = ROOT_CLIENT.torch\n",
    "remote_python = ROOT_CLIENT.python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence(SyModule):\n",
    "    def __init__(self, **kwargs: Any) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.lstm1 = torch.nn.LSTMCell(1, 51)\n",
    "        self.lstm2 = torch.nn.LSTMCell(51, 51)\n",
    "        self.linear = torch.nn.Linear(51, 1)\n",
    "        self.future = 0\n",
    "\n",
    "    def forward(self, input: Any) -> Any:\n",
    "        outputs = remote_python.List([])\n",
    "        h_t = torch.zeros(97, 51)\n",
    "        c_t = torch.zeros(97, 51)\n",
    "        h_t2 = torch.zeros(97, 51)\n",
    "        c_t2 = torch.zeros(97, 51)\n",
    "\n",
    "        state_1 = remote_python.Tuple((h_t, c_t))\n",
    "        state_2 = remote_python.Tuple((h_t2, c_t2))\n",
    "\n",
    "        for input_t in input.split(1, dim=1):\n",
    "            state_1 = self.lstm1(input_t, state_1)\n",
    "            state_2 = self.lstm2(h_t, state_2)\n",
    "            output = self.linear(state_2[0])\n",
    "            outputs.append(output)\n",
    "\n",
    "        for i in range(self.future):  # if we should predict the future\n",
    "            state_1 = self.lstm1(output, state_1)\n",
    "            state_2 = self.lstm2(h_t, state_2)\n",
    "            output = self.linear(state_2[0])\n",
    "            outputs.append(output)\n",
    "\n",
    "        outputs = remote_torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_size = 9\n",
    "dummy_input = input[:, :dummy_size]\n",
    "dummy_target = target[:, :dummy_size]\n",
    "local_model = Sequence(input_size=(input_size_0, dummy_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@make_plan\n",
    "def train(\n",
    "    input: torch.Tensor = dummy_input,\n",
    "    target: torch.Tensor = dummy_target,\n",
    "    model: SyModule = local_model,\n",
    ") -> TypeList:\n",
    "\n",
    "    # optimizer = remote_torch.optim.LBFGS(model.parameters(), lr=1e-2)\n",
    "    optimizer = remote_torch.optim.AdamW(model.parameters(), lr=1e-2)\n",
    "    criterion = remote_torch.nn.MSELoss()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    out = model(input=input)[0]\n",
    "\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.tag(\"train\")\n",
    "train.send(duet, pointable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 1 : Now STOP and run the Data Scientist notebook until the same checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-light.png\" alt=\"he-black-box\" width=\"100\"/> Checkpoint 2 : Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
