{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Centric Federated Learning - MNIST Example: Create Plan\n",
    "\n",
    "This notebook is an example of creating a simple model and a training plan\n",
    "for solving MNIST classification in model-centric (aka cross-device) federated learning fashion.\n",
    "\n",
    "It consists of the following steps:\n",
    "* Defining the model\n",
    "* Defining the Training Plan\n",
    "* Defining the Averaging Plan & FL configuration\n",
    "* Hosting everything to PyGrid\n",
    "* Extra: demonstration of PyGrid API\n",
    "\n",
    "The process of training a hosted model using existing python FL worker is demonstrated in\n",
    "the following \"[MCFL - Execute Plan](mcfl_execute_plan.ipynb)\" notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# third party\n",
    "import jwt\n",
    "import requests\n",
    "import torch as th\n",
    "from websocket import create_connection\n",
    "\n",
    "# syft absolute\n",
    "import syft as sy\n",
    "from syft import deserialize\n",
    "from syft import serialize\n",
    "from syft.core.plan.plan_builder import ROOT_CLIENT\n",
    "from syft.core.plan.plan_builder import make_plan\n",
    "from syft.federated.model_centric_fl_client import ModelCentricFLClient\n",
    "from syft.lib.python.int import Int\n",
    "from syft.lib.python.list import List\n",
    "from syft.proto.core.plan.plan_pb2 import Plan as PlanPB\n",
    "from syft.proto.lib.python.list_pb2 import List as ListPB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114c07570>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.random.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the model\n",
    "\n",
    "This model will train on MNIST data, it's very simple yet can demonstrate learning process.\n",
    "There're 2 linear layers: \n",
    "\n",
    "* Linear 784x100\n",
    "* ReLU\n",
    "* Linear 100x10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super().__init__(torch_ref=torch_ref)\n",
    "        self.l1 = self.torch_ref.nn.Linear(784, 100)\n",
    "        self.a1 = self.torch_ref.nn.ReLU()\n",
    "        self.l2 = self.torch_ref.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_reshaped = x.view(-1, 28 * 28)\n",
    "        l1_out = self.a1(self.l1(x_reshaped))\n",
    "        l2_out = self.l2(l1_out)\n",
    "        return l2_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Training Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_params(model, params):\n",
    "    for p, p_new in zip(model.parameters(), params):\n",
    "        p.data = p_new.data\n",
    "\n",
    "\n",
    "def cross_entropy_loss(logits, targets, batch_size):\n",
    "    norm_logits = logits - logits.max()\n",
    "    log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "    return -(targets * log_probs).sum() / batch_size\n",
    "\n",
    "\n",
    "def sgd_step(model, lr=0.1):\n",
    "    with ROOT_CLIENT.torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            p.data = p.data - lr * p.grad\n",
    "            p.grad = th.zeros_like(p.grad.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = MLP(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_plan\n",
    "def train(\n",
    "    xs=th.rand([64 * 3, 1, 28, 28]),\n",
    "    ys=th.randint(0, 10, [64 * 3, 10]),\n",
    "    params=List(local_model.parameters()),\n",
    "):\n",
    "\n",
    "    model = local_model.send(ROOT_CLIENT)\n",
    "    set_params(model, params)\n",
    "    for i in range(1):\n",
    "        indices = th.tensor(range(64 * i, 64 * (i + 1)))\n",
    "        x, y = xs.index_select(0, indices), ys.index_select(0, indices)\n",
    "        out = model(x)\n",
    "        loss = cross_entropy_loss(out, y, 64)\n",
    "        loss.backward()\n",
    "        sgd_step(model)\n",
    "\n",
    "    return model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Averaging Plan\n",
    "\n",
    "Averaging Plan is executed by PyGrid at the end of the cycle,\n",
    "to average _diffs_ submitted by workers and update the model\n",
    "and create new checkpoint for the next cycle.\n",
    "\n",
    "_Diff_ is the difference between client-trained\n",
    "model params and original model params,\n",
    "so it has same number of tensors and tensor's shapes\n",
    "as the model parameters.\n",
    "\n",
    "We define Plan that processes one diff at a time.\n",
    "Such Plans require `iterative_plan` flag set to `True`\n",
    "in `server_config` when hosting FL model to PyGrid.\n",
    "\n",
    "Plan below will calculate simple mean of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@make_plan\n",
    "def avg_plan(\n",
    "    avg=List(local_model.parameters()), item=List(local_model.parameters()), num=Int(0)\n",
    "):\n",
    "    new_avg = []\n",
    "    for i, param in enumerate(avg):\n",
    "        new_avg.append((avg[i] * num + item[i]) / (num + 1))\n",
    "    return new_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config & keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"mnist\"\n",
    "version = \"1.0\"\n",
    "\n",
    "client_config = {\n",
    "    \"name\": name,\n",
    "    \"version\": version,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.1,\n",
    "    \"max_updates\": 1,  # custom syft.js option that limits number of training loops per worker\n",
    "}\n",
    "\n",
    "server_config = {\n",
    "    \"min_workers\": 2,\n",
    "    \"max_workers\": 2,\n",
    "    \"pool_selection\": \"random\",\n",
    "    \"do_not_reuse_workers_until_cycle\": 6,\n",
    "    \"cycle_length\": 28800,  # max cycle length in seconds\n",
    "    \"num_cycles\": 30,  # max number of cycles\n",
    "    \"max_diffs\": 1,  # number of diffs to collect before avg\n",
    "    \"minimum_upload_speed\": 0,\n",
    "    \"minimum_download_speed\": 0,\n",
    "    \"iterative_plan\": True,  # tells PyGrid that avg plan is executed per diff\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    with open(fname, \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_key = read_file(\"example_rsa\").strip()\n",
    "public_key = read_file(\"example_rsa.pub\").strip()\n",
    "\n",
    "server_config[\"authentication\"] = {\n",
    "    \"type\": \"jwt\",\n",
    "    \"pub_key\": public_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Host in PyGrid\n",
    "\n",
    "Let's now host everything in PyGrid so that it can be accessed by worker libraries (syft.js, KotlinSyft, SwiftSyft, or even PySyft itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Start a PyGrid Domain\n",
    "- Clone PyGrid Github repository from https://github.com/OpenMined/PyGrid\n",
    "\n",
    "- Install poetry using pip:\n",
    "```\n",
    "$ pip install poetry\n",
    "```\n",
    "\n",
    "- Go to apps/domain and install requirements:\n",
    "```\n",
    "$ poetry install\n",
    "```\n",
    "\n",
    "- run a Grid domain using the command:\n",
    "```\n",
    "$ ./run.sh --name bob --port 7000 --start_local_db\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_address = \"localhost:7000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ModelCentricFLClient(address=grid_address, secure=False)\n",
    "grid.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the process already exists, might you need to clear the db. To do that, set path below correctly and run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm PyGrid/apps/domain/src/nodedatabase.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = grid.host_federated_training(\n",
    "    model=local_model,\n",
    "    client_plans={\"training_plan\": train},\n",
    "    client_protocols={},\n",
    "    server_averaging_plan=avg_plan,\n",
    "    client_config=client_config,\n",
    "    server_config=server_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'model-centric/host-training', 'data': {'status': 'success'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate for cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to make WS requests\n",
    "def sendWsMessage(data):\n",
    "    ws = create_connection(\"ws://\" + grid_address)\n",
    "    ws.send(json.dumps(data))\n",
    "    message = ws.recv()\n",
    "    return json.loads(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_token = jwt.encode({}, private_key, algorithm=\"RS256\").decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'model-centric/authenticate',\n",
       " 'data': {'status': 'success',\n",
       "  'worker_id': '99663011-6eea-4135-a998-a3e4ac5a4553',\n",
       "  'requires_speed_test': True}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth_request = {\n",
    "    \"type\": \"model-centric/authenticate\",\n",
    "    \"data\": {\n",
    "        \"model_name\": name,\n",
    "        \"model_version\": version,\n",
    "        \"auth_token\": auth_token,\n",
    "    },\n",
    "}\n",
    "auth_response = sendWsMessage(auth_request)\n",
    "auth_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do cycle request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle response: {\n",
      "  \"type\": \"model-centric/cycle-request\",\n",
      "  \"data\": {\n",
      "    \"status\": \"accepted\",\n",
      "    \"request_key\": \"c5d6a1183aec817bc29de87d745e6760ad2748377c331c8e5d3adbddbdebf600\",\n",
      "    \"version\": \"1.0\",\n",
      "    \"model\": \"mnist\",\n",
      "    \"plans\": {\n",
      "      \"training_plan\": 2\n",
      "    },\n",
      "    \"protocols\": {},\n",
      "    \"client_config\": {\n",
      "      \"name\": \"mnist\",\n",
      "      \"version\": \"1.0\",\n",
      "      \"batch_size\": 64,\n",
      "      \"lr\": 0.1,\n",
      "      \"max_updates\": 1\n",
      "    },\n",
      "    \"model_id\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cycle_request = {\n",
    "    \"type\": \"model-centric/cycle-request\",\n",
    "    \"data\": {\n",
    "        \"worker_id\": auth_response[\"data\"][\"worker_id\"],\n",
    "        \"model\": name,\n",
    "        \"version\": version,\n",
    "        \"ping\": 1,\n",
    "        \"download\": 10000,\n",
    "        \"upload\": 10000,\n",
    "    },\n",
    "}\n",
    "cycle_response = sendWsMessage(cycle_request)\n",
    "print(\"Cycle response:\", json.dumps(cycle_response, indent=2).replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_id = auth_response[\"data\"][\"worker_id\"]\n",
    "request_key = cycle_response[\"data\"][\"request_key\"]\n",
    "model_id = cycle_response[\"data\"][\"model_id\"]\n",
    "training_plan_id = cycle_response[\"data\"][\"plans\"][\"training_plan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(grid_address, worker_id, request_key, model_id):\n",
    "    req = requests.get(\n",
    "        f\"http://{grid_address}/model-centric/get-model?worker_id={worker_id}&request_key={request_key}&model_id={model_id}\"\n",
    "    )\n",
    "    model_data = req.content\n",
    "    pb = ListPB()\n",
    "    pb.ParseFromString(req.content)\n",
    "    return deserialize(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params shapes: [torch.Size([100, 784]), torch.Size([100]), torch.Size([10, 100]), torch.Size([10])]\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model_params_downloaded = get_model(grid_address, worker_id, request_key, model_id)\n",
    "print(\"Params shapes:\", [p.shape for p in model_params_downloaded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "        [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "        ...,\n",
       "        [-0.0255,  0.0213,  0.0111,  ...,  0.0060, -0.0308,  0.0306],\n",
       "        [-0.0323, -0.0083, -0.0017,  ...,  0.0317, -0.0348,  0.0304],\n",
       "        [-0.0058,  0.0239, -0.0202,  ..., -0.0106,  0.0301, -0.0222]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params_downloaded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download & Execute Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\n",
    "    f\"http://{grid_address}/model-centric/get-plan?worker_id={worker_id}&request_key={request_key}&plan_id={training_plan_id}&receive_operations_as=list\"\n",
    ")\n",
    "pb = PlanPB()\n",
    "pb.ParseFromString(req.content)\n",
    "plan = deserialize(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = th.rand([64 * 3, 1, 28, 28])\n",
    "ys = th.randint(0, 10, [64 * 3, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res,) = plan(xs=xs, ys=ys, params=model_params_downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Model diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhavajay/dev/PySyft/src/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "diff = [orig - new for orig, new in zip(res, local_model.parameters())]\n",
    "diff_serialized = serialize((List(diff))).SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"type\": \"model-centric/report\",\n",
    "    \"data\": {\n",
    "        \"worker_id\": worker_id,\n",
    "        \"request_key\": request_key,\n",
    "        \"diff\": base64.b64encode(diff_serialized).decode(\"ascii\"),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'model-centric/report', 'data': {'status': 'success'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sendWsMessage(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_params = {\n",
    "    \"name\": name,\n",
    "    \"version\": version,\n",
    "    \"checkpoint\": \"latest\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(f\"http://{grid_address}/model-centric/retrieve-model\", req_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pb = ListPB()\n",
    "params_pb.ParseFromString(res.content)\n",
    "new_model_params = deserialize(params_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "        [-0.0205, -0.0405,  0.0165,  ..., -0.0154, -0.0009,  0.0094],\n",
       "        [ 0.0012,  0.0043,  0.0069,  ..., -0.0116, -0.0177,  0.0073],\n",
       "        ...,\n",
       "        [-0.0228,  0.0258,  0.0132,  ...,  0.0085, -0.0291,  0.0339],\n",
       "        [-0.0366, -0.0134, -0.0075,  ...,  0.0274, -0.0388,  0.0244],\n",
       "        [-0.0018,  0.0306, -0.0153,  ..., -0.0078,  0.0365, -0.0224]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm PyGrid/apps/domain/src/nodedatabase.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 5: Train\n",
    "\n",
    "To train hosted model, you can use existing python FL worker.\n",
    "See the \"[MCFL - Execute Plan](mcfl_execute_plan.ipynb)\" notebook that\n",
    "has example of using Python FL worker.\n",
    "\n",
    "To understand how to make similar model working for mobile FL workers,\n",
    "see \"[MCFL for Mobile - Create Plan](mcfl_execute_plan_mobile.ipynb)\" notebook!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
