{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Lightning âš¡ï¸ Syft Duet - Data Scientist ðŸ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the Data Scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server in their Notebook.\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. The code will look like this, importantly with their real Server ID.\n",
    "\n",
    "```\n",
    "import syft as sy\n",
    "duet = sy.duet('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "```\n",
    "\n",
    "This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Paste the code or Server ID that the Data Owner gives you and run it in the cell below. It will return your Client ID which you must send to the Data Owner to enter into Duet so it can pair your notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import syft as sy\n",
    "\n",
    "from torch import nn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.experimental.plugins.secure.pysyft import SyLightningModule\n",
    "from pytorch_lightning.utilities.imports import is_syft_initialized\n",
    "from pytorch_lightning.metrics import Accuracy\n",
    "from syft.util import get_root_data_path\n",
    "\n",
    "duet = sy.join_duet(loopback=True)\n",
    "sy.load(\"pytorch_lightning\")\n",
    "\n",
    "sy.client_cache[\"duet\"] = duet\n",
    "assert is_syft_initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Setting up a Model and our Data\n",
    "The majority of the code below has been adapted closely from the original PyTorch MNIST example which is available in the `original` directory with these notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `duet` variable is now your reference to a whole world of remote operations including supported libraries like torch.\n",
    "\n",
    "Lets take a look at the duet.torch attribute.\n",
    "```\n",
    "duet.torch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a model just like the one in the MNIST example. We do this in almost the exact same way as in PyTorch. The main difference is we inherit from sy.Module instead of nn.Module and we need to pass in a variable called torch_ref which we will use internally for any calls that would normally be to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref) -> None:\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "        \n",
    "        self.train_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiftSyLightningModule(SyLightningModule):\n",
    "    def __init__(self, module, duet):\n",
    "        super().__init__(module, duet)\n",
    "    \n",
    "    def train(self, mode: bool = True):\n",
    "        if self.is_remote:\n",
    "            return self.remote_model.train(mode)\n",
    "        else:\n",
    "            return self.module.train(mode)\n",
    "        \n",
    "    def eval(self):\n",
    "        return self.train(False)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data_ptr, target_ptr = batch[0], batch[1]  # batch is list so no destructuring\n",
    "        output = self.forward(data_ptr)\n",
    "        loss = self.torch.nn.functional.nll_loss(output, target_ptr)\n",
    "        \n",
    "        target = target_ptr.get(delete_obj=False)\n",
    "        real_output = output.get(delete_obj=False)\n",
    "        \n",
    "        self.log(\"train_acc\", self.module.train_acc(real_output.argmax(-1), target), on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        data, target = batch[0], batch[1]  # batch is list so no destructuring\n",
    "        output = self.forward(data)\n",
    "        loss = self.torch.nn.functional.nll_loss(output, target)\n",
    "        self.log(\"test_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.torch.optim.SGD(self.model.parameters(), lr=0.1)\n",
    "        return optimizer\n",
    "    \n",
    "    @property\n",
    "    def torchvision(self):\n",
    "        tv = duet.torchvision if self.is_remote() else torchvision\n",
    "        return tv\n",
    "    \n",
    "    def get_transforms(self):\n",
    "        current_list = duet.python.List if self.is_remote() else list\n",
    "        transforms = current_list()\n",
    "        transforms.append(self.torchvision.transforms.ToTensor())\n",
    "        transforms.append(self.torchvision.transforms.Normalize(0.1307, 0.3081))\n",
    "        transforms_compose = self.torchvision.transforms.Compose(transforms)\n",
    "        return transforms_compose\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        transforms_ptr = self.get_transforms()\n",
    "        train_dataset_ptr = self.torchvision.datasets.MNIST(\n",
    "            str(get_root_data_path()),\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms_ptr,\n",
    "        )\n",
    "        train_loader_ptr = self.torch.utils.data.DataLoader(\n",
    "            train_dataset_ptr, batch_size=500\n",
    "        )\n",
    "        return train_loader_ptr\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        transforms = self.get_transforms()\n",
    "        test_dataset = self.torchvision.datasets.MNIST(\n",
    "            str(get_root_data_path()),\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms,\n",
    "        )\n",
    "        test_loader = self.torch.utils.data.DataLoader(test_dataset, batch_size=1)\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = SyNet(torch)\n",
    "model = LiftSyLightningModule(module=module, duet=duet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_train_batches = 1.0 # 1.0 is 100% of data\n",
    "\n",
    "trainer = Trainer(\n",
    "    default_root_dir=\"./\",\n",
    "    max_epochs=1,\n",
    "    limit_train_batches=limit_train_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LiftSyLightningModule.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path, module=module, duet=duet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model.module.is_local:\n",
    "    local_model = model.module.get(\n",
    "        request_block=True,\n",
    "        reason=\"test evaluation\",\n",
    "        timeout_secs=5\n",
    "    )\n",
    "else:\n",
    "    local_model = model\n",
    "\n",
    "torch.save(local_model.state_dict(), \"weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class NormalModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(NormalModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1) \n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = NormalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_state_dict = torch.load(\"weights.pt\")\n",
    "torch_model.load_state_dict(saved_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchVision hotfix https://github.com/pytorch/vision/issues/3549\n",
    "from syft.util import get_root_data_path\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "datasets.MNIST.resources = [\n",
    "    (\n",
    "        \"https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\",\n",
    "        \"f68b3c2dcbeaaa9fbdd348bbdeb94873\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\",\n",
    "        \"d53e105ee54ea40749a09fcbcd1e9432\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "        \"9fb629c4189551a2d022fa330f9573f3\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\",\n",
    "        \"ec29112dd5afa0611ce80d1b7f02629c\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "batch_size_test = 100\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        get_root_data_path(),\n",
    "        train=False, download=True,\n",
    "        transform=torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size_test, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network, test_loader):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), accuracy))\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test(torch_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_accuracy = 93.0\n",
    "assert result > expected_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
