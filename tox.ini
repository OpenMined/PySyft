[tox]
envlist =
    dev.k8s.registry
    dev.k8s.start
    dev.k8s.deploy
    dev.k8s.info
    dev.k8s.destroy
    dev.k8s.destroyall
    hagrid.publish
    lint
    stack.test.integration
    syft.docs
    syft.jupyter
    syft.publish
    syft.test.security
    syft.test.unit
    syft.test.notebook
    stack.test.notebook
    stack.test.integration.enclave.oblv
    stack.test.integration.k8s
    stack.test.vm
    stack.test.podman
    frontend.test.unit
    frontend.test.e2e
    frontend.generate.types
    syft.build.helm
    syft.package.helm
    syft.test.helm
    syft.protocol.check
    syftcli.test.unit
    syftcli.publish
    syftcli.build
    backend.test.basecpu
skipsdist = True


[testenv]
basepython = python3
install_command = pip install {opts} {packages}
commands =
    python --version

# Syft
[testenv:syft]
deps =
    -e{toxinidir}/packages/syft[dev]
changedir = {toxinidir}/packages/syft
description = Syft
commands =
    pip list

# Syft Minimal - without dev packages
[testenv:syft-minimal]
deps =
    -e{toxinidir}/packages/syft
changedir = {toxinidir}/packages/syft
description = Syft
commands =
    pip list

# data science packages
[testenv:syft-ds]
deps =
    -e{toxinidir}/packages/syft[data_science]
changedir = {toxinidir}/packages/syft
description = Syft
commands =
    pip list

[testenv:hagrid]
deps =
    -e{toxinidir}/packages/hagrid[dev]
changedir = {toxinidir}/packages/hagrid
description = Syft
commands =
    pip list

[testenv:syftcli]
deps =
    -e{toxinidir}/packages/syftcli[dev]
changedir = {toxinidir}/packages/syftcli
description = Syft CLI
install_command = pip install {opts} {packages}
commands =
    pip list

[testenv:hagrid.publish]
changedir = {toxinidir}/packages/hagrid
description = Build and Publish Hagrid Wheel
commands =
    python -m pip install --upgrade pip
    pip install --upgrade setuptools wheel twine tox build
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .

[testenv:syftcli.publish]
changedir = {toxinidir}/packages/syftcli
description = Build and Publish Syft CLI Wheel
allowlist_externals =
    bash
commands =
    python -m pip install --upgrade pip
    pip install --upgrade setuptools wheel twine tox build
    bash -c 'rm -rf build/ dist/ syftcli.egg-info/'
    python -m build .

[testenv:syftcli.build]
basepython = python3
changedir = {toxinidir}/packages/syftcli
description = Build SyftCLI Binary for each platform
allowlist_externals =
    bash
setenv =
    SYFT_CLI_VERSION = {env:SYFT_CLI_VERSION}
commands =
    python -m pip install --upgrade pip
    pip install -e ".[build]"
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'


    ;Since we build universal binary for MacOS,we need to check the python is universal2 or not
    bash -c 'if [[ "$OSTYPE" == "darwin"* ]]; then \
        arch_info=$(lipo -info "$(which python3)"); \
        echo "Arch: $arch_info"; \
        if [[ "$arch_info" == *"Non-fat"* ]]; then \
            echo "Building on MacOS Requires Universal2 python"; \
            echo "Please install universal2 python from https://www.python.org/downloads/macos/"; \
            exit 1; \
        fi; \
    fi'

    ;check the platform and build accordingly by naming the binary as syftcli plus the extension
    ; Check if SYFT_CLI_VERSION is set or choosing the current version available
    bash -c 'if [ -z $SYFT_CLI_VERSION ]; then \
        echo "SYFT_CLI_VERSION is not set"; \
        SYFT_CLI_VERSION=$(python3 syftcli/version.py); \
        echo "Setting SYFT_CLI_VERSION to $SYFT_CLI_VERSION"; \
    else \
        echo "SYFT_CLI_VERSION is already set to $SYFT_CLI_VERSION"; \
    fi && \

    echo "Building syftcli-$SYFT_CLI_VERSION for $OSTYPE" && \

    if [[ "$OSTYPE" == "darwin"* ]]; then \
         pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-macos-universal2 --distpath ./dist/cli syftcli/cli.py --target-arch universal2; \
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-linux-x86_64 --distpath ./dist/cli syftcli/cli.py; \
    else \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-windows-x86_64  --distpath ./dist/cli syftcli/cli.py; \
    fi'


[testenv:lint]
description = Linting
allowlist_externals =
    bash
deps =
    black[python2]
    isort
    pre-commit
commands =
    black .
    isort .
    pre-commit run --all-files

[testenv:frontend.test.unit]
description = Frontend Unit Tests
deps =
    {[testenv:hagrid]deps}
allowlist_externals =
    docker
    bash
    pnpm
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    DOCKER = {env:DOCKER:false}
commands =
    bash -c "echo Running with DOCKER=$DOCKER; date"

    bash -c 'if [[ "$DOCKER" == "false" ]]; then \
        bash ./scripts/check_pnpm.sh; \
        pnpm install; \
        pnpm run test:unit; \
    else \
        docker build --target grid-ui-tests -t ui-test -f frontend.dockerfile .; \
        docker run -t ui-test; \
    fi'

[testenv:frontend.test.e2e]
description = Frontend Unit Tests
deps =
    {[testenv:hagrid]deps}
allowlist_externals =
    docker
    bash
    pnpm
    sleep
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    HAGRID_FLAGS = {env:HAGRID_FLAGS:--tag=local --test}
    ENABLE_SIGNUP=True
commands =
    bash ./scripts/check_pnpm.sh

    bash -c "echo Running with HAGRID_FLAGS=$HAGRID_FLAGS; date"

    ; install hagrid
    bash -c 'if [[ "$HAGRID_FLAGS" == *"local"* ]]; then \
        pip install -e ../../hagrid; \
    else \
        pip install --force hagrid; \
    fi'

    ; fix windows encoding
    - chcp 65001

    ; check docker versions
    bash -c "docker --version"
    bash -c "docker compose version"

    ; reset volumes and create nodes
    bash -c "echo Starting Nodes; date"
    bash -c "docker rm -f $(docker ps -a -q) || true"
    bash -c "docker volume rm test-domain-1_mongo-data --force || true"
    bash -c "docker volume rm test-domain-1_credentials-data --force || true"
    bash -c "docker volume rm test-domain-1_seaweedfs-data --force || true"

    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test_domain_1 domain to docker:9081 $HAGRID_FLAGS --enable-signup --no-health-checks --verbose --no-warnings'

    bash -c '(docker logs test_domain_1-frontend-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c '(docker logs test_domain_1-backend-1 -f &) | grep -q "Application startup complete" || true'

    pnpm install
    pnpm dlx playwright@1.36.1 install --with-deps
    pnpm test:e2e

    ; shutdown
    bash -c "echo Killing Nodes; date"
    bash -c 'HAGRID_ART=false hagrid land all --force'


[testenv:stack.test.integration]
description = Integration Tests for Core Stack
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
changedir = {toxinidir}
allowlist_externals =
    docker
    grep
    sleep
    bash
    chcp
passenv=HOME, USER
setenv =
    HAGRID_FLAGS = {env:HAGRID_FLAGS:--tag=local --release=development --test}
    EMULATION = {env:EMULATION:false}
    HAGRID_ART = false
    PYTHONIOENCODING = utf-8
    PYTEST_MODULES = {env:PYTEST_MODULES:frontend network e2e security redis}
commands =
    bash -c "whoami; id;"

    bash -c "echo Running with HAGRID_FLAGS=$HAGRID_FLAGS EMULATION=$EMULATION PYTEST_MODULES=$PYTEST_MODULES; date"

    ; install syft and hagrid
    bash -c 'if [[ "$HAGRID_FLAGS" == *"latest"* ]]; then \
        pip install --force pytest hagrid syft; \
    elif [[ "$HAGRID_FLAGS" == *"beta"* ]]; then \
        pip install --force pytest hagrid; \
        pip install --force -U --pre syft; \
    else \
        pip install -e packages/hagrid -e packages/syft[dev]; \
    fi'

    ; fix windows encoding
    - chcp 65001

    ; check docker versions
    bash -c "docker --version"
    bash -c "docker compose version"

    ; reset volumes and create nodes
    bash -c "echo Starting Nodes; date"
    bash -c "docker rm -f $(docker ps -a -q) || true"
    bash -c "docker volume rm test-domain-1_mongo-data --force || true"
    bash -c "docker volume rm test-domain-1_credentials-data --force || true"
    bash -c "docker volume rm test-domain-1_seaweedfs-data --force || true"
    ; bash -c "docker volume rm test-domain-2_mongo-data --force || true"
    ; bash -c "docker volume rm test-domain-2_credentials-data --force || true"
    ; bash -c "docker volume rm test-domain-2_seaweedfs-data --force || true"
    bash -c "docker volume rm test-gateway-1_mongo-data --force || true"
    bash -c "docker volume rm test-gateway-1_credentials-data --force || true"
    bash -c "docker volume rm test-gateway-1_seaweedfs-data --force || true"

    python -c 'import syft as sy; sy.stage_protocol_changes()'

    ; Make sure that pacakge-cache is owned by the current user
    ; instead of docker creating it as root
    bash -c 'mkdir -p packages/grid/data/package-cache'

    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-gateway-1 gateway to docker:9081 $HAGRID_FLAGS --no-health-checks --verbose --no-warnings --build'
    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-domain-1 domain to docker:9082 $HAGRID_FLAGS --no-health-checks --enable-signup --verbose --no-warnings --build'
    ; bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-domain-2 domain to docker:9083 --headless $HAGRID_FLAGS --enable-signup --no-health-checks --verbose --no-warnings --build'

    ; wait for nodes to start
    docker ps
    bash -c "echo Waiting for Nodes; date"
    bash -c '(docker logs test-domain-1-frontend-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c '(docker logs test-domain-1-backend-1 -f &) | grep -q "Application startup complete" || true'
    ; bash -c '(docker logs test_domain_2-backend-1 -f &) | grep -q "Application startup complete" || true'
    bash -c '(docker logs test-gateway-1-backend-1 -f &) | grep -q "Application startup complete" || true'

    ; frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
        return=$?; \
        docker stop test_domain_1-frontend-1 || true; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'

    ; network
    bash -c 'if [[ "$PYTEST_MODULES" == *"network"* ]]; then \
        echo "Starting network"; date; \
        pytest tests/integration -m network -p no:randomly --co; \
        pytest tests/integration -m network -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
        return=$?; \
        echo "Finished network"; date; \
        exit $return; \
    fi'

    ; shutdown
    bash -c "echo Killing Nodes; date"
    bash -c 'HAGRID_ART=false hagrid land all --force'

[testenv:syft.docs]
description = Build Docs for Syft
changedir = {toxinidir}/docs
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    -r {toxinidir}/docs/requirements.txt
allowlist_externals =
    make
    echo
    cd
    rm
    ls
    xargs
    bash
commands =
    python --version
    bash -c "cd source/api_reference && ls | grep -v index.rst | xargs rm"
    sphinx-apidoc -f -M -d 2 -o ./source/api_reference/ ../packages/syft/src/syft
    make html
    echo "Open: {toxinidir}/docs/build/html/index.html"

[testenv:syft.jupyter]
description = Jupyter Notebook with Editable Syft
deps =
    {[testenv:syft]deps}
    {[testenv:syft-ds]deps}
    {[testenv:hagrid]deps}
    jupyter
    jupyterlab
commands =
    pip install -e packages/hagrid
    pip install jupyter jupyterlab --upgrade
    jupyter lab --ip 0.0.0.0 --ServerApp.token={posargs}

[testenv:syft.protocol.check]
description = Syft Protocol Check
deps =
    {[testenv:syft-minimal]deps}
changedir = {toxinidir}/packages/syft
allowlist_externals =
    bash
setenv =
    BUMP = {env:BUMP:False}
commands =
    bash -c "echo Using BUMP=${BUMP}"
    python -c 'import syft as sy; sy.check_or_stage_protocol()'
    bash -c 'if [[ "$BUMP" != "False" ]]; then \
        python -c "import syft as sy; sy.bump_protocol_version()"; \
        fi'

[testenv:syft.publish]
changedir = {toxinidir}/packages/syft
description = Build and Publish Syft Wheel
commands =
    python -m pip install --upgrade pip
    pip install --upgrade setuptools wheel twine tox build
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .

[testenv:syft.test.security]
description = Security Checks for Syft
changedir = {toxinidir}/packages/syft
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
commands =
    pip install --upgrade pip
    bandit -r src
    # ansible 8.4.0
    # restrictedpython 6.2
    safety check -i 60840 -i 54229 -i 54230 -i 42923

[testenv:syft.test.unit]
description = Syft Unit Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
changedir = {toxinidir}/packages/syft
setenv =
    ENABLE_SIGNUP=False
commands =
    pip list
    pytest -n auto

[testenv:stack.test.integration.enclave.oblv]
description = Integration Tests for Oblv Enclave
changedir = {toxinidir}
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    grep
    bash
passenv=HOME, USER
setenv =
    LOCAL_ENCLAVE_PORT=8010
    ENABLE_OBLV=true
    DOMAIN_CONNECTION_PORT=8010
    ENABLE_SIGNUP=True
commands =
    pip install oblv-ctl==0.3.1
    # run at start to kill any process started beforehand
    bash -c 'chmod +x scripts/kill_process_in_port.sh && ./scripts/kill_process_in_port.sh $LOCAL_ENCLAVE_PORT'

    bash -c 'rm -rf ~/.syft/syft-enclave'
    bash -c 'git clone https://github.com/OpenMined/syft-enclave.git ~/.syft/syft-enclave || true'
    bash -c 'cd ~/.syft/syft-enclave && git fetch && git checkout dev && git pull && pip install -r requirements_test.txt || true'

    # Starting FastAPI server locally
    bash -c 'cd ~/.syft/syft-enclave/src && uvicorn app:app --host 0.0.0.0 --port $LOCAL_ENCLAVE_PORT > /dev/null 2>&1 &'

    bash -c 'cd tests/integration/external/oblv && pytest -p no:randomly -vvvv'
    bash -c 'chmod +x scripts/kill_process_in_port.sh && ./scripts/kill_process_in_port.sh $LOCAL_ENCLAVE_PORT'

[testenv:syft.test.notebook]
description = Syft Notebook Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:python}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8,tutorials}
    ENABLE_SIGNUP=True
commands =
    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' '); do \
    if [[ $subfolder == *tutorials* ]]; then \
        pytest --nbmake "$subfolder" -p no:randomly --ignore=tutorials/model-training -n $(python -c 'import multiprocessing; print(multiprocessing.cpu_count())') -vvvv && \
        pytest --nbmake tutorials/model-training -p no:randomly -vvvv; \
    else \
        pytest --nbmake "$subfolder" -p no:randomly -vvvv; \
    fi \
    done"
    ; pytest --nbmake api/0.8 -p no:randomly -vvvv
    ; pytest --nbmake api/0.9 -p no:randomly -vvvv
    ; pytest --nbmake tutorials -p no:randomly -vvvv
    ; pytest --nbmake tutorials/pandas-cookbook -p no:randomly -vvvv



[testenv:stack.test.notebook]
description = Stack Notebook Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:single_container}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8}
    ENABLE_SIGNUP=True
commands =

    # Volume cleanup
    bash -c "docker volume rm test-domain-1_mongo-data --force || true"
    bash -c "docker volume rm test-domain-1_credentials-data --force || true"
    bash -c "docker volume rm test-domain-1_seaweedfs-data --force || true"

    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' ');\
    do \
        pytest --nbmake "$subfolder" -p no:randomly -vvvv --nbmake-timeout=1000;\
    done"

    ; pytest --nbmake api/0.8 -p no:randomly -vvvv
    ; pytest --nbmake api/0.9 -p no:randomly -vvvv
    ; pytest --nbmake tutorials -p no:randomly -vvvv
    ; pytest --nbmake tutorials/pandas-cookbook -p no:randomly -vvvv

[testenv:stack.test.vm]
description = Stack VM Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:vm}
    VAGRANT_DESTROY = {env:VAGRANT_DESTROY:skip}
commands =
    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    else \
        vagrant ssh $VAGRANT_BOX -c "docker ps -aq | xargs -I {:} docker rm {:} --force"; \
        vagrant ssh $VAGRANT_BOX -c "docker volume prune --filter all=1 --force || true"; \
    fi; \
    vagrant up $VAGRANT_BOX --provision; \
    '

    pytest --nbmake notebooks/api/0.8 -p no:randomly -vvvv
    ; pytest --nbmake notebooks/api/0.9 -p no:randomly -vvvv

    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    fi; \
    '

[testenv:stack.test.podman]
description = Stack podman Tests for Rhel & Centos
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:podman}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    bash -c "podman pod rm --force --all || true";
    bash -c "podman system prune --volumes --force || true";
    bash -c "podman volume rm $(podman volume ls -q)||true";

    # Force Removal of images
    bash -c "podman image prune --all --force || true";

    # Build Backend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-backend:$SYFT_VERSION -f packages/grid/backend/backend.dockerfile --target backend packages";

    # Build Frontend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-frontend:$SYFT_VERSION -f packages/grid/frontend/frontend.dockerfile --target grid-ui-development packages/grid/frontend";

    bash -c 'cd packages/grid/podman/podman-kube && podman play kube podman-syft-kube.yaml --configmap=podman-syft-kube-config.yaml'
    bash -c '(podman logs -f syft-backend &) | grep -q "Application startup complete" || true'
    pytest --nbmake notebooks/api/0.8 -p no:randomly -vvvv

[testenv:frontend.generate.types]
description = Generate Types for Frontend
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    cd
    bash
    pnpm
changedir = {toxinidir}/packages/grid/frontend
passenv =
    PNPM_HOME
commands =
    bash -c ./scripts/check_pnpm.sh
    pnpm add -g json-schema-to-typescript

    ; clear the old ones
    bash -c 'rm -rf ./schema'
    bash -c 'rm -rf ./src/types/generated'

    ; generate new ones
    bash -c 'python3 -c "import syft as sy;sy.util.schema.generate_json_schemas()"'
    bash -c "json2ts -i './schema/**/*.json' -o ./src/types/generated"
    bash -c "python3 ./scripts/replace_imports.py ./src/types/generated"

[mypy]
python_version = 3.11
disable_error_code = attr-defined, valid-type, no-untyped-call, arg-type


[testenv:stack.test.integration.k8s]
description = Integration Tests for Core Stack
basepython = python3
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:9082}
    GITHUB_CI = {env:GITHUB_CI:false}
commands =
    bash -c "echo Running with GITHUB_CI=$GITHUB_CI; date"
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    k3d version

    # bash -c "docker rm $(docker ps -aq) --force || true"
    # Deleting current cluster
    bash -c "k3d cluster delete test-gateway-1 || true"
    bash -c "k3d cluster delete test-domain-1 || true"
    # bash -c "k3d cluster delete test-domain-2 || true"

    # Deleting registery & volumes
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-test-gateway-1-images --force || true"
    bash -c "docker volume rm k3d-test-domain-1-images --force || true"
    # bash -c "docker volume rm k3d-test-domain-2-images --force || true"

    # Creating registory
    bash -c 'k3d registry create registry.localhost --port 12345  -v `pwd`/k3d-registry:/var/lib/registry || true'

    # Creating test-gateway-1 cluster on port 9081
    bash -c 'NODE_NAME=test-gateway-1 NODE_PORT=9081 && \
        k3d cluster create $NODE_NAME -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
        k3d cluster start $NODE_NAME'

    bash -c 'NODE_NAME=test-gateway-1 NODE_PORT=9081 && \
        cd packages/grid && \
        (r=5;while ! \
        devspace --no-warn --kube-context "k3d-$NODE_NAME" --namespace $NODE_NAME \
        -p gateway \
        --var NODE_NAME=$NODE_NAME \
        --var NETWORK_CHECK_INTERVAL=5 \
        --var ASSOCIATION_TIMEOUT=100 \
        --var TEST_MODE=1 \
        --var CONTAINER_REGISTRY=k3d-registry.localhost:12345 \
        --var NODE_TYPE=gateway \
        deploy -b; \
        do ((--r))||exit;echo "retrying" && sleep 20;done)'

    # Creating test-domain-1 cluster on port 9082
    bash -c 'NODE_NAME=test-domain-1 NODE_PORT=9082 && \
        k3d cluster create $NODE_NAME -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
        k3d cluster start $NODE_NAME'

    bash -c 'NODE_NAME=test-domain-1 NODE_PORT=9082 && \
        cd packages/grid && \
        (r=5;while ! \
        devspace --no-warn --kube-context "k3d-$NODE_NAME" --namespace $NODE_NAME \
        --var NODE_NAME=$NODE_NAME \
        --var DOMAIN_CHECK_INTERVAL=5 \
        --var ASSOCIATION_TIMEOUT=100 \
        --var TEST_MODE=1 \
        --var CONTAINER_REGISTRY=k3d-registry.localhost:12345 \
        deploy -b; \
        do ((--r))||exit;echo "retrying" && sleep 20;done)'

    # bash -c 'NODE_NAME=test-domain-2 NODE_PORT=9083 && \
    #     k3d cluster create $NODE_NAME -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
    #     k3d cluster start $NODE_NAME'

    # bash -c 'NODE_NAME=test-domain-2 NODE_PORT=9083 && \
    #     cd packages/grid && \
    #     (r=5;while ! \
    #     devspace --no-warn --kube-context "k3d-$NODE_NAME" --namespace $NODE_NAME \
    #     --var DOMAIN_NAME=$NODE_NAME \
    #     --var DOMAIN_CHECK_INTERVAL=5 \
    #     --var ASSOCIATION_TIMEOUT=100 \
    #     --var TEST_MODE=1 \
    #     --var CONTAINER_REGISTRY=k3d-registry.localhost:12345 \
    #     deploy -b -p domain; \
    #     do ((--r))||exit;echo "retrying" && sleep 20;done)'

    # free up build cache after build of images
    bash -c 'if [[ "$GITHUB_CI" != "false" ]]; then \
        docker image prune --all --force; \
        docker builder prune --all --force; \
    fi'

    sleep 30

    # wait for front end
    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-test-domain-1 --namespace test-domain-1
    bash -c '(kubectl logs service/frontend --context k3d-test-domain-1 --namespace test-domain-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    # wait for test gateway 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-test-gateway-1 --namespace test-gateway-1
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-test-gateway-1 --namespace test-gateway-1
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-test-gateway-1 --namespace test-gateway-1
    # bash packages/grid/scripts/wait_for.sh service queue --context k3d-test-gateway-1 --namespace test-gateway-1
    # bash packages/grid/scripts/wait_for.sh service redis --context k3d-test-gateway-1 --namespace test-gateway-1
    # bash packages/grid/scripts/wait_for.sh service backend-stream --context k3d-test-gateway-1 --namespace test-gateway-1

    # wait for test domain 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-test-domain-1 --namespace test-domain-1
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-test-domain-1 --namespace test-domain-1
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-test-domain-1 --namespace test-domain-1
    # bash packages/grid/scripts/wait_for.sh service frontend --context k3d-test-domain-1 --namespace test-domain-1
    # bash packages/grid/scripts/wait_for.sh service proxy --context k3d-test-domain-1 --namespace test-domain-1
    # bash packages/grid/scripts/wait_for.sh service queue --context k3d-test-domain-1 --namespace test-domain-1
    # bash packages/grid/scripts/wait_for.sh service redis --context k3d-test-domain-1 --namespace test-domain-1
    # bash packages/grid/scripts/wait_for.sh service backend-stream --context k3d-test-domain-1 --namespace test-domain-1
    # bash packages/grid/scripts/wait_for.sh service seaweedfs --context k3d-test-domain-1 --namespace test-domain-1

    # wait for test domain 2
    # bash packages/grid/scripts/wait_for.sh service frontend --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service proxy --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service queue --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service redis --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service db --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service backend --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service backend-stream --context k3d-test-domain-2 --namespace test-domain-2
    # bash packages/grid/scripts/wait_for.sh service seaweedfs --context k3d-test-domain-2 --namespace test-domain-2

    # pytest tests/integration -m frontend -p no:randomly --co
    # bash -c "CONTAINER_HOST=$CONTAINER_HOST pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no"

    # Checking logs generated & startup of test-domain 1
    bash -c '(kubectl logs service/backend --context k3d-test-domain-1 --namespace test-domain-1 -f &) | grep -q "Application startup complete" || true'
    # Checking logs generated & startup of test-gateway-1
    bash -c '(kubectl logs service/backend --context k3d-test-gateway-1 --namespace test-gateway-1 -f &) | grep -q "Application startup complete" || true'


    # frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly -k "test_serves_domain_frontend" --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no -k "test_serves_domain_frontend"; \
        return=$?; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'


    # ignore 06 because of opendp on arm64
    # Run 0.8 notebooks
    pytest --nbmake notebooks/api/0.8 -p no:randomly -vvvv

    #Integration + Gateway Connection Tests
    pytest tests/integration/network -p no:randomly -vvvv

    # deleting clusters created
    bash -c "k3d cluster delete test-gateway-1 || true"
    bash -c "k3d cluster delete test-domain-1 || true"
    # bash -c "k3d cluster delete test-domain-2 || true"
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker rm $(docker ps -aq) --force || true"
    bash -c "docker volume rm k3d-test-gateway-1-images --force || true"
    bash -c "docker volume rm k3d-test-domain-1-images --force || true"
    # bash -c "docker volume rm k3d-test-domain-2-images --force || true"



[testenv:syft.build.helm]
description = Build Helm Chart for Kubernetes
deps =
    pyyaml
changedir = {toxinidir}
passenv=HOME, USER, CONTAINER_REGISTRY , VERSION
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
    rm
    helm
commands =
    k3d version
    devspace version

    bash -c "k3d cluster delete build ; \
        docker volume rm k3d-build-images --force || true"

    bash -c 'k3d cluster create build && \
        k3d cluster start build && \
        echo "Waiting for cluster to be ready..." && \
        sleep 20'

    bash -c 'cd packages/grid && \
        [[ -n "$CONTAINER_REGISTRY" ]] && REGISTRY_FLAG="--var CONTAINER_REGISTRY=$CONTAINER_REGISTRY" || REGISTRY_FLAG="" && \
        [[ -n "$VERSION" ]] && VERSION_FLAG="--var VERSION=$VERSION" || VERSION_FLAG="" && \
        devspace deploy --render --skip-build ${REGISTRY_FLAG} ${VERSION_FLAG} --kube-context "k3d-build" --no-warn --no-colors > out.txt ; \
        EXITCODE=$?; OUTPUT=$(cat out.txt); printf "Devspace exit code: $EXITCODE\nDevspace output:\n$OUTPUT\n"; exit $EXITCODE'

    bash -c 'cd packages/grid && \
        python3 helm/helm.py out.txt && \
        rm out.txt'

    bash -c 'cd packages/grid/helm && \
        helm lint syft'

    bash -c "k3d cluster delete build; docker volume rm k3d-build-images --force; echo Done"

[testenv:syft.package.helm]
description = Package Helm Chart for Kubernetes
deps =
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
    rm
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        helm lint syft'

    bash -c 'cd packages/grid/helm/syft && \
        helm dependency update'

    bash -c 'cd packages/grid/helm && \
        helm package syft --destination repo'

    bash -c 'cd packages/grid/helm/repo && \
        helm repo index . --url https://openmined.github.io/PySyft/helm'

[testenv:syft.test.helm]
description = Test Helm Chart for Kubernetes
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
    rm
    helm
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    k3d version

    ; bash -c "docker rm $(docker ps -aq) --force || true"
    bash -c "k3d cluster delete syft || true"
    bash -c "docker volume rm k3d-syft-images --force || true"

    bash -c "k3d registry delete k3d-registry.localhost || true"

    bash -c 'k3d registry create registry.localhost --port 12345  -v `pwd`/k3d-registry:/var/lib/registry || true'

    bash -c 'NODE_NAME=syft NODE_PORT=8080 && \
        k3d cluster create syft -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
        k3d cluster start syft'

    ; skopeo list-tags --tls-verify=false docker://k3d-registry.localhost:12345/openmined/grid-backend
    ; skopeo inspect --tls-verify=false docker://k3d-registry.localhost:12345/openmined/grid-backend:f1725f
    ; helm uninstall --kube-context k3d-syft --namespace syft syft
    ; helm install --kube-context k3d-syft --namespace syft syft ./syft
    ; k3d cluster create syft -p "8080:80@loadbalancer" && k3d cluster start syft

    sleep 50

    bash -c 'cd packages/grid && \
        kubectl --context k3d-syft create namespace syft || true; \
        helm install --kube-context k3d-syft --namespace syft syft ./helm/syft --debug'

    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-syft --namespace syft
    bash -c '(kubectl logs service/frontend --context k3d-syft --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    ; wait for everything else to be loaded
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-syft --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-syft --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-syft --namespace syft

    bash -c '(kubectl logs service/backend --context k3d-syft --namespace syft -f &) | grep -q "Application startup complete" || true'


    ; frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly -k "test_serves_domain_frontend" --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no -k "test_serves_domain_frontend"; \
        return=$?; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'

    ; ignore 06 because of opendp on arm64
    pytest --nbmake notebooks/api/0.8 -p no:randomly -vvvv

    bash -c "k3d cluster delete syft || true"
    bash -c "docker volume rm k3d-syft-images --force || true"

[testenv:syftcli.test.unit]
description = Syft CLI Unit Tests
deps =
    {[testenv:syftcli]deps}
changedir = {toxinidir}/packages/syftcli
commands =
    pip list
    pytest

[testenv:dev.k8s.registry]
description = Start local Kubernetes registry with k3d
changedir = {toxinidir}
passenv=HOME,USER
allowlist_externals =
    bash
    sudo
commands =
    bash -c 'k3d registry create registry.localhost --port 12345 -v $HOME/.k3d-registry:/var/lib/registry || true'
    sudo {envpython} scripts/patch_hosts.py --add-k3d-registry --fix-docker-hosts

[testenv:dev.k8s.start]
description = Start local Kubernetes registry & cluster with k3d
changedir = {toxinidir}
passenv=*
allowlist_externals =
    bash
    sleep
    tox
commands =
    tox -e dev.k8s.registry
    sleep 3
    bash -c 'URL=http://k3d-registry.localhost:12345/v2/_catalog; curl -X GET $URL'
    bash -c 'k3d cluster create syft-dev -p "8080:80@loadbalancer" --registry-use k3d-registry.localhost:12345; \
        kubectl create namespace syft;'
    tox -e dev.k8s.info

[testenv:dev.k8s.deploy]
description = Deploy to a local Kubernetes cluster with Devspace
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
allowlist_externals =
    bash
commands =
    bash -c 'devspace deploy -b --kube-context k3d-syft-dev --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:12345'

[testenv:dev.k8s.info]
description = Gather info about the localKubernetes cluster
passenv=HOME, USER
ignore_errors = True
allowlist_externals =
    k3d
    kubectl
commands =
    kubectl config view
    k3d cluster list
    kubectl cluster-info
    kubectl config current-context
    kubectl get namespaces

[testenv:dev.k8s.destroy]
description = Destroy local Kubernetes cluster
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
allowlist_externals =
    bash
commands =
    bash -c '\
        devspace purge --kube-context k3d-syft-dev --namespace syft; \
        rm -rf .devspace; echo ""; \
        k3d cluster delete syft-dev; echo ""; \
        kubectl config view'

[testenv:dev.k8s.destroyall]
description = Destroy both local Kubernetes cluster and registry
changedir = {toxinidir}
passenv=HOME, USER
ignore_errors=True
allowlist_externals =
    bash
    tox
    sudo
    rm
commands =
    tox -e dev.k8s.destroy
    bash -c 'k3d registry delete registry.localhost || true'
    sudo rm -rf ~/.k3d-registry

[testenv:backend.test.basecpu]
description = Base CPU Docker Image Test
changedir = {toxinidir}/packages
allowlist_externals =
    docker
    bash
setenv =
    PIP_PACKAGES = {env:PIP_PACKAGES:llama-index opendp}
    SYSTEM_PACKAGES = {env:SYSTEM_PACKAGES:curl wget htop}
commands =
    bash -c 'docker rm $(docker ps -aq) --force || true'
    bash -c 'docker buildx use default || true'
    ; Build the base image
    bash -c 'docker build -f ./grid/backend/syft_base_cpu.dockerfile . -t cpu-worker:latest'
    bash -c 'docker rmi cpu-worker:latest'

    bash -c 'docker rm $(docker ps -aq) --force || true'
    bash -c '\
        docker build \
            -f grid/backend/syft_base_cpu.dockerfile . \
            -t cpu-worker:opendp \
            --build-arg PIP_PACKAGES="$PIP_PACKAGES" \
            --build-arg SYSTEM_PACKAGES="$SYSTEM_PACKAGES"'
    bash -c 'for pkg in $PIP_PACKAGES; do docker run --rm cpu-worker:opendp pip list | grep "$pkg"; done'
    bash -c 'for pkg in $SYSTEM_PACKAGES; do docker run --rm cpu-worker:opendp apk -e info "$pkg"; done'

    bash -c 'docker rm $(docker ps -aq) --force || true'
    bash -c '\
        docker build \
            -f grid/backend/syft_base_cpu.dockerfile . \
            -t cpu-worker:custom-cmd  \
            --build-arg SYSTEM_PACKAGES="perl wget curl make " \
            --build-arg CUSTOM_CMD="""wget -O - "https://github.com/cowsay-org/cowsay/archive/refs/tags/v3.7.0.tar.gz" | tar xvzf - && cd cowsay-3.7.0 && make"""'
    bash -c 'for pkg in perl make curl wget; do docker run --rm cpu-worker:custom-cmd apk -e info "$pkg"; done'
    bash -c 'docker run --rm cpu-worker:custom-cmd bash -c "cd cowsay-3.7.0 && curl https://api.github.com/zen -s | ./cowsay"'
    bash -c 'docker rmi cpu-worker:custom-cmd'
