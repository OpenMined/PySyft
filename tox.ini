[tox]
envlist =
    dev.k8s.registry
    dev.k8s.start
    dev.k8s.deploy
    dev.k8s.hotreload
    dev.k8s.info
    dev.k8s.cleanup
    dev.k8s.destroy
    dev.k8s.destroyall
    lint
    stack.test.integration
    syft.docs
    syft.jupyter
    syft.publish
    syft.test.security
    syft.test.unit
    syft.test.notebook
    single_container.launch
    single_container.destroy
    stack.test.notebook
    stack.test.integration.k8s
    stack.test.vm
    stack.test.podman
    frontend.test.unit
    frontend.test.e2e
    frontend.generate.types
    syft.build.helm
    syft.package.helm
    syft.test.helm
    syft.test.helm.upgrade
    syft.protocol.check
    syftcli.test.unit
    syftcli.publish
    syftcli.build
    seaweedfs.test.unit
    backend.test.basecpu
    e2e.test.notebook
skipsdist = True


[testenv]
basepython = python3
commands =
    python --version
setenv =
    UV_HTTP_TIMEOUT = 600

# Syft
[testenv:syft]
deps =
    -e{toxinidir}/packages/syft[dev,data_science]
changedir = {toxinidir}/packages/syft
description = Syft
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

# Syft Minimal - without dev+datascience packages
[testenv:syft-minimal]
deps =
    -e{toxinidir}/packages/syft
changedir = {toxinidir}/packages/syft
description = Syft
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

[testenv:syftcli]
deps =
    -e{toxinidir}/packages/syftcli[dev]
changedir = {toxinidir}/packages/syftcli
description = Syft CLI
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

[testenv:syft.publish]
changedir = {toxinidir}/packages/syft
description = Build and Publish Syft Wheel
deps =
    build
commands =
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .


[testenv:syftcli.publish]
changedir = {toxinidir}/packages/syftcli
description = Build and Publish Syft CLI Wheel
deps =
    build
allowlist_externals =
    bash
commands =
    bash -c 'rm -rf build/ dist/ syftcli.egg-info/'
    python -m build .

[testenv:syftcli.build]
basepython = python3
changedir = {toxinidir}/packages/syftcli
description = Build SyftCLI Binary for each platform
deps =
    -e{toxinidir}/packages/syftcli[build]
allowlist_externals =
    bash
setenv =
    SYFT_CLI_VERSION = {env:SYFT_CLI_VERSION}
commands =
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'


    ;Since we build universal binary for MacOS,we need to check the python is universal2 or not
    bash -c 'if [[ "$OSTYPE" == "darwin"* ]]; then \
        arch_info=$(lipo -info "$(which python3)"); \
        echo "Arch: $arch_info"; \
        if [[ "$arch_info" == *"Non-fat"* ]]; then \
            echo "Building on MacOS Requires Universal2 python"; \
            echo "Please install universal2 python from https://www.python.org/downloads/macos/"; \
            exit 1; \
        fi; \
    fi'

    ;check the platform and build accordingly by naming the binary as syftcli plus the extension
    ; Check if SYFT_CLI_VERSION is set or choosing the current version available
    bash -c 'if [ -z $SYFT_CLI_VERSION ]; then \
        echo "SYFT_CLI_VERSION is not set"; \
        SYFT_CLI_VERSION=$(python3 syftcli/version.py); \
        echo "Setting SYFT_CLI_VERSION to $SYFT_CLI_VERSION"; \
    else \
        echo "SYFT_CLI_VERSION is already set to $SYFT_CLI_VERSION"; \
    fi && \

    echo "Building syftcli-$SYFT_CLI_VERSION for $OSTYPE" && \

    if [[ "$OSTYPE" == "darwin"* ]]; then \
         pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-macos-universal2 --distpath ./dist/cli syftcli/cli.py --target-arch universal2; \
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-linux-x86_64 --distpath ./dist/cli syftcli/cli.py; \
    else \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-windows-x86_64  --distpath ./dist/cli syftcli/cli.py; \
    fi'


[testenv:lint]
description = Linting
allowlist_externals =
    bash
deps =
    black[python2]
    isort
    pre-commit
commands =
    black .
    isort .
    pre-commit run --all-files

[testenv:frontend.test.unit]
description = Frontend Unit Tests
allowlist_externals =
    docker
    bash
    pnpm
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    DOCKER = {env:DOCKER:false}
commands =
    bash -c "echo Running with DOCKER=$DOCKER; date"

    bash -c 'if [[ "$DOCKER" == "false" ]]; then \
        bash ./scripts/check_pnpm.sh; \
        pnpm install; \
        pnpm run test:unit; \
    else \
        docker build --target grid-ui-tests -t ui-test -f frontend.dockerfile .; \
        docker run -t ui-test; \
    fi'



[testenv:syft.docs]
description = Build Docs for Syft
changedir = {toxinidir}/docs
deps =
    {[testenv:syft]deps}
    -r {toxinidir}/docs/requirements.txt
allowlist_externals =
    make
    echo
    cd
    rm
    ls
    xargs
    bash
commands =
    python --version
    bash -c "cd source/api_reference && ls | grep -v index.rst | xargs rm"
    sphinx-apidoc -f -M -d 2 -o ./source/api_reference/ ../packages/syft/src/syft
    make html
    echo "Open: {toxinidir}/docs/build/html/index.html"

[testenv:syft.jupyter]
description = Jupyter Notebook with Editable Syft
deps =
    {[testenv:syft]deps}
    jupyter
    jupyterlab
commands =
    jupyter lab --ip 0.0.0.0 --ServerApp.token={posargs}

[testenv:syft.protocol.check]
description = Syft Protocol Check
deps =
    {[testenv:syft-minimal]deps}
changedir = {toxinidir}/packages/syft
allowlist_externals =
    bash
setenv =
    BUMP = {env:BUMP:False}
commands =
    bash -c "echo Using BUMP=${BUMP}"
    python -c 'import syft as sy; sy.check_or_stage_protocol()'
    bash -c 'if [[ "$BUMP" != "False" ]]; then \
        python -c "import syft as sy; sy.bump_protocol_version()"; \
        fi'

[testenv:syft.test.security]
description = Security Checks for Syft
changedir = {toxinidir}/packages/syft
deps =
    {[testenv:syft]deps}
commands =
    bandit -r src
    # ansible 8.4.0
    # restrictedpython 6.2
    safety check -i 60840 -i 54229 -i 54230 -i 42923 -i 54230 -i 54229 -i 62044 -i 65213 -i 54564

[testenv:syft.test.unit]
description = Syft Unit Tests
deps =
    {[testenv:syft]deps}
allowlist_externals =
    bash
    uv
changedir = {toxinidir}/packages/syft
setenv =
    ENABLE_SIGNUP=False
commands =
    bash -c 'ulimit -n 4096 || true'
    pytest -n auto --dist loadgroup --durations=20 --disable-warnings

[testenv:syft.test.notebook]
description = Syft Notebook Tests
deps =
    -e{toxinidir}/packages/syft[dev,data_science]
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:python}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8,tutorials}
    ENABLE_SIGNUP={env:ENABLE_SIGNUP:False}
    BUMP_PROTOCOL={env:BUMP_PROTOCOL:False}
commands =
    bash -c 'if [[ $BUMP_PROTOCOL == "True" ]]; then \
                python -c "import syft as sy; sy.bump_protocol_version()"; \
            fi;'
    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; ENABLE_SIGNUP=$ENABLE_SIGNUP; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' '); do \
    if [[ $subfolder == *tutorials* ]]; then \
        pytest -x --nbmake "$subfolder" -p no:randomly --ignore=tutorials/model-training -n $(python -c 'import multiprocessing; print(multiprocessing.cpu_count())') -vvvv && \
        pytest -x --nbmake tutorials/model-training -p no:randomly -vvvv; \
    else \
        pytest -x --nbmake "$subfolder" -p no:randomly -k 'not 11-container-images-k8s.ipynb' -vvvv; \
    fi \
    done"
    ; pytest -x --nbmake api/0.8 -p no:randomly -vvvv
    ; pytest -x --nbmake api/0.9 -p no:randomly -vvvv
    ; pytest -x --nbmake tutorials -p no:randomly -vvvv
    ; pytest -x --nbmake tutorials/pandas-cookbook -p no:randomly -vvvv


[testenv:single_container.launch]
description = Launch a single backend container using the dockerfile
changedir = {toxinidir}/packages
setenv =
    N_CONSUMERS = {env:N_CONSUMERS:1}
    NODE_NAME = {env:NODE_NAME:test_domain_sc}
    NODE_TYPE = {env:NODE_TYPE:domain}
    NODE_PORT = {env:NODE_PORT:8080}
allowlist_externals =
    bash
commands =
    bash -c 'tox -e single_container.destroy'
    bash -c 'docker build -f grid/backend/backend.dockerfile . -t openmined/grid-backend:local-dev'
    bash -c 'docker run -d \
    -e NODE_NAME=${NODE_NAME} \
    -e NODE_TYPE=${NODE_TYPE} \
    -e N_CONSUMERS=${N_CONSUMERS} \
    -e SINGLE_CONTAINER_MODE=true \
    -e CREATE_PRODUCER=true \
    -e INMEMORY_WORKERS=true \
    -p ${NODE_PORT}:80 --add-host=host.docker.internal:host-gateway \
    --name ${NODE_NAME} openmined/grid-backend:local-dev'

[testenv:single_container.destroy]
description = Destroy the single backend container run using single_container.launch
changedir = {toxinidir}/packages
setenv =
    NODE_NAME = {env:NODE_NAME:test_domain_sc}
allowlist_externals =
    bash
commands =
    # Image is not cleaned up
    bash -c 'docker stop ${NODE_NAME} || true'
    bash -c 'docker rm ${NODE_NAME} || true'

[testenv:stack.test.notebook]
description = Stack Notebook Tests
deps =
    {[testenv:syft]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:remote}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8}
    ENABLE_SIGNUP=True
commands =

    # Volume cleanup
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=com.docker.volume.anonymous") || true'
    bash -c 'docker network rm -f $(docker network ls -q --filter "label=orgs.openmined.syft") || true'

    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' ');\
    do \
        pytest -x --nbmake --nbmake-timeout=1000 "$subfolder" -p no:randomly -vvvv -k 'not 11-container-images-k8s.ipynb';\
    done"

    ; pytest -x --nbmake --nbmake-timeout=1000 api/0.8 -p no:randomly -vvvv
    ; pytest -x --nbmake --nbmake-timeout=1000 api/0.9 -p no:randomly -vvvv
    ; pytest -x --nbmake --nbmake-timeout=1000 tutorials -p no:randomly -vvvv
    ; pytest -x --nbmake --nbmake-timeout=1000 tutorials/pandas-cookbook -p no:randomly -vvvv

    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=com.docker.volume.anonymous") || true'
    bash -c 'docker network rm -f $(docker network ls -q --filter "label=orgs.openmined.syft") || true'

[testenv:stack.test.vm]
description = Stack VM Tests
deps =
    {[testenv:syft]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:vm}
    VAGRANT_DESTROY = {env:VAGRANT_DESTROY:skip}
commands =
    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    else \
        vagrant ssh $VAGRANT_BOX -c "docker ps -aq | xargs -I {:} docker rm {:} --force"; \
        vagrant ssh $VAGRANT_BOX -c "docker volume prune --filter all=1 --force || true"; \
    fi; \
    vagrant up $VAGRANT_BOX --provision; \
    '

    pytest -x --nbmake  --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -vvvv
    ; pytest -x --nbmake  --nbmake-timeout=1000 notebooks/api/0.9 -p no:randomly -vvvv

    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    fi; \
    '

[testenv:stack.test.podman]
description = Stack podman Tests for Rhel & Centos
deps =
    {[testenv:syft]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:podman}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    bash -c "podman pod rm --force --all || true";
    bash -c "podman system prune --volumes --force || true";
    bash -c "podman volume rm $(podman volume ls -q)||true";

    # Force Removal of images
    bash -c "podman image prune --all --force || true";

    # Build Backend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-backend:$SYFT_VERSION -f packages/grid/backend/backend.dockerfile --target backend packages";

    # Build Frontend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-frontend:$SYFT_VERSION -f packages/grid/frontend/frontend.dockerfile --target grid-ui-development packages/grid/frontend";

    bash -c 'cd packages/grid/podman/podman-kube && podman play kube podman-syft-kube.yaml --configmap=podman-syft-kube-config.yaml'
    bash -c '(podman logs -f syft-backend &) | grep -q "Application startup complete" || true'
    pytest -x --nbmake --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -vvvv

[testenv:frontend.generate.types]
description = Generate Types for Frontend
deps =
    {[testenv:syft]deps}
allowlist_externals =
    cd
    bash
    pnpm
changedir = {toxinidir}/packages/grid/frontend
passenv =
    PNPM_HOME
commands =
    bash -c ./scripts/check_pnpm.sh
    pnpm add -g json-schema-to-typescript

    ; clear the old ones
    bash -c 'rm -rf ./schema'
    bash -c 'rm -rf ./src/types/generated'

    ; generate new ones
    bash -c 'python3 -c "import syft as sy;sy.util.schema.generate_json_schemas()"'
    bash -c "json2ts -i './schema/**/*.json' -o ./src/types/generated"
    bash -c "python3 ./scripts/replace_imports.py ./src/types/generated"

[mypy]
python_version = 3.12
disable_error_code = attr-defined, valid-type, no-untyped-call, arg-type

[testenv:syft.test.integration]
description = Integration Tests for Syft Stack
basepython = python3
deps =
    {[testenv:syft]deps}
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
setenv =
    PYTEST_MODULES = {env:PYTEST_MODULES:local_node}
    ASSOCIATION_REQUEST_AUTO_APPROVAL = {env:ASSOCIATION_REQUEST_AUTO_APPROVAL:true}
    PYTEST_FLAGS = {env:PYTEST_FLAGS:--ignore=tests/integration/local/gateway_local_test.py --ignore=tests/integration/local/job_test.py}
commands =
    python -c 'import syft as sy; sy.stage_protocol_changes()'

    # Run Integration Tests
    bash -c '\
        PYTEST_MODULES=($PYTEST_MODULES); \
        for i in "${PYTEST_MODULES[@]}"; do \
            echo "Starting test for $i"; date; \
            pytest tests/integration -m $i -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no $PYTEST_FLAGS; \
            return=$?; \
            echo "Finished $i"; \
            date; \
            if [[ $return -ne 0 ]]; then \
                exit $return; \
            fi; \
        done'

[testenv:stack.test.integration.k8s]
description = Integration Tests for Core Stack using K8s
basepython = python3
deps =
    {[testenv:syft]deps}
changedir = {toxinidir}
passenv=HOME, USER, AZURE_BLOB_STORAGE_KEY
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
    tox
setenv =
    NODE_PORT = {env:NODE_PORT:9082}
    GITHUB_CI = {env:GITHUB_CI:false}
    PYTEST_MODULES = {env:PYTEST_MODULES:frontend network container_workload}
    DOMAIN_CLUSTER_NAME = {env:DOMAIN_CLUSTER_NAME:test-domain-1}
    GATEWAY_CLUSTER_NAME = {env:GATEWAY_CLUSTER_NAME:test-gateway-1}
    ASSOCIATION_REQUEST_AUTO_APPROVAL = {env:ASSOCIATION_REQUEST_AUTO_APPROVAL:true}
    SYFT_BASE_IMAGE_REGISTRY = {env:SYFT_BASE_IMAGE_REGISTRY:k3d-registry.localhost:5800}
commands =
    bash -c "echo Running with GITHUB_CI=$GITHUB_CI; date"
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    k3d version

    # Deleting Old Cluster
    bash -c "k3d cluster delete ${DOMAIN_CLUSTER_NAME} || true"
    bash -c "k3d cluster delete ${GATEWAY_CLUSTER_NAME} || true"

    # Deleting registry & volumes
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-${DOMAIN_CLUSTER_NAME}-images --force || true"
    bash -c "docker volume rm k3d-${GATEWAY_CLUSTER_NAME}-images --force || true"

    # Create registry
    tox -e dev.k8s.registry

    # Creating test-gateway-1 cluster on port 9081
    bash -c '\
        export CLUSTER_NAME=${GATEWAY_CLUSTER_NAME} CLUSTER_HTTP_PORT=9081 DEVSPACE_PROFILE=gateway && \
        tox -e dev.k8s.start && \
            tox -e dev.k8s.deploy'

    # Creating test-domain-1 cluster on port 9082
    bash -c '\
        export CLUSTER_NAME=${DOMAIN_CLUSTER_NAME} CLUSTER_HTTP_PORT=9082 && \
        tox -e dev.k8s.start && \
        tox -e dev.k8s.deploy'

    # free up build cache after build of images
    bash -c 'if [[ "$GITHUB_CI" != "false" ]]; then \
        docker image prune --all --force; \
        docker builder prune --all --force; \
    fi'

    sleep 30

    # wait for test gateway 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-{env:GATEWAY_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-{env:GATEWAY_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-{env:GATEWAY_CLUSTER_NAME} --namespace syft

    # wait for test domain 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service seaweedfs --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash -c '(kubectl logs service/frontend --context k3d-${DOMAIN_CLUSTER_NAME} --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    # Checking logs generated & startup of test-domain 1
    bash -c '(kubectl logs service/backend --context k3d-${DOMAIN_CLUSTER_NAME} --namespace syft -f &) | grep -q "Application startup complete" || true'
    # Checking logs generated & startup of testgateway1
    bash -c '(kubectl logs service/backend --context k3d-${GATEWAY_CLUSTER_NAME} --namespace syft -f &) | grep -q "Application startup complete" || true'

    # Run Integration Tests
    bash -c '\
        PYTEST_MODULES=($PYTEST_MODULES); \
        for i in "${PYTEST_MODULES[@]}"; do \
            echo "Starting test for $i"; date; \
            pytest tests/integration -m $i -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
            return=$?; \
            echo "Finished $i"; \
            date; \
            if [[ $return -ne 0 ]]; then \
                exit $return; \
            fi; \
        done'

    # deleting clusters created
    bash -c "CLUSTER_NAME=${DOMAIN_CLUSTER_NAME} tox -e dev.k8s.destroy || true"
    bash -c "CLUSTER_NAME=${GATEWAY_CLUSTER_NAME} tox -e dev.k8s.destroy || true"
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-${DOMAIN_CLUSTER_NAME}-images --force || true"
    bash -c "docker volume rm k3d-${GATEWAY_CLUSTER_NAME}-images --force || true"

[testenv:stack.test.notebook.k8s]
description = Notebook Tests for Core Stack using K8s
basepython = python3
deps =
    {[testenv:syft]deps}
    nbmake
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    k3d
    echo
    tox
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:remote}
    GITHUB_CI = {env:GITHUB_CI:false}
    SYFT_BASE_IMAGE_REGISTRY = {env:SYFT_BASE_IMAGE_REGISTRY:k3d-registry.localhost:5800}
    DOMAIN_CLUSTER_NAME = {env:DOMAIN_CLUSTER_NAME:test-domain-1}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    bash -c "echo Running with GITHUB_CI=$GITHUB_CI; date"
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    k3d version

    # Deleting Old Cluster
    bash -c "k3d cluster delete ${DOMAIN_CLUSTER_NAME} || true"

    # Deleting registry & volumes
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-${DOMAIN_CLUSTER_NAME}-images --force || true"

    # Create registry
    tox -e dev.k8s.registry


    # Creating test-domain-1 cluster on port NODE_PORT
    bash -c '\
        export CLUSTER_NAME=${DOMAIN_CLUSTER_NAME} CLUSTER_HTTP_PORT=${NODE_PORT} && \
        tox -e dev.k8s.start && \
        tox -e dev.k8s.deploy'

    # free up build cache after build of images
    bash -c 'if [[ "$GITHUB_CI" != "false" ]]; then \
        docker image prune --all --force; \
        docker builder prune --all --force; \
    fi'

    sleep 30

    # wait for test-domain-1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service seaweedfs --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-{env:DOMAIN_CLUSTER_NAME} --namespace syft
    bash -c '(kubectl logs service/frontend --context k3d-${DOMAIN_CLUSTER_NAME} --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    # Checking logs generated & startup of test-domain 1
    bash -c '(kubectl logs service/backend --context k3d-${DOMAIN_CLUSTER_NAME} --namespace syft -f &) | grep -q "Application startup complete" || true'

    bash -c "pytest -x --nbmake notebooks/api/0.8 -p no:randomly -k 'not 10-container-images.ipynb' -vvvv --nbmake-timeout=1000"

    # deleting clusters created
    bash -c "CLUSTER_NAME=${DOMAIN_CLUSTER_NAME} tox -e dev.k8s.destroy || true"
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-${DOMAIN_CLUSTER_NAME}-images --force || true"


[testenv:syft.build.helm]
description = Build Helm Chart for Kubernetes
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        python3 generate_helm_notes.py ./syft/templates'

    bash -c 'cd packages/grid/helm && \
        helm lint syft'


[testenv:syft.lint.helm]
description = Lint helm chart
changedir = {toxinidir}/packages/grid/helm
passenv=HOME, USER
allowlist_externals =
    bash
commands =
    bash -c 'kube-linter lint ./syft --config ./kubelinter-config.yaml'

[testenv:syft.package.helm]
description = Package Helm Chart for Kubernetes
deps =
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        helm lint syft'

    bash -c 'cd packages/grid/helm/syft && \
        helm dependency update'

    bash -c 'cd packages/grid/helm && \
        helm package syft --destination repo'

    bash -c 'cd packages/grid/helm/repo && \
        helm repo index . --url https://openmined.github.io/PySyft/helm'

[testenv:syft.test.helm]
description = Test Helm Chart for Kubernetes
changedir = {toxinidir}/packages/grid
passenv=HOME, USER, EXTERNAL_REGISTRY_USERNAME, EXTERNAL_REGISTRY_PASSWORD
allowlist_externals =
    bash
    tox
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:remote}
    NODE_PORT = {env:NODE_PORT:8080}
    NODE_URL = {env:NODE_URL:http://localhost}
    EXCLUDE_NOTEBOOKS = {env:EXCLUDE_NOTEBOOKS:not 10-container-images.ipynb}
    SYFT_VERSION = {env:SYFT_VERSION:local}
    EXTERNAL_REGISTRY = {env:EXTERNAL_REGISTRY:k3d-registry.localhost:5800}
    ; env vars for dev.k8s.start
    CLUSTER_NAME = testdomain
    CLUSTER_HTTP_PORT = {env:NODE_PORT:8080}
commands =
    bash -c "env; date; k3d version"

    bash -c "k3d cluster delete ${CLUSTER_NAME} || true"

    tox -e dev.k8s.start

    bash -c 'if [[ $SYFT_VERSION == "local" ]]; then \
        echo "Installing local helm charts"; \
        helm install ${CLUSTER_NAME} ./helm/syft -f ./helm/values.dev.yaml --kube-context k3d-${CLUSTER_NAME} --namespace syft --create-namespace; \
    else \
        echo "Installing helm charts from repo for syft version: ${SYFT_VERSION}"; \
        helm repo add openmined https://openmined.github.io/PySyft/helm; \
        helm repo update openmined; \
        helm install ${CLUSTER_NAME} openmined/syft --version=${SYFT_VERSION} -f ./helm/values.dev.yaml --kube-context k3d-${CLUSTER_NAME} --namespace syft --create-namespace; \
    fi'

    ; wait for everything else to be loaded
    bash -c './scripts/wait_for.sh service frontend --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c '(kubectl logs service/frontend --context k3d-$CLUSTER_NAME --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c './scripts/wait_for.sh service mongo --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c './scripts/wait_for.sh service backend --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c './scripts/wait_for.sh service proxy --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c '(kubectl logs service/backend --context k3d-$CLUSTER_NAME --namespace syft -f &) | grep -q "Application startup complete" || true'

    # Run Notebook tests
    tox -e e2e.test.notebook

    bash -c "k3d cluster delete ${CLUSTER_NAME} || true"

[testenv:syft.test.helm.upgrade]
description = Test helm upgrade
changedir = {toxinidir}/packages/grid/
passenv=HOME,USER,KUBE_CONTEXT
setenv =
    UPGRADE_TYPE = {env:UPGRADE_TYPE:ProdToBeta}
allowlist_externals =
    bash
commands =
    bash ./scripts/helm_upgrade.sh {env:UPGRADE_TYPE}

[testenv:syftcli.test.unit]
description = Syft CLI Unit Tests
deps =
    {[testenv:syftcli]deps}
changedir = {toxinidir}/packages/syftcli
allowlist_externals =
    uv
    pytest
commands =
    pytest

[testenv:dev.k8s.registry]
description = Start local Kubernetes registry with k3d
changedir = {toxinidir}
passenv=HOME,USER
allowlist_externals =
    bash
    sudo
commands =
    ; check k3d version
    bash -c 'k3d --version'

    ; create registry
    bash -c 'docker volume create k3d-registry-vol || true'
    bash -c 'k3d registry create registry.localhost --port 5800 -v k3d-registry-vol:/var/lib/registry --no-help || true'

    ; add patches to host
    bash -c 'if ! grep -q k3d-registry.localhost /etc/hosts; then sudo {envpython} scripts/patch_hosts.py --add-k3d-registry --fix-docker-hosts; fi'

    ; Fail this command if registry is not working
    bash -c 'curl --retry 5 --retry-all-errors http://k3d-registry.localhost:5800/v2/_catalog'

[testenv:dev.k8s.patch.coredns]
description = Patch CoreDNS to resolve k3d-registry.localhost
changedir = {toxinidir}
passenv=HOME,USER,CLUSTER_NAME
setenv =
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    ; patch coredns so k3d-registry.localhost works in k3d
    bash -c 'kubectl apply -f ./scripts/k8s-coredns-custom.yml --context k3d-${CLUSTER_NAME}'

    ; restarts coredns
    bash -c 'kubectl delete pod -n kube-system -l k8s-app=kube-dns --context k3d-${CLUSTER_NAME}'

[testenv:dev.k8s.start]
description = Start local Kubernetes registry & cluster with k3d
changedir = {toxinidir}
passenv = HOME, USER
setenv =
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
    CLUSTER_HTTP_PORT = {env:CLUSTER_HTTP_PORT:8080}
allowlist_externals =
    bash
    sleep
    tox
commands =
    ; start registry
    tox -e dev.k8s.registry

    ; for NodePort to work add the following --> -p "NodePort:NodePort@loadbalancer"
    bash -c 'k3d cluster create ${CLUSTER_NAME} -p "${CLUSTER_HTTP_PORT}:80@loadbalancer" --registry-use k3d-registry.localhost:5800 {posargs} && \
        kubectl --context k3d-${CLUSTER_NAME} create namespace syft || true'

    ; patch coredns
    tox -e dev.k8s.patch.coredns

    ; dump cluster info
    tox -e dev.k8s.info

[testenv:dev.k8s.deploy]
description = Deploy Syft to a local Kubernetes cluster with Devspace
changedir = {toxinidir}/packages/grid
passenv = HOME, USER, DEVSPACE_PROFILE
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    ; deploy syft helm charts
    bash -c '\
        if [[ -n "${DEVSPACE_PROFILE}" ]]; then export DEVSPACE_PROFILE="-p ${DEVSPACE_PROFILE}"; fi && \
        devspace deploy -b --kube-context k3d-${CLUSTER_NAME} --no-warn ${DEVSPACE_PROFILE} --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5800'

[testenv:dev.k8s.hotreload]
description = Start development with hot-reload in Kubernetes
changedir = {toxinidir}/packages/grid
passenv = HOME, USER, DEVSPACE_PROFILE
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    ; deploy syft helm charts with hot-reload
    bash -c '\
        if [[ -n "${DEVSPACE_PROFILE}" ]]; then export DEVSPACE_PROFILE="-p ${DEVSPACE_PROFILE}"; fi && \
        devspace dev --kube-context k3d-${CLUSTER_NAME} --no-warn ${DEVSPACE_PROFILE} --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5800'

[testenv:dev.k8s.info]
description = Gather info about the localKubernetes cluster
passenv = HOME, USER
ignore_errors = True
allowlist_externals =
    k3d
    kubectl
commands =
    k3d cluster list
    kubectl cluster-info
    kubectl config current-context
    kubectl get namespaces

[testenv:dev.k8s.cleanup]
description = Cleanup Syft deployment and associated resources, but keep the cluster running
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    bash -c 'devspace purge --force-purge --kube-context k3d-${CLUSTER_NAME} --no-warn --namespace syft; sleep 3'
    bash -c 'devspace cleanup images --kube-context k3d-${CLUSTER_NAME} --no-warn --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5800 || true'
    bash -c 'kubectl --context k3d-${CLUSTER_NAME} delete namespace syft --now=true || true'

[testenv:dev.k8s.launch.gateway]
description = Launch a single gateway on K8s
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:test-gateway-1}
    CLUSTER_HTTP_PORT={env:CLUSTER_HTTP_PORT:9081}
    DEVSPACE_PROFILE=gateway
allowlist_externals =
    tox
commands =
    tox -e dev.k8s.start
    tox -e dev.k8s.{posargs:deploy}

[testenv:dev.k8s.launch.domain]
description = Launch a single domain  on K8s
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:test-domain-1}
    CLUSTER_HTTP_PORT={env:CLUSTER_HTTP_PORT:9082}
allowlist_externals =
    tox
commands =
    tox -e dev.k8s.start
    tox -e dev.k8s.{posargs:deploy}

[testenv:dev.k8s.launch.enclave]
description = Launch a single Enclave on K8s
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:test-enclave-1}
    CLUSTER_HTTP_PORT={env:CLUSTER_HTTP_PORT:9083}
    DEVSPACE_PROFILE=enclave
allowlist_externals =
    tox
commands =
    tox -e dev.k8s.start -- --volume /sys/kernel/security:/sys/kernel/security --volume /dev/tmprm0:/dev/tmprm0
    tox -e dev.k8s.{posargs:deploy}

[testenv:dev.k8s.destroy]
description = Destroy local Kubernetes cluster
changedir = {toxinidir}/packages/grid
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    tox
    bash
commands =
    ; destroy cluster
    bash -c '\
        rm -rf .devspace; echo ""; \
        k3d cluster delete ${CLUSTER_NAME};'

[testenv:dev.k8s.destroyall]
description = Destroy both local Kubernetes cluster and registry
changedir = {toxinidir}
passenv = HOME, USER, CLUSTER_NAME
ignore_errors=True
allowlist_externals =
    bash
    tox
commands =
    ; destroy cluster
    tox -e dev.k8s.destroy

    ; destroy registry
    bash -c 'k3d registry delete registry.localhost || true'
    bash -c 'docker volume rm k3d-registry-vol --force || true'

[testenv:backend.test.basecpu]
description = Base CPU Docker Image Test
changedir = {toxinidir}/packages
allowlist_externals =
    docker
    bash
    env
setenv =
    PIP_PACKAGES = {env:PIP_PACKAGES:llama-index opendp}
    SYSTEM_PACKAGES = {env:SYSTEM_PACKAGES:curl wget}
    BUILD_PLATFORM = {env:BUILD_PLATFORM:linux/amd64}
commands =
    env

    ; Build the base image
    bash -c 'docker buildx build \
        --platform $BUILD_PLATFORM \
        -f ./grid/backend/grid/images/worker_cpu.dockerfile . \
        -t cpu-worker:latest'
    bash -c 'docker rmi cpu-worker:latest'

    bash -c '\
        docker buildx build \
            --platform $BUILD_PLATFORM \
            -f grid/backend/grid/images/worker_cpu.dockerfile . \
            -t cpu-worker:opendp \
            --build-arg PIP_PACKAGES="$PIP_PACKAGES" \
            --build-arg SYSTEM_PACKAGES="$SYSTEM_PACKAGES"'
    bash -c 'for pkg in $PIP_PACKAGES; do docker run --rm cpu-worker:opendp pip list | grep "$pkg"; done'
    bash -c 'for pkg in $SYSTEM_PACKAGES; do docker run --rm cpu-worker:opendp apk -e info "$pkg"; done'
    bash -c 'docker rmi cpu-worker:opendp'

    bash -c '\
        docker buildx build \
            --platform $BUILD_PLATFORM \
            -f grid/backend/grid/images/worker_cpu.dockerfile . \
            -t cpu-worker:custom-cmd  \
            --build-arg SYSTEM_PACKAGES="perl wget curl make " \
            --build-arg CUSTOM_CMD="""wget -O - "https://github.com/cowsay-org/cowsay/archive/refs/tags/v3.7.0.tar.gz" | tar xvzf - && cd cowsay-3.7.0 && make"""'
    bash -c 'for pkg in perl make curl wget; do docker run --rm cpu-worker:custom-cmd apk -e info "$pkg"; done'
    bash -c 'docker run --rm cpu-worker:custom-cmd bash -c "cd cowsay-3.7.0 && curl https://api.github.com/zen -s | ./cowsay"'
    bash -c 'docker rmi cpu-worker:custom-cmd'


# There are other adjacent notebook tests like
# stack.test.notebook, syft.test.notebook, etc.
# They could be modularized and reused.
# The below is the notebook test suite for point at external servers
[testenv:e2e.test.notebook]
description = E2E Notebook tests
changedir = {toxinidir}
deps =
    {[testenv:syft]deps}
    nbmake
allowlist_externals =
    bash
    pytest
passenv = EXTERNAL_REGISTRY,EXTERNAL_REGISTRY_USERNAME,EXTERNAL_REGISTRY_PASSWORD
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:remote}
    NODE_PORT = {env:NODE_PORT:8080}
    NODE_URL = {env:NODE_URL:http://localhost}
    EXCLUDE_NOTEBOOKS = {env:EXCLUDE_NOTEBOOKS:}
    SYFT_VERSION = {env:SYFT_VERSION:local}
commands =
    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE NODE_PORT=$NODE_PORT NODE_URL=$NODE_URL \
    Excluding notebooks: $EXCLUDE_NOTEBOOKS SYFT_VERSION=$SYFT_VERSION \
    EXTERNAL_REGISTRY=$EXTERNAL_REGISTRY; date"

    # Schema for EXLUDE_NOTEBOOKS is
    # for excluding
    # notebook1.ipynb, notebook2.ipynb
    # EXCLUDE_NOTEBOOKS=not notebook1.ipynb and not notebook2.ipynb

    # If the syft version is local install the local version
    # else install the version of syft specified
    bash -c "if [[ $SYFT_VERSION == 'local' ]]; then \
        echo 'Using local syft'; \
    else \
        echo 'Installing syft version: ${SYFT_VERSION}'; \
        uv pip install syft[data_science]==${SYFT_VERSION}; \
    fi"

    pytest -x --nbmake --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -vvvv -k '{env:EXCLUDE_NOTEBOOKS:}'

[testenv:seaweedfs.test.unit]
description = Seaweedfs Unit Tests
deps =
    -r{toxinidir}/packages/grid/seaweedfs/requirements.txt
    -r{toxinidir}/packages/grid/seaweedfs/requirements.dev.txt
changedir = {toxinidir}/packages/grid/seaweedfs
allowlist_externals =
    bash
    pytest
commands =
    bash -c 'ulimit -n 4096 || true'
    pytest --disable-warnings
