[tox]
envlist =
    dev.k8s.registry
    dev.k8s.start
    dev.k8s.deploy
    dev.k8s.hotreload
    dev.k8s.info
    dev.k8s.cleanup
    dev.k8s.destroy
    dev.k8s.destroyall
    hagrid.publish
    lint
    stack.test.integration
    syft.docs
    syft.jupyter
    syft.publish
    syft.test.security
    syft.test.unit
    syft.test.notebook
    stack.test.notebook
    stack.test.integration.enclave.oblv
    stack.test.integration.k8s
    stack.test.vm
    stack.test.podman
    frontend.test.unit
    frontend.test.e2e
    frontend.generate.types
    syft.build.helm
    syft.package.helm
    syft.test.helm
    syft.protocol.check
    syftcli.test.unit
    syftcli.publish
    syftcli.build
    backend.test.basecpu
skipsdist = True


[testenv]
basepython = python3
install_command = pip install {opts} {packages}
commands =
    python --version

# Syft
[testenv:syft]
deps =
    -e{toxinidir}/packages/syft[dev]
changedir = {toxinidir}/packages/syft
description = Syft
commands =
    pip list

# Syft Minimal - without dev packages
[testenv:syft-minimal]
deps =
    -e{toxinidir}/packages/syft
changedir = {toxinidir}/packages/syft
description = Syft
commands =
    pip list

# data science packages
[testenv:syft-ds]
deps =
    -e{toxinidir}/packages/syft[data_science]
changedir = {toxinidir}/packages/syft
description = Syft
commands =
    pip list

[testenv:hagrid]
deps =
    -e{toxinidir}/packages/hagrid[dev]
changedir = {toxinidir}/packages/hagrid
description = Syft
commands =
    pip list

[testenv:syftcli]
deps =
    -e{toxinidir}/packages/syftcli[dev]
changedir = {toxinidir}/packages/syftcli
description = Syft CLI
install_command = pip install {opts} {packages}
commands =
    pip list

[testenv:hagrid.publish]
changedir = {toxinidir}/packages/hagrid
description = Build and Publish Hagrid Wheel
commands =
    python -m pip install --upgrade pip
    pip install --upgrade setuptools wheel twine tox build
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .

[testenv:syftcli.publish]
changedir = {toxinidir}/packages/syftcli
description = Build and Publish Syft CLI Wheel
allowlist_externals =
    bash
commands =
    python -m pip install --upgrade pip
    pip install --upgrade setuptools wheel twine tox build
    bash -c 'rm -rf build/ dist/ syftcli.egg-info/'
    python -m build .

[testenv:syftcli.build]
basepython = python3
changedir = {toxinidir}/packages/syftcli
description = Build SyftCLI Binary for each platform
allowlist_externals =
    bash
setenv =
    SYFT_CLI_VERSION = {env:SYFT_CLI_VERSION}
commands =
    python -m pip install --upgrade pip
    pip install -e ".[build]"
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'


    ;Since we build universal binary for MacOS,we need to check the python is universal2 or not
    bash -c 'if [[ "$OSTYPE" == "darwin"* ]]; then \
        arch_info=$(lipo -info "$(which python3)"); \
        echo "Arch: $arch_info"; \
        if [[ "$arch_info" == *"Non-fat"* ]]; then \
            echo "Building on MacOS Requires Universal2 python"; \
            echo "Please install universal2 python from https://www.python.org/downloads/macos/"; \
            exit 1; \
        fi; \
    fi'

    ;check the platform and build accordingly by naming the binary as syftcli plus the extension
    ; Check if SYFT_CLI_VERSION is set or choosing the current version available
    bash -c 'if [ -z $SYFT_CLI_VERSION ]; then \
        echo "SYFT_CLI_VERSION is not set"; \
        SYFT_CLI_VERSION=$(python3 syftcli/version.py); \
        echo "Setting SYFT_CLI_VERSION to $SYFT_CLI_VERSION"; \
    else \
        echo "SYFT_CLI_VERSION is already set to $SYFT_CLI_VERSION"; \
    fi && \

    echo "Building syftcli-$SYFT_CLI_VERSION for $OSTYPE" && \

    if [[ "$OSTYPE" == "darwin"* ]]; then \
         pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-macos-universal2 --distpath ./dist/cli syftcli/cli.py --target-arch universal2; \
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-linux-x86_64 --distpath ./dist/cli syftcli/cli.py; \
    else \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-windows-x86_64  --distpath ./dist/cli syftcli/cli.py; \
    fi'


[testenv:lint]
description = Linting
allowlist_externals =
    bash
deps =
    black[python2]
    isort
    pre-commit
commands =
    black .
    isort .
    pre-commit run --all-files

[testenv:frontend.test.unit]
description = Frontend Unit Tests
deps =
    {[testenv:hagrid]deps}
allowlist_externals =
    docker
    bash
    pnpm
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    DOCKER = {env:DOCKER:false}
commands =
    bash -c "echo Running with DOCKER=$DOCKER; date"

    bash -c 'if [[ "$DOCKER" == "false" ]]; then \
        bash ./scripts/check_pnpm.sh; \
        pnpm install; \
        pnpm run test:unit; \
    else \
        docker build --target grid-ui-tests -t ui-test -f frontend.dockerfile .; \
        docker run -t ui-test; \
    fi'

[testenv:frontend.test.e2e]
description = Frontend Unit Tests
deps =
    {[testenv:hagrid]deps}
allowlist_externals =
    docker
    bash
    pnpm
    sleep
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    HAGRID_FLAGS = {env:HAGRID_FLAGS:--tag=local --test}
    ENABLE_SIGNUP=True
commands =
    bash ./scripts/check_pnpm.sh

    bash -c "echo Running with HAGRID_FLAGS=$HAGRID_FLAGS; date"

    ; install hagrid
    bash -c 'if [[ "$HAGRID_FLAGS" == *"local"* ]]; then \
        pip install -e ../../hagrid; \
    else \
        pip install --force hagrid; \
    fi'

    ; fix windows encoding
    - chcp 65001

    ; check docker versions
    bash -c "docker --version"
    bash -c "docker compose version"

    ; reset volumes and create nodes
    bash -c "echo Starting Nodes; date"
    bash -c "docker rm -f $(docker ps -a -q) || true"
    bash -c "docker volume rm test-domain-1_mongo-data --force || true"
    bash -c "docker volume rm test-domain-1_credentials-data --force || true"
    bash -c "docker volume rm test-domain-1_seaweedfs-data --force || true"

    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test_domain_1 domain to docker:9081 $HAGRID_FLAGS --enable-signup --no-health-checks --verbose --no-warnings'

    bash -c '(docker logs test_domain_1-frontend-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c '(docker logs test_domain_1-backend-1 -f &) | grep -q "Application startup complete" || true'

    pnpm install
    pnpm dlx playwright@1.36.1 install --with-deps
    pnpm test:e2e

    ; shutdown
    bash -c "echo Killing Nodes; date"
    bash -c 'HAGRID_ART=false hagrid land all --force'


[testenv:stack.test.integration]
description = Integration Tests for Core Stack
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
changedir = {toxinidir}
allowlist_externals =
    docker
    grep
    sleep
    bash
    chcp
passenv=HOME, USER
setenv =
    HAGRID_FLAGS = {env:HAGRID_FLAGS:--tag=local --release=development --test}
    EMULATION = {env:EMULATION:false}
    HAGRID_ART = false
    PYTHONIOENCODING = utf-8
    PYTEST_MODULES = {env:PYTEST_MODULES:frontend container_workload network e2e security redis}
commands =
    bash -c "whoami; id;"

    bash -c "echo Running with HAGRID_FLAGS=$HAGRID_FLAGS EMULATION=$EMULATION PYTEST_MODULES=$PYTEST_MODULES; date"

    ; install syft and hagrid
    bash -c 'if [[ "$HAGRID_FLAGS" == *"latest"* ]]; then \
        pip install --force pytest hagrid syft; \
    elif [[ "$HAGRID_FLAGS" == *"beta"* ]]; then \
        pip install --force pytest hagrid; \
        pip install --force -U --pre syft; \
    else \
        pip install -e packages/hagrid -e packages/syft[dev]; \
    fi'

    ; fix windows encoding
    - chcp 65001

    ; check docker versions
    bash -c "docker --version"
    bash -c "docker compose version"

    ; reset volumes and create nodes
    bash -c "echo Starting Nodes; date"
    bash -c "docker rm -f $(docker ps -a -q) || true"
    bash -c "docker volume rm test-domain-1_mongo-data --force || true"
    bash -c "docker volume rm test-domain-1_credentials-data --force || true"
    bash -c "docker volume rm test-domain-1_seaweedfs-data --force || true"
    ; bash -c "docker volume rm test-domain-2_mongo-data --force || true"
    ; bash -c "docker volume rm test-domain-2_credentials-data --force || true"
    ; bash -c "docker volume rm test-domain-2_seaweedfs-data --force || true"
    bash -c "docker volume rm test-gateway-1_mongo-data --force || true"
    bash -c "docker volume rm test-gateway-1_credentials-data --force || true"
    bash -c "docker volume rm test-gateway-1_seaweedfs-data --force || true"

    python -c 'import syft as sy; sy.stage_protocol_changes()'

    ; Make sure that pacakge-cache is owned by the current user
    ; instead of docker creating it as root
    bash -c 'mkdir -p packages/grid/data/package-cache'

    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-gateway-1 gateway to docker:9081 $HAGRID_FLAGS --no-health-checks --verbose --no-warnings --build'
    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-domain-1 domain to docker:9082 $HAGRID_FLAGS --no-health-checks --enable-signup --verbose --no-warnings --build'
    ; bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-domain-2 domain to docker:9083 --headless $HAGRID_FLAGS --enable-signup --no-health-checks --verbose --no-warnings --build'

    ; wait for nodes to start
    docker ps
    bash -c "echo Waiting for Nodes; date"
    bash -c '(docker logs test-domain-1-frontend-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c '(docker logs test-domain-1-backend-1 -f &) | grep -q "Application startup complete" || true'
    ; bash -c '(docker logs test_domain_2-backend-1 -f &) | grep -q "Application startup complete" || true'
    bash -c '(docker logs test-gateway-1-backend-1 -f &) | grep -q "Application startup complete" || true'

    ; frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
        return=$?; \
        docker stop test_domain_1-frontend-1 || true; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'

    ; container workload
    bash -c 'if [[ "$PYTEST_MODULES" == *"container_workload"* ]]; then \
        echo "Starting Container Workload test"; date; \
        pytest tests/integration -m container_workload -p no:randomly --co; \
        pytest tests/integration -m container_workload -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
        return=$?; \
        echo "Finished container workload"; date; \
        exit $return; \
    fi'

    ; network
    bash -c 'if [[ "$PYTEST_MODULES" == *"network"* ]]; then \
        echo "Starting network"; date; \
        pytest tests/integration -m network -p no:randomly --co; \
        pytest tests/integration -m network -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
        return=$?; \
        echo "Finished network"; date; \
        exit $return; \
    fi'

    ; shutdown
    bash -c "echo Killing Nodes; date"
    bash -c 'HAGRID_ART=false hagrid land all --force'

[testenv:syft.docs]
description = Build Docs for Syft
changedir = {toxinidir}/docs
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    -r {toxinidir}/docs/requirements.txt
allowlist_externals =
    make
    echo
    cd
    rm
    ls
    xargs
    bash
commands =
    python --version
    bash -c "cd source/api_reference && ls | grep -v index.rst | xargs rm"
    sphinx-apidoc -f -M -d 2 -o ./source/api_reference/ ../packages/syft/src/syft
    make html
    echo "Open: {toxinidir}/docs/build/html/index.html"

[testenv:syft.jupyter]
description = Jupyter Notebook with Editable Syft
deps =
    {[testenv:syft]deps}
    {[testenv:syft-ds]deps}
    {[testenv:hagrid]deps}
    jupyter
    jupyterlab
commands =
    pip install -e packages/hagrid
    pip install jupyter jupyterlab --upgrade
    jupyter lab --ip 0.0.0.0 --ServerApp.token={posargs}

[testenv:syft.protocol.check]
description = Syft Protocol Check
deps =
    {[testenv:syft-minimal]deps}
changedir = {toxinidir}/packages/syft
allowlist_externals =
    bash
setenv =
    BUMP = {env:BUMP:False}
commands =
    bash -c "echo Using BUMP=${BUMP}"
    python -c 'import syft as sy; sy.check_or_stage_protocol()'
    bash -c 'if [[ "$BUMP" != "False" ]]; then \
        python -c "import syft as sy; sy.bump_protocol_version()"; \
        fi'

[testenv:syft.publish]
changedir = {toxinidir}/packages/syft
description = Build and Publish Syft Wheel
commands =
    python -m pip install --upgrade pip
    pip install --upgrade setuptools wheel twine tox build
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .

[testenv:syft.test.security]
description = Security Checks for Syft
changedir = {toxinidir}/packages/syft
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
commands =
    pip install --upgrade pip
    bandit -r src
    # ansible 8.4.0
    # restrictedpython 6.2
    safety check -i 60840 -i 54229 -i 54230 -i 42923 -i 54230 -i 54229 -i 62044

[testenv:syft.test.unit]
description = Syft Unit Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    bash
changedir = {toxinidir}/packages/syft
setenv =
    ENABLE_SIGNUP=False
commands =
    pip list
    bash -c 'ulimit -n 4096 || true'
    pytest -n auto

[testenv:stack.test.integration.enclave.oblv]
description = Integration Tests for Oblv Enclave
changedir = {toxinidir}
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    grep
    bash
passenv=HOME, USER
setenv =
    LOCAL_ENCLAVE_PORT=8010
    ENABLE_OBLV=true
    DOMAIN_CONNECTION_PORT=8010
    ENABLE_SIGNUP=True
commands =
    pip install oblv-ctl==0.3.1
    # run at start to kill any process started beforehand
    bash -c 'chmod +x scripts/kill_process_in_port.sh && ./scripts/kill_process_in_port.sh $LOCAL_ENCLAVE_PORT'

    bash -c 'rm -rf ~/.syft/syft-enclave'
    bash -c 'git clone https://github.com/OpenMined/syft-enclave.git ~/.syft/syft-enclave || true'
    bash -c 'cd ~/.syft/syft-enclave && git fetch && git checkout dev && git pull && pip install -r requirements_test.txt || true'

    # Starting FastAPI server locally
    bash -c 'cd ~/.syft/syft-enclave/src && uvicorn app:app --host 0.0.0.0 --port $LOCAL_ENCLAVE_PORT > /dev/null 2>&1 &'

    bash -c 'cd tests/integration/external/oblv && pytest -p no:randomly -vvvv'
    bash -c 'chmod +x scripts/kill_process_in_port.sh && ./scripts/kill_process_in_port.sh $LOCAL_ENCLAVE_PORT'

[testenv:syft.test.notebook]
description = Syft Notebook Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:python}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8,tutorials}
    ENABLE_SIGNUP=True
commands =
    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' '); do \
    if [[ $subfolder == *tutorials* ]]; then \
        pytest --nbmake "$subfolder" -p no:randomly --ignore=tutorials/model-training -n $(python -c 'import multiprocessing; print(multiprocessing.cpu_count())') -vvvv && \
        pytest --nbmake tutorials/model-training -p no:randomly -vvvv; \
    else \
        pytest --nbmake "$subfolder" -p no:randomly -k 'not 11-container-images-k8s.ipynb' -vvvv; \
    fi \
    done"
    ; pytest --nbmake api/0.8 -p no:randomly -vvvv
    ; pytest --nbmake api/0.9 -p no:randomly -vvvv
    ; pytest --nbmake tutorials -p no:randomly -vvvv
    ; pytest --nbmake tutorials/pandas-cookbook -p no:randomly -vvvv



[testenv:stack.test.notebook]
description = Stack Notebook Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:single_container}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8}
    ENABLE_SIGNUP=True
commands =

    # Volume cleanup
    bash -c 'hagrid land all --force || true'
    bash -c "docker volume rm test-domain-1_mongo-data --force || true"
    bash -c "docker volume rm test-domain-1_credentials-data --force || true"
    bash -c "docker volume rm test-domain-1_seaweedfs-data --force || true"

    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' ');\
    do \
        pytest --nbmake "$subfolder" -p no:randomly -vvvv -k 'not 11-container-images-k8s.ipynb' --nbmake-timeout=1000;\
    done"

    ; pytest --nbmake api/0.8 -p no:randomly -vvvv
    ; pytest --nbmake api/0.9 -p no:randomly -vvvv
    ; pytest --nbmake tutorials -p no:randomly -vvvv
    ; pytest --nbmake tutorials/pandas-cookbook -p no:randomly -vvvv

    bash -c 'hagrid land all --force'

[testenv:stack.test.vm]
description = Stack VM Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:vm}
    VAGRANT_DESTROY = {env:VAGRANT_DESTROY:skip}
commands =
    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    else \
        vagrant ssh $VAGRANT_BOX -c "docker ps -aq | xargs -I {:} docker rm {:} --force"; \
        vagrant ssh $VAGRANT_BOX -c "docker volume prune --filter all=1 --force || true"; \
    fi; \
    vagrant up $VAGRANT_BOX --provision; \
    '

    pytest --nbmake notebooks/api/0.8 -p no:randomly -vvvv
    ; pytest --nbmake notebooks/api/0.9 -p no:randomly -vvvv

    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    fi; \
    '

[testenv:stack.test.podman]
description = Stack podman Tests for Rhel & Centos
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:podman}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    bash -c "podman pod rm --force --all || true";
    bash -c "podman system prune --volumes --force || true";
    bash -c "podman volume rm $(podman volume ls -q)||true";

    # Force Removal of images
    bash -c "podman image prune --all --force || true";

    # Build Backend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-backend:$SYFT_VERSION -f packages/grid/backend/backend.dockerfile --target backend packages";

    # Build Frontend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-frontend:$SYFT_VERSION -f packages/grid/frontend/frontend.dockerfile --target grid-ui-development packages/grid/frontend";

    bash -c 'cd packages/grid/podman/podman-kube && podman play kube podman-syft-kube.yaml --configmap=podman-syft-kube-config.yaml'
    bash -c '(podman logs -f syft-backend &) | grep -q "Application startup complete" || true'
    pytest --nbmake notebooks/api/0.8 -p no:randomly -vvvv

[testenv:frontend.generate.types]
description = Generate Types for Frontend
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    cd
    bash
    pnpm
changedir = {toxinidir}/packages/grid/frontend
passenv =
    PNPM_HOME
commands =
    bash -c ./scripts/check_pnpm.sh
    pnpm add -g json-schema-to-typescript

    ; clear the old ones
    bash -c 'rm -rf ./schema'
    bash -c 'rm -rf ./src/types/generated'

    ; generate new ones
    bash -c 'python3 -c "import syft as sy;sy.util.schema.generate_json_schemas()"'
    bash -c "json2ts -i './schema/**/*.json' -o ./src/types/generated"
    bash -c "python3 ./scripts/replace_imports.py ./src/types/generated"

[mypy]
python_version = 3.11
disable_error_code = attr-defined, valid-type, no-untyped-call, arg-type


[testenv:stack.test.integration.k8s]
description = Integration Tests for Core Stack
basepython = python3
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    {[testenv:syft-ds]deps}
    nbmake
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:9082}
    GITHUB_CI = {env:GITHUB_CI:false}
    PYTEST_MODULES = {env:PYTEST_MODULES:frontend container_workload}
commands =
    bash -c "echo Running with GITHUB_CI=$GITHUB_CI; date"
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    k3d version

    # Since cluster name cannot have underscore and environment variable cannot have hyphen
    # we are passing a grouped name for node names
    # bash -c "docker rm $(docker ps -aq) --force || true"
    # Deleting current cluster
    bash -c "k3d cluster delete testgateway1 || true"
    bash -c "k3d cluster delete testdomain1 || true"

    # Deleting registery & volumes
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-testgateway1-images --force || true"
    bash -c "docker volume rm k3d-testdomain1-images --force || true"


    # Creating registory
    bash -c 'k3d registry create registry.localhost --port 5000  -v `pwd`/k3d-registry:/var/lib/registry || true'

    # Creating testgateway1 cluster on port 9081
    bash -c 'NODE_NAME=testgateway1 NODE_PORT=9081 && \
        k3d cluster create $NODE_NAME -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
        k3d cluster start $NODE_NAME'

    bash -c 'NODE_NAME=testgateway1 NODE_PORT=9081 && \
        cd packages/grid && \
        (r=5;while ! \
        devspace --no-warn --kube-context "k3d-$NODE_NAME" --namespace $NODE_NAME \
        -p gateway \
        --var NODE_NAME=$NODE_NAME \
        --var TEST_MODE=1 \
        --var CONTAINER_REGISTRY=k3d-registry.localhost:5000 \
        --var NODE_TYPE=gateway \
        deploy -b; \
        do ((--r))||exit;echo "retrying" && sleep 20;done)'

    # Creating testdomain1 cluster on port 9082
    bash -c 'NODE_NAME=testdomain1 NODE_PORT=9082 && \
        k3d cluster create $NODE_NAME -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
        k3d cluster start $NODE_NAME'

    bash -c 'NODE_NAME=testdomain1 NODE_PORT=9082 && \
        cd packages/grid && \
        (r=5;while ! \
        devspace --no-warn --kube-context "k3d-$NODE_NAME" --namespace $NODE_NAME \
        --var NODE_NAME=$NODE_NAME \
        --var TEST_MODE=1 \
        --var CONTAINER_REGISTRY=k3d-registry.localhost:5000 \
        deploy -b; \
        do ((--r))||exit;echo "retrying" && sleep 20;done)'

    # free up build cache after build of images
    bash -c 'if [[ "$GITHUB_CI" != "false" ]]; then \
        docker image prune --all --force; \
        docker builder prune --all --force; \
    fi'

    sleep 30

    # wait for front end
    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-testdomain1 --namespace testdomain1
    bash -c '(kubectl logs service/frontend --context k3d-testdomain1 --namespace testdomain1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    # wait for test gateway 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-testgateway1 --namespace testgateway1
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-testgateway1 --namespace testgateway1
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-testgateway1 --namespace testgateway1

    # wait for test domain 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-testdomain1 --namespace testdomain1
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-testdomain1 --namespace testdomain1
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-testdomain1 --namespace testdomain1
    bash packages/grid/scripts/wait_for.sh service seaweedfs --context k3d-testdomain1 --namespace testdomain1

    # Checking logs generated & startup of test-domain 1
    bash -c '(kubectl logs service/backend --context k3d-testdomain1 --namespace testdomain1 -f &) | grep -q "Application startup complete" || true'
    # Checking logs generated & startup of testgateway1
    bash -c '(kubectl logs service/backend --context k3d-testgateway1 --namespace testgateway1 -f &) | grep -q "Application startup complete" || true'


    # frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly -k "test_serves_domain_frontend" --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no -k "test_serves_domain_frontend"; \
        return=$?; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'

    #Integration + Gateway Connection Tests
    # Gateway tests are not run in kuberetes, as currently,it does not have a way to configure
    # high/low side warning flag.
    bash -c " source ./scripts/get_k8s_secret_ci.sh; \
    pytest tests/integration/network -k 'not test_domain_gateway_user_code' -p no:randomly -vvvv"

    # Shutting down the gateway cluster to free up space, as the
    # below code does not require gateway cluster
    bash -c "k3d cluster delete testgateway1 || true"
    bash -c "docker volume rm k3d-testgateway1-images --force || true"

    ; ; container workload
    ; bash -c 'if [[ "$PYTEST_MODULES" == *"container_workload"* ]]; then \
    ;     echo "Starting Container Workload test"; date; \
    ;     pytest tests/integration -m container_workload -p no:randomly --co; \
    ;     pytest tests/integration -m container_workload -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
    ;     return=$?; \
    ;     echo "Finished container workload"; date; \
    ;     exit $return; \
    ; fi'

    # Since we randomize the password, we retrieve them and store as environment variables
    # which would then be used by the notebook


    # ignore 06 because of opendp on arm64
    # Run 0.8 notebooks

    bash -c " source ./scripts/get_k8s_secret_ci.sh; \
     pytest --nbmake notebooks/api/0.8 -p no:randomly -k 'not 10-container-images.ipynb' -vvvv --nbmake-timeout=1000"


    # deleting clusters created
    bash -c "k3d cluster delete testgateway1 || true"
    bash -c "k3d cluster delete testdomain1 || true"
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker rm $(docker ps -aq) --force || true"
    bash -c "docker volume rm k3d-testgateway1-images --force || true"
    bash -c "docker volume rm k3d-testdomain1-images --force || true"



[testenv:syft.build.helm]
description = Build Helm Chart for Kubernetes
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        python3 generate_helm_notes.py ./syft/templates'

    bash -c 'cd packages/grid/helm && \
        helm lint syft'


[testenv:syft.package.helm]
description = Package Helm Chart for Kubernetes
deps =
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        helm lint syft'

    bash -c 'cd packages/grid/helm/syft && \
        helm dependency update'

    bash -c 'cd packages/grid/helm && \
        helm package syft --destination repo'

    bash -c 'cd packages/grid/helm/repo && \
        helm repo index . --url https://openmined.github.io/PySyft/helm'

[testenv:syft.test.helm]
description = Test Helm Chart for Kubernetes
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
    rm
    helm
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    k3d version

    ; bash -c "docker rm $(docker ps -aq) --force || true"
    bash -c "k3d cluster delete syft || true"
    bash -c "docker volume rm k3d-syft-images --force || true"

    bash -c "k3d registry delete k3d-registry.localhost || true"

    bash -c 'k3d registry create registry.localhost --port 5000  -v `pwd`/k3d-registry:/var/lib/registry || true'

    bash -c 'NODE_NAME=syft NODE_PORT=8080 && \
        k3d cluster create syft -p "$NODE_PORT:80@loadbalancer" --registry-use k3d-registry.localhost || true \
        k3d cluster start syft'

    ; skopeo list-tags --tls-verify=false docker://k3d-registry.localhost:5000/openmined/grid-backend
    ; skopeo inspect --tls-verify=false docker://k3d-registry.localhost:5000/openmined/grid-backend:f1725f
    ; helm uninstall --kube-context k3d-syft --namespace syft syft
    ; helm install --kube-context k3d-syft --namespace syft syft ./syft
    ; k3d cluster create syft -p "8080:80@loadbalancer" && k3d cluster start syft

    sleep 50

    bash -c 'cd packages/grid && \
        kubectl --context k3d-syft create namespace syft || true; \
        helm install --kube-context k3d-syft --namespace syft syft ./helm/syft --debug'

    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-syft --namespace syft
    bash -c '(kubectl logs service/frontend --context k3d-syft --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    ; wait for everything else to be loaded
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-syft --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-syft --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-syft --namespace syft

    bash -c '(kubectl logs service/backend --context k3d-syft --namespace syft -f &) | grep -q "Application startup complete" || true'


    ; frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly -k "test_serves_domain_frontend" --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no -k "test_serves_domain_frontend"; \
        return=$?; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'

    ; ignore 06 because of opendp on arm64
    pytest --nbmake notebooks/api/0.8 -p no:randomly -k 'not 10-container-images.ipynb' -vvvv

    bash -c "k3d cluster delete syft || true"
    bash -c "docker volume rm k3d-syft-images --force || true"

[testenv:syftcli.test.unit]
description = Syft CLI Unit Tests
deps =
    {[testenv:syftcli]deps}
changedir = {toxinidir}/packages/syftcli
commands =
    pip list
    pytest

[testenv:dev.k8s.registry]
description = Start local Kubernetes registry with k3d
changedir = {toxinidir}
passenv=HOME,USER
allowlist_externals =
    bash
    sudo
commands =
    ; create registry
    bash -c 'k3d registry create registry.localhost --port 5000 -v $HOME/.k3d-registry:/var/lib/registry || true'

    ; add patches to host
    bash -c 'if ! grep -q k3d-registry.localhost /etc/hosts; then sudo {envpython} scripts/patch_hosts.py --add-k3d-registry --fix-docker-hosts; fi'

    ; Fail this command if registry is not working
    bash -c 'URL=http://k3d-registry.localhost:5000/v2/_catalog; curl -X GET $URL'

[testenv:dev.k8s.start]
description = Start local Kubernetes registry & cluster with k3d
changedir = {toxinidir}
passenv=*
allowlist_externals =
    bash
    sleep
    tox
commands =
    ; start registry
    tox -e dev.k8s.registry

    ; for NodePort to work add the following --> -p "NodePort:NodePort@loadbalancer"
    bash -c 'k3d cluster create syft-dev -p "8080:80@loadbalancer" --registry-use k3d-registry.localhost:5000; \
        kubectl create namespace syft || true'

    ; dump cluster info
    tox -e dev.k8s.info

[testenv:dev.k8s.deploy]
description = Deploy Syft to a local Kubernetes cluster with Devspace
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
allowlist_externals =
    tox
    bash
commands =
    ; deploy syft helm charts
    bash -c 'devspace deploy -b --kube-context k3d-syft-dev --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5000'

[testenv:dev.k8s.hotreload]
description = Start development with hot-reload in Kubernetes
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
allowlist_externals =
    bash
    tox
commands =
    ; deploy syft helm charts with hot-reload
    bash -c 'devspace dev --kube-context k3d-syft-dev --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5000'

[testenv:dev.k8s.info]
description = Gather info about the localKubernetes cluster
passenv=HOME, USER
ignore_errors = True
allowlist_externals =
    k3d
    kubectl
commands =
    kubectl config view
    k3d cluster list
    kubectl cluster-info
    kubectl config current-context
    kubectl get namespaces

[testenv:dev.k8s.cleanup]
description = Cleanup Syft deployment and associated resources, but keep the cluster running
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
allowlist_externals =
    bash
commands =
    bash -c 'devspace purge --force-purge --kube-context k3d-syft-dev --namespace syft; sleep 3'
    bash -c 'devspace cleanup images --kube-context k3d-syft-dev --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5000 || true'
    bash -c 'kubectl config use-context k3d-syft-dev'
    bash -c 'kubectl delete all --all --namespace syft || true'
    bash -c 'kubectl delete pvc --all --namespace syft || true'
    bash -c 'kubectl delete secret --all --namespace syft || true'
    bash -c 'kubectl delete configmap --all --namespace syft || true'
    bash -c 'kubectl delete serviceaccount --all --namespace syft || true'

[testenv:dev.k8s.destroy]
description = Destroy local Kubernetes cluster
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
allowlist_externals =
    tox
    bash
commands =
    ; purge deployment and dangling resources
    tox -e dev.k8s.cleanup

    ; destroy cluster
    bash -c '\
        rm -rf .devspace; echo ""; \
        k3d cluster delete syft-dev; echo ""; \
        kubectl config view'

[testenv:dev.k8s.destroyall]
description = Destroy both local Kubernetes cluster and registry
changedir = {toxinidir}
passenv=HOME, USER
ignore_errors=True
allowlist_externals =
    bash
    tox
    rm
commands =
    ; destroy cluster
    tox -e dev.k8s.destroy

    ; destroy registry
    bash -c 'k3d registry delete registry.localhost || true'
    bash -c 'sudo rm -rf ~/.k3d-registry'

[testenv:backend.test.basecpu]
description = Base CPU Docker Image Test
changedir = {toxinidir}/packages
allowlist_externals =
    docker
    bash
setenv =
    PIP_PACKAGES = {env:PIP_PACKAGES:llama-index opendp}
    SYSTEM_PACKAGES = {env:SYSTEM_PACKAGES:curl wget}
commands =
    bash -c 'docker buildx use default || true'
    ; Build the base image
    bash -c 'docker build -f ./grid/backend/worker_cpu.dockerfile . -t cpu-worker:latest'
    bash -c 'docker rmi cpu-worker:latest'

    bash -c '\
        docker build \
            -f grid/backend/worker_cpu.dockerfile . \
            -t cpu-worker:opendp \
            --build-arg PIP_PACKAGES="$PIP_PACKAGES" \
            --build-arg SYSTEM_PACKAGES="$SYSTEM_PACKAGES"'
    bash -c 'for pkg in $PIP_PACKAGES; do docker run --rm cpu-worker:opendp pip list | grep "$pkg"; done'
    bash -c 'for pkg in $SYSTEM_PACKAGES; do docker run --rm cpu-worker:opendp apk -e info "$pkg"; done'
    bash -c 'docker rmi cpu-worker:opendp'

    bash -c '\
        docker build \
            -f grid/backend/worker_cpu.dockerfile . \
            -t cpu-worker:custom-cmd  \
            --build-arg SYSTEM_PACKAGES="perl wget curl make " \
            --build-arg CUSTOM_CMD="""wget -O - "https://github.com/cowsay-org/cowsay/archive/refs/tags/v3.7.0.tar.gz" | tar xvzf - && cd cowsay-3.7.0 && make"""'
    bash -c 'for pkg in perl make curl wget; do docker run --rm cpu-worker:custom-cmd apk -e info "$pkg"; done'
    bash -c 'docker run --rm cpu-worker:custom-cmd bash -c "cd cowsay-3.7.0 && curl https://api.github.com/zen -s | ./cowsay"'
    bash -c 'docker rmi cpu-worker:custom-cmd'
