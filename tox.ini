[tox]
envlist =
    dev.k8s.registry
    dev.k8s.start
    dev.k8s.deploy
    dev.k8s.hotreload
    dev.k8s.info
    dev.k8s.cleanup
    dev.k8s.destroy
    dev.k8s.destroyall
    hagrid.publish
    lint
    stack.test.integration
    syft.docs
    syft.jupyter
    syft.publish
    syft.test.security
    syft.test.unit
    syft.test.notebook
    single_container.launch
    single_container.destroy
    stack.test.notebook
    stack.test.integration.k8s
    stack.test.vm
    stack.test.podman
    frontend.test.unit
    frontend.test.e2e
    frontend.generate.types
    syft.build.helm
    syft.package.helm
    syft.test.helm
    syft.test.helm.upgrade
    syft.protocol.check
    syftcli.test.unit
    syftcli.publish
    syftcli.build
    seaweedfs.test.unit
    backend.test.basecpu
    e2e.test.notebook
skipsdist = True


[testenv]
basepython = python3
commands =
    python --version
setenv =
    UV_HTTP_TIMEOUT = 600

# Syft
[testenv:syft]
deps =
    -e{toxinidir}/packages/syft[dev,data_science]
changedir = {toxinidir}/packages/syft
description = Syft
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

# Syft Minimal - without dev+datascience packages
[testenv:syft-minimal]
deps =
    -e{toxinidir}/packages/syft
changedir = {toxinidir}/packages/syft
description = Syft
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

[testenv:hagrid]
deps =
    -e{toxinidir}/packages/hagrid[dev]
changedir = {toxinidir}/packages/hagrid
description = Syft
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

[testenv:syftcli]
deps =
    -e{toxinidir}/packages/syftcli[dev]
changedir = {toxinidir}/packages/syftcli
description = Syft CLI
allowlist_externals =
    bash
commands =
    bash -c 'uv pip list || pip list'

[testenv:syft.publish]
changedir = {toxinidir}/packages/syft
description = Build and Publish Syft Wheel
deps =
    build
commands =
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .

[testenv:hagrid.publish]
changedir = {toxinidir}/packages/hagrid
description = Build and Publish Hagrid Wheel
deps =
    build
commands =
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'
    python -m build .

[testenv:syftcli.publish]
changedir = {toxinidir}/packages/syftcli
description = Build and Publish Syft CLI Wheel
deps =
    build
allowlist_externals =
    bash
commands =
    bash -c 'rm -rf build/ dist/ syftcli.egg-info/'
    python -m build .

[testenv:syftcli.build]
basepython = python3
changedir = {toxinidir}/packages/syftcli
description = Build SyftCLI Binary for each platform
deps =
    -e{toxinidir}/packages/syftcli[build]
allowlist_externals =
    bash
setenv =
    SYFT_CLI_VERSION = {env:SYFT_CLI_VERSION}
commands =
    python -c 'from shutil import rmtree; rmtree("build", True); rmtree("dist", True)'


    ;Since we build universal binary for MacOS,we need to check the python is universal2 or not
    bash -c 'if [[ "$OSTYPE" == "darwin"* ]]; then \
        arch_info=$(lipo -info "$(which python3)"); \
        echo "Arch: $arch_info"; \
        if [[ "$arch_info" == *"Non-fat"* ]]; then \
            echo "Building on MacOS Requires Universal2 python"; \
            echo "Please install universal2 python from https://www.python.org/downloads/macos/"; \
            exit 1; \
        fi; \
    fi'

    ;check the platform and build accordingly by naming the binary as syftcli plus the extension
    ; Check if SYFT_CLI_VERSION is set or choosing the current version available
    bash -c 'if [ -z $SYFT_CLI_VERSION ]; then \
        echo "SYFT_CLI_VERSION is not set"; \
        SYFT_CLI_VERSION=$(python3 syftcli/version.py); \
        echo "Setting SYFT_CLI_VERSION to $SYFT_CLI_VERSION"; \
    else \
        echo "SYFT_CLI_VERSION is already set to $SYFT_CLI_VERSION"; \
    fi && \

    echo "Building syftcli-$SYFT_CLI_VERSION for $OSTYPE" && \

    if [[ "$OSTYPE" == "darwin"* ]]; then \
         pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-macos-universal2 --distpath ./dist/cli syftcli/cli.py --target-arch universal2; \
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-linux-x86_64 --distpath ./dist/cli syftcli/cli.py; \
    else \
        pyinstaller --clean --onefile --name syftcli-v$SYFT_CLI_VERSION-windows-x86_64  --distpath ./dist/cli syftcli/cli.py; \
    fi'


[testenv:lint]
description = Linting
allowlist_externals =
    bash
deps =
    black[python2]
    isort
    pre-commit
commands =
    black .
    isort .
    pre-commit run --all-files

[testenv:frontend.test.unit]
description = Frontend Unit Tests
deps =
    {[testenv:hagrid]deps}
allowlist_externals =
    docker
    bash
    pnpm
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    DOCKER = {env:DOCKER:false}
commands =
    bash -c "echo Running with DOCKER=$DOCKER; date"

    bash -c 'if [[ "$DOCKER" == "false" ]]; then \
        bash ./scripts/check_pnpm.sh; \
        pnpm install; \
        pnpm run test:unit; \
    else \
        docker build --target grid-ui-tests -t ui-test -f frontend.dockerfile .; \
        docker run -t ui-test; \
    fi'

[testenv:frontend.test.e2e]
description = Frontend Unit Tests
deps =
    {[testenv:hagrid]deps}
allowlist_externals =
    docker
    bash
    pnpm
    sleep
passenv=HOME, USER
changedir = {toxinidir}/packages/grid/frontend
setenv =
    HAGRID_FLAGS = {env:HAGRID_FLAGS:--tag=local --test}
    ENABLE_SIGNUP=True
commands =
    bash ./scripts/check_pnpm.sh

    bash -c "echo Running with HAGRID_FLAGS=$HAGRID_FLAGS; date"

    ; install hagrid
    bash -c 'if [[ "$HAGRID_FLAGS" == *"local"* ]]; then \
        uv pip install -e "../../hagrid"; \
    else \
        uv pip install --force hagrid; \
    fi'

    ; fix windows encoding
    - chcp 65001

    ; check docker versions
    bash -c "docker --version"
    bash -c "docker compose version"

    ; reset volumes and create nodes
    bash -c "echo Starting Nodes; date"
    bash -c "docker rm -f $(docker ps -a -q) || true"
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'

    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test_domain_1 domain to docker:9081 $HAGRID_FLAGS --enable-signup --no-health-checks --verbose --no-warnings'

    bash -c '(docker logs test_domain_1-frontend-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c '(docker logs test_domain_1-backend-1 -f &) | grep -q "Application startup complete" || true'

    pnpm install
    pnpm dlx playwright@1.36.1 install --with-deps
    pnpm exec playwright install
    pnpm test:e2e

    ; shutdown
    bash -c "echo Killing Nodes; date"
    bash -c 'HAGRID_ART=false hagrid land all --force'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'


[testenv:stack.test.integration]
description = Integration Tests for Core Stack
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    pytest
changedir = {toxinidir}
allowlist_externals =
    docker
    grep
    sleep
    bash
    chcp
passenv=HOME, USER, AZURE_BLOB_STORAGE_KEY
setenv =
    HAGRID_FLAGS = {env:HAGRID_FLAGS:--tag=local --dev}
    EMULATION = {env:EMULATION:false}
    HAGRID_ART = false
    PYTHONIOENCODING = utf-8
    PYTEST_MODULES = {env:PYTEST_MODULES:frontend container_workload network local}
commands =
    bash -c "whoami; id;"

    bash -c "echo Running with HAGRID_FLAGS=$HAGRID_FLAGS EMULATION=$EMULATION PYTEST_MODULES=$PYTEST_MODULES; date"

    ; install syft and hagrid
    bash -c 'if [[ "$HAGRID_FLAGS" == *"latest"* ]]; then \
        echo "Installing latest syft and hagrid"; \
        uv pip install --force hagrid syft; \
    elif [[ "$HAGRID_FLAGS" == *"beta"* ]]; then \
        echo "Installing beta syft and hagrid"; \
        uv pip install --force hagrid; \
        uv pip install --force -U --pre syft; \
    else \
        echo "Using local syft and hagrid"; \
    fi'

    ; fix windows encoding
    - chcp 65001

    ; check docker versions
    bash -c "docker --version"
    bash -c "docker compose version"

    ; reset volumes and create nodes
    bash -c "echo Starting Nodes; date"
    bash -c 'docker rm -f $(docker ps -a -q --filter "label=orgs.openmined.syft") || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'

    python -c 'import syft as sy; sy.stage_protocol_changes()'

    ; Make sure that pacakge-cache is owned by the current user
    ; instead of docker creating it as root
    bash -c 'mkdir -p packages/grid/data/package-cache'

    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-gateway-1 gateway to docker:9081 $HAGRID_FLAGS --no-health-checks --verbose --no-warnings --build'
    bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-domain-1 domain to docker:9082 $HAGRID_FLAGS --no-health-checks --enable-signup --verbose --no-warnings --build'
    ; bash -c 'HAGRID_ART=$HAGRID_ART hagrid launch test-domain-2 domain to docker:9083 --headless $HAGRID_FLAGS --enable-signup --no-health-checks --verbose --no-warnings --build'

    ; wait for nodes to start
    docker ps
    bash -c "echo Waiting for Nodes; date"
    bash -c '(docker logs test-domain-1-frontend-1 -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c '(docker logs test-domain-1-backend-1 -f &) | grep -q "Application startup complete" || true'
    ; bash -c '(docker logs test_domain_2-backend-1 -f &) | grep -q "Application startup complete" || true'
    bash -c '(docker logs test-gateway-1-backend-1 -f &) | grep -q "Application startup complete" || true'

    bash -c '\
        PYTEST_MODULES=($PYTEST_MODULES); \
        for i in "${PYTEST_MODULES[@]}"; do \
            echo "Starting test for $i"; date; \
            pytest tests/integration -m $i -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
            return=$?; \
            echo "Finished $i"; \
            date; \
            if [[ $return -ne 0 ]]; then \
                exit $return; \
            fi; \
        done'

    ; shutdown
    bash -c "echo Killing Nodes; date"
    bash -c 'HAGRID_ART=false hagrid land all --force'
    bash -c 'docker rm -f $(docker ps -a -q --filter "label=orgs.openmined.syft") || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'


[testenv:syft.docs]
description = Build Docs for Syft
changedir = {toxinidir}/docs
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    -r {toxinidir}/docs/requirements.txt
allowlist_externals =
    make
    echo
    cd
    rm
    ls
    xargs
    bash
commands =
    python --version
    bash -c "cd source/api_reference && ls | grep -v index.rst | xargs rm"
    sphinx-apidoc -f -M -d 2 -o ./source/api_reference/ ../packages/syft/src/syft
    make html
    echo "Open: {toxinidir}/docs/build/html/index.html"

[testenv:syft.jupyter]
description = Jupyter Notebook with Editable Syft
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    jupyter
    jupyterlab
commands =
    jupyter lab --ip 0.0.0.0 --ServerApp.token={posargs}

[testenv:syft.protocol.check]
description = Syft Protocol Check
deps =
    {[testenv:syft-minimal]deps}
changedir = {toxinidir}/packages/syft
allowlist_externals =
    bash
setenv =
    BUMP = {env:BUMP:False}
commands =
    bash -c "echo Using BUMP=${BUMP}"
    python -c 'import syft as sy; sy.check_or_stage_protocol()'
    bash -c 'if [[ "$BUMP" != "False" ]]; then \
        python -c "import syft as sy; sy.bump_protocol_version()"; \
        fi'

[testenv:syft.test.security]
description = Security Checks for Syft
changedir = {toxinidir}/packages/syft
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
commands =
    bandit -r src
    # ansible 8.4.0
    # restrictedpython 6.2
    safety check -i 60840 -i 54229 -i 54230 -i 42923 -i 54230 -i 54229 -i 62044 -i 65213 -i 54564

[testenv:syft.test.unit]
description = Syft Unit Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    bash
    uv
changedir = {toxinidir}/packages/syft
setenv =
    ENABLE_SIGNUP=False
commands =
    bash -c 'ulimit -n 4096 || true'
    pytest -n auto --dist loadgroup --durations=20 --disable-warnings

[testenv:syft.test.notebook]
description = Syft Notebook Tests
deps =
    -e{toxinidir}/packages/syft[dev,data_science]
    {[testenv:hagrid]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:python}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8,tutorials}
    ENABLE_SIGNUP={env:ENABLE_SIGNUP:False}
    BUMP_PROTOCOL={env:BUMP_PROTOCOL:False}
commands =
    bash -c 'if [[ $BUMP_PROTOCOL == "True" ]]; then \
                python -c "import syft as sy; sy.bump_protocol_version()"; \
            fi;'
    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; ENABLE_SIGNUP=$ENABLE_SIGNUP; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' '); do \
    if [[ $subfolder == *tutorials* ]]; then \
        pytest -x --nbmake "$subfolder" -p no:randomly --ignore=tutorials/model-training -n $(python -c 'import multiprocessing; print(multiprocessing.cpu_count())') -vvvv && \
        pytest -x --nbmake tutorials/model-training -p no:randomly -vvvv; \
    else \
        pytest -x --nbmake "$subfolder" -p no:randomly -k 'not 11-container-images-k8s.ipynb' -vvvv; \
    fi \
    done"
    ; pytest -x --nbmake api/0.8 -p no:randomly -vvvv
    ; pytest -x --nbmake api/0.9 -p no:randomly -vvvv
    ; pytest -x --nbmake tutorials -p no:randomly -vvvv
    ; pytest -x --nbmake tutorials/pandas-cookbook -p no:randomly -vvvv


[testenv:single_container.launch]
description = Launch a single backend container using the dockerfile
changedir = {toxinidir}/packages
setenv =
    N_CONSUMERS = {env:N_CONSUMERS:1}
    NODE_NAME = {env:NODE_NAME:test_domain_sc}
    NODE_TYPE = {env:NODE_TYPE:domain}
    NODE_PORT = {env:NODE_PORT:8080}
allowlist_externals =
    bash
commands =
    bash -c 'tox -e single_container.destroy'
    bash -c 'docker build -f grid/backend/backend.dockerfile . -t openmined/grid-backend:local-dev'
    bash -c 'docker run -d \
    -e NODE_NAME=${NODE_NAME} \
    -e NODE_TYPE=${NODE_TYPE} \
    -e N_CONSUMERS=${N_CONSUMERS} \
    -e SINGLE_CONTAINER_MODE=true \
    -e CREATE_PRODUCER=true \
    -e INMEMORY_WORKERS=true \
    -p ${NODE_PORT}:80 --add-host=host.docker.internal:host-gateway \
    --name ${NODE_NAME} openmined/grid-backend:local-dev'

[testenv:single_container.destroy]
description = Destroy the single backend container run using single_container.launch
changedir = {toxinidir}/packages
setenv =
    NODE_NAME = {env:NODE_NAME:test_domain_sc}
allowlist_externals =
    bash
commands =
    # Image is not cleaned up
    bash -c 'docker stop ${NODE_NAME} || true'
    bash -c 'docker rm ${NODE_NAME} || true'

[testenv:stack.test.notebook]
description = Stack Notebook Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
changedir = {toxinidir}/notebooks
allowlist_externals =
    bash
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    DEV_MODE = {env:DEV_MODE:True}
    TEST_NOTEBOOK_PATHS = {env:TEST_NOTEBOOK_PATHS:api/0.8}
    ENABLE_SIGNUP=True
commands =

    # Volume cleanup
    bash -c 'hagrid land all --force --prune-vol || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=com.docker.volume.anonymous") || true'
    bash -c 'docker network rm -f $(docker network ls -q --filter "label=orgs.openmined.syft") || true'

    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE DEV_MODE=$DEV_MODE TEST_NOTEBOOK_PATHS=$TEST_NOTEBOOK_PATHS; date"
    bash -c "for subfolder in $(echo ${TEST_NOTEBOOK_PATHS} | tr ',' ' ');\
    do \
        pytest -x --nbmake --nbmake-timeout=1000 "$subfolder" -p no:randomly -vvvv -k 'not 11-container-images-k8s.ipynb';\
    done"

    ; pytest -x --nbmake --nbmake-timeout=1000 api/0.8 -p no:randomly -vvvv
    ; pytest -x --nbmake --nbmake-timeout=1000 api/0.9 -p no:randomly -vvvv
    ; pytest -x --nbmake --nbmake-timeout=1000 tutorials -p no:randomly -vvvv
    ; pytest -x --nbmake --nbmake-timeout=1000 tutorials/pandas-cookbook -p no:randomly -vvvv

    bash -c 'hagrid land all --force --prune-vol'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=orgs.openmined.syft") || true'
    bash -c 'docker volume rm -f $(docker volume ls -q --filter "label=com.docker.volume.anonymous") || true'
    bash -c 'docker network rm -f $(docker network ls -q --filter "label=orgs.openmined.syft") || true'

[testenv:stack.test.vm]
description = Stack VM Tests
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:vm}
    VAGRANT_DESTROY = {env:VAGRANT_DESTROY:skip}
commands =
    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    else \
        vagrant ssh $VAGRANT_BOX -c "docker ps -aq | xargs -I {:} docker rm {:} --force"; \
        vagrant ssh $VAGRANT_BOX -c "docker volume prune --filter all=1 --force || true"; \
    fi; \
    vagrant up $VAGRANT_BOX --provision; \
    '

    pytest -x --nbmake  --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -vvvv
    ; pytest -x --nbmake  --nbmake-timeout=1000 notebooks/api/0.9 -p no:randomly -vvvv

    bash -c 'if [[ "$(uname -m)" == *"arm"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-arm64"; \
    elif [[ "$(uname -m)" == *"x86"* ]]; then \
        export VAGRANT_BOX="ubuntu-22-04-x86"; \
    else \
        echo "Unsupported architecture."; \
    fi; \
    echo $VAGRANT_BOX; \
    cd packages/grid; \
    if [[ "$VAGRANT_DESTROY" == *"true"* ]]; then \
        vagrant destroy $VAGRANT_BOX --force || true; \
    fi; \
    '

[testenv:stack.test.podman]
description = Stack podman Tests for Rhel & Centos
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
allowlist_externals =
    cd
    vagrant
    bash
changedir = {toxinidir}
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:podman}
    NODE_PORT = {env:NODE_PORT:8080}
commands =
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    bash -c "podman pod rm --force --all || true";
    bash -c "podman system prune --volumes --force || true";
    bash -c "podman volume rm $(podman volume ls -q)||true";

    # Force Removal of images
    bash -c "podman image prune --all --force || true";

    # Build Backend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-backend:$SYFT_VERSION -f packages/grid/backend/backend.dockerfile --target backend packages";

    # Build Frontend Image
    bash -c "SYFT_VERSION=$(python packages/grid/VERSION) && podman build -t docker.io/openmined/grid-frontend:$SYFT_VERSION -f packages/grid/frontend/frontend.dockerfile --target grid-ui-development packages/grid/frontend";

    bash -c 'cd packages/grid/podman/podman-kube && podman play kube podman-syft-kube.yaml --configmap=podman-syft-kube-config.yaml'
    bash -c '(podman logs -f syft-backend &) | grep -q "Application startup complete" || true'
    pytest -x --nbmake --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -vvvv

[testenv:frontend.generate.types]
description = Generate Types for Frontend
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
allowlist_externals =
    cd
    bash
    pnpm
changedir = {toxinidir}/packages/grid/frontend
passenv =
    PNPM_HOME
commands =
    bash -c ./scripts/check_pnpm.sh
    pnpm add -g json-schema-to-typescript

    ; clear the old ones
    bash -c 'rm -rf ./schema'
    bash -c 'rm -rf ./src/types/generated'

    ; generate new ones
    bash -c 'python3 -c "import syft as sy;sy.util.schema.generate_json_schemas()"'
    bash -c "json2ts -i './schema/**/*.json' -o ./src/types/generated"
    bash -c "python3 ./scripts/replace_imports.py ./src/types/generated"

[mypy]
python_version = 3.12
disable_error_code = attr-defined, valid-type, no-untyped-call, arg-type


[testenv:stack.test.integration.k8s]
description = Integration Tests for Core Stack
basepython = python3
deps =
    {[testenv:syft]deps}
    {[testenv:hagrid]deps}
    nbmake
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    devspace
    kubectl
    grep
    sleep
    bash
    kubectx
    k3d
    echo
    tox
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:9082}
    GITHUB_CI = {env:GITHUB_CI:false}
    PYTEST_MODULES = {env:PYTEST_MODULES:frontend container_workload local}
    SYFT_BASE_IMAGE_REGISTRY = {env:SYFT_BASE_IMAGE_REGISTRY:k3d-registry.localhost:5800}
    ASSOCIATION_REQUEST_AUTO_APPROVAL = {env:ASSOCIATION_REQUEST_AUTO_APPROVAL:true}
commands =
    bash -c "echo Running with GITHUB_CI=$GITHUB_CI; date"
    python -c 'import syft as sy; sy.stage_protocol_changes()'
    k3d version

    # Since cluster name cannot have underscore and environment variable cannot have hyphen
    # we are passing a grouped name for node names
    # bash -c "docker rm $(docker ps -aq) --force || true"
    # Deleting current cluster
    bash -c "k3d cluster delete testgateway1 || true"
    bash -c "k3d cluster delete testdomain1 || true"

    # Deleting registry & volumes
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker volume rm k3d-testgateway1-images --force || true"
    bash -c "docker volume rm k3d-testdomain1-images --force || true"

    # Create registry
    tox -e dev.k8s.registry

    # Creating testgateway1 cluster on port 9081
    bash -c '\
        export CLUSTER_NAME=testgateway1 CLUSTER_HTTP_PORT=9081 DEVSPACE_PROFILE=gateway && \
        tox -e dev.k8s.start && \
            tox -e dev.k8s.deploy'

    # Creating testdomain1 cluster on port 9082
    bash -c '\
        export CLUSTER_NAME=testdomain1 CLUSTER_HTTP_PORT=9082 && \
        tox -e dev.k8s.start && \
        tox -e dev.k8s.deploy'

    # free up build cache after build of images
    bash -c 'if [[ "$GITHUB_CI" != "false" ]]; then \
        docker image prune --all --force; \
        docker builder prune --all --force; \
    fi'

    sleep 30

    # wait for front end
    bash packages/grid/scripts/wait_for.sh service frontend --context k3d-testdomain1 --namespace syft
    bash -c '(kubectl logs service/frontend --context k3d-testdomain1 --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'

    # wait for test gateway 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-testgateway1 --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-testgateway1 --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-testgateway1 --namespace syft

    # wait for test domain 1
    bash packages/grid/scripts/wait_for.sh service mongo --context k3d-testdomain1 --namespace syft
    bash packages/grid/scripts/wait_for.sh service backend --context k3d-testdomain1 --namespace syft
    bash packages/grid/scripts/wait_for.sh service proxy --context k3d-testdomain1 --namespace syft
    bash packages/grid/scripts/wait_for.sh service seaweedfs --context k3d-testdomain1 --namespace syft

    # Checking logs generated & startup of test-domain 1
    bash -c '(kubectl logs service/backend --context k3d-testdomain1 --namespace syft -f &) | grep -q "Application startup complete" || true'
    # Checking logs generated & startup of testgateway1
    bash -c '(kubectl logs service/backend --context k3d-testgateway1 --namespace syft -f &) | grep -q "Application startup complete" || true'

    # frontend
    bash -c 'if [[ "$PYTEST_MODULES" == *"frontend"* ]]; then \
        echo "Starting frontend"; date; \
        pytest tests/integration -m frontend -p no:randomly -k "test_serves_domain_frontend" --co; \
        pytest tests/integration -m frontend -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no -k "test_serves_domain_frontend"; \
        return=$?; \
        echo "Finished frontend"; date; \
        exit $return; \
    fi'

    # Integration + Gateway Connection Tests
    # Gateway tests are not run in kuberetes, as currently,it does not have a way to configure
    # high/low side warning flag.
    bash -c "source ./scripts/get_k8s_secret_ci.sh; \
    pytest tests/integration/network -p no:randomly -vvvv"

    # Shutting down the gateway cluster to free up space, as the
    # below code does not require gateway cluster
    bash -c "CLUSTER_NAME=testgateway1 tox -e dev.k8s.destroy || true"
    bash -c "docker volume rm k3d-testgateway1-images --force || true"

    ; container workload
    ; bash -c 'if [[ "$PYTEST_MODULES" == *"container_workload"* ]]; then \
    ;     echo "Starting Container Workload test"; date; \
    ;     pytest tests/integration -m container_workload -p no:randomly --co; \
    ;     pytest tests/integration -m container_workload -vvvv -p no:randomly -p no:benchmark -o log_cli=True --capture=no; \
    ;     return=$?; \
    ;     echo "Finished container workload"; date; \
    ;     exit $return; \
    ; fi'

    bash -c "source ./scripts/get_k8s_secret_ci.sh; \
        pytest -x --nbmake  --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -k 'not 10-container-images.ipynb' -vvvv"

    # deleting clusters created
    bash -c "CLUSTER_NAME=testdomain1 tox -e dev.k8s.destroy || true"
    bash -c "k3d registry delete k3d-registry.localhost || true"
    bash -c "docker rm $(docker ps -aq) --force || true"
    bash -c "docker volume rm k3d-testdomain1-images --force || true"


[testenv:syft.build.helm]
description = Build Helm Chart for Kubernetes
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        python3 generate_helm_notes.py ./syft/templates'

    bash -c 'cd packages/grid/helm && \
        helm lint syft'


[testenv:syft.lint.helm]
description = Lint helm chart
changedir = {toxinidir}/packages/grid/helm
passenv=HOME, USER
allowlist_externals =
    bash
commands =
    bash -c 'kube-linter lint ./syft --config ./kubelinter-config.yaml'

[testenv:syft.package.helm]
description = Package Helm Chart for Kubernetes
deps =
changedir = {toxinidir}
passenv=HOME, USER
allowlist_externals =
    bash
    helm
commands =
    bash -c 'cd packages/grid/helm && \
        helm lint syft'

    bash -c 'cd packages/grid/helm/syft && \
        helm dependency update'

    bash -c 'cd packages/grid/helm && \
        helm package syft --destination repo'

    bash -c 'cd packages/grid/helm/repo && \
        helm repo index . --url https://openmined.github.io/PySyft/helm'

[testenv:syft.test.helm]
description = Test Helm Chart for Kubernetes
changedir = {toxinidir}/packages/grid
passenv=HOME, USER, EXTERNAL_REGISTRY_USERNAME, EXTERNAL_REGISTRY_PASSWORD
allowlist_externals =
    bash
    tox
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:8080}
    NODE_URL = {env:NODE_URL:http://localhost}
    EXCLUDE_NOTEBOOKS = {env:EXCLUDE_NOTEBOOKS:not 10-container-images.ipynb}
    SYFT_VERSION = {env:SYFT_VERSION:local}
    EXTERNAL_REGISTRY = {env:EXTERNAL_REGISTRY:k3d-registry.localhost:5800}
    ; env vars for dev.k8s.start
    CLUSTER_NAME = testdomain
    CLUSTER_HTTP_PORT = {env:NODE_PORT:8080}
commands =
    bash -c "env; date; k3d version"

    bash -c "k3d cluster delete ${CLUSTER_NAME} || true"

    tox -e dev.k8s.start

    bash -c 'if [[ $SYFT_VERSION == "local" ]]; then \
        echo "Installing local helm charts"; \
        helm install ${CLUSTER_NAME} ./helm/syft -f ./helm/values.dev.yaml --kube-context k3d-${CLUSTER_NAME} --namespace syft --create-namespace; \
    else \
        echo "Installing helm charts from repo for syft version: ${SYFT_VERSION}"; \
        helm repo add openmined https://openmined.github.io/PySyft/helm; \
        helm repo update openmined; \
        helm install ${CLUSTER_NAME} openmined/syft --version=${SYFT_VERSION} -f ./helm/values.dev.yaml --kube-context k3d-${CLUSTER_NAME} --namespace syft --create-namespace; \
    fi'

    ; wait for everything else to be loaded
    bash -c './scripts/wait_for.sh service frontend --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c '(kubectl logs service/frontend --context k3d-$CLUSTER_NAME --namespace syft -f &) | grep -q -E "Network:\s+https?://[a-zA-Z0-9.-]+:[0-9]+/" || true'
    bash -c './scripts/wait_for.sh service mongo --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c './scripts/wait_for.sh service backend --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c './scripts/wait_for.sh service proxy --context k3d-$CLUSTER_NAME --namespace syft'
    bash -c '(kubectl logs service/backend --context k3d-$CLUSTER_NAME --namespace syft -f &) | grep -q "Application startup complete" || true'

    # Run Notebook tests
    tox -e e2e.test.notebook

    bash -c "k3d cluster delete ${CLUSTER_NAME} || true"

[testenv:syft.test.helm.upgrade]
description = Test helm upgrade
changedir = {toxinidir}/packages/grid/
passenv=HOME,USER,KUBE_CONTEXT
setenv =
    UPGRADE_TYPE = {env:UPGRADE_TYPE:ProdToBeta}
allowlist_externals =
    bash
commands =
    bash ./scripts/helm_upgrade.sh {env:UPGRADE_TYPE}

[testenv:syftcli.test.unit]
description = Syft CLI Unit Tests
deps =
    {[testenv:syftcli]deps}
changedir = {toxinidir}/packages/syftcli
allowlist_externals =
    uv
    pytest
commands =
    pytest

[testenv:dev.k8s.registry]
description = Start local Kubernetes registry with k3d
changedir = {toxinidir}
passenv=HOME,USER
allowlist_externals =
    bash
    sudo
commands =
    ; check k3d version
    bash -c 'k3d --version'

    ; create registry
    bash -c 'k3d registry create registry.localhost --port 5800 -v $HOME/.k3d-registry:/var/lib/registry || true'

    ; add patches to host
    bash -c 'if ! grep -q k3d-registry.localhost /etc/hosts; then sudo {envpython} scripts/patch_hosts.py --add-k3d-registry --fix-docker-hosts; fi'

    ; Fail this command if registry is not working
    bash -c 'curl --retry 5 --retry-all-errors http://k3d-registry.localhost:5800/v2/_catalog'

[testenv:dev.k8s.patch.coredns]
description = Patch CoreDNS to resolve k3d-registry.localhost
changedir = {toxinidir}
passenv=HOME,USER,CLUSTER_NAME
setenv =
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    ; patch coredns so k3d-registry.localhost works in k3d
    bash -c 'kubectl apply -f ./scripts/k8s-coredns-custom.yml --context k3d-${CLUSTER_NAME}'

    ; restarts coredns
    bash -c 'kubectl delete pod -n kube-system -l k8s-app=kube-dns --context k3d-${CLUSTER_NAME}'

[testenv:dev.k8s.start]
description = Start local Kubernetes registry & cluster with k3d
changedir = {toxinidir}
passenv = HOME, USER
setenv =
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
    CLUSTER_HTTP_PORT = {env:CLUSTER_HTTP_PORT:8080}
allowlist_externals =
    bash
    sleep
    tox
commands =
    ; start registry
    tox -e dev.k8s.registry

    ; for NodePort to work add the following --> -p "NodePort:NodePort@loadbalancer"
    bash -c 'k3d cluster create ${CLUSTER_NAME} -p "${CLUSTER_HTTP_PORT}:80@loadbalancer" --registry-use k3d-registry.localhost:5800 {posargs} && \
        kubectl --context k3d-${CLUSTER_NAME} create namespace syft || true'

    ; patch coredns
    tox -e dev.k8s.patch.coredns

    ; dump cluster info
    tox -e dev.k8s.info

[testenv:dev.k8s.deploy]
description = Deploy Syft to a local Kubernetes cluster with Devspace
changedir = {toxinidir}/packages/grid
passenv = HOME, USER, DEVSPACE_PROFILE
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    ; deploy syft helm charts
    bash -c '\
        if [[ -n "${DEVSPACE_PROFILE}" ]]; then export DEVSPACE_PROFILE="-p ${DEVSPACE_PROFILE}"; fi && \
        devspace deploy -b --kube-context k3d-${CLUSTER_NAME} --no-warn ${DEVSPACE_PROFILE} --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5800'

[testenv:dev.k8s.hotreload]
description = Start development with hot-reload in Kubernetes
changedir = {toxinidir}/packages/grid
passenv = HOME, USER, DEVSPACE_PROFILE
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    ; deploy syft helm charts with hot-reload
    bash -c '\
        if [[ -n "${DEVSPACE_PROFILE}" ]]; then export DEVSPACE_PROFILE="-p ${DEVSPACE_PROFILE}"; fi && \
        devspace dev --kube-context k3d-${CLUSTER_NAME} --no-warn ${DEVSPACE_PROFILE} --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5800'

[testenv:dev.k8s.info]
description = Gather info about the localKubernetes cluster
passenv = HOME, USER
ignore_errors = True
allowlist_externals =
    k3d
    kubectl
commands =
    k3d cluster list
    kubectl cluster-info
    kubectl config current-context
    kubectl get namespaces

[testenv:dev.k8s.cleanup]
description = Cleanup Syft deployment and associated resources, but keep the cluster running
changedir = {toxinidir}/packages/grid
passenv=HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    bash
commands =
    bash -c 'devspace purge --force-purge --kube-context k3d-${CLUSTER_NAME} --no-warn --namespace syft; sleep 3'
    bash -c 'devspace cleanup images --kube-context k3d-${CLUSTER_NAME} --no-warn --namespace syft --var CONTAINER_REGISTRY=k3d-registry.localhost:5800 || true'
    bash -c 'kubectl --context k3d-${CLUSTER_NAME} delete namespace syft --now=true || true'

[testenv:dev.k8s.launch.gateway]
description = Launch a single gateway on K8s
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:test-gateway-1}
    CLUSTER_HTTP_PORT={env:CLUSTER_HTTP_PORT:9081}
    DEVSPACE_PROFILE=gateway
allowlist_externals =
    tox
commands =
    tox -e dev.k8s.start
    tox -e dev.k8s.{posargs:deploy}

[testenv:dev.k8s.launch.domain]
description = Launch a single domain  on K8s
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:test-domain-1}
    CLUSTER_HTTP_PORT={env:CLUSTER_HTTP_PORT:9082}
allowlist_externals =
    tox
commands =
    tox -e dev.k8s.start
    tox -e dev.k8s.{posargs:deploy}

[testenv:dev.k8s.launch.enclave]
description = Launch a single Enclave  on K8s
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:test-enclave-1}
    CLUSTER_HTTP_PORT={env:CLUSTER_HTTP_PORT:9083}
    DEVSPACE_PROFILE=enclave
allowlist_externals =
    tox
commands =
    tox -e dev.k8s.start -- --volume /sys/kernel/security:/sys/kernel/security --volume /dev/tmprm0:/dev/tmprm0
    tox -e dev.k8s.{posargs:deploy}

[testenv:dev.k8s.destroy]
description = Destroy local Kubernetes cluster
changedir = {toxinidir}/packages/grid
passenv = HOME, USER
setenv=
    CLUSTER_NAME = {env:CLUSTER_NAME:syft-dev}
allowlist_externals =
    tox
    bash
commands =
    ; purge deployment and dangling resources
    tox -e dev.k8s.cleanup

    ; destroy cluster
    bash -c '\
        rm -rf .devspace; echo ""; \
        k3d cluster delete ${CLUSTER_NAME};'

[testenv:dev.k8s.destroyall]
description = Destroy both local Kubernetes cluster and registry
changedir = {toxinidir}
passenv = HOME, USER, CLUSTER_NAME
ignore_errors=True
allowlist_externals =
    bash
    tox
commands =
    ; destroy cluster
    tox -e dev.k8s.destroy

    ; destroy registry
    bash -c 'k3d registry delete registry.localhost || true'
    bash -c 'sudo rm -rf ~/.k3d-registry'

[testenv:backend.test.basecpu]
description = Base CPU Docker Image Test
changedir = {toxinidir}/packages
allowlist_externals =
    docker
    bash
    env
setenv =
    PIP_PACKAGES = {env:PIP_PACKAGES:llama-index opendp}
    SYSTEM_PACKAGES = {env:SYSTEM_PACKAGES:curl wget}
    BUILD_PLATFORM = {env:BUILD_PLATFORM:linux/amd64}
commands =
    env

    ; Build the base image
    bash -c 'docker buildx build \
        --platform $BUILD_PLATFORM \
        -f ./grid/backend/grid/images/worker_cpu.dockerfile . \
        -t cpu-worker:latest'
    bash -c 'docker rmi cpu-worker:latest'

    bash -c '\
        docker buildx build \
            --platform $BUILD_PLATFORM \
            -f grid/backend/grid/images/worker_cpu.dockerfile . \
            -t cpu-worker:opendp \
            --build-arg PIP_PACKAGES="$PIP_PACKAGES" \
            --build-arg SYSTEM_PACKAGES="$SYSTEM_PACKAGES"'
    bash -c 'for pkg in $PIP_PACKAGES; do docker run --rm cpu-worker:opendp pip list | grep "$pkg"; done'
    bash -c 'for pkg in $SYSTEM_PACKAGES; do docker run --rm cpu-worker:opendp apk -e info "$pkg"; done'
    bash -c 'docker rmi cpu-worker:opendp'

    bash -c '\
        docker buildx build \
            --platform $BUILD_PLATFORM \
            -f grid/backend/grid/images/worker_cpu.dockerfile . \
            -t cpu-worker:custom-cmd  \
            --build-arg SYSTEM_PACKAGES="perl wget curl make " \
            --build-arg CUSTOM_CMD="""wget -O - "https://github.com/cowsay-org/cowsay/archive/refs/tags/v3.7.0.tar.gz" | tar xvzf - && cd cowsay-3.7.0 && make"""'
    bash -c 'for pkg in perl make curl wget; do docker run --rm cpu-worker:custom-cmd apk -e info "$pkg"; done'
    bash -c 'docker run --rm cpu-worker:custom-cmd bash -c "cd cowsay-3.7.0 && curl https://api.github.com/zen -s | ./cowsay"'
    bash -c 'docker rmi cpu-worker:custom-cmd'


# There are other adjacent notebook tests like
# stack.test.notebook, syft.test.notebook, etc.
# They could be modularized and reused.
# The below is the notebook test suite for point at external servers
[testenv:e2e.test.notebook]
description = E2E Notebook tests
changedir = {toxinidir}
deps =
    {[testenv:syft]deps}
    nbmake
allowlist_externals =
    bash
    pytest
passenv = EXTERNAL_REGISTRY,EXTERNAL_REGISTRY_USERNAME,EXTERNAL_REGISTRY_PASSWORD
setenv =
    ORCHESTRA_DEPLOYMENT_TYPE = {env:ORCHESTRA_DEPLOYMENT_TYPE:k8s}
    NODE_PORT = {env:NODE_PORT:8080}
    NODE_URL = {env:NODE_URL:http://localhost}
    EXCLUDE_NOTEBOOKS = {env:EXCLUDE_NOTEBOOKS:}
    SYFT_VERSION = {env:SYFT_VERSION:local}
commands =
    bash -c "echo Running with ORCHESTRA_DEPLOYMENT_TYPE=$ORCHESTRA_DEPLOYMENT_TYPE NODE_PORT=$NODE_PORT NODE_URL=$NODE_URL \
    Excluding notebooks: $EXCLUDE_NOTEBOOKS SYFT_VERSION=$SYFT_VERSION \
    EXTERNAL_REGISTRY=$EXTERNAL_REGISTRY; date"

    # Schema for EXLUDE_NOTEBOOKS is
    # for excluding
    # notebook1.ipynb, notebook2.ipynb
    # EXCLUDE_NOTEBOOKS=not notebook1.ipynb and not notebook2.ipynb

    # If the syft version is local install the local version
    # else install the version of syft specified
    bash -c "if [[ $SYFT_VERSION == 'local' ]]; then \
        echo 'Using local syft'; \
    else \
        echo 'Installing syft version: ${SYFT_VERSION}'; \
        uv pip install syft[data_science]==${SYFT_VERSION}; \
    fi"

    pytest -x --nbmake --nbmake-timeout=1000 notebooks/api/0.8 -p no:randomly -vvvv -k '{env:EXCLUDE_NOTEBOOKS:}'

[testenv:seaweedfs.test.unit]
description = Seaweedfs Unit Tests
deps =
    -r{toxinidir}/packages/grid/seaweedfs/requirements.txt
    -r{toxinidir}/packages/grid/seaweedfs/requirements.dev.txt
changedir = {toxinidir}/packages/grid/seaweedfs
allowlist_externals =
    bash
    pytest
commands =
    bash -c 'ulimit -n 4096 || true'
    pytest --disable-warnings
